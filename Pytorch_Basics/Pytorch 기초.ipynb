{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d6e61a",
   "metadata": {},
   "source": [
    "# 코드 실습에 앞서 머신러닝, 딥러닝에 대해 학습\n",
    "\n",
    "## 예: 지도학습, 비지도학습, 군집화, 신경망 개념, 손실 함수, 최적화(경사하강법, 역전파, 학습률), 최적화 알고리즘(SGD, Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4313b487",
   "metadata": {},
   "source": [
    "## 텐서란?\n",
    "### 텐서는 numpy에 존재하는데 배열, 행렬과 유사한 자료 구조 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7bf2986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.tensor([1, 2, 3])) # 입력 데이터 형식을 참조해 해당 자료형 텐서를생성, 입력 데이터 복사해서 생성\n",
    "print(torch.Tensor([[1, 2, 3],[4, 5, 6]])) # 자동으로 float 형식의 텐서 생성, # 텐서 인스턴스 생성\n",
    "print(torch.LongTensor([1, 2, 3])) # Long 자료형 텐서\n",
    "print(torch.FloatTensor([1, 2, 3])) # float형 자료형 텐서 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e8aa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9081, 0.7480]])\n",
      "torch.Size([1, 2])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "tensor = torch.rand(1, 2)\n",
    "print(tensor) \n",
    "print(tensor.shape) # 텐서 차원 출력\n",
    "print(tensor.dtype) # 텐서 타입 출력\n",
    "print(tensor.device) # 텐서의 저장 위치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56040567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0529, 0.3562]])\n",
      "torch.Size([1, 2])\n",
      "tensor([[0.0529],\n",
      "        [0.3562]])\n",
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.rand(1, 2)\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "tensor = tensor.reshape(2, 1) #차원 변환 # view()도 존재한다.\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f9864a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3186, 0.6584, 0.0475],\n",
      "        [0.2441, 0.4476, 0.7344],\n",
      "        [0.1849, 0.3153, 0.3337]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "tensor = torch.rand((3, 3), dtype=torch.float) # 자료형 설정 방법\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c50ff10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], device='cuda:0')\n",
      "tensor([[0.0758]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_40620\\721341711.py:6: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ..\\torch\\csrc\\tensor\\python_tensor.cpp:85.)\n",
      "  gpu = torch.cuda.FloatTensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "cpu = torch.FloatTensor([1, 2, 3])\n",
    "gpu = torch.cuda.FloatTensor([1, 2, 3])\n",
    "tensor = torch.rand((1, 1), device=device) # 텐서의 저장 위치 설정\n",
    "print(device)\n",
    "print(cpu)\n",
    "print(gpu)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4e87711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "tensor([[0.5972]])\n"
     ]
    }
   ],
   "source": [
    "# 애플 실리콘이 탑재된 맥 사용자의 경우\n",
    "import torch\n",
    "\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() and torch.backends.mps.is_built() else \"cpu\"\n",
    "cpu = torch.FloatTensor([1, 2, 3])\n",
    "mps = torch.rand((1, 1), device=device)\n",
    "print(device)\n",
    "print(mps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a5f362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], device='cuda:0')\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "cpu = torch.FloatTensor([1, 2, 3])\n",
    "gpu = cpu.cuda() # gpu()로 변경\n",
    "gpu2cpu = gpu.cpu() # Cpu()로 변경\n",
    "cpu2gpu = cpu.to(\"cuda\") # to('장치')로도 가능\n",
    "print(cpu)\n",
    "print(gpu)\n",
    "print(gpu2cpu)\n",
    "print(cpu2gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61cff613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.uint8)\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "numpy 배열을 파이토치 텐서로\n",
    "\"\"\"\n",
    "ndarray = np.array([1, 2, 3], dtype=np.uint8) \n",
    "print(torch.tensor(ndarray)) \n",
    "print(torch.Tensor(ndarray))\n",
    "print(torch.from_numpy(ndarray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ef0cffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 2. 3.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\"\"\"\n",
    "detach()는 파이토치 텐서의 경우 모든 연산을 추적하여 역전파 연산등에 사용됨으로 \n",
    "연산 그래프에서 제거하기 위해 사용해야함\n",
    "\"\"\"\n",
    "tensor = torch.cuda.FloatTensor([1, 2, 3])\n",
    "ndarray = tensor.detach().cpu().numpy() #파이토치 텐서 자료형을 numpy 배열로\n",
    "print(ndarray)\n",
    "print(type(ndarray))\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "#tensor = torch.FloatTensor([1, 2, 3]).to(\"mps\") #mac 에서는 주석 해제 해서 실행\n",
    "ndarray = tensor.detach().cpu().numpy() \n",
    "print(ndarray)\n",
    "print(type(ndarray))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d8e50b",
   "metadata": {},
   "source": [
    "## 단순 선형 회귀 구현\n",
    "### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbae0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 입력\n",
    "x = np.array(\n",
    "    [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
    "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
    "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]]\n",
    ") \n",
    "# 정답\n",
    "y = np.array(\n",
    "    [[0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
    "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
    "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b60009f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.0 # 초기 가중치 \n",
    "bias = 0.0 # 초기 bias\n",
    "learning_rate = 0.005 # 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88b48e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Weight : 0.872, Bias : -0.290, Cost : 1.377\n",
      "Epoch : 2000, Weight : 0.877, Bias : -0.391, Cost : 1.373\n",
      "Epoch : 3000, Weight : 0.878, Bias : -0.422, Cost : 1.372\n",
      "Epoch : 4000, Weight : 0.879, Bias : -0.432, Cost : 1.372\n",
      "Epoch : 5000, Weight : 0.879, Bias : -0.435, Cost : 1.372\n",
      "Epoch : 6000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
      "Epoch : 7000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
      "Epoch : 8000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
      "Epoch : 9000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
      "Epoch : 10000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10000): #epoch 학습 횟수\n",
    "    y_hat = weight * x + bias # 정답 예측 선형 회귀 이므로 y=wx+b\n",
    "\n",
    "    cost = ((y - y_hat) ** 2).mean() # 오차 측정 mse \n",
    "\n",
    "    weight = weight - learning_rate * ((y_hat - y) * x).mean() # 가중치 조절\n",
    "    bias = bias - learning_rate * (y_hat - y).mean() # bias 조절\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Weight : {weight:.3f}, Bias : {bias:.3f}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35cdd7e",
   "metadata": {},
   "source": [
    "### Pytorch 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daf06ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "262607de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([\n",
    "    [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
    "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
    "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]\n",
    "])\n",
    "y = torch.FloatTensor([\n",
    "    [0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
    "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
    "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22e3a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.zeros(1, requires_grad=True)\n",
    "bias = torch.zeros(1, requires_grad=True)\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ad955fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([weight, bias], lr=learning_rate) # SGD 옵티마이저 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a03708e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Weight : 0.864, Bias : -0.138, Cost : 1.393\n",
      "Epoch : 2000, Weight : 0.870, Bias : -0.251, Cost : 1.380\n",
      "Epoch : 3000, Weight : 0.873, Bias : -0.321, Cost : 1.375\n",
      "Epoch : 4000, Weight : 0.875, Bias : -0.364, Cost : 1.373\n",
      "Epoch : 5000, Weight : 0.877, Bias : -0.391, Cost : 1.373\n",
      "Epoch : 6000, Weight : 0.878, Bias : -0.408, Cost : 1.372\n",
      "Epoch : 7000, Weight : 0.878, Bias : -0.419, Cost : 1.372\n",
      "Epoch : 8000, Weight : 0.878, Bias : -0.425, Cost : 1.372\n",
      "Epoch : 9000, Weight : 0.879, Bias : -0.429, Cost : 1.372\n",
      "Epoch : 10000, Weight : 0.879, Bias : -0.432, Cost : 1.372\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    hypothesis = weight * x + bias\n",
    "    cost = torch.mean((hypothesis - y) ** 2)\n",
    "\n",
    "    optimizer.zero_grad() # 이전 gradients 값을 0으로 설정, 텐서의 기울기는 grad 속성에 누적되어 더해지기 때문에, \n",
    "    cost.backward() # loss 역전파\n",
    "    optimizer.step() # #최적화 함수에 계산된 가중치와 편향들을 반영\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Weight : {weight.item():.3f}, Bias : {bias.item():.3f}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd87b4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :    1\n",
      "Step [1] : Gradient : None, Weight : 0.00000\n",
      "Step [2] : Gradient : None, Weight : 0.00000\n",
      "Step [3] : Gradient : tensor([-540.4854]), Weight : 0.00000\n",
      "Step [4] : Gradient : tensor([-540.4854]), Weight : 0.54049\n",
      "Epoch :    2\n",
      "Step [1] : Gradient : tensor([-540.4854]), Weight : 0.54049\n",
      "Step [2] : Gradient : None, Weight : 0.54049\n",
      "Step [3] : Gradient : tensor([-198.9818]), Weight : 0.54049\n",
      "Step [4] : Gradient : tensor([-198.9818]), Weight : 0.73947\n",
      "Epoch :    3\n",
      "Step [1] : Gradient : tensor([-198.9818]), Weight : 0.73947\n",
      "Step [2] : Gradient : None, Weight : 0.73947\n",
      "Step [3] : Gradient : tensor([-73.2604]), Weight : 0.73947\n",
      "Step [4] : Gradient : tensor([-73.2604]), Weight : 0.81273\n",
      "Epoch :    4\n",
      "Step [1] : Gradient : tensor([-73.2604]), Weight : 0.81273\n",
      "Step [2] : Gradient : None, Weight : 0.81273\n",
      "Step [3] : Gradient : tensor([-26.9772]), Weight : 0.81273\n",
      "Step [4] : Gradient : tensor([-26.9772]), Weight : 0.83970\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "x = torch.FloatTensor([\n",
    "    [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
    "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
    "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]\n",
    "])\n",
    "y = torch.FloatTensor([\n",
    "    [0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
    "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
    "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]\n",
    "])\n",
    "\n",
    "weight = torch.zeros(1, requires_grad=True)\n",
    "bias = torch.zeros(1, requires_grad=True)\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = optim.SGD([weight, bias], lr=learning_rate)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    hypothesis = weight * x + bias\n",
    "    cost = torch.mean((hypothesis - y) ** 2)\n",
    "    \n",
    "    print(f\"Epoch : {epoch+1:4d}\")\n",
    "    print(f\"Step [1] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    print(f\"Step [2] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
    "\n",
    "    cost.backward()\n",
    "    print(f\"Step [3] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
    "\n",
    "    optimizer.step()\n",
    "    print(f\"Step [4] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
    "    \n",
    "    if epoch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a1b860",
   "metadata": {},
   "source": [
    "### torch.nn 신경망 패키지 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a27d3c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41f47488",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([\n",
    "    [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
    "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
    "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]\n",
    "])\n",
    "y = torch.FloatTensor([\n",
    "    [0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
    "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
    "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9361143a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
    "\"\"\"\n",
    "in_features: 신경망의 입력 뉴런 수\n",
    "out_features: 신경망의 출력 뉴런수\n",
    "\"\"\"\n",
    "layer=nn.Linear(1, 1, bias=True, device=None, dtype=None)\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa4dbd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1, 1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed0641fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Model : [Parameter containing:\n",
      "tensor([[0.8702]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2588], requires_grad=True)], Cost : 1.380\n",
      "Epoch : 2000, Model : [Parameter containing:\n",
      "tensor([[0.8735]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3257], requires_grad=True)], Cost : 1.375\n",
      "Epoch : 3000, Model : [Parameter containing:\n",
      "tensor([[0.8755]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3673], requires_grad=True)], Cost : 1.373\n",
      "Epoch : 4000, Model : [Parameter containing:\n",
      "tensor([[0.8768]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3933], requires_grad=True)], Cost : 1.373\n",
      "Epoch : 5000, Model : [Parameter containing:\n",
      "tensor([[0.8776]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4094], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 6000, Model : [Parameter containing:\n",
      "tensor([[0.8781]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4194], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 7000, Model : [Parameter containing:\n",
      "tensor([[0.8784]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4256], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 8000, Model : [Parameter containing:\n",
      "tensor([[0.8786]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4295], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 9000, Model : [Parameter containing:\n",
      "tensor([[0.8787]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4319], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 10000, Model : [Parameter containing:\n",
      "tensor([[0.8788]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4335], requires_grad=True)], Cost : 1.372\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    output = model(x)\n",
    "    cost = criterion(output, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db361b",
   "metadata": {},
   "source": [
    "## 데이터세트, 데이터 로더\n",
    "\n",
    "### 데이터셋은 특정 입력데이터와 정답지를 제공해주기 위해 제공하는 클래스\n",
    "### 데이터로더는 데이터세트에 저장된 데이터를 어떠한 방식으로 불러와 활용하지는 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "49254f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3a1ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        \"\"\"\n",
    "            입력 데이터의 전처리 과정 수행 메소드\n",
    "            학습에 필요한 데이터 형태로 변형하는 과정\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        \n",
    "       \n",
    "        self.X = self.data.iloc[:, 1:-1].values  \n",
    "        self.y = self.data.iloc[:, -1].values  \n",
    "\n",
    "        self.label_map = {label: idx for idx, label in enumerate(sorted(set(self.y)))}\n",
    "        self.y = [self.label_map[label] for label in self.y]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "            데이터 전체 개수 반환\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "            학습이 진행 될 때, 하나의 데이터 샘플을 반환하는 메소드\n",
    "        \"\"\"\n",
    "        x = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b97e7391",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset('Iris.csv')\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0, drop_last=False) \n",
    "# drop_last: 배치 단위로 데이터를 가져오는 경우 배치보다 작은 경우 존재한다. 이 때, True면 배치 크기보다 작으면 가져오지 않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca27073d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.1000, 3.5000, 1.4000, 0.2000]), tensor(0))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a11b43a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[7.3000, 2.9000, 6.3000, 1.8000],\n",
       "         [7.9000, 3.8000, 6.4000, 2.0000],\n",
       "         [4.8000, 3.4000, 1.9000, 0.2000],\n",
       "         [6.8000, 2.8000, 4.8000, 1.4000]]),\n",
       " tensor([2, 2, 0, 1])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "68c3e183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size : 105\n",
      "Validation Data Size : 22\n",
      "Testing Data Size : 23\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.7)\n",
    "validation_size = int(dataset_size * 0.15)\n",
    "test_size = dataset_size - train_size - validation_size\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size]) # 데이터셋 분리\n",
    "print(f\"Training Data Size : {len(train_dataset)}\")\n",
    "print(f\"Validation Data Size : {len(validation_dataset)}\")\n",
    "print(f\"Testing Data Size : {len(test_dataset)}\")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bee678",
   "metadata": {},
   "source": [
    "## 모델 구현\n",
    "### nn.Module 상속 받아 서브클래스로 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "53f917f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fe074494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "            모델 레이어 선언\n",
    "        \"\"\"\n",
    "        self.layer1 = nn.Linear(4, 4)\n",
    "        self.layer2 = nn.Linear(4, 3)\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            순전파 과정 작성\n",
    "        \"\"\"\n",
    "        out = F.relu(self.layer1(x))\n",
    "        out = F.relu(self.layer2(out))\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "21e7cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomModel().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bf3466",
   "metadata": {},
   "source": [
    "## iris dataset train and model save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a18473",
   "metadata": {},
   "source": [
    "### 모델 저장 방법은 torch.save(model, path), 불러오는 방법 torch.load(path, map_location) map_location: 모델 장치 설정 \n",
    "\n",
    "### 중요한점은 model 인스턴스를 저장 할 때, 모델 전체를 저장 할 수 도 있고, 모델 상태만 저장 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c3eb746e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, train_loss: 1.0970689058303833, val_loss: 1.1208529949188233\n",
      "1, train_loss: 1.0964369361217206, val_loss: 1.144818162918091\n",
      "2, train_loss: 1.0926966735949883, val_loss: 1.0866971015930176\n",
      "3, train_loss: 1.0899724524754744, val_loss: 1.126435399055481\n",
      "4, train_loss: 1.0946032519523914, val_loss: 1.1120399236679077\n",
      "5, train_loss: 1.0940483625118549, val_loss: 1.095466959476471\n",
      "6, train_loss: 1.0906881873424237, val_loss: 1.1235671520233155\n",
      "7, train_loss: 1.088030111331206, val_loss: 1.1226458311080934\n",
      "8, train_loss: 1.086980938911438, val_loss: 1.1076229810714722\n",
      "9, train_loss: 1.0924096015783458, val_loss: 1.12067391872406\n",
      "10, train_loss: 1.0868570827520811, val_loss: 1.0908809542655944\n",
      "11, train_loss: 1.0867642783201659, val_loss: 1.0914372205734253\n",
      "12, train_loss: 1.0863305101027856, val_loss: 1.1200945854187012\n",
      "13, train_loss: 1.0909379835312183, val_loss: 1.1174624919891358\n",
      "14, train_loss: 1.0854188272586236, val_loss: 1.0883784532546996\n",
      "15, train_loss: 1.0846409522570097, val_loss: 1.1157182931900025\n",
      "16, train_loss: 1.0850688241995299, val_loss: 1.1002862691879272\n",
      "17, train_loss: 1.0844054428430705, val_loss: 1.0884680509567262\n",
      "18, train_loss: 1.084044486284256, val_loss: 1.0997819185256958\n",
      "19, train_loss: 1.0841267567414503, val_loss: 1.100394034385681\n",
      "20, train_loss: 1.0839499097604017, val_loss: 1.09878568649292\n",
      "21, train_loss: 1.0836387460048382, val_loss: 1.0864249348640442\n",
      "22, train_loss: 1.0881145229706397, val_loss: 1.1127968430519104\n",
      "23, train_loss: 1.087839206823936, val_loss: 1.0989474296569823\n",
      "24, train_loss: 1.0850474880291865, val_loss: 1.1088536500930786\n",
      "25, train_loss: 1.0850953115866735, val_loss: 1.0860198974609374\n",
      "26, train_loss: 1.0821745166411767, val_loss: 1.0854089975357055\n",
      "27, train_loss: 1.0868015128832598, val_loss: 1.0680415511131287\n",
      "28, train_loss: 1.0818563585097973, val_loss: 1.1065839052200317\n",
      "29, train_loss: 1.0813548725384932, val_loss: 1.0810429096221923\n",
      "30, train_loss: 1.0812988808521857, val_loss: 1.1052107572555543\n",
      "31, train_loss: 1.0811656621786265, val_loss: 1.0654680013656617\n",
      "32, train_loss: 1.0807092877534719, val_loss: 1.0796364784240722\n",
      "33, train_loss: 1.0853616686967702, val_loss: 1.103219985961914\n",
      "34, train_loss: 1.0852857690591078, val_loss: 1.0886877059936524\n",
      "35, train_loss: 1.085006560270603, val_loss: 1.0786982655525208\n",
      "36, train_loss: 1.08271628847489, val_loss: 1.1014050722122193\n",
      "37, train_loss: 1.0798828716461475, val_loss: 1.0901208639144897\n",
      "38, train_loss: 1.0845216833628142, val_loss: 1.0996816396713256\n",
      "39, train_loss: 1.0798084002274733, val_loss: 1.076136863231659\n",
      "40, train_loss: 1.0841401265217707, val_loss: 1.0982608318328857\n",
      "41, train_loss: 1.0840219557285309, val_loss: 1.083953285217285\n",
      "42, train_loss: 1.0820347506266375, val_loss: 1.1078414797782898\n",
      "43, train_loss: 1.0790142898376172, val_loss: 1.0890468597412108\n",
      "44, train_loss: 1.0835062150771801, val_loss: 1.0571438312530517\n",
      "45, train_loss: 1.0832761709506695, val_loss: 1.1056495428085327\n",
      "46, train_loss: 1.0830908257227678, val_loss: 1.084612214565277\n",
      "47, train_loss: 1.0829790372114916, val_loss: 1.094547438621521\n",
      "48, train_loss: 1.0810573559540968, val_loss: 1.0690077304840089\n",
      "49, train_loss: 1.0826624012910402, val_loss: 1.0935899257659911\n",
      "50, train_loss: 1.0811284069831555, val_loss: 1.080430817604065\n",
      "51, train_loss: 1.0777422373111432, val_loss: 1.0933810234069825\n",
      "52, train_loss: 1.082184142791308, val_loss: 1.0937296867370605\n",
      "53, train_loss: 1.0800022528721736, val_loss: 1.082117986679077\n",
      "54, train_loss: 1.0804414680370917, val_loss: 1.0819490432739258\n",
      "55, train_loss: 1.081731874209184, val_loss: 1.081001877784729\n",
      "56, train_loss: 1.0799822761462285, val_loss: 1.0820654273033141\n",
      "57, train_loss: 1.0772591554201567, val_loss: 1.0752784967422486\n",
      "58, train_loss: 1.081435134777656, val_loss: 1.0809664726257324\n",
      "59, train_loss: 1.0812550737307622, val_loss: 1.0807990789413453\n",
      "60, train_loss: 1.0796657594350667, val_loss: 1.0882877588272095\n",
      "61, train_loss: 1.0769012364057393, val_loss: 1.0653847694396972\n",
      "62, train_loss: 1.076558775626696, val_loss: 1.049691343307495\n",
      "63, train_loss: 1.0808135637870202, val_loss: 1.0719987392425536\n",
      "64, train_loss: 1.0763039543078496, val_loss: 1.0716258525848388\n",
      "65, train_loss: 1.076131066450706, val_loss: 1.0639424324035645\n",
      "66, train_loss: 1.0804263743070455, val_loss: 1.0633866786956787\n",
      "67, train_loss: 1.0803557588503911, val_loss: 1.0645574450492858\n",
      "68, train_loss: 1.0759090001766498, val_loss: 1.0845678329467774\n",
      "69, train_loss: 1.0800945231547723, val_loss: 1.0773702383041381\n",
      "70, train_loss: 1.0790837384187257, val_loss: 1.0783946633338928\n",
      "71, train_loss: 1.075474807849297, val_loss: 1.0634577989578247\n",
      "72, train_loss: 1.075436186331969, val_loss: 1.0458027243614196\n",
      "73, train_loss: 1.0786893161443563, val_loss: 1.0755149602890015\n",
      "74, train_loss: 1.0754180069153125, val_loss: 1.061565089225769\n",
      "75, train_loss: 1.0750046945535219, val_loss: 1.0454275488853455\n",
      "76, train_loss: 1.0753076878877788, val_loss: 1.0673137307167053\n",
      "77, train_loss: 1.0753579414807832, val_loss: 1.0882484078407288\n",
      "78, train_loss: 1.0784088579507976, val_loss: 1.080987024307251\n",
      "79, train_loss: 1.0781145027050605, val_loss: 1.0750621557235718\n",
      "80, train_loss: 1.0783207714557648, val_loss: 1.065213131904602\n",
      "81, train_loss: 1.0782920122146606, val_loss: 1.0642010688781738\n",
      "82, train_loss: 1.0789539424272685, val_loss: 1.0572107553482055\n",
      "83, train_loss: 1.077991517690512, val_loss: 1.085672640800476\n",
      "84, train_loss: 1.0744729615174806, val_loss: 1.0784796237945558\n",
      "85, train_loss: 1.0779199875318086, val_loss: 1.0793532013893128\n",
      "86, train_loss: 1.0778762377225435, val_loss: 1.0626829385757446\n",
      "87, train_loss: 1.0743135374325972, val_loss: 1.0779746055603028\n",
      "88, train_loss: 1.0784747554705694, val_loss: 1.0776525855064392\n",
      "89, train_loss: 1.0741750322855437, val_loss: 1.0550501108169557\n",
      "90, train_loss: 1.078325968522292, val_loss: 1.0772549629211425\n",
      "91, train_loss: 1.078241657752257, val_loss: 1.0390708923339844\n",
      "92, train_loss: 1.0776718098383684, val_loss: 1.0750396490097045\n",
      "93, train_loss: 1.0780608355998993, val_loss: 1.075990581512451\n",
      "94, train_loss: 1.0779862358019903, val_loss: 1.060530924797058\n",
      "95, train_loss: 1.0779215624699225, val_loss: 1.0781323432922363\n",
      "96, train_loss: 1.0737095383497386, val_loss: 1.0602853775024415\n",
      "97, train_loss: 1.0737156592882597, val_loss: 1.058436918258667\n",
      "98, train_loss: 1.076373013166281, val_loss: 1.075692391395569\n",
      "99, train_loss: 1.073652643423814, val_loss: 1.075043785572052\n",
      "100, train_loss: 1.0771049627890954, val_loss: 1.0369300603866578\n",
      "101, train_loss: 1.0774891789142902, val_loss: 1.0695133090019227\n",
      "102, train_loss: 1.0735341127102191, val_loss: 1.0742099165916443\n",
      "103, train_loss: 1.0733689597019782, val_loss: 1.0563869953155518\n",
      "104, train_loss: 1.0769502910283895, val_loss: 1.0735947132110595\n",
      "105, train_loss: 1.077188423046699, val_loss: 1.0771225452423097\n",
      "106, train_loss: 1.0764680298475118, val_loss: 1.052737033367157\n",
      "107, train_loss: 1.0763379977299616, val_loss: 1.0550710201263427\n",
      "108, train_loss: 1.0769653136913593, val_loss: 1.0666644811630248\n",
      "109, train_loss: 1.0729098503406231, val_loss: 1.0539949774742126\n",
      "110, train_loss: 1.0762408467439504, val_loss: 1.0710483074188233\n",
      "111, train_loss: 1.0767474862245412, val_loss: 1.0705523371696473\n",
      "112, train_loss: 1.0759485043012178, val_loss: 1.0509456872940064\n",
      "113, train_loss: 1.0759995121222277, val_loss: 1.0507667064666748\n",
      "114, train_loss: 1.0757734775543213, val_loss: 1.0662644147872924\n",
      "115, train_loss: 1.0725613763699164, val_loss: 1.0713898897171021\n",
      "116, train_loss: 1.0760836073985467, val_loss: 1.0484321355819701\n",
      "117, train_loss: 1.0756785456950848, val_loss: 1.0527804017066955\n",
      "118, train_loss: 1.0762249598136315, val_loss: 1.0525310754776\n",
      "119, train_loss: 1.0720957655173082, val_loss: 1.031320869922638\n",
      "120, train_loss: 1.075358821795537, val_loss: 1.0479688882827758\n",
      "121, train_loss: 1.0760108484671667, val_loss: 1.048117196559906\n",
      "122, train_loss: 1.0751676995020647, val_loss: 1.0720304489135741\n",
      "123, train_loss: 1.075904632990177, val_loss: 1.0682057738304138\n",
      "124, train_loss: 1.0752024260851054, val_loss: 1.064447557926178\n",
      "125, train_loss: 1.0757435583151305, val_loss: 1.0483072996139526\n",
      "126, train_loss: 1.0716673915202801, val_loss: 1.0688287973403932\n",
      "127, train_loss: 1.0755749826247876, val_loss: 1.047071099281311\n",
      "128, train_loss: 1.075457025032777, val_loss: 1.0300571203231812\n",
      "129, train_loss: 1.0754584899315467, val_loss: 1.0475138545036315\n",
      "130, train_loss: 1.0753620977585132, val_loss: 1.0495376467704773\n",
      "131, train_loss: 1.0714344955407655, val_loss: 1.067203450202942\n",
      "132, train_loss: 1.0752769318910746, val_loss: 1.063713502883911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133, train_loss: 1.074704484297679, val_loss: 1.0692167043685914\n",
      "134, train_loss: 1.0712237472717578, val_loss: 1.0684911489486695\n",
      "135, train_loss: 1.0750095156522899, val_loss: 1.0665980100631713\n",
      "136, train_loss: 1.0745398769011865, val_loss: 1.047727108001709\n",
      "137, train_loss: 1.0749351909527411, val_loss: 1.063467538356781\n",
      "138, train_loss: 1.0748280814060798, val_loss: 1.044848084449768\n",
      "139, train_loss: 1.0708649112628057, val_loss: 1.0468290090560912\n",
      "140, train_loss: 1.074684787255067, val_loss: 1.0666366457939147\n",
      "141, train_loss: 1.0747948907888853, val_loss: 1.0658403754234314\n",
      "142, train_loss: 1.0745175618391771, val_loss: 1.0639983534812927\n",
      "143, train_loss: 1.0744654627946706, val_loss: 1.0660336017608643\n",
      "144, train_loss: 1.0735501738694997, val_loss: 1.0618476510047912\n",
      "145, train_loss: 1.0743083839233105, val_loss: 1.0260773420333862\n",
      "146, train_loss: 1.070622613796821, val_loss: 1.0254459142684937\n",
      "147, train_loss: 1.07378024321336, val_loss: 1.061331284046173\n",
      "148, train_loss: 1.074336602137639, val_loss: 1.0423882722854614\n",
      "149, train_loss: 1.0740156471729279, val_loss: 1.043733286857605\n",
      "150, train_loss: 1.073541705424969, val_loss: 1.0265210151672364\n",
      "151, train_loss: 1.0738504437299876, val_loss: 1.0257784128189087\n",
      "152, train_loss: 1.070225252554967, val_loss: 1.061720895767212\n",
      "153, train_loss: 1.0737294440086071, val_loss: 1.0640350461006165\n",
      "154, train_loss: 1.0736830532550812, val_loss: 1.0237546682357788\n",
      "155, train_loss: 1.0697412674243634, val_loss: 1.0410807490348817\n",
      "156, train_loss: 1.073553000505154, val_loss: 1.0611119508743285\n",
      "157, train_loss: 1.0734715622205, val_loss: 1.0434195756912232\n",
      "158, train_loss: 1.0731799510809092, val_loss: 1.0578163504600524\n",
      "159, train_loss: 1.073333591222763, val_loss: 1.042575192451477\n",
      "160, train_loss: 1.0695056089988122, val_loss: 1.0593621253967285\n",
      "161, train_loss: 1.0730613882725055, val_loss: 1.0598037719726563\n",
      "162, train_loss: 1.0692140964361339, val_loss: 1.0613809823989868\n",
      "163, train_loss: 1.0692548591357012, val_loss: 1.0620750188827515\n",
      "164, train_loss: 1.0728505918612847, val_loss: 1.0609140634536742\n",
      "165, train_loss: 1.072928284223263, val_loss: 1.0400717854499817\n",
      "166, train_loss: 1.0726978274492116, val_loss: 1.0599170327186584\n",
      "167, train_loss: 1.072700356061642, val_loss: 1.0416310667991637\n",
      "168, train_loss: 1.072591747228916, val_loss: 1.0600170135498046\n",
      "169, train_loss: 1.0686468390318065, val_loss: 1.0623681545257568\n",
      "170, train_loss: 1.0727808658893292, val_loss: 1.0412904381752015\n",
      "171, train_loss: 1.07277983885545, val_loss: 1.0626742720603943\n",
      "172, train_loss: 1.0723517995614271, val_loss: 1.0377631783485413\n",
      "173, train_loss: 1.0719788097418272, val_loss: 1.0577240943908692\n",
      "174, train_loss: 1.0682922624624693, val_loss: 1.0621458888053894\n",
      "175, train_loss: 1.068373088653271, val_loss: 1.057934319972992\n",
      "176, train_loss: 1.0682262778282166, val_loss: 1.0593128204345703\n",
      "177, train_loss: 1.0681874339397137, val_loss: 1.0589251399040223\n",
      "178, train_loss: 1.071763235789079, val_loss: 1.02063649892807\n",
      "179, train_loss: 1.0718551599062407, val_loss: 1.0566193819046021\n",
      "180, train_loss: 1.0681446080024426, val_loss: 1.0571264386177064\n",
      "181, train_loss: 1.072227065379803, val_loss: 1.0604693174362183\n",
      "182, train_loss: 1.070971830533101, val_loss: 1.0545475244522096\n",
      "183, train_loss: 1.0714710836227124, val_loss: 1.0396832585334779\n",
      "184, train_loss: 1.0676893660655389, val_loss: 1.0560553312301635\n",
      "185, train_loss: 1.067613381605882, val_loss: 1.0196625471115113\n",
      "186, train_loss: 1.0712701449027429, val_loss: 1.0557307481765748\n",
      "187, train_loss: 1.0717832560722644, val_loss: 1.0563937902450562\n",
      "188, train_loss: 1.0711266237955828, val_loss: 1.0546023845672607\n",
      "189, train_loss: 1.067144547517483, val_loss: 1.060432744026184\n",
      "190, train_loss: 1.070923307767281, val_loss: 1.040990662574768\n",
      "191, train_loss: 1.0708501889155462, val_loss: 1.0584981441497803\n",
      "192, train_loss: 1.0708205539446611, val_loss: 1.0550935983657836\n",
      "193, train_loss: 1.0706430306801429, val_loss: 1.0361910104751586\n",
      "194, train_loss: 1.0706437665682573, val_loss: 1.036673653125763\n",
      "195, train_loss: 1.066807916531196, val_loss: 1.0543694972991944\n",
      "196, train_loss: 1.0699733518637145, val_loss: 1.0362330794334411\n",
      "197, train_loss: 1.0704456315590785, val_loss: 1.0545374989509582\n",
      "198, train_loss: 1.0703931886416216, val_loss: 1.0178934693336488\n",
      "199, train_loss: 1.06975967838214, val_loss: 1.0541705250740052\n",
      "200, train_loss: 1.0663348665604224, val_loss: 1.0345366597175598\n",
      "201, train_loss: 1.0703604817390442, val_loss: 1.0520066738128662\n",
      "202, train_loss: 1.0699960910356963, val_loss: 1.0387946009635924\n",
      "203, train_loss: 1.0699588060379028, val_loss: 1.0355588912963867\n",
      "204, train_loss: 1.069835582604775, val_loss: 1.0526179790496826\n",
      "205, train_loss: 1.069948593011269, val_loss: 1.0338752746582032\n",
      "206, train_loss: 1.0697609002773578, val_loss: 1.0538659334182738\n",
      "207, train_loss: 1.0660990614157457, val_loss: 1.0349412560462952\n",
      "208, train_loss: 1.0695542349265172, val_loss: 1.0513435840606689\n",
      "209, train_loss: 1.0694347046888792, val_loss: 1.0371907711029054\n",
      "210, train_loss: 1.0693151354789734, val_loss: 1.0554530143737793\n",
      "211, train_loss: 1.0690690920903132, val_loss: 1.0516729593276977\n",
      "212, train_loss: 1.065569886794457, val_loss: 1.0142679333686828\n",
      "213, train_loss: 1.0654225464050586, val_loss: 1.0519524574279786\n",
      "214, train_loss: 1.0691017577281365, val_loss: 1.0323700308799744\n",
      "215, train_loss: 1.0689918811504657, val_loss: 1.0521685838699342\n",
      "216, train_loss: 1.0652115895197942, val_loss: 1.0323737382888794\n",
      "217, train_loss: 1.0688130580461943, val_loss: 1.0525172233581543\n",
      "218, train_loss: 1.0687757913882916, val_loss: 1.0518048763275147\n",
      "219, train_loss: 1.065032374400359, val_loss: 1.0511263251304626\n",
      "220, train_loss: 1.0649277476164012, val_loss: 1.033136522769928\n",
      "221, train_loss: 1.0648621870921209, val_loss: 1.031412088871002\n",
      "222, train_loss: 1.0648455573962285, val_loss: 1.0135796070098877\n",
      "223, train_loss: 1.0650965846501863, val_loss: 1.0316997170448303\n",
      "224, train_loss: 1.0683025259238024, val_loss: 1.0302008509635925\n",
      "225, train_loss: 1.0683023585722997, val_loss: 1.0319676041603087\n",
      "226, train_loss: 1.068099714242495, val_loss: 1.030820369720459\n",
      "227, train_loss: 1.0679586621431203, val_loss: 1.0296676754951477\n",
      "228, train_loss: 1.0679346116689534, val_loss: 1.0333173632621766\n",
      "229, train_loss: 1.0642379476473882, val_loss: 1.0488410711288452\n",
      "230, train_loss: 1.067809474009734, val_loss: 1.0495762705802918\n",
      "231, train_loss: 1.0677191385856042, val_loss: 1.0535830855369568\n",
      "232, train_loss: 1.0640482237705817, val_loss: 1.0293458104133606\n",
      "233, train_loss: 1.0675771190569951, val_loss: 1.029162549972534\n",
      "234, train_loss: 1.063827966268246, val_loss: 1.0483327627182006\n",
      "235, train_loss: 1.0673849697296436, val_loss: 1.0300895690917968\n",
      "236, train_loss: 1.0672670006752014, val_loss: 1.0524046182632447\n",
      "237, train_loss: 1.067203728052286, val_loss: 1.0488356232643128\n",
      "238, train_loss: 1.0635122610972478, val_loss: 1.0334286212921142\n",
      "239, train_loss: 1.0678670773139367, val_loss: 1.0507677793502808\n",
      "240, train_loss: 1.0633068932936742, val_loss: 1.0490859985351562\n",
      "241, train_loss: 1.0633393549002135, val_loss: 1.0280416131019592\n",
      "242, train_loss: 1.0632997728311098, val_loss: 1.0523199558258056\n",
      "243, train_loss: 1.0666798376120055, val_loss: 1.0516554832458496\n",
      "244, train_loss: 1.067529531625601, val_loss: 1.0476881742477417\n",
      "245, train_loss: 1.0671095893933222, val_loss: 1.02993586063385\n",
      "246, train_loss: 1.0628800048277929, val_loss: 1.0274048805236817\n",
      "247, train_loss: 1.0627738695878248, val_loss: 1.0272053956985474\n",
      "248, train_loss: 1.0665745230821462, val_loss: 1.0342153549194335\n",
      "249, train_loss: 1.0624986336781428, val_loss: 1.047616720199585\n",
      "250, train_loss: 1.0624989156539624, val_loss: 1.0300831079483033\n",
      "251, train_loss: 1.0658930906882653, val_loss: 1.0259786128997803\n",
      "252, train_loss: 1.0658252009978662, val_loss: 1.0297512054443358\n",
      "253, train_loss: 1.0660463686172779, val_loss: 1.0491588592529297\n",
      "254, train_loss: 1.0658197517578418, val_loss: 1.047842764854431\n",
      "255, train_loss: 1.0656442779761095, val_loss: 1.0320664405822755\n",
      "256, train_loss: 1.0657880971064935, val_loss: 1.0263168454170226\n",
      "257, train_loss: 1.0653680494198432, val_loss: 1.0457574605941773\n",
      "258, train_loss: 1.0653203198542962, val_loss: 1.044127881526947\n",
      "259, train_loss: 1.0616120375119722, val_loss: 1.0248793125152589\n",
      "260, train_loss: 1.0650418079816377, val_loss: 1.0434557914733886\n",
      "261, train_loss: 1.0650799595392668, val_loss: 1.043415093421936\n",
      "262, train_loss: 1.0648890137672424, val_loss: 1.0283962965011597\n",
      "263, train_loss: 1.0654054146546583, val_loss: 1.0250995397567748\n",
      "264, train_loss: 1.065038039134099, val_loss: 1.0490915179252625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265, train_loss: 1.06462339254526, val_loss: 1.030836319923401\n",
      "266, train_loss: 1.0610712927121382, val_loss: 1.0285249471664428\n",
      "267, train_loss: 1.065127581357956, val_loss: 1.0455490589141845\n",
      "268, train_loss: 1.0643320633814886, val_loss: 1.0450671792030335\n",
      "269, train_loss: 1.0607281304322755, val_loss: 1.0258431434631348\n",
      "270, train_loss: 1.0642430851092706, val_loss: 1.0258256554603578\n",
      "271, train_loss: 1.064009625178117, val_loss: 1.0490086078643799\n",
      "272, train_loss: 1.060555806526771, val_loss: 1.027996826171875\n",
      "273, train_loss: 1.0649529695510864, val_loss: 1.0057157754898072\n",
      "274, train_loss: 1.0603259526766264, val_loss: 1.0234151244163514\n",
      "275, train_loss: 1.063694036923922, val_loss: 1.0443276643753052\n",
      "276, train_loss: 1.0599890970266783, val_loss: 1.025149655342102\n",
      "277, train_loss: 1.0638133241580083, val_loss: 1.0237481594085693\n",
      "278, train_loss: 1.0599540770053864, val_loss: 1.0229647517204286\n",
      "279, train_loss: 1.063552384193127, val_loss: 1.024044644832611\n",
      "280, train_loss: 1.0596781441798577, val_loss: 1.0445292472839356\n",
      "281, train_loss: 1.0641647210487952, val_loss: 1.0436766147613525\n",
      "282, train_loss: 1.0595556016151721, val_loss: 1.0222857475280762\n",
      "283, train_loss: 1.0594394275775323, val_loss: 1.0220142006874084\n",
      "284, train_loss: 1.063524264555711, val_loss: 1.045059323310852\n",
      "285, train_loss: 1.0589664647212396, val_loss: 1.044959807395935\n",
      "286, train_loss: 1.062652507653603, val_loss: 1.0222842216491699\n",
      "287, train_loss: 1.0625400451513438, val_loss: 1.040309774875641\n",
      "288, train_loss: 1.0593398603109212, val_loss: 1.004180872440338\n",
      "289, train_loss: 1.0622585920187144, val_loss: 1.0410450935363769\n",
      "290, train_loss: 1.0624483640377338, val_loss: 1.0220692873001098\n",
      "291, train_loss: 1.062139488183535, val_loss: 1.0430519700050354\n",
      "292, train_loss: 1.0619622285549457, val_loss: 1.002932608127594\n",
      "293, train_loss: 1.0585064429503221, val_loss: 1.0219247102737428\n",
      "294, train_loss: 1.0617741323434389, val_loss: 1.0422577619552613\n",
      "295, train_loss: 1.0616561197317564, val_loss: 1.0438661575317383\n",
      "296, train_loss: 1.061641826079442, val_loss: 1.0224489569664001\n",
      "297, train_loss: 1.061508806852194, val_loss: 1.0410634517669677\n",
      "298, train_loss: 1.0614279371041517, val_loss: 1.0376184821128844\n",
      "299, train_loss: 1.061387272981497, val_loss: 1.0219083547592163\n",
      "300, train_loss: 1.057841814481295, val_loss: 1.0386587619781493\n",
      "301, train_loss: 1.061167448759079, val_loss: 1.0385146021842957\n",
      "302, train_loss: 1.0610284461424901, val_loss: 1.037442696094513\n",
      "303, train_loss: 1.0615032727901752, val_loss: 1.0394923329353332\n",
      "304, train_loss: 1.0608160472833192, val_loss: 1.038169014453888\n",
      "305, train_loss: 1.0573610548789685, val_loss: 1.0408024787902832\n",
      "306, train_loss: 1.0606310230035048, val_loss: 1.0418608784675598\n",
      "307, train_loss: 1.0573600691098433, val_loss: 1.0202064990997315\n",
      "308, train_loss: 1.0569555094608893, val_loss: 1.0177654504776001\n",
      "309, train_loss: 1.060895018852674, val_loss: 1.0434722900390625\n",
      "310, train_loss: 1.0567280581364265, val_loss: 1.0178528428077698\n",
      "311, train_loss: 1.060763920728977, val_loss: 1.0187844514846802\n",
      "312, train_loss: 1.0608149537673364, val_loss: 1.037286365032196\n",
      "313, train_loss: 1.056557678259336, val_loss: 1.0375563979148865\n",
      "314, train_loss: 1.0562728253694682, val_loss: 1.036483919620514\n",
      "315, train_loss: 1.0603996538198912, val_loss: 1.039243960380554\n",
      "316, train_loss: 1.0601145877287939, val_loss: 1.0426900863647461\n",
      "317, train_loss: 1.0559831605507777, val_loss: 1.0449334144592286\n",
      "318, train_loss: 1.059810874553827, val_loss: 1.0191841840744018\n",
      "319, train_loss: 1.0597194983409002, val_loss: 1.0382190227508545\n",
      "320, train_loss: 1.059722751379013, val_loss: 1.018309187889099\n",
      "321, train_loss: 1.060070982346168, val_loss: 1.0415279865264893\n",
      "322, train_loss: 1.0592158826497884, val_loss: 1.0428855061531066\n",
      "323, train_loss: 1.058829163129513, val_loss: 1.0193121552467346\n",
      "324, train_loss: 1.0591982969870934, val_loss: 1.0165114164352418\n",
      "325, train_loss: 1.058559463574336, val_loss: 1.0166704416275025\n",
      "326, train_loss: 1.0583975475568037, val_loss: 1.0339437007904053\n",
      "327, train_loss: 1.0589837225583882, val_loss: 1.033749282360077\n",
      "328, train_loss: 1.0549111320422246, val_loss: 1.0350812196731567\n",
      "329, train_loss: 1.0545529470993922, val_loss: 1.041117012500763\n",
      "330, train_loss: 1.054658048428022, val_loss: 0.9990267634391785\n",
      "331, train_loss: 1.057936253455969, val_loss: 1.0341985821723938\n",
      "332, train_loss: 1.0578035505918355, val_loss: 1.0184499263763427\n",
      "333, train_loss: 1.0576647772238805, val_loss: 1.0155805349349976\n",
      "334, train_loss: 1.0541460032646472, val_loss: 1.0216148376464844\n",
      "335, train_loss: 1.0579495911414807, val_loss: 1.0180086374282837\n",
      "336, train_loss: 1.0539196592110853, val_loss: 1.0333857417106629\n",
      "337, train_loss: 1.0571291813483605, val_loss: 1.0203989744186401\n",
      "338, train_loss: 1.05371469947008, val_loss: 1.0324198484420777\n",
      "339, train_loss: 1.0570498865384321, val_loss: 1.019121766090393\n",
      "340, train_loss: 1.0536684027084937, val_loss: 1.0140857934951781\n",
      "341, train_loss: 1.0533542954004729, val_loss: 1.0162229418754578\n",
      "342, train_loss: 1.0567537041810842, val_loss: 1.0186774015426636\n",
      "343, train_loss: 1.05662418787296, val_loss: 1.0367851972579956\n",
      "344, train_loss: 1.0564664258406713, val_loss: 1.0147031545639038\n",
      "345, train_loss: 1.0529320331720204, val_loss: 1.0169157981872559\n",
      "346, train_loss: 1.0528672222907727, val_loss: 1.0304078102111816\n",
      "347, train_loss: 1.0560703323437617, val_loss: 1.0125480532646178\n",
      "348, train_loss: 1.0525285853789403, val_loss: 1.033743643760681\n",
      "349, train_loss: 1.0526708570810466, val_loss: 1.011569619178772\n",
      "350, train_loss: 1.0565728568113768, val_loss: 1.0311154127120972\n",
      "351, train_loss: 1.052423887527906, val_loss: 1.0136188626289369\n",
      "352, train_loss: 1.0558892488479614, val_loss: 1.0133235216140748\n",
      "353, train_loss: 1.0554701731755183, val_loss: 0.9934893131256104\n",
      "354, train_loss: 1.0519934686330648, val_loss: 1.031418776512146\n",
      "355, train_loss: 1.056057884142949, val_loss: 0.9931563377380371\n",
      "356, train_loss: 1.0551343949941487, val_loss: 1.0344666123390198\n",
      "357, train_loss: 1.0515225300422082, val_loss: 1.028998816013336\n",
      "358, train_loss: 1.0516378375200124, val_loss: 1.0308491587638855\n",
      "359, train_loss: 1.0515836683603434, val_loss: 1.0299710154533386\n",
      "360, train_loss: 1.0551539865823893, val_loss: 1.0356056451797486\n",
      "361, train_loss: 1.054425230393043, val_loss: 1.0136665225028991\n",
      "362, train_loss: 1.0510689318180084, val_loss: 1.0098984241485596\n",
      "363, train_loss: 1.0550482410650988, val_loss: 1.0283638954162597\n",
      "364, train_loss: 1.0550105090324695, val_loss: 1.0099257349967956\n",
      "365, train_loss: 1.0507305883444273, val_loss: 1.0361884355545044\n",
      "366, train_loss: 1.0504793433042674, val_loss: 1.0094647526741027\n",
      "367, train_loss: 1.050403716472479, val_loss: 1.016270673274994\n",
      "368, train_loss: 1.0502280936791346, val_loss: 1.0291418790817262\n",
      "369, train_loss: 1.0535861116189222, val_loss: 1.0289891719818116\n",
      "370, train_loss: 1.0540359180707197, val_loss: 1.010839867591858\n",
      "371, train_loss: 1.0533349009660573, val_loss: 0.9907266139984131\n",
      "372, train_loss: 1.0500392753344316, val_loss: 1.0100206136703491\n",
      "373, train_loss: 1.0545012629949129, val_loss: 1.0304595112800599\n",
      "374, train_loss: 1.05297396503962, val_loss: 1.0084373354911804\n",
      "375, train_loss: 1.052885142656473, val_loss: 1.0262621641159058\n",
      "376, train_loss: 1.0527610182762146, val_loss: 1.011754047870636\n",
      "377, train_loss: 1.0525725942391615, val_loss: 1.0313090443611146\n",
      "378, train_loss: 1.0525103371876936, val_loss: 1.0278172135353087\n",
      "379, train_loss: 1.0523672860402327, val_loss: 1.0255175828933716\n",
      "380, train_loss: 1.0522285401821136, val_loss: 1.0089978218078612\n",
      "381, train_loss: 1.0487894599254315, val_loss: 1.032948112487793\n",
      "382, train_loss: 1.0484719780775218, val_loss: 1.0112094163894654\n",
      "383, train_loss: 1.0518305118267353, val_loss: 1.024967646598816\n",
      "384, train_loss: 1.0528001464330232, val_loss: 1.0262099623680114\n",
      "385, train_loss: 1.0515971275476308, val_loss: 1.0284703135490418\n",
      "386, train_loss: 1.0515204209547777, val_loss: 1.0238826274871826\n",
      "387, train_loss: 1.0513129967909594, val_loss: 1.0263726949691772\n",
      "388, train_loss: 1.04801050057778, val_loss: 1.0066843271255492\n",
      "389, train_loss: 1.0518687963485718, val_loss: 1.0058207273483277\n",
      "390, train_loss: 1.0475874222241914, val_loss: 1.0144700884819031\n",
      "391, train_loss: 1.0507977444391985, val_loss: 1.0345143318176269\n",
      "392, train_loss: 1.0514979981459105, val_loss: 1.0297969579696655\n",
      "393, train_loss: 1.0472082633238573, val_loss: 1.0303652048110963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394, train_loss: 1.0503597809718206, val_loss: 1.007102632522583\n",
      "395, train_loss: 1.0470328330993652, val_loss: 1.0250148177146912\n",
      "396, train_loss: 1.050133622609652, val_loss: 0.9904473781585693\n",
      "397, train_loss: 1.0501064199667711, val_loss: 1.0232597589492798\n",
      "398, train_loss: 1.0499469477396746, val_loss: 1.0288962721824646\n",
      "399, train_loss: 1.0467208692660699, val_loss: 1.0260076880455018\n",
      "400, train_loss: 1.0504874197336345, val_loss: 1.003869080543518\n",
      "401, train_loss: 1.0496044434033907, val_loss: 1.0073952674865723\n",
      "402, train_loss: 1.0459284140513494, val_loss: 1.0283995747566224\n",
      "403, train_loss: 1.0500590686614697, val_loss: 1.0256159424781799\n",
      "404, train_loss: 1.0490489441614885, val_loss: 1.0278268933296204\n",
      "405, train_loss: 1.0496612328749437, val_loss: 1.0074254989624023\n",
      "406, train_loss: 1.0460185775390038, val_loss: 1.0025999665260314\n",
      "407, train_loss: 1.0494046807289124, val_loss: 1.0072341680526733\n",
      "408, train_loss: 1.0485616899453676, val_loss: 1.0277634978294372\n",
      "409, train_loss: 1.049757677775163, val_loss: 1.0030677437782287\n",
      "410, train_loss: 1.045068500133661, val_loss: 1.0315659284591674\n",
      "411, train_loss: 1.0489760797757368, val_loss: 0.9875218510627747\n",
      "412, train_loss: 1.0494367411503425, val_loss: 1.0314277291297913\n",
      "413, train_loss: 1.0478924467013433, val_loss: 1.021943175792694\n",
      "414, train_loss: 1.0443971821895013, val_loss: 1.004253876209259\n",
      "415, train_loss: 1.044165430160669, val_loss: 1.0222346186637878\n",
      "416, train_loss: 1.0482531831814692, val_loss: 1.0081046223640442\n",
      "417, train_loss: 1.0473163861494799, val_loss: 1.0065824508666992\n",
      "418, train_loss: 1.0438641584836519, val_loss: 1.029032015800476\n",
      "419, train_loss: 1.0469664679123805, val_loss: 1.002552616596222\n",
      "420, train_loss: 1.0468358512108142, val_loss: 1.004916489124298\n",
      "421, train_loss: 1.0467725877578442, val_loss: 1.0346720218658447\n",
      "422, train_loss: 1.0431921940583448, val_loss: 0.9831416487693787\n",
      "423, train_loss: 1.0473015766877394, val_loss: 1.0277607083320617\n",
      "424, train_loss: 1.0469211546274333, val_loss: 1.0231594562530517\n",
      "425, train_loss: 1.042822159253634, val_loss: 1.0003706693649292\n",
      "426, train_loss: 1.0426522011940296, val_loss: 1.0248879075050354\n",
      "427, train_loss: 1.0474196901688209, val_loss: 1.0074899911880493\n",
      "428, train_loss: 1.046911915907493, val_loss: 1.007166576385498\n",
      "429, train_loss: 1.0460873337892385, val_loss: 1.0231655359268188\n",
      "430, train_loss: 1.0462091863155365, val_loss: 1.0184049606323242\n",
      "431, train_loss: 1.0452447694081526, val_loss: 1.0204461693763733\n",
      "432, train_loss: 1.0457713168400984, val_loss: 1.0201429367065429\n",
      "433, train_loss: 1.0416621978466327, val_loss: 1.0023455500602723\n",
      "434, train_loss: 1.045654950233606, val_loss: 1.0266469717025757\n",
      "435, train_loss: 1.0415463287096758, val_loss: 1.0241428375244142\n",
      "436, train_loss: 1.0445546897558065, val_loss: 1.0088281750679016\n",
      "437, train_loss: 1.0450477393773885, val_loss: 1.019524300098419\n",
      "438, train_loss: 1.0448153569148138, val_loss: 1.0238107681274413\n",
      "439, train_loss: 1.0407369641157298, val_loss: 1.0054152369499207\n",
      "440, train_loss: 1.0450964386646564, val_loss: 0.9989070653915405\n",
      "441, train_loss: 1.0438117614159217, val_loss: 1.0064556121826171\n",
      "442, train_loss: 1.0444421676489024, val_loss: 1.0202640056610108\n",
      "443, train_loss: 1.0434189186646388, val_loss: 1.001548206806183\n",
      "444, train_loss: 1.0398866098660688, val_loss: 1.0007272958755493\n",
      "445, train_loss: 1.0398256732867315, val_loss: 1.024943721294403\n",
      "446, train_loss: 1.0397012119109814, val_loss: 1.0181780457496643\n",
      "447, train_loss: 1.0395002021239355, val_loss: 1.001587951183319\n",
      "448, train_loss: 1.039595638330166, val_loss: 1.0001408934593201\n",
      "449, train_loss: 1.0426333088141222, val_loss: 0.9828199982643128\n",
      "450, train_loss: 1.0391427461917584, val_loss: 1.0155563354492188\n",
      "451, train_loss: 1.0422489734796376, val_loss: 1.0149214744567872\n",
      "452, train_loss: 1.0387664414369142, val_loss: 1.0011878848075866\n",
      "453, train_loss: 1.042010717667066, val_loss: 1.014126193523407\n",
      "454, train_loss: 1.0429203418584971, val_loss: 1.0234783411026\n",
      "455, train_loss: 1.038074417756154, val_loss: 1.016641664505005\n",
      "456, train_loss: 1.0415002405643463, val_loss: 1.0191046833992004\n",
      "457, train_loss: 1.042425112082408, val_loss: 1.00488600730896\n",
      "458, train_loss: 1.041250508565169, val_loss: 0.9970112562179565\n",
      "459, train_loss: 1.041037910259687, val_loss: 0.9789399623870849\n",
      "460, train_loss: 1.0408682800256288, val_loss: 0.9977247595787049\n",
      "461, train_loss: 1.0410968959331512, val_loss: 1.0174822568893434\n",
      "462, train_loss: 1.0414784986239214, val_loss: 1.015453541278839\n",
      "463, train_loss: 1.041510052405871, val_loss: 0.9945476174354553\n",
      "464, train_loss: 1.0368956740085895, val_loss: 0.994380247592926\n",
      "465, train_loss: 1.0368063404009893, val_loss: 1.01762912273407\n",
      "466, train_loss: 1.040483119396063, val_loss: 1.021571898460388\n",
      "467, train_loss: 1.036623397698769, val_loss: 0.9798224687576294\n",
      "468, train_loss: 1.0396567514309516, val_loss: 1.001244580745697\n",
      "469, train_loss: 1.039505958557129, val_loss: 0.9969589591026307\n",
      "470, train_loss: 1.0359369929020221, val_loss: 1.0231537103652955\n",
      "471, train_loss: 1.0358053996012762, val_loss: 1.0119203686714173\n",
      "472, train_loss: 1.0398973043148334, val_loss: 1.010857379436493\n",
      "473, train_loss: 1.0393824095909412, val_loss: 1.0135044932365418\n",
      "474, train_loss: 1.0392218713576977, val_loss: 1.014970338344574\n",
      "475, train_loss: 1.0384394503556764, val_loss: 0.9950907826423645\n",
      "476, train_loss: 1.0396175269897168, val_loss: 1.017852008342743\n",
      "477, train_loss: 1.0381241601247053, val_loss: 1.012925672531128\n",
      "478, train_loss: 1.0388998182920308, val_loss: 1.0147730946540832\n",
      "479, train_loss: 1.0391285809186788, val_loss: 0.9964237213134766\n",
      "480, train_loss: 1.0391802627306719, val_loss: 0.9951597094535828\n",
      "481, train_loss: 1.037423821595999, val_loss: 0.9950018763542176\n",
      "482, train_loss: 1.0373676029535441, val_loss: 0.9944915533065796\n",
      "483, train_loss: 1.0338059663772583, val_loss: 0.9963687300682068\n",
      "484, train_loss: 1.038484669648684, val_loss: 1.0096285343170166\n",
      "485, train_loss: 1.0337528838561132, val_loss: 1.0118919968605042\n",
      "486, train_loss: 1.0378559736105113, val_loss: 1.016331946849823\n",
      "487, train_loss: 1.036544219805644, val_loss: 1.0161174893379212\n",
      "488, train_loss: 1.0363462200531592, val_loss: 1.0140446782112122\n",
      "489, train_loss: 1.0362072609938109, val_loss: 1.010446834564209\n",
      "490, train_loss: 1.0326875058504252, val_loss: 1.0146103143692016\n",
      "491, train_loss: 1.035829252921618, val_loss: 1.0109275817871093\n",
      "492, train_loss: 1.0361604071580446, val_loss: 0.9966030120849609\n",
      "493, train_loss: 1.0354293928696559, val_loss: 1.0128512382507324\n",
      "494, train_loss: 1.0352931091418633, val_loss: 1.0128466725349425\n",
      "495, train_loss: 1.0350639820098877, val_loss: 0.9933642864227294\n",
      "496, train_loss: 1.032034729535763, val_loss: 1.0148766756057739\n",
      "497, train_loss: 1.0347027824475215, val_loss: 1.0093127369880677\n",
      "498, train_loss: 1.0313939841894002, val_loss: 1.0123007535934447\n",
      "499, train_loss: 1.0312055601523473, val_loss: 0.9937997460365295\n",
      "500, train_loss: 1.0342116608069494, val_loss: 1.0135010600090026\n",
      "501, train_loss: 1.0341074145757234, val_loss: 0.9891761183738709\n",
      "502, train_loss: 1.0306120285621057, val_loss: 0.9916561961174011\n",
      "503, train_loss: 1.0337486290014708, val_loss: 1.0155479192733765\n",
      "504, train_loss: 1.0335479860122387, val_loss: 0.9907338738441467\n",
      "505, train_loss: 1.0303825529722066, val_loss: 0.9956997871398926\n",
      "506, train_loss: 1.0339654202644641, val_loss: 0.9886482000350952\n",
      "507, train_loss: 1.0330662773205683, val_loss: 1.0147550106048584\n",
      "508, train_loss: 1.0297383872362285, val_loss: 1.0153827667236328\n",
      "509, train_loss: 1.0294821216509893, val_loss: 0.9891433835029602\n",
      "510, train_loss: 1.0333868563175201, val_loss: 0.990717101097107\n",
      "511, train_loss: 1.0323514709105859, val_loss: 0.9919461488723755\n",
      "512, train_loss: 1.033561958716466, val_loss: 0.9969919919967651\n",
      "513, train_loss: 1.0328591855672689, val_loss: 0.9864021062850952\n",
      "514, train_loss: 1.0286503090308263, val_loss: 0.9922279477119446\n",
      "515, train_loss: 1.0315954318413367, val_loss: 0.9894297122955322\n",
      "516, train_loss: 1.0314322893436139, val_loss: 0.9861522912979126\n",
      "517, train_loss: 1.0321205052045674, val_loss: 1.0060338854789734\n",
      "518, train_loss: 1.0310643384089837, val_loss: 1.010927140712738\n",
      "519, train_loss: 1.0317379648868854, val_loss: 1.015270960330963\n",
      "520, train_loss: 1.0315372668779814, val_loss: 1.0055966973304749\n",
      "521, train_loss: 1.0271410368956053, val_loss: 0.9684299826622009\n",
      "522, train_loss: 1.0272584832631624, val_loss: 0.9898874998092652\n",
      "523, train_loss: 1.026906160207895, val_loss: 1.0070243716239928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524, train_loss: 1.0299253440820253, val_loss: 1.0069980025291443\n",
      "525, train_loss: 1.0297509065041175, val_loss: 1.0045935750007629\n",
      "526, train_loss: 1.0265552126444304, val_loss: 1.0110839486122132\n",
      "527, train_loss: 1.0303335052270155, val_loss: 1.0089480400085449\n",
      "528, train_loss: 1.0296304432245402, val_loss: 0.9913602709770203\n",
      "529, train_loss: 1.0302438690112188, val_loss: 1.0070276618003846\n",
      "530, train_loss: 1.0287285309571486, val_loss: 1.0031612396240235\n",
      "531, train_loss: 1.0292937893133898, val_loss: 0.9859187006950378\n",
      "532, train_loss: 1.0283800822037916, val_loss: 0.9933483719825744\n",
      "533, train_loss: 1.0294877015627348, val_loss: 0.9836754918098449\n",
      "534, train_loss: 1.0289685336443095, val_loss: 1.0005114316940307\n",
      "535, train_loss: 1.0277900925049415, val_loss: 1.002284300327301\n",
      "536, train_loss: 1.0284719260839315, val_loss: 0.9909204244613647\n",
      "537, train_loss: 1.0286233608539288, val_loss: 0.9837003827095032\n",
      "538, train_loss: 1.0279611440805287, val_loss: 0.9873885989189148\n",
      "539, train_loss: 1.0237294871073503, val_loss: 1.0016209483146667\n",
      "540, train_loss: 1.0236902443262248, val_loss: 0.9825380325317383\n",
      "541, train_loss: 1.0266053424431727, val_loss: 1.0088819026947022\n",
      "542, train_loss: 1.0277131727108588, val_loss: 0.9815746784210205\n",
      "543, train_loss: 1.0229276212362142, val_loss: 1.0084586143493652\n",
      "544, train_loss: 1.027111406509693, val_loss: 0.9918678522109985\n",
      "545, train_loss: 1.0267394895736988, val_loss: 1.0034247398376466\n",
      "546, train_loss: 1.0224455824265113, val_loss: 0.9858059883117676\n",
      "547, train_loss: 1.0224543993289654, val_loss: 0.998205554485321\n",
      "548, train_loss: 1.026300840652906, val_loss: 0.9978736996650696\n",
      "549, train_loss: 1.0250572951940389, val_loss: 1.0017382502555847\n",
      "550, train_loss: 1.0217891679360316, val_loss: 0.9849585056304931\n",
      "551, train_loss: 1.0262063970932593, val_loss: 0.9801559925079346\n",
      "552, train_loss: 1.021456023821464, val_loss: 0.9998831152915955\n",
      "553, train_loss: 1.0211569024966314, val_loss: 1.0014191031455995\n",
      "554, train_loss: 1.023996577813075, val_loss: 0.9787404060363769\n",
      "555, train_loss: 1.0205689989603484, val_loss: 1.0014253973960876\n",
      "556, train_loss: 1.0203474920529585, val_loss: 1.003281259536743\n",
      "557, train_loss: 1.024383925474607, val_loss: 0.9614403128623963\n",
      "558, train_loss: 1.0241727920678945, val_loss: 0.9958231806755066\n",
      "559, train_loss: 1.0229449295080626, val_loss: 1.0053919911384583\n",
      "560, train_loss: 1.0227309075685649, val_loss: 1.009378397464752\n",
      "561, train_loss: 1.0225588862712567, val_loss: 0.9849272966384888\n",
      "562, train_loss: 1.0223605151359851, val_loss: 0.9615410923957824\n",
      "563, train_loss: 1.0192387998104095, val_loss: 0.9845534682273864\n",
      "564, train_loss: 1.0233157552205598, val_loss: 0.9768361330032349\n",
      "565, train_loss: 1.0230830013751984, val_loss: 1.0042330741882324\n",
      "566, train_loss: 1.0183529922595391, val_loss: 0.9987560033798217\n",
      "567, train_loss: 1.01828517134373, val_loss: 0.9986363887786865\n",
      "568, train_loss: 1.0182981422314277, val_loss: 0.996302580833435\n",
      "569, train_loss: 1.0222496825915117, val_loss: 1.0007791996002198\n",
      "570, train_loss: 1.0214011875482707, val_loss: 0.9816411733627319\n",
      "571, train_loss: 1.0207993067227876, val_loss: 0.9980913162231445\n",
      "572, train_loss: 1.0208473709913402, val_loss: 0.9960428237915039\n",
      "573, train_loss: 1.0199090448709636, val_loss: 0.9948433756828308\n",
      "574, train_loss: 1.0197296394751623, val_loss: 0.978641939163208\n",
      "575, train_loss: 1.0164518631421602, val_loss: 0.9746467471122742\n",
      "576, train_loss: 1.019922178525191, val_loss: 0.9808736681938172\n",
      "577, train_loss: 1.0191628566155067, val_loss: 1.009652554988861\n",
      "578, train_loss: 1.018865624299416, val_loss: 0.991778552532196\n",
      "579, train_loss: 1.0156063116513765, val_loss: 0.9738173604011535\n",
      "580, train_loss: 1.015492326938189, val_loss: 0.9785422325134278\n",
      "581, train_loss: 1.0189006145183856, val_loss: 0.9789875268936157\n",
      "582, train_loss: 1.0180533207379854, val_loss: 0.9901214599609375\n",
      "583, train_loss: 1.017828120635106, val_loss: 0.9982430815696717\n",
      "584, train_loss: 1.0188797070429876, val_loss: 0.9763781309127808\n",
      "585, train_loss: 1.0143987559355223, val_loss: 0.992562186717987\n",
      "586, train_loss: 1.0139889281529646, val_loss: 0.9977280378341675\n",
      "587, train_loss: 1.0140198102364173, val_loss: 0.9925873637199402\n",
      "588, train_loss: 1.013781604858545, val_loss: 0.9912465453147888\n",
      "589, train_loss: 1.0164120243145869, val_loss: 0.9918816208839416\n",
      "590, train_loss: 1.0162453445104451, val_loss: 0.9939301013946533\n",
      "591, train_loss: 1.0173745499207423, val_loss: 0.955150818824768\n",
      "592, train_loss: 1.0157343240884633, val_loss: 0.973549771308899\n",
      "593, train_loss: 1.0163324108490577, val_loss: 0.9711367368698121\n",
      "594, train_loss: 1.0153186390033135, val_loss: 0.9562009334564209\n",
      "595, train_loss: 1.0150564060761378, val_loss: 0.9956178188323974\n",
      "596, train_loss: 1.0148033499717712, val_loss: 0.975888192653656\n",
      "597, train_loss: 1.0156343991939838, val_loss: 0.9924779653549194\n",
      "598, train_loss: 1.0114317719752972, val_loss: 0.9799715399742126\n",
      "599, train_loss: 1.014081604205645, val_loss: 0.9706340670585633\n",
      "600, train_loss: 1.010765988093156, val_loss: 0.9558226943016053\n",
      "601, train_loss: 1.0136708525510936, val_loss: 1.0045706629753113\n",
      "602, train_loss: 1.0106074810028076, val_loss: 0.9886837124824523\n",
      "603, train_loss: 1.0105223816174727, val_loss: 0.9685826897621155\n",
      "604, train_loss: 1.0128810566205244, val_loss: 0.971211051940918\n",
      "605, train_loss: 1.0104719217006977, val_loss: 0.9747239351272583\n",
      "606, train_loss: 1.00971568777011, val_loss: 0.9931617021560669\n",
      "607, train_loss: 1.0129584876390605, val_loss: 0.9702424764633178\n",
      "608, train_loss: 1.0088421518986042, val_loss: 0.9701948046684266\n",
      "609, train_loss: 1.0118002043320582, val_loss: 0.984485924243927\n",
      "610, train_loss: 1.008394147341068, val_loss: 0.9527741074562073\n",
      "611, train_loss: 1.0121786296367645, val_loss: 0.9863714575767517\n",
      "612, train_loss: 1.0111568936934838, val_loss: 0.988703989982605\n",
      "613, train_loss: 1.0108323784974904, val_loss: 0.9830134749412537\n",
      "614, train_loss: 1.0105595221886268, val_loss: 0.9673910140991211\n",
      "615, train_loss: 1.007373259617732, val_loss: 0.9929952144622802\n",
      "616, train_loss: 1.011676400899887, val_loss: 0.9687785387039185\n",
      "617, train_loss: 1.0097800630789537, val_loss: 0.9686229586601257\n",
      "618, train_loss: 1.0068238790218647, val_loss: 0.9710051417350769\n",
      "619, train_loss: 1.0066081354251275, val_loss: 0.9851665616035461\n",
      "620, train_loss: 1.0097052248624654, val_loss: 0.9866100072860717\n",
      "621, train_loss: 1.0088216341458833, val_loss: 0.9702242493629456\n",
      "622, train_loss: 1.006414709182886, val_loss: 0.9673815727233886\n",
      "623, train_loss: 1.0052760289265559, val_loss: 0.980194354057312\n",
      "624, train_loss: 1.0089073112377753, val_loss: 0.9664750099182129\n",
      "625, train_loss: 1.0078773957032423, val_loss: 0.9906387805938721\n",
      "626, train_loss: 1.0075441277944124, val_loss: 0.9825109362602233\n",
      "627, train_loss: 1.0091883012881646, val_loss: 0.9683384418487548\n",
      "628, train_loss: 1.006983805161256, val_loss: 0.98757404088974\n",
      "629, train_loss: 1.006788432598114, val_loss: 0.9636335849761963\n",
      "630, train_loss: 1.0038434679691608, val_loss: 0.9904380440711975\n",
      "631, train_loss: 1.0034097662338843, val_loss: 0.9711317300796509\n",
      "632, train_loss: 1.0074159984405224, val_loss: 0.9703430533409119\n",
      "633, train_loss: 1.0057298449369578, val_loss: 0.9654842853546143\n",
      "634, train_loss: 1.0054522477663481, val_loss: 0.9941522598266601\n",
      "635, train_loss: 1.0062733338429377, val_loss: 0.9805283546447754\n",
      "636, train_loss: 1.0019231828359456, val_loss: 0.987999951839447\n",
      "637, train_loss: 1.0045711558598738, val_loss: 0.9723644018173218\n",
      "638, train_loss: 1.0043755609255571, val_loss: 0.9800254344940186\n",
      "639, train_loss: 1.0048484687621777, val_loss: 0.972717034816742\n",
      "640, train_loss: 1.0038507695381458, val_loss: 0.9633917570114136\n",
      "641, train_loss: 1.0035578493888562, val_loss: 0.9846528530120849\n",
      "642, train_loss: 1.0032546864106104, val_loss: 0.9840586543083191\n",
      "643, train_loss: 1.0003731823884523, val_loss: 0.9691344857215881\n",
      "644, train_loss: 1.0027526250252357, val_loss: 0.9494523882865906\n",
      "645, train_loss: 1.0024324082411253, val_loss: 0.9807147145271301\n",
      "646, train_loss: 0.9995851562573359, val_loss: 0.9620386719703674\n",
      "647, train_loss: 1.0033851518080785, val_loss: 0.9781249403953552\n",
      "648, train_loss: 0.9987076796018161, val_loss: 0.9463094472885132\n",
      "649, train_loss: 0.9988997005499326, val_loss: 0.9701089859008789\n",
      "650, train_loss: 1.0022158737366016, val_loss: 0.9741104960441589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "651, train_loss: 1.0025996772142558, val_loss: 0.9774925112724304\n",
      "652, train_loss: 1.0005698502063751, val_loss: 0.973811936378479\n",
      "653, train_loss: 1.0002764532199273, val_loss: 0.9604787826538086\n",
      "654, train_loss: 1.0000312832685618, val_loss: 0.9767881751060485\n",
      "655, train_loss: 1.0005797445774078, val_loss: 0.9580682992935181\n",
      "656, train_loss: 1.000123686515368, val_loss: 0.9604374408721924\n",
      "657, train_loss: 0.9991355171570411, val_loss: 0.982883095741272\n",
      "658, train_loss: 0.9988649510420285, val_loss: 0.9774632096290589\n",
      "659, train_loss: 0.9985524943241706, val_loss: 0.9750048875808716\n",
      "660, train_loss: 0.9954534814907954, val_loss: 0.9671562314033508\n",
      "661, train_loss: 0.9980106949806213, val_loss: 0.9766224503517151\n",
      "662, train_loss: 0.9977025527220506, val_loss: 0.9665326118469239\n",
      "663, train_loss: 0.9943582369731023, val_loss: 0.9593841552734375\n",
      "664, train_loss: 0.9940822720527649, val_loss: 0.9574065804481506\n",
      "665, train_loss: 0.9944042082016284, val_loss: 0.9543638467788697\n",
      "666, train_loss: 0.9965486320165488, val_loss: 0.9701151847839355\n",
      "667, train_loss: 0.9972986143368942, val_loss: 0.9414483070373535\n",
      "668, train_loss: 0.9959799463932331, val_loss: 0.9403587341308594\n",
      "669, train_loss: 0.9957143137088189, val_loss: 0.9591617345809936\n",
      "670, train_loss: 0.9969108746601985, val_loss: 0.9748949885368348\n",
      "671, train_loss: 0.9923872191172379, val_loss: 0.9583128929138184\n",
      "672, train_loss: 0.9962454713307894, val_loss: 0.9803788423538208\n",
      "673, train_loss: 0.9917993201659276, val_loss: 0.9746392011642456\n",
      "674, train_loss: 0.9941091354076679, val_loss: 0.9712386012077332\n",
      "675, train_loss: 0.9909513317621671, val_loss: 0.9572311043739319\n",
      "676, train_loss: 0.9935634869795579, val_loss: 0.9727435350418091\n",
      "677, train_loss: 0.9903859450266912, val_loss: 0.9694883823394775\n",
      "678, train_loss: 0.9930212704034952, val_loss: 0.9648419380187988\n",
      "679, train_loss: 0.9926682985745944, val_loss: 0.9600082874298096\n",
      "680, train_loss: 0.9923768662489377, val_loss: 0.9750632405281067\n",
      "681, train_loss: 0.9920398959746728, val_loss: 0.9767942786216736\n",
      "682, train_loss: 0.9927960886405065, val_loss: 0.9682831645011902\n",
      "683, train_loss: 0.9913796713719001, val_loss: 0.9721341609954834\n",
      "684, train_loss: 0.9915622266439291, val_loss: 0.9728313207626342\n",
      "685, train_loss: 0.9918990914638226, val_loss: 0.9702440142631531\n",
      "686, train_loss: 0.9880408828075116, val_loss: 0.9527520895004272\n",
      "687, train_loss: 0.9876052118264712, val_loss: 0.9729059934616089\n",
      "688, train_loss: 0.9872427513966193, val_loss: 0.9640864372253418\n",
      "689, train_loss: 0.9905792979093698, val_loss: 0.9731658101081848\n",
      "690, train_loss: 0.9864307137636038, val_loss: 0.960463535785675\n",
      "691, train_loss: 0.9888965670879071, val_loss: 0.9633056998252869\n",
      "692, train_loss: 0.9885599613189697, val_loss: 0.9682308793067932\n",
      "693, train_loss: 0.9882539739975562, val_loss: 0.9501068830490113\n",
      "694, train_loss: 0.9852538475623498, val_loss: 0.9708368182182312\n",
      "695, train_loss: 0.9876946761057928, val_loss: 0.9523377180099487\n",
      "696, train_loss: 0.9851116583897517, val_loss: 0.9645821928977967\n",
      "697, train_loss: 0.9887513059836167, val_loss: 0.9528988122940063\n",
      "698, train_loss: 0.9844369338108943, val_loss: 0.955308485031128\n",
      "699, train_loss: 0.9882385157621824, val_loss: 0.9519622564315796\n",
      "700, train_loss: 0.986823551929914, val_loss: 0.9477857708930969\n",
      "701, train_loss: 0.9833177603208102, val_loss: 0.9497665405273438\n",
      "702, train_loss: 0.9855119585990906, val_loss: 0.9445807337760925\n",
      "703, train_loss: 0.9853435089954963, val_loss: 0.944532036781311\n",
      "704, train_loss: 0.9868413714262155, val_loss: 0.965243399143219\n",
      "705, train_loss: 0.9845509781287267, val_loss: 0.9449517846107482\n",
      "706, train_loss: 0.9818085225728842, val_loss: 0.9676024198532105\n",
      "707, train_loss: 0.9813165343724765, val_loss: 0.9615851283073426\n",
      "708, train_loss: 0.983517756828895, val_loss: 0.9634023785591126\n",
      "709, train_loss: 0.9832596366222088, val_loss: 0.9517171740531921\n",
      "710, train_loss: 0.9802161111281469, val_loss: 0.9434197068214416\n",
      "711, train_loss: 0.9804694950580597, val_loss: 0.945077121257782\n",
      "712, train_loss: 0.9823453151262723, val_loss: 0.9658303260803223\n",
      "713, train_loss: 0.9820072903082921, val_loss: 0.9478480339050293\n",
      "714, train_loss: 0.9828120928544265, val_loss: 0.9477437496185303\n",
      "715, train_loss: 0.9813474233333881, val_loss: 0.9670378684997558\n",
      "716, train_loss: 0.9787142070440146, val_loss: 0.9585628271102905\n",
      "717, train_loss: 0.9814311793217292, val_loss: 0.9438765168190002\n",
      "718, train_loss: 0.9803418517112732, val_loss: 0.9553631186485291\n",
      "719, train_loss: 0.9800039415176098, val_loss: 0.9489702224731446\n",
      "720, train_loss: 0.9771965146064758, val_loss: 0.9609415888786316\n",
      "721, train_loss: 0.9771285721888909, val_loss: 0.9464719653129577\n",
      "722, train_loss: 0.9765444741799281, val_loss: 0.9620375752449035\n",
      "723, train_loss: 0.9796823056844565, val_loss: 0.9647569060325623\n",
      "724, train_loss: 0.9761918508089505, val_loss: 0.9601953625679016\n",
      "725, train_loss: 0.975535702246886, val_loss: 0.9562188625335694\n",
      "726, train_loss: 0.9787117128188794, val_loss: 0.964229154586792\n",
      "727, train_loss: 0.9783602769558246, val_loss: 0.9419395685195923\n",
      "728, train_loss: 0.9746877413529617, val_loss: 0.943111801147461\n",
      "729, train_loss: 0.9741738644930032, val_loss: 0.9412928104400635\n",
      "730, train_loss: 0.9762548345785874, val_loss: 0.9511150121688843\n",
      "731, train_loss: 0.9758470700337336, val_loss: 0.9602985382080078\n",
      "732, train_loss: 0.9755741013930395, val_loss: 0.9652790069580078\n",
      "733, train_loss: 0.9751913868463956, val_loss: 0.9260636806488037\n",
      "734, train_loss: 0.9724604831292079, val_loss: 0.9530738592147827\n",
      "735, train_loss: 0.9722095888394576, val_loss: 0.9444188833236694\n",
      "736, train_loss: 0.9751638747178591, val_loss: 0.9358530640602112\n",
      "737, train_loss: 0.9748052266927866, val_loss: 0.9582852840423584\n",
      "738, train_loss: 0.9743302693733802, val_loss: 0.9558133602142334\n",
      "739, train_loss: 0.9709796722118671, val_loss: 0.9271361231803894\n",
      "740, train_loss: 0.9726797479849595, val_loss: 0.9345784068107605\n",
      "741, train_loss: 0.9724092185497284, val_loss: 0.9331522703170776\n",
      "742, train_loss: 0.9696547870452588, val_loss: 0.953151261806488\n",
      "743, train_loss: 0.9732608818090879, val_loss: 0.9534351706504822\n",
      "744, train_loss: 0.9691805816613711, val_loss: 0.9491391897201538\n",
      "745, train_loss: 0.9709299917404468, val_loss: 0.9555368781089782\n",
      "746, train_loss: 0.9717866044778091, val_loss: 0.9520271062850952\n",
      "747, train_loss: 0.9702113477083353, val_loss: 0.960556709766388\n",
      "748, train_loss: 0.9679755981151874, val_loss: 0.9349053502082825\n",
      "749, train_loss: 0.9671604083134577, val_loss: 0.9660544753074646\n",
      "750, train_loss: 0.9690490273328928, val_loss: 0.9365393042564392\n",
      "751, train_loss: 0.9666088429781107, val_loss: 0.9374760866165162\n",
      "752, train_loss: 0.9696930050849915, val_loss: 0.931307590007782\n",
      "753, train_loss: 0.9679886744572566, val_loss: 0.9494457125663758\n",
      "754, train_loss: 0.9655585013903104, val_loss: 0.9433281660079956\n",
      "755, train_loss: 0.9650362982199743, val_loss: 0.9524866700172424\n",
      "756, train_loss: 0.9647054901489844, val_loss: 0.9577095746994019\n",
      "757, train_loss: 0.9648630527349619, val_loss: 0.9461191415786743\n",
      "758, train_loss: 0.9663283595672021, val_loss: 0.9292370915412903\n",
      "759, train_loss: 0.9638703350837414, val_loss: 0.9566139459609986\n",
      "760, train_loss: 0.9656901840980237, val_loss: 0.9467531323432923\n",
      "761, train_loss: 0.9629326921242934, val_loss: 0.9467053890228272\n",
      "762, train_loss: 0.9628731768864852, val_loss: 0.9173540234565735\n",
      "763, train_loss: 0.9659142379577343, val_loss: 0.9398059010505676\n",
      "764, train_loss: 0.9644107910302969, val_loss: 0.9396296977996826\n",
      "765, train_loss: 0.9640130996704102, val_loss: 0.9467466115951538\n",
      "766, train_loss: 0.9618840584388146, val_loss: 0.926639986038208\n",
      "767, train_loss: 0.9633839153326474, val_loss: 0.9600499153137207\n",
      "768, train_loss: 0.9630777881695674, val_loss: 0.9418263912200928\n",
      "769, train_loss: 0.9639783914272602, val_loss: 0.9496423840522766\n",
      "770, train_loss: 0.9632039070129395, val_loss: 0.935742199420929\n",
      "771, train_loss: 0.9595001890109136, val_loss: 0.9308492779731751\n",
      "772, train_loss: 0.9599765814267672, val_loss: 0.9274423241615295\n",
      "773, train_loss: 0.9590597267334278, val_loss: 0.926349425315857\n",
      "774, train_loss: 0.9611553893639491, val_loss: 0.9449630856513977\n",
      "775, train_loss: 0.9608023648078625, val_loss: 0.9354536890983581\n",
      "776, train_loss: 0.9584151116701273, val_loss: 0.9351091504096984\n",
      "777, train_loss: 0.9601964056491852, val_loss: 0.9383546590805054\n",
      "778, train_loss: 0.9607356282380911, val_loss: 0.9472336411476135\n",
      "779, train_loss: 0.9613893765669602, val_loss: 0.9248006105422973\n",
      "780, train_loss: 0.9592049557429093, val_loss: 0.9263076543807983\n",
      "781, train_loss: 0.9567913298423474, val_loss: 0.9378216981887817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782, train_loss: 0.9585556594225076, val_loss: 0.9392747282981873\n",
      "783, train_loss: 0.95922029706148, val_loss: 0.929268765449524\n",
      "784, train_loss: 0.9557471940150628, val_loss: 0.9386910438537598\n",
      "785, train_loss: 0.9555220764416915, val_loss: 0.9067089676856994\n",
      "786, train_loss: 0.9582878557535318, val_loss: 0.9398625612258911\n",
      "787, train_loss: 0.9589550311748798, val_loss: 0.9237895846366883\n",
      "788, train_loss: 0.9546039677583255, val_loss: 0.9118585467338562\n",
      "789, train_loss: 0.9569660539810474, val_loss: 0.9459577798843384\n",
      "790, train_loss: 0.9568592722599323, val_loss: 0.9342744588851929\n",
      "791, train_loss: 0.9556915462017059, val_loss: 0.9337334394454956\n",
      "792, train_loss: 0.9534737995037665, val_loss: 0.9158557891845703\n",
      "793, train_loss: 0.9557042213586661, val_loss: 0.9170266389846802\n",
      "794, train_loss: 0.9547974673601297, val_loss: 0.9193159103393554\n",
      "795, train_loss: 0.9544483446157895, val_loss: 0.9233400702476502\n",
      "796, train_loss: 0.9554916551479926, val_loss: 0.9277462601661682\n",
      "797, train_loss: 0.9517541046325977, val_loss: 0.9340238690376281\n",
      "798, train_loss: 0.953552055817384, val_loss: 0.9183201789855957\n",
      "799, train_loss: 0.9535739559393662, val_loss: 0.9331236720085144\n",
      "800, train_loss: 0.9541896489950327, val_loss: 0.932689619064331\n",
      "801, train_loss: 0.9507374304991502, val_loss: 0.9307455778121948\n",
      "802, train_loss: 0.9522622502767123, val_loss: 0.9353837251663208\n",
      "803, train_loss: 0.9499300466133997, val_loss: 0.9248287796974182\n",
      "804, train_loss: 0.9497301303423368, val_loss: 0.935750424861908\n",
      "805, train_loss: 0.9523762258199545, val_loss: 0.9112984299659729\n",
      "806, train_loss: 0.9492552142876846, val_loss: 0.8990985989570618\n",
      "807, train_loss: 0.9507469213925875, val_loss: 0.941250741481781\n",
      "808, train_loss: 0.9522424248548654, val_loss: 0.9186665296554566\n",
      "809, train_loss: 0.9517617775843694, val_loss: 0.9314612030982972\n",
      "810, train_loss: 0.9480466544628143, val_loss: 0.9302781581878662\n",
      "811, train_loss: 0.9505069989424485, val_loss: 0.9339244484901428\n",
      "812, train_loss: 0.9471122141067798, val_loss: 0.929148507118225\n",
      "813, train_loss: 0.9467348616856796, val_loss: 0.9376072287559509\n",
      "814, train_loss: 0.9465073599265172, val_loss: 0.925782322883606\n",
      "815, train_loss: 0.9496766099563012, val_loss: 0.9092040300369263\n",
      "816, train_loss: 0.9480929305920234, val_loss: 0.934816312789917\n",
      "817, train_loss: 0.9456277375037854, val_loss: 0.9084086298942566\n",
      "818, train_loss: 0.947534822500669, val_loss: 0.8950725317001342\n",
      "819, train_loss: 0.948599405013598, val_loss: 0.9308323621749878\n",
      "820, train_loss: 0.9469398764463571, val_loss: 0.9235714912414551\n",
      "821, train_loss: 0.9443039687780234, val_loss: 0.9182618737220765\n",
      "822, train_loss: 0.9462785674975469, val_loss: 0.9178125619888305\n",
      "823, train_loss: 0.9441357553005219, val_loss: 0.9100038290023804\n",
      "824, train_loss: 0.9437140363913316, val_loss: 0.9306069016456604\n",
      "825, train_loss: 0.9435330927371979, val_loss: 0.9148861765861511\n",
      "826, train_loss: 0.9451187092524308, val_loss: 0.8941837310791015\n",
      "827, train_loss: 0.9463087228628305, val_loss: 0.9347942233085632\n",
      "828, train_loss: 0.9445509199912732, val_loss: 0.9307852029800415\n",
      "829, train_loss: 0.9425018590230209, val_loss: 0.905641520023346\n",
      "830, train_loss: 0.9419314746673291, val_loss: 0.8942404866218567\n",
      "831, train_loss: 0.9454227089881897, val_loss: 0.9216639518737793\n",
      "832, train_loss: 0.9434126982322106, val_loss: 0.919053316116333\n",
      "833, train_loss: 0.9445895048288199, val_loss: 0.9103060245513916\n",
      "834, train_loss: 0.9410775510164407, val_loss: 0.9039139986038208\n",
      "835, train_loss: 0.942584542127756, val_loss: 0.9151427030563355\n",
      "836, train_loss: 0.9423137192542737, val_loss: 0.9112303018569946\n",
      "837, train_loss: 0.9400835197705489, val_loss: 0.9161782383918762\n",
      "838, train_loss: 0.9433205723762512, val_loss: 0.9103557825088501\n",
      "839, train_loss: 0.9396432110896478, val_loss: 0.9039946794509888\n",
      "840, train_loss: 0.9411675654924833, val_loss: 0.9263887524604797\n",
      "841, train_loss: 0.9419598694031055, val_loss: 0.9035674929618835\n",
      "842, train_loss: 0.9389377396840316, val_loss: 0.9055141091346741\n",
      "843, train_loss: 0.9413774701265188, val_loss: 0.9175644278526306\n",
      "844, train_loss: 0.9415008907134716, val_loss: 0.9036953330039978\n",
      "845, train_loss: 0.9414836626786453, val_loss: 0.912366247177124\n",
      "846, train_loss: 0.9406061585132892, val_loss: 0.8959433555603027\n",
      "847, train_loss: 0.9391465553870568, val_loss: 0.8880170941352844\n",
      "848, train_loss: 0.9371178356500772, val_loss: 0.921924352645874\n",
      "849, train_loss: 0.9394756830655612, val_loss: 0.9044112443923951\n",
      "850, train_loss: 0.9382760799848117, val_loss: 0.9154503226280213\n",
      "851, train_loss: 0.9380146677677448, val_loss: 0.9021180510520935\n",
      "852, train_loss: 0.9388905855325552, val_loss: 0.92080717086792\n",
      "853, train_loss: 0.9374430981966165, val_loss: 0.9116254448890686\n",
      "854, train_loss: 0.9371304924671466, val_loss: 0.894614577293396\n",
      "855, train_loss: 0.9368584316510421, val_loss: 0.9135676383972168\n",
      "856, train_loss: 0.938631724852782, val_loss: 0.8849066972732544\n",
      "857, train_loss: 0.9363298691236056, val_loss: 0.893683397769928\n",
      "858, train_loss: 0.933764595251817, val_loss: 0.9037847757339478\n",
      "859, train_loss: 0.9338508890225337, val_loss: 0.9034801959991455\n",
      "860, train_loss: 0.9367715097390689, val_loss: 0.899858272075653\n",
      "861, train_loss: 0.9371198415756226, val_loss: 0.8913941264152527\n",
      "862, train_loss: 0.9370626050692338, val_loss: 0.9170851469039917\n",
      "863, train_loss: 0.9330554535755744, val_loss: 0.8956954717636109\n",
      "864, train_loss: 0.9368005349085882, val_loss: 0.9124717354774475\n",
      "865, train_loss: 0.9341446734391726, val_loss: 0.9010616779327393\n",
      "866, train_loss: 0.9351395208102006, val_loss: 0.9224346995353698\n",
      "867, train_loss: 0.933557567688135, val_loss: 0.8890669226646424\n",
      "868, train_loss: 0.9314684065488669, val_loss: 0.9059165358543396\n",
      "869, train_loss: 0.9330163277112521, val_loss: 0.9143490791320801\n",
      "870, train_loss: 0.9327608117690454, val_loss: 0.9060667395591736\n",
      "871, train_loss: 0.9324513261134808, val_loss: 0.9174007058143616\n",
      "872, train_loss: 0.9339097096369817, val_loss: 0.916033673286438\n",
      "873, train_loss: 0.9301608342390794, val_loss: 0.9019147515296936\n",
      "874, train_loss: 0.9329368426249578, val_loss: 0.8938996195793152\n",
      "875, train_loss: 0.9326710586364453, val_loss: 0.8933011412620544\n",
      "876, train_loss: 0.9290905869924105, val_loss: 0.8862199783325195\n",
      "877, train_loss: 0.9289288108165448, val_loss: 0.9027666807174682\n",
      "878, train_loss: 0.928836485514274, val_loss: 0.9050149917602539\n",
      "879, train_loss: 0.9323866138091454, val_loss: 0.9003558993339539\n",
      "880, train_loss: 0.9325359440766848, val_loss: 0.904620885848999\n",
      "881, train_loss: 0.9297301838031182, val_loss: 0.9114318490028381\n",
      "882, train_loss: 0.9278931892835177, val_loss: 0.904235577583313\n",
      "883, train_loss: 0.9292053373960348, val_loss: 0.8945096373558045\n",
      "884, train_loss: 0.9266745952459482, val_loss: 0.9148223996162415\n",
      "885, train_loss: 0.9269694708860837, val_loss: 0.8826765537261962\n",
      "886, train_loss: 0.9283697100786062, val_loss: 0.9156607031822205\n",
      "887, train_loss: 0.9298196687148168, val_loss: 0.9176498293876648\n",
      "888, train_loss: 0.9260558761083163, val_loss: 0.8995723962783814\n",
      "889, train_loss: 0.92588744025964, val_loss: 0.886977207660675\n",
      "890, train_loss: 0.9256169131168952, val_loss: 0.9206371307373047\n",
      "891, train_loss: 0.9285614192485809, val_loss: 0.8901845932006835\n",
      "892, train_loss: 0.9249336490264306, val_loss: 0.8919067144393921\n",
      "893, train_loss: 0.9289656327320979, val_loss: 0.8937799572944641\n",
      "894, train_loss: 0.9282232866837428, val_loss: 0.8818360090255737\n",
      "895, train_loss: 0.9267257795884059, val_loss: 0.8933534741401672\n",
      "896, train_loss: 0.9275656411280999, val_loss: 0.8838934302330017\n",
      "897, train_loss: 0.9235911736121545, val_loss: 0.8970851182937623\n",
      "898, train_loss: 0.9233808265282557, val_loss: 0.9024190902709961\n",
      "899, train_loss: 0.9230941534042358, val_loss: 0.8966108083724975\n",
      "900, train_loss: 0.9260261265131143, val_loss: 0.86721773147583\n",
      "901, train_loss: 0.9243250282911154, val_loss: 0.8692282319068909\n",
      "902, train_loss: 0.9258929720291724, val_loss: 0.8878708720207215\n",
      "903, train_loss: 0.9253557714132162, val_loss: 0.884756863117218\n",
      "904, train_loss: 0.9219756516126486, val_loss: 0.8921074032783508\n",
      "905, train_loss: 0.9232035875320435, val_loss: 0.8653589367866517\n",
      "906, train_loss: 0.9229062772714175, val_loss: 0.8755588889122009\n",
      "907, train_loss: 0.9210306474795709, val_loss: 0.8994012951850892\n",
      "908, train_loss: 0.9206627538570991, val_loss: 0.8810561299324036\n",
      "909, train_loss: 0.9245127141475677, val_loss: 0.8823762536048889\n",
      "910, train_loss: 0.921924522289863, val_loss: 0.9056525349617004\n",
      "911, train_loss: 0.9239601859679589, val_loss: 0.8798167824745178\n",
      "912, train_loss: 0.9214213582185599, val_loss: 0.9013266444206238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913, train_loss: 0.9196188128911532, val_loss: 0.8917195558547973\n",
      "914, train_loss: 0.9208895976726825, val_loss: 0.9031549096107483\n",
      "915, train_loss: 0.9190924580280597, val_loss: 0.8802514791488647\n",
      "916, train_loss: 0.9222993300511286, val_loss: 0.8970582604408264\n",
      "917, train_loss: 0.9201018214225769, val_loss: 0.8635424971580505\n",
      "918, train_loss: 0.9214347348763392, val_loss: 0.892333447933197\n",
      "919, train_loss: 0.9217081276270059, val_loss: 0.8915746092796326\n",
      "920, train_loss: 0.9192071167322305, val_loss: 0.898888111114502\n",
      "921, train_loss: 0.9173656495717856, val_loss: 0.8821076989173889\n",
      "922, train_loss: 0.9187741485925821, val_loss: 0.8845871090888977\n",
      "923, train_loss: 0.9167189987806174, val_loss: 0.8880637288093567\n",
      "924, train_loss: 0.9165017054631159, val_loss: 0.880084216594696\n",
      "925, train_loss: 0.9155804537809812, val_loss: 0.8608506202697754\n",
      "926, train_loss: 0.9199101283000066, val_loss: 0.887021791934967\n",
      "927, train_loss: 0.9156642831288851, val_loss: 0.8891791343688965\n",
      "928, train_loss: 0.919526049723992, val_loss: 0.8862275123596192\n",
      "929, train_loss: 0.9187664481309744, val_loss: 0.8861306190490723\n",
      "930, train_loss: 0.9148803307459905, val_loss: 0.8678433418273925\n",
      "931, train_loss: 0.9183575763152196, val_loss: 0.8777625799179077\n",
      "932, train_loss: 0.9161154627799988, val_loss: 0.8873172640800476\n",
      "933, train_loss: 0.9158429572215447, val_loss: 0.8741017580032349\n",
      "934, train_loss: 0.9139884205964895, val_loss: 0.8807488083839417\n",
      "935, train_loss: 0.9153067951018994, val_loss: 0.8761240243911743\n",
      "936, train_loss: 0.9173241830789126, val_loss: 0.8653958559036254\n",
      "937, train_loss: 0.9130656604583447, val_loss: 0.8916588187217712\n",
      "938, train_loss: 0.9144897781885587, val_loss: 0.8812220811843872\n",
      "939, train_loss: 0.9124293075158045, val_loss: 0.9018515706062317\n",
      "940, train_loss: 0.9123313449896299, val_loss: 0.8910791039466858\n",
      "941, train_loss: 0.9115792237795316, val_loss: 0.8814268946647644\n",
      "942, train_loss: 0.9152039289474487, val_loss: 0.889008104801178\n",
      "943, train_loss: 0.9132348299026489, val_loss: 0.8735937118530274\n",
      "944, train_loss: 0.9159813569142268, val_loss: 0.8875808358192444\n",
      "945, train_loss: 0.9109818476897019, val_loss: 0.8896912097930908\n",
      "946, train_loss: 0.9123536806840163, val_loss: 0.8971415638923645\n",
      "947, train_loss: 0.9120012957316178, val_loss: 0.8797685980796814\n",
      "948, train_loss: 0.9103135420725896, val_loss: 0.8718403816223145\n",
      "949, train_loss: 0.9116130150281466, val_loss: 0.8790218472480774\n",
      "950, train_loss: 0.9113682921116169, val_loss: 0.8624996900558471\n",
      "951, train_loss: 0.9110894409509805, val_loss: 0.8868698954582215\n",
      "952, train_loss: 0.9108587480508364, val_loss: 0.8601040482521057\n",
      "953, train_loss: 0.9086816402582022, val_loss: 0.8669050931930542\n",
      "954, train_loss: 0.9122894429243528, val_loss: 0.8617067933082581\n",
      "955, train_loss: 0.9086629931743329, val_loss: 0.8688051700592041\n",
      "956, train_loss: 0.9098540223561801, val_loss: 0.896504533290863\n",
      "957, train_loss: 0.9111927059980539, val_loss: 0.866567051410675\n",
      "958, train_loss: 0.9091800084480872, val_loss: 0.8688674092292785\n",
      "959, train_loss: 0.9090139132279617, val_loss: 0.8476544499397278\n",
      "960, train_loss: 0.9087534844875336, val_loss: 0.8673636436462402\n",
      "961, train_loss: 0.9102195822275602, val_loss: 0.8761178493499756\n",
      "962, train_loss: 0.9082416892051697, val_loss: 0.8749033689498902\n",
      "963, train_loss: 0.9078521545116718, val_loss: 0.8690855026245117\n",
      "964, train_loss: 0.9077277687879709, val_loss: 0.8664855718612671\n",
      "965, train_loss: 0.9096764234396127, val_loss: 0.8915605664253234\n",
      "966, train_loss: 0.9071957446061648, val_loss: 0.8553572535514832\n",
      "967, train_loss: 0.905568356697376, val_loss: 0.8638458847999573\n",
      "968, train_loss: 0.9052800948803241, val_loss: 0.8731701970100403\n",
      "969, train_loss: 0.9089083488170917, val_loss: 0.8723054170608521\n",
      "970, train_loss: 0.9039095525558178, val_loss: 0.8725106000900269\n",
      "971, train_loss: 0.9081896566427671, val_loss: 0.8538382411003113\n",
      "972, train_loss: 0.9056299305879153, val_loss: 0.8635665893554687\n",
      "973, train_loss: 0.9051839525883014, val_loss: 0.8613244652748108\n",
      "974, train_loss: 0.9034875860581031, val_loss: 0.8722661852836608\n",
      "975, train_loss: 0.9047893973497244, val_loss: 0.884500515460968\n",
      "976, train_loss: 0.9062708707956167, val_loss: 0.8728742122650146\n",
      "977, train_loss: 0.9042688447695512, val_loss: 0.8810350060462951\n",
      "978, train_loss: 0.9038862998668964, val_loss: 0.8767304420471191\n",
      "979, train_loss: 0.9037151451294239, val_loss: 0.8624393224716187\n",
      "980, train_loss: 0.9034322270980248, val_loss: 0.8779320001602173\n",
      "981, train_loss: 0.9031642560775464, val_loss: 0.8684261798858642\n",
      "982, train_loss: 0.9029347988275381, val_loss: 0.8696305513381958\n",
      "983, train_loss: 0.9041294822326074, val_loss: 0.8773452520370484\n",
      "984, train_loss: 0.9023418426513672, val_loss: 0.879224693775177\n",
      "985, train_loss: 0.9039932672794049, val_loss: 0.8673657536506653\n",
      "986, train_loss: 0.9018306640478281, val_loss: 0.8742088913917542\n",
      "987, train_loss: 0.9014297654995551, val_loss: 0.8781253814697265\n",
      "988, train_loss: 0.9035198092460632, val_loss: 0.8696638703346252\n",
      "989, train_loss: 0.9032390117645264, val_loss: 0.8570823788642883\n",
      "990, train_loss: 0.9033586359941043, val_loss: 0.8678485989570618\n",
      "991, train_loss: 0.8988745418878702, val_loss: 0.8484328269958497\n",
      "992, train_loss: 0.8985496484316312, val_loss: 0.861077082157135\n",
      "993, train_loss: 0.8999160023835989, val_loss: 0.8751659274101258\n",
      "994, train_loss: 0.9015430303720328, val_loss: 0.856756043434143\n",
      "995, train_loss: 0.8995012434629294, val_loss: 0.8575382590293884\n",
      "996, train_loss: 0.8975800023629115, val_loss: 0.8541008591651916\n",
      "997, train_loss: 0.9004695667670324, val_loss: 0.8640750169754028\n",
      "998, train_loss: 0.8986495710336245, val_loss: 0.8566888570785522\n",
      "999, train_loss: 0.8984678181318136, val_loss: 0.8526496648788452\n",
      "1000, train_loss: 0.9007932750078348, val_loss: 0.8341180086135864\n",
      "1001, train_loss: 0.8977872385428503, val_loss: 0.8337556838989257\n",
      "1002, train_loss: 0.8958995181780595, val_loss: 0.8652449607849121\n",
      "1003, train_loss: 0.8973716084773724, val_loss: 0.8717057943344116\n",
      "1004, train_loss: 0.8989982650830195, val_loss: 0.8688560009002686\n",
      "1005, train_loss: 0.8969628810882568, val_loss: 0.8439189672470093\n",
      "1006, train_loss: 0.8956352816178248, val_loss: 0.8416308760643005\n",
      "1007, train_loss: 0.8964125834978544, val_loss: 0.8680448412895203\n",
      "1008, train_loss: 0.8992399137753707, val_loss: 0.8602895855903625\n",
      "1009, train_loss: 0.89436297921034, val_loss: 0.8623144268989563\n",
      "1010, train_loss: 0.8981343737015357, val_loss: 0.8762246608734131\n",
      "1011, train_loss: 0.8975213353450482, val_loss: 0.8514674186706543\n",
      "1012, train_loss: 0.8951361431525304, val_loss: 0.8625484347343445\n",
      "1013, train_loss: 0.8967710251991565, val_loss: 0.8584303855895996\n",
      "1014, train_loss: 0.894674674822734, val_loss: 0.8712668299674988\n",
      "1015, train_loss: 0.8942279494725741, val_loss: 0.8618957996368408\n",
      "1016, train_loss: 0.8968315124511719, val_loss: 0.8406511425971985\n",
      "1017, train_loss: 0.8938300861762121, val_loss: 0.8404942989349365\n",
      "1018, train_loss: 0.8914513083604666, val_loss: 0.8490211844444275\n",
      "1019, train_loss: 0.892028652704679, val_loss: 0.8494180798530578\n",
      "1020, train_loss: 0.8953016560811263, val_loss: 0.8695894598960876\n",
      "1021, train_loss: 0.8941114499018743, val_loss: 0.831830894947052\n",
      "1022, train_loss: 0.8926802575588226, val_loss: 0.857129693031311\n",
      "1023, train_loss: 0.8906929057378036, val_loss: 0.8493102192878723\n",
      "1024, train_loss: 0.8920865333997287, val_loss: 0.8722800731658935\n",
      "1025, train_loss: 0.8938479263048905, val_loss: 0.8649116516113281\n",
      "1026, train_loss: 0.889949197952564, val_loss: 0.8359166979789734\n",
      "1027, train_loss: 0.8933740143592541, val_loss: 0.8740474224090576\n",
      "1028, train_loss: 0.8910596783344562, val_loss: 0.8760205149650574\n",
      "1029, train_loss: 0.8907956526829646, val_loss: 0.8278578996658326\n",
      "1030, train_loss: 0.8929944932460785, val_loss: 0.8574189901351928\n",
      "1031, train_loss: 0.8885509234208328, val_loss: 0.8570683240890503\n",
      "1032, train_loss: 0.8900339534649482, val_loss: 0.8376978516578675\n",
      "1033, train_loss: 0.8886574117036966, val_loss: 0.8730342507362365\n",
      "1034, train_loss: 0.8880819426133082, val_loss: 0.8284252882003784\n",
      "1035, train_loss: 0.8873637937582456, val_loss: 0.8601372838020325\n",
      "1036, train_loss: 0.8890661436777848, val_loss: 0.8556928873062134\n",
      "1037, train_loss: 0.8887970195366786, val_loss: 0.8651085495948792\n",
      "1038, train_loss: 0.8884413379889268, val_loss: 0.8774451971054077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1039, train_loss: 0.8905010383862716, val_loss: 0.8268477320671082\n",
      "1040, train_loss: 0.8899123233098251, val_loss: 0.8322584986686706\n",
      "1041, train_loss: 0.8877251079449286, val_loss: 0.8584004044532776\n",
      "1042, train_loss: 0.8873191200769864, val_loss: 0.8434186339378357\n",
      "1043, train_loss: 0.8903416693210602, val_loss: 0.8697062969207764\n",
      "1044, train_loss: 0.8889957139125237, val_loss: 0.8656029105186462\n",
      "1045, train_loss: 0.8866935899624457, val_loss: 0.8485628008842468\n",
      "1046, train_loss: 0.8862833472398611, val_loss: 0.8676131129264831\n",
      "1047, train_loss: 0.8860588532227737, val_loss: 0.8305451154708863\n",
      "1048, train_loss: 0.8877580005388993, val_loss: 0.833618414402008\n",
      "1049, train_loss: 0.8874861827263465, val_loss: 0.833731186389923\n",
      "1050, train_loss: 0.8873905745836405, val_loss: 0.8524215698242188\n",
      "1051, train_loss: 0.8832229971885681, val_loss: 0.8433195352554321\n",
      "1052, train_loss: 0.8832749678538396, val_loss: 0.8637366652488708\n",
      "1053, train_loss: 0.8861809120728419, val_loss: 0.8221179366111755\n",
      "1054, train_loss: 0.8824219245177048, val_loss: 0.8510486245155334\n",
      "1055, train_loss: 0.882582024886058, val_loss: 0.8590255737304687\n",
      "1056, train_loss: 0.8823286822208991, val_loss: 0.8482124209403992\n",
      "1057, train_loss: 0.8814171254634857, val_loss: 0.8209847569465637\n",
      "1058, train_loss: 0.8848968400405004, val_loss: 0.827716326713562\n",
      "1059, train_loss: 0.8828479785185593, val_loss: 0.8291179895401001\n",
      "1060, train_loss: 0.8827195809437678, val_loss: 0.8531794071197509\n",
      "1061, train_loss: 0.8849508212162898, val_loss: 0.8198786616325379\n",
      "1062, train_loss: 0.8845992386341095, val_loss: 0.8177013993263245\n",
      "1063, train_loss: 0.8840285104054671, val_loss: 0.8464066386222839\n",
      "1064, train_loss: 0.8816441320455991, val_loss: 0.854893958568573\n",
      "1065, train_loss: 0.8813646527437063, val_loss: 0.8485710859298706\n",
      "1066, train_loss: 0.8833357622990241, val_loss: 0.8363117337226867\n",
      "1067, train_loss: 0.8796376723509568, val_loss: 0.8480066180229187\n",
      "1068, train_loss: 0.880587772681163, val_loss: 0.8355673551559448\n",
      "1069, train_loss: 0.8803074061870575, val_loss: 0.8283217310905456\n",
      "1070, train_loss: 0.8799317043561202, val_loss: 0.8468771696090698\n",
      "1071, train_loss: 0.8783533504376044, val_loss: 0.8360689878463745\n",
      "1072, train_loss: 0.8794766228932601, val_loss: 0.8338449478149415\n",
      "1073, train_loss: 0.8780390482682449, val_loss: 0.84340740442276\n",
      "1074, train_loss: 0.8815960586071014, val_loss: 0.8375936627388001\n",
      "1075, train_loss: 0.8775023382443649, val_loss: 0.8590670347213745\n",
      "1076, train_loss: 0.878516293489016, val_loss: 0.8245771408081055\n",
      "1077, train_loss: 0.8801014721393585, val_loss: 0.8179020762443543\n",
      "1078, train_loss: 0.8797745521251972, val_loss: 0.8633186936378479\n",
      "1079, train_loss: 0.8776883161984957, val_loss: 0.8511015176773071\n",
      "1080, train_loss: 0.8760383610542004, val_loss: 0.8545170307159424\n",
      "1081, train_loss: 0.8755775162806878, val_loss: 0.8403463721275329\n",
      "1082, train_loss: 0.8755626609692206, val_loss: 0.8438625454902648\n",
      "1083, train_loss: 0.8764844972353715, val_loss: 0.8435728430747986\n",
      "1084, train_loss: 0.8783838863556201, val_loss: 0.8335190653800965\n",
      "1085, train_loss: 0.8780615811164563, val_loss: 0.8528944492340088\n",
      "1086, train_loss: 0.8758733983223255, val_loss: 0.8240366816520691\n",
      "1087, train_loss: 0.873932400575051, val_loss: 0.8302289247512817\n",
      "1088, train_loss: 0.8753312826156616, val_loss: 0.8460356950759887\n",
      "1089, train_loss: 0.8751406715466425, val_loss: 0.8230292677879334\n",
      "1090, train_loss: 0.8748846971071683, val_loss: 0.8292168498039245\n",
      "1091, train_loss: 0.8746059468159308, val_loss: 0.831918454170227\n",
      "1092, train_loss: 0.8729254947258875, val_loss: 0.8475358247756958\n",
      "1093, train_loss: 0.8723536408864535, val_loss: 0.8528839945793152\n",
      "1094, train_loss: 0.8772523334393134, val_loss: 0.8535971760749816\n",
      "1095, train_loss: 0.8724409983708308, val_loss: 0.8382832288742066\n",
      "1096, train_loss: 0.8753800460925469, val_loss: 0.8277398586273194\n",
      "1097, train_loss: 0.8731145996313828, val_loss: 0.8274579286575318\n",
      "1098, train_loss: 0.8719430634608636, val_loss: 0.8275508522987366\n",
      "1099, train_loss: 0.8748942476052505, val_loss: 0.8267187118530274\n",
      "1100, train_loss: 0.87517049908638, val_loss: 0.8185761094093322\n",
      "1101, train_loss: 0.870767932671767, val_loss: 0.8183411478996276\n",
      "1102, train_loss: 0.8718637434335855, val_loss: 0.847645890712738\n",
      "1103, train_loss: 0.8716500034699073, val_loss: 0.8420399069786072\n",
      "1104, train_loss: 0.8734472004266886, val_loss: 0.8177556157112121\n",
      "1105, train_loss: 0.8692016899585724, val_loss: 0.8264646649360656\n",
      "1106, train_loss: 0.8692550682104551, val_loss: 0.8339869022369385\n",
      "1107, train_loss: 0.8705691259640914, val_loss: 0.8326501965522766\n",
      "1108, train_loss: 0.8694685880954449, val_loss: 0.8325431704521179\n",
      "1109, train_loss: 0.872282665509444, val_loss: 0.8243138074874878\n",
      "1110, train_loss: 0.8684441355558542, val_loss: 0.81437828540802\n",
      "1111, train_loss: 0.8723984681642972, val_loss: 0.8402148246765136\n",
      "1112, train_loss: 0.8682308059472305, val_loss: 0.8336419939994812\n",
      "1113, train_loss: 0.8679108390441308, val_loss: 0.8321511030197144\n",
      "1114, train_loss: 0.8711801767349243, val_loss: 0.8232373833656311\n",
      "1115, train_loss: 0.8686814674964318, val_loss: 0.8133948564529419\n",
      "1116, train_loss: 0.8707778362127451, val_loss: 0.8323347330093384\n",
      "1117, train_loss: 0.8698856303325067, val_loss: 0.814176082611084\n",
      "1118, train_loss: 0.8678395816913018, val_loss: 0.8512463569641113\n",
      "1119, train_loss: 0.8700472093545474, val_loss: 0.8073071002960205\n",
      "1120, train_loss: 0.869504112463731, val_loss: 0.8317772626876831\n",
      "1121, train_loss: 0.8658054791964017, val_loss: 0.8398395895957946\n",
      "1122, train_loss: 0.8656507524160238, val_loss: 0.8475071668624878\n",
      "1123, train_loss: 0.8666354692899264, val_loss: 0.836726713180542\n",
      "1124, train_loss: 0.8689915950481708, val_loss: 0.8312238693237305\n",
      "1125, train_loss: 0.8660362362861633, val_loss: 0.8265570044517517\n",
      "1126, train_loss: 0.864967052753155, val_loss: 0.8326764822006225\n",
      "1127, train_loss: 0.865576473566202, val_loss: 0.8226233720779419\n",
      "1128, train_loss: 0.8678546272791349, val_loss: 0.8428520798683167\n",
      "1129, train_loss: 0.8650589562379397, val_loss: 0.8355579137802124\n",
      "1130, train_loss: 0.8646863263386947, val_loss: 0.8290322065353394\n",
      "1131, train_loss: 0.867194272004641, val_loss: 0.8217458486557007\n",
      "1132, train_loss: 0.86438571031277, val_loss: 0.8247649669647217\n",
      "1133, train_loss: 0.8641441854146811, val_loss: 0.8283547520637512\n",
      "1134, train_loss: 0.8625317720266489, val_loss: 0.8344537734985351\n",
      "1135, train_loss: 0.8634101037795727, val_loss: 0.8174001812934876\n",
      "1136, train_loss: 0.8633609780898461, val_loss: 0.8094386458396912\n",
      "1137, train_loss: 0.8655762145152459, val_loss: 0.8191669106483459\n",
      "1138, train_loss: 0.8614844840306503, val_loss: 0.8197688460350037\n",
      "1139, train_loss: 0.8649932031448071, val_loss: 0.8210191845893859\n",
      "1140, train_loss: 0.865531515616637, val_loss: 0.8372846245765686\n",
      "1141, train_loss: 0.8620907687223874, val_loss: 0.8412742614746094\n",
      "1142, train_loss: 0.8650844670259036, val_loss: 0.8066830992698669\n",
      "1143, train_loss: 0.8647572168937097, val_loss: 0.8366039395332336\n",
      "1144, train_loss: 0.8632389994767996, val_loss: 0.8286021232604981\n",
      "1145, train_loss: 0.8630947378965524, val_loss: 0.8365564942359924\n",
      "1146, train_loss: 0.8597206312876481, val_loss: 0.8217706441879272\n",
      "1147, train_loss: 0.8606694042682648, val_loss: 0.8359305500984192\n",
      "1148, train_loss: 0.8603033515123221, val_loss: 0.8252204298973084\n",
      "1149, train_loss: 0.8601618844729203, val_loss: 0.8240976452827453\n",
      "1150, train_loss: 0.859883562876628, val_loss: 0.8243183135986328\n",
      "1151, train_loss: 0.8596137784994565, val_loss: 0.8142851114273071\n",
      "1152, train_loss: 0.8577539989581475, val_loss: 0.8168537020683289\n",
      "1153, train_loss: 0.8589663459704473, val_loss: 0.8236201405525208\n",
      "1154, train_loss: 0.857662171125412, val_loss: 0.8133958578109741\n",
      "1155, train_loss: 0.8608577297284052, val_loss: 0.8355885148048401\n",
      "1156, train_loss: 0.8572988762305334, val_loss: 0.8196781992912292\n",
      "1157, train_loss: 0.8570880110447223, val_loss: 0.8474240899085999\n",
      "1158, train_loss: 0.8579635918140411, val_loss: 0.8135488390922546\n",
      "1159, train_loss: 0.857559486077382, val_loss: 0.7986398220062256\n",
      "1160, train_loss: 0.8604668149581323, val_loss: 0.8367233157157898\n",
      "1161, train_loss: 0.8571417492169601, val_loss: 0.8382103085517884\n",
      "1162, train_loss: 0.8566891298844264, val_loss: 0.8180140018463135\n",
      "1163, train_loss: 0.8566554670150464, val_loss: 0.8127097606658935\n",
      "1164, train_loss: 0.8563323800380414, val_loss: 0.8395985960960388\n",
      "1165, train_loss: 0.8581748971572289, val_loss: 0.8213273406028747\n",
      "1166, train_loss: 0.8581870885995718, val_loss: 0.8152381777763367\n",
      "1167, train_loss: 0.8577829874478854, val_loss: 0.8122712850570679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168, train_loss: 0.8544202309388381, val_loss: 0.7937962532043457\n",
      "1169, train_loss: 0.855141804768489, val_loss: 0.8145133495330811\n",
      "1170, train_loss: 0.8580698737731347, val_loss: 0.8326186299324035\n",
      "1171, train_loss: 0.8578015221999242, val_loss: 0.8383652210235596\n",
      "1172, train_loss: 0.854361375937095, val_loss: 0.8315580606460571\n",
      "1173, train_loss: 0.8564846492730654, val_loss: 0.8186366200447083\n",
      "1174, train_loss: 0.852991562623244, val_loss: 0.8313896298408509\n",
      "1175, train_loss: 0.8525589544039506, val_loss: 0.8088957905769348\n",
      "1176, train_loss: 0.8522803898041065, val_loss: 0.8137254118919373\n",
      "1177, train_loss: 0.8529086112976074, val_loss: 0.819084620475769\n",
      "1178, train_loss: 0.8548433069999402, val_loss: 0.8007587790489197\n",
      "1179, train_loss: 0.852621351297085, val_loss: 0.8006803631782532\n",
      "1180, train_loss: 0.8523739759738629, val_loss: 0.8119074106216431\n",
      "1181, train_loss: 0.8506954885446109, val_loss: 0.8161742448806762\n",
      "1182, train_loss: 0.8539145703499134, val_loss: 0.8275006890296936\n",
      "1183, train_loss: 0.8515606362086076, val_loss: 0.7991259217262268\n",
      "1184, train_loss: 0.8533492867763226, val_loss: 0.8164920926094055\n",
      "1185, train_loss: 0.849818800504391, val_loss: 0.8162612915039062\n",
      "1186, train_loss: 0.8528336836741521, val_loss: 0.8063735604286194\n",
      "1187, train_loss: 0.8505959808826447, val_loss: 0.8181862711906434\n",
      "1188, train_loss: 0.8488512749855335, val_loss: 0.8332275509834289\n",
      "1189, train_loss: 0.8491820830565232, val_loss: 0.797878646850586\n",
      "1190, train_loss: 0.8525752585667831, val_loss: 0.8245322585105896\n",
      "1191, train_loss: 0.8526737689971924, val_loss: 0.8085365176200867\n",
      "1192, train_loss: 0.8492751304919903, val_loss: 0.8277149796485901\n",
      "1193, train_loss: 0.8481569129687089, val_loss: 0.804505443572998\n",
      "1194, train_loss: 0.8487855998369364, val_loss: 0.8125895738601685\n",
      "1195, train_loss: 0.8484814808918879, val_loss: 0.7896739363670349\n",
      "1196, train_loss: 0.8480535080799689, val_loss: 0.8195260763168335\n",
      "1197, train_loss: 0.8469300613953517, val_loss: 0.7874964714050293\n",
      "1198, train_loss: 0.8498256000188681, val_loss: 0.8253254532814026\n",
      "1199, train_loss: 0.8499828599966489, val_loss: 0.8079957962036133\n",
      "1200, train_loss: 0.8503475051659805, val_loss: 0.8137305617332459\n",
      "1201, train_loss: 0.8495955765247345, val_loss: 0.8059109807014465\n",
      "1202, train_loss: 0.8466882889087384, val_loss: 0.8247227549552918\n",
      "1203, train_loss: 0.8453396260738373, val_loss: 0.8067453026771545\n",
      "1204, train_loss: 0.8489819375368265, val_loss: 0.8295236110687256\n",
      "1205, train_loss: 0.8448140025138855, val_loss: 0.8045655488967896\n",
      "1206, train_loss: 0.8455776411753434, val_loss: 0.8019620656967164\n",
      "1207, train_loss: 0.8446531800123361, val_loss: 0.8297384023666382\n",
      "1208, train_loss: 0.8450439870357513, val_loss: 0.8216819524765014\n",
      "1209, train_loss: 0.8441401169850276, val_loss: 0.7939732193946838\n",
      "1210, train_loss: 0.8445288791106298, val_loss: 0.8017832159996032\n",
      "1211, train_loss: 0.8428227442961472, val_loss: 0.8289159893989563\n",
      "1212, train_loss: 0.8431861102581024, val_loss: 0.793015205860138\n",
      "1213, train_loss: 0.8430784482222337, val_loss: 0.7929127216339111\n",
      "1214, train_loss: 0.8424679751579578, val_loss: 0.8154004335403442\n",
      "1215, train_loss: 0.8433153056181394, val_loss: 0.819304347038269\n",
      "1216, train_loss: 0.8416132720617148, val_loss: 0.8012986779212952\n",
      "1217, train_loss: 0.8430354182536786, val_loss: 0.8213564991950989\n",
      "1218, train_loss: 0.8419664456294134, val_loss: 0.8062713980674744\n",
      "1219, train_loss: 0.8447802502375382, val_loss: 0.8328363180160523\n",
      "1220, train_loss: 0.8414625983971816, val_loss: 0.8082227230072021\n",
      "1221, train_loss: 0.8419614617641156, val_loss: 0.8080923914909363\n",
      "1222, train_loss: 0.8415601826631106, val_loss: 0.8084935188293457\n",
      "1223, train_loss: 0.8400279375223013, val_loss: 0.8097281575202941\n",
      "1224, train_loss: 0.8433111011981964, val_loss: 0.8177531361579895\n",
      "1225, train_loss: 0.8410792419543633, val_loss: 0.7902976989746093\n",
      "1226, train_loss: 0.8428111190979297, val_loss: 0.7981770157814025\n",
      "1227, train_loss: 0.8397173698131855, val_loss: 0.8043004512786865\n",
      "1228, train_loss: 0.8403038222056168, val_loss: 0.8039454936981201\n",
      "1229, train_loss: 0.8390499926530398, val_loss: 0.8099523663520813\n",
      "1230, train_loss: 0.8423983408854558, val_loss: 0.7985654354095459\n",
      "1231, train_loss: 0.8395532277914194, val_loss: 0.8061447739601135\n",
      "1232, train_loss: 0.8385076660376328, val_loss: 0.7891104817390442\n",
      "1233, train_loss: 0.8391522398361793, val_loss: 0.7989144325256348\n",
      "1234, train_loss: 0.8380417846716367, val_loss: 0.79798903465271\n",
      "1235, train_loss: 0.8408807149300208, val_loss: 0.786941134929657\n",
      "1236, train_loss: 0.8410613903632531, val_loss: 0.8165219068527222\n",
      "1237, train_loss: 0.8371474697039678, val_loss: 0.8060560107231141\n",
      "1238, train_loss: 0.8379034124887906, val_loss: 0.8168283700942993\n",
      "1239, train_loss: 0.8366831128413861, val_loss: 0.8023501992225647\n",
      "1240, train_loss: 0.8364678002320803, val_loss: 0.7992303371429443\n",
      "1241, train_loss: 0.8394503983167502, val_loss: 0.7787251114845276\n",
      "1242, train_loss: 0.8369145737244532, val_loss: 0.8058144807815552\n",
      "1243, train_loss: 0.8381282182840201, val_loss: 0.8049590706825256\n",
      "1244, train_loss: 0.8392698352153485, val_loss: 0.7861357688903808\n",
      "1245, train_loss: 0.8361466481135442, val_loss: 0.8048143029212952\n",
      "1246, train_loss: 0.8386832154714144, val_loss: 0.8044322967529297\n",
      "1247, train_loss: 0.8349910974502563, val_loss: 0.8195216417312622\n",
      "1248, train_loss: 0.8356489630845877, val_loss: 0.7954397916793823\n",
      "1249, train_loss: 0.8354337605146261, val_loss: 0.7839588165283203\n",
      "1250, train_loss: 0.8343887122777792, val_loss: 0.7835392951965332\n",
      "1251, train_loss: 0.8341834315886865, val_loss: 0.8000759840011596\n",
      "1252, train_loss: 0.8347065494610713, val_loss: 0.80113685131073\n",
      "1253, train_loss: 0.8344324850119077, val_loss: 0.8013036489486695\n",
      "1254, train_loss: 0.8343161321603335, val_loss: 0.7907013893127441\n",
      "1255, train_loss: 0.83323201078635, val_loss: 0.8020228862762451\n",
      "1256, train_loss: 0.8356495774709262, val_loss: 0.8057095408439636\n",
      "1257, train_loss: 0.8358581226605636, val_loss: 0.8123577475547791\n",
      "1258, train_loss: 0.8325928816428552, val_loss: 0.7957378625869751\n",
      "1259, train_loss: 0.8320799859670492, val_loss: 0.7767450094223023\n",
      "1260, train_loss: 0.8360667526721954, val_loss: 0.7992002487182617\n",
      "1261, train_loss: 0.8317947892042307, val_loss: 0.7763458490371704\n",
      "1262, train_loss: 0.831719309091568, val_loss: 0.7988574266433716\n",
      "1263, train_loss: 0.8313357875897334, val_loss: 0.7764804244041443\n",
      "1264, train_loss: 0.8313088646301856, val_loss: 0.7881962060928345\n",
      "1265, train_loss: 0.8339361685972947, val_loss: 0.7938618898391724\n",
      "1266, train_loss: 0.8316437326944791, val_loss: 0.7937231421470642\n",
      "1267, train_loss: 0.8340539794701797, val_loss: 0.8082165718078613\n",
      "1268, train_loss: 0.8300358309195592, val_loss: 0.7811785817146302\n",
      "1269, train_loss: 0.8302384202296917, val_loss: 0.8100684762001038\n",
      "1270, train_loss: 0.8308238776830527, val_loss: 0.7954679489135742\n",
      "1271, train_loss: 0.830537729538404, val_loss: 0.783140218257904\n",
      "1272, train_loss: 0.8295997083187103, val_loss: 0.7985456347465515\n",
      "1273, train_loss: 0.8292415348383096, val_loss: 0.8043762445449829\n",
      "1274, train_loss: 0.8300359340814444, val_loss: 0.7954013347625732\n",
      "1275, train_loss: 0.8320111150924976, val_loss: 0.7799228549003601\n",
      "1276, train_loss: 0.8295621207127204, val_loss: 0.788809847831726\n",
      "1277, train_loss: 0.8323218662005204, val_loss: 0.7979905366897583\n",
      "1278, train_loss: 0.8309604365092057, val_loss: 0.7750829696655274\n",
      "1279, train_loss: 0.8281669204051678, val_loss: 0.7791162252426147\n",
      "1280, train_loss: 0.8308135156448071, val_loss: 0.7847593665122986\n",
      "1281, train_loss: 0.8311051244919117, val_loss: 0.8072261571884155\n",
      "1282, train_loss: 0.8273439086400546, val_loss: 0.805284059047699\n",
      "1283, train_loss: 0.8305860643203442, val_loss: 0.8000310063362122\n",
      "1284, train_loss: 0.8271555648400233, val_loss: 0.8064616203308106\n",
      "1285, train_loss: 0.8267903236242441, val_loss: 0.7887835621833801\n",
      "1286, train_loss: 0.8267307121020097, val_loss: 0.7858574986457825\n",
      "1287, train_loss: 0.82712433888362, val_loss: 0.7755554676055908\n",
      "1288, train_loss: 0.8284513996197627, val_loss: 0.7838464498519897\n",
      "1289, train_loss: 0.8294312518376571, val_loss: 0.7862659454345703\n",
      "1290, train_loss: 0.8259214437924899, val_loss: 0.7935576558113098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1291, train_loss: 0.8264371913212997, val_loss: 0.795210886001587\n",
      "1292, train_loss: 0.8253774963892423, val_loss: 0.7950787901878357\n",
      "1293, train_loss: 0.826091142801138, val_loss: 0.7908931255340577\n",
      "1294, train_loss: 0.8258463098452642, val_loss: 0.8020636796951294\n",
      "1295, train_loss: 0.825710823902717, val_loss: 0.791742205619812\n",
      "1296, train_loss: 0.827814920590474, val_loss: 0.7924271583557129\n",
      "1297, train_loss: 0.8273314100045425, val_loss: 0.8061963200569153\n",
      "1298, train_loss: 0.8280373032276447, val_loss: 0.7883030533790588\n",
      "1299, train_loss: 0.8281268729613378, val_loss: 0.7938746452331543\n",
      "1300, train_loss: 0.8245944862182324, val_loss: 0.7991401553153992\n",
      "1301, train_loss: 0.8230523329514724, val_loss: 0.800524091720581\n",
      "1302, train_loss: 0.8242455377028539, val_loss: 0.7774638652801513\n",
      "1303, train_loss: 0.8228509265642899, val_loss: 0.7905763626098633\n",
      "1304, train_loss: 0.8228903344044318, val_loss: 0.7825852394104004\n",
      "1305, train_loss: 0.8263668922277597, val_loss: 0.7823326110839843\n",
      "1306, train_loss: 0.822221217247156, val_loss: 0.7801340341567993\n",
      "1307, train_loss: 0.8225521926696484, val_loss: 0.775973093509674\n",
      "1308, train_loss: 0.8230871099692124, val_loss: 0.7915397644042969\n",
      "1309, train_loss: 0.8218695062857407, val_loss: 0.7718445658683777\n",
      "1310, train_loss: 0.822619073666059, val_loss: 0.7981327533721924\n",
      "1311, train_loss: 0.8225107215918027, val_loss: 0.7790568351745606\n",
      "1312, train_loss: 0.8256180767829602, val_loss: 0.7753536581993103\n",
      "1313, train_loss: 0.8214397843067462, val_loss: 0.7783554077148438\n",
      "1314, train_loss: 0.8219916018155905, val_loss: 0.7965270519256592\n",
      "1315, train_loss: 0.821787382547672, val_loss: 0.7844254732131958\n",
      "1316, train_loss: 0.820875685948592, val_loss: 0.806204617023468\n",
      "1317, train_loss: 0.8202000191578498, val_loss: 0.7834543943405151\n",
      "1318, train_loss: 0.8211932090612558, val_loss: 0.7974501848220825\n",
      "1319, train_loss: 0.8236444661250482, val_loss: 0.7859701752662659\n",
      "1320, train_loss: 0.8200688430896172, val_loss: 0.7880825877189637\n",
      "1321, train_loss: 0.8192144471865433, val_loss: 0.7973666548728943\n",
      "1322, train_loss: 0.8204099994439346, val_loss: 0.7712644100189209\n",
      "1323, train_loss: 0.8193027537602645, val_loss: 0.7676247239112854\n",
      "1324, train_loss: 0.8188365904184488, val_loss: 0.7732840776443481\n",
      "1325, train_loss: 0.8198440441718469, val_loss: 0.79835205078125\n",
      "1326, train_loss: 0.8187593290439019, val_loss: 0.7845366835594177\n",
      "1327, train_loss: 0.8215695940531217, val_loss: 0.7811355352401733\n",
      "1328, train_loss: 0.8184709571875058, val_loss: 0.7774535059928894\n",
      "1329, train_loss: 0.8180964566194094, val_loss: 0.7903977036476135\n",
      "1330, train_loss: 0.8181883784440848, val_loss: 0.78825523853302\n",
      "1331, train_loss: 0.8216376006603241, val_loss: 0.7695869207382202\n",
      "1332, train_loss: 0.8185207431132977, val_loss: 0.7816325306892395\n",
      "1333, train_loss: 0.8173321462594546, val_loss: 0.7871191740036011\n",
      "1334, train_loss: 0.8201528764688052, val_loss: 0.7872146368026733\n",
      "1335, train_loss: 0.8177434824980222, val_loss: 0.8030652046203614\n",
      "1336, train_loss: 0.8169185633842762, val_loss: 0.7684386968612671\n",
      "1337, train_loss: 0.8175455767374772, val_loss: 0.7808424830436707\n",
      "1338, train_loss: 0.8171493800786825, val_loss: 0.7708540916442871\n",
      "1339, train_loss: 0.8172226869142972, val_loss: 0.7809141635894775\n",
      "1340, train_loss: 0.8190181988936204, val_loss: 0.7897737264633179\n",
      "1341, train_loss: 0.8161214911020719, val_loss: 0.7675420999526977\n",
      "1342, train_loss: 0.8196175992488861, val_loss: 0.7828544855117798\n",
      "1343, train_loss: 0.8157447072175833, val_loss: 0.7735276103019715\n",
      "1344, train_loss: 0.8162784438866836, val_loss: 0.7847176194190979\n",
      "1345, train_loss: 0.8187377086052527, val_loss: 0.776924479007721\n",
      "1346, train_loss: 0.8178705664781424, val_loss: 0.7674885034561157\n",
      "1347, train_loss: 0.8155946869116563, val_loss: 0.7841219782829285\n",
      "1348, train_loss: 0.8174894818892846, val_loss: 0.7773341417312623\n",
      "1349, train_loss: 0.8178226626836337, val_loss: 0.7774587273597717\n",
      "1350, train_loss: 0.8151299815911514, val_loss: 0.7837729811668396\n",
      "1351, train_loss: 0.8167236814132104, val_loss: 0.7768944144248963\n",
      "1352, train_loss: 0.8168147229231321, val_loss: 0.7870840907096863\n",
      "1353, train_loss: 0.8134037233315982, val_loss: 0.7741363406181335\n",
      "1354, train_loss: 0.8160442045101752, val_loss: 0.7764302372932435\n",
      "1355, train_loss: 0.816755093061007, val_loss: 0.78308584690094\n",
      "1356, train_loss: 0.8137879371643066, val_loss: 0.772810959815979\n",
      "1357, train_loss: 0.8135422124312475, val_loss: 0.8011440157890319\n",
      "1358, train_loss: 0.8136016084597661, val_loss: 0.7977664589881897\n",
      "1359, train_loss: 0.8151656939433172, val_loss: 0.7656669378280639\n",
      "1360, train_loss: 0.8129739853051993, val_loss: 0.782740318775177\n",
      "1361, train_loss: 0.8129821488490472, val_loss: 0.7797008037567139\n",
      "1362, train_loss: 0.8121965940182025, val_loss: 0.7876415848731995\n",
      "1363, train_loss: 0.8125929328111502, val_loss: 0.7663372874259948\n",
      "1364, train_loss: 0.8123418826323289, val_loss: 0.77419193983078\n",
      "1365, train_loss: 0.8146752096139468, val_loss: 0.7642254710197449\n",
      "1366, train_loss: 0.8119328022003174, val_loss: 0.7663007974624634\n",
      "1367, train_loss: 0.8117638390797836, val_loss: 0.7632231831550598\n",
      "1368, train_loss: 0.8116033054315127, val_loss: 0.7771258592605591\n",
      "1369, train_loss: 0.8137817222338456, val_loss: 0.7741341829299927\n",
      "1370, train_loss: 0.8107573000284342, val_loss: 0.774506151676178\n",
      "1371, train_loss: 0.8105776883088626, val_loss: 0.7598943114280701\n",
      "1372, train_loss: 0.8110553759794968, val_loss: 0.7733196020126343\n",
      "1373, train_loss: 0.8102207963283246, val_loss: 0.7772144198417663\n",
      "1374, train_loss: 0.8106377881306869, val_loss: 0.7759940981864929\n",
      "1375, train_loss: 0.8104700927550976, val_loss: 0.7625589013099671\n",
      "1376, train_loss: 0.8100983638029832, val_loss: 0.7705853819847107\n",
      "1377, train_loss: 0.8125843245249528, val_loss: 0.7569636940956116\n",
      "1378, train_loss: 0.8124757386170901, val_loss: 0.761517059803009\n",
      "1379, train_loss: 0.8091195363264817, val_loss: 0.7954580307006835\n",
      "1380, train_loss: 0.809451006926023, val_loss: 0.7616907238960267\n",
      "1381, train_loss: 0.8091647693744073, val_loss: 0.7764366865158081\n",
      "1382, train_loss: 0.8088828050173246, val_loss: 0.7948640942573547\n",
      "1383, train_loss: 0.8089731587813451, val_loss: 0.775250506401062\n",
      "1384, train_loss: 0.8080631173574008, val_loss: 0.765256142616272\n",
      "1385, train_loss: 0.8079751409017123, val_loss: 0.786885118484497\n",
      "1386, train_loss: 0.8108068819229419, val_loss: 0.7657622337341309\n",
      "1387, train_loss: 0.808122822871575, val_loss: 0.7624732732772828\n",
      "1388, train_loss: 0.8074468878599314, val_loss: 0.7872453808784485\n",
      "1389, train_loss: 0.8105961313614478, val_loss: 0.7623011589050293\n",
      "1390, train_loss: 0.807130176287431, val_loss: 0.7528515815734863\n",
      "1391, train_loss: 0.8069880490119641, val_loss: 0.7724893450736999\n",
      "1392, train_loss: 0.8094110122093787, val_loss: 0.7566851019859314\n",
      "1393, train_loss: 0.8065987366896409, val_loss: 0.7721923232078552\n",
      "1394, train_loss: 0.8093214608155764, val_loss: 0.7705618262290954\n",
      "1395, train_loss: 0.8068167613102839, val_loss: 0.7884567379951477\n",
      "1396, train_loss: 0.805990083859517, val_loss: 0.7592868566513061\n",
      "1397, train_loss: 0.8091471562018762, val_loss: 0.7861011385917663\n",
      "1398, train_loss: 0.8062624312364138, val_loss: 0.7789119005203247\n",
      "1399, train_loss: 0.8054990493334256, val_loss: 0.7828825831413269\n",
      "1400, train_loss: 0.8058212124384366, val_loss: 0.7733464121818543\n",
      "1401, train_loss: 0.8051235584112314, val_loss: 0.7784225821495057\n",
      "1402, train_loss: 0.8053676394315866, val_loss: 0.7758661985397339\n",
      "1403, train_loss: 0.8083082804313073, val_loss: 0.7817099452018738\n",
      "1404, train_loss: 0.8050527114134568, val_loss: 0.762637460231781\n",
      "1405, train_loss: 0.8043822462742145, val_loss: 0.7903520464897156\n",
      "1406, train_loss: 0.8070700283233936, val_loss: 0.7682392120361328\n",
      "1407, train_loss: 0.8067557376164657, val_loss: 0.7728129148483276\n",
      "1408, train_loss: 0.8070297149511484, val_loss: 0.7625613451004029\n",
      "1409, train_loss: 0.8041729629039764, val_loss: 0.7577690601348877\n",
      "1410, train_loss: 0.8030858750526721, val_loss: 0.7571632385253906\n",
      "1411, train_loss: 0.8033361022288983, val_loss: 0.7852711319923401\n",
      "1412, train_loss: 0.8030950312431042, val_loss: 0.7668128252029419\n",
      "1413, train_loss: 0.8029591532853934, val_loss: 0.758925485610962\n",
      "1414, train_loss: 0.8032952409524184, val_loss: 0.7681098699569702\n",
      "1415, train_loss: 0.803148831312473, val_loss: 0.7830527424812317\n",
      "1416, train_loss: 0.8030088314643273, val_loss: 0.7882644176483155\n",
      "1417, train_loss: 0.8018256907279675, val_loss: 0.7725874423980713\n",
      "1418, train_loss: 0.8048833929575406, val_loss: 0.778282630443573\n",
      "1419, train_loss: 0.8018952034986936, val_loss: 0.7558954954147339\n",
      "1420, train_loss: 0.8021620603708121, val_loss: 0.7824054479598999\n",
      "1421, train_loss: 0.8015275207849649, val_loss: 0.7575969696044922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1422, train_loss: 0.8009357635791485, val_loss: 0.7777764916419982\n",
      "1423, train_loss: 0.8034077951541314, val_loss: 0.757467246055603\n",
      "1424, train_loss: 0.8010007991240575, val_loss: 0.7595279932022094\n",
      "1425, train_loss: 0.8008470810376681, val_loss: 0.7657070517539978\n",
      "1426, train_loss: 0.8011586803656358, val_loss: 0.7792518138885498\n",
      "1427, train_loss: 0.8002946216326493, val_loss: 0.7693926334381104\n",
      "1428, train_loss: 0.8003182823841388, val_loss: 0.7538410902023316\n",
      "1429, train_loss: 0.8024413058390985, val_loss: 0.7788029313087463\n",
      "1430, train_loss: 0.799942101423557, val_loss: 0.7582949519157409\n",
      "1431, train_loss: 0.7993733814129462, val_loss: 0.7768931984901428\n",
      "1432, train_loss: 0.8000097206005683, val_loss: 0.769995927810669\n",
      "1433, train_loss: 0.7998955456110147, val_loss: 0.7795377612113953\n",
      "1434, train_loss: 0.7992450090555044, val_loss: 0.7779651403427124\n",
      "1435, train_loss: 0.7994782397380242, val_loss: 0.7538399577140809\n",
      "1436, train_loss: 0.8024276540829585, val_loss: 0.7526487112045288\n",
      "1437, train_loss: 0.8012517255086166, val_loss: 0.7788988709449768\n",
      "1438, train_loss: 0.8013889216459714, val_loss: 0.7503883838653564\n",
      "1439, train_loss: 0.7981686156529647, val_loss: 0.7528348445892334\n",
      "1440, train_loss: 0.8007480410429147, val_loss: 0.7506878137588501\n",
      "1441, train_loss: 0.7975781307770655, val_loss: 0.7652591824531555\n",
      "1442, train_loss: 0.798386248258444, val_loss: 0.7537284970283509\n",
      "1443, train_loss: 0.7995443435815665, val_loss: 0.7773464679718017\n",
      "1444, train_loss: 0.797504567182981, val_loss: 0.7683299660682679\n",
      "1445, train_loss: 0.8001150190830231, val_loss: 0.751694118976593\n",
      "1446, train_loss: 0.7976195789300479, val_loss: 0.7660418033599854\n",
      "1447, train_loss: 0.7969998648533454, val_loss: 0.7468273043632507\n",
      "1448, train_loss: 0.7992914594136752, val_loss: 0.7831115007400513\n",
      "1449, train_loss: 0.7991168040495652, val_loss: 0.7533726334571839\n",
      "1450, train_loss: 0.7964520202233241, val_loss: 0.7515510678291321\n",
      "1451, train_loss: 0.7967656484017005, val_loss: 0.7669537544250489\n",
      "1452, train_loss: 0.7985831728348365, val_loss: 0.775896942615509\n",
      "1453, train_loss: 0.7961118335907276, val_loss: 0.7625558376312256\n",
      "1454, train_loss: 0.7962454396944779, val_loss: 0.7663791298866272\n",
      "1455, train_loss: 0.7960193913716537, val_loss: 0.774477732181549\n",
      "1456, train_loss: 0.7988374829292297, val_loss: 0.764671790599823\n",
      "1457, train_loss: 0.7957157309238727, val_loss: 0.7766553640365601\n",
      "1458, train_loss: 0.7942668589261862, val_loss: 0.7593142986297607\n",
      "1459, train_loss: 0.7949168773797842, val_loss: 0.765864896774292\n",
      "1460, train_loss: 0.7947101822266212, val_loss: 0.7619962930679322\n",
      "1461, train_loss: 0.7969801471783564, val_loss: 0.7593637466430664\n",
      "1462, train_loss: 0.7939775196405557, val_loss: 0.7808463454246521\n",
      "1463, train_loss: 0.7946782685243167, val_loss: 0.7497061371803284\n",
      "1464, train_loss: 0.7941935039483584, val_loss: 0.7485142469406127\n",
      "1465, train_loss: 0.7941272900654719, val_loss: 0.7644805669784546\n",
      "1466, train_loss: 0.7935650898860052, val_loss: 0.7642448663711547\n",
      "1467, train_loss: 0.7935933172702789, val_loss: 0.770907723903656\n",
      "1468, train_loss: 0.7937898154442127, val_loss: 0.7607460856437683\n",
      "1469, train_loss: 0.7961297585414007, val_loss: 0.7780238032341004\n",
      "1470, train_loss: 0.7930198678603539, val_loss: 0.7714087843894959\n",
      "1471, train_loss: 0.7933437136503366, val_loss: 0.7480407357215881\n",
      "1472, train_loss: 0.795685887336731, val_loss: 0.7708359003067017\n",
      "1473, train_loss: 0.7919555696157309, val_loss: 0.7700459837913514\n",
      "1474, train_loss: 0.7949336423323705, val_loss: 0.7621712684631348\n",
      "1475, train_loss: 0.7921463938859793, val_loss: 0.7590404629707337\n",
      "1476, train_loss: 0.7924341444785779, val_loss: 0.7450831651687622\n",
      "1477, train_loss: 0.7922696287815387, val_loss: 0.7634842991828918\n",
      "1478, train_loss: 0.7921287532036121, val_loss: 0.7598767161369324\n",
      "1479, train_loss: 0.7944477590230795, val_loss: 0.762106466293335\n",
      "1480, train_loss: 0.7913111448287964, val_loss: 0.7427651405334472\n",
      "1481, train_loss: 0.7908347294880793, val_loss: 0.7532451629638672\n",
      "1482, train_loss: 0.7913364768028259, val_loss: 0.7483464479446411\n",
      "1483, train_loss: 0.7904490668040055, val_loss: 0.7598313927650452\n",
      "1484, train_loss: 0.7924446050937359, val_loss: 0.757688331604004\n",
      "1485, train_loss: 0.7904862784422361, val_loss: 0.7574059724807739\n",
      "1486, train_loss: 0.7906699318152207, val_loss: 0.7635967969894409\n",
      "1487, train_loss: 0.7900849603689634, val_loss: 0.7452459692955017\n",
      "1488, train_loss: 0.7899873623481164, val_loss: 0.7609791994094849\n",
      "1489, train_loss: 0.7902995485525864, val_loss: 0.7710491418838501\n",
      "1490, train_loss: 0.7901442188483018, val_loss: 0.7430295348167419\n",
      "1491, train_loss: 0.7895146608352661, val_loss: 0.749292528629303\n",
      "1492, train_loss: 0.7889353289053991, val_loss: 0.7468431472778321\n",
      "1493, train_loss: 0.7896559192584112, val_loss: 0.7581460356712342\n",
      "1494, train_loss: 0.7894169848698837, val_loss: 0.7537705302238464\n",
      "1495, train_loss: 0.7918057648035196, val_loss: 0.7485441207885742\n",
      "1496, train_loss: 0.7891416985255021, val_loss: 0.7636579155921936\n",
      "1497, train_loss: 0.7888774803051581, val_loss: 0.7714552402496337\n",
      "1498, train_loss: 0.7907518927867596, val_loss: 0.7597739338874817\n",
      "1499, train_loss: 0.7885865821288183, val_loss: 0.7590685963630677\n",
      "1500, train_loss: 0.7902512573278867, val_loss: 0.7531793475151062\n",
      "1501, train_loss: 0.7881628481241373, val_loss: 0.7709771275520325\n",
      "1502, train_loss: 0.7876849197424375, val_loss: 0.7373187065124511\n",
      "1503, train_loss: 0.7875558206668267, val_loss: 0.7684169888496399\n",
      "1504, train_loss: 0.7873566746711731, val_loss: 0.7497437357902527\n",
      "1505, train_loss: 0.7898752483037802, val_loss: 0.75263991355896\n",
      "1506, train_loss: 0.7870239454966325, val_loss: 0.7510075211524964\n",
      "1507, train_loss: 0.787268762405102, val_loss: 0.7429574370384217\n",
      "1508, train_loss: 0.7870777891232417, val_loss: 0.7457920432090759\n",
      "1509, train_loss: 0.7867138890119699, val_loss: 0.7504095315933228\n",
      "1510, train_loss: 0.7864009141921997, val_loss: 0.7640116453170777\n",
      "1511, train_loss: 0.7894514524019681, val_loss: 0.7785905838012696\n",
      "1512, train_loss: 0.7858699445541089, val_loss: 0.7399375438690186\n",
      "1513, train_loss: 0.786285019837893, val_loss: 0.7513911008834839\n",
      "1514, train_loss: 0.7861307263374329, val_loss: 0.753243362903595\n",
      "1515, train_loss: 0.7855684963556436, val_loss: 0.7495833277702332\n",
      "1516, train_loss: 0.785405314885653, val_loss: 0.7516522765159607\n",
      "1517, train_loss: 0.7851649431081918, val_loss: 0.7445699453353882\n",
      "1518, train_loss: 0.7854839425820571, val_loss: 0.7624222874641419\n",
      "1519, train_loss: 0.7850873928803664, val_loss: 0.744518494606018\n",
      "1520, train_loss: 0.7847867974868188, val_loss: 0.736711573600769\n",
      "1521, train_loss: 0.7850486429838034, val_loss: 0.7543876767158508\n",
      "1522, train_loss: 0.7865185760534726, val_loss: 0.7503140330314636\n",
      "1523, train_loss: 0.7846466555045202, val_loss: 0.7537654757499694\n",
      "1524, train_loss: 0.7841418912777534, val_loss: 0.7513340950012207\n",
      "1525, train_loss: 0.7839808486975156, val_loss: 0.7397346496582031\n",
      "1526, train_loss: 0.784101454111246, val_loss: 0.7409541964530945\n",
      "1527, train_loss: 0.7836800997073834, val_loss: 0.7430094480514526\n",
      "1528, train_loss: 0.7832143169182998, val_loss: 0.7698917746543884\n",
      "1529, train_loss: 0.783739108305711, val_loss: 0.7646529078483582\n",
      "1530, train_loss: 0.7835433574823233, val_loss: 0.7456641316413879\n",
      "1531, train_loss: 0.7832960807360135, val_loss: 0.7543507099151612\n",
      "1532, train_loss: 0.7828739698116596, val_loss: 0.7523849368095398\n",
      "1533, train_loss: 0.7827191169445331, val_loss: 0.7481426239013672\n",
      "1534, train_loss: 0.7848364756657527, val_loss: 0.7537485003471375\n",
      "1535, train_loss: 0.7823710120641268, val_loss: 0.7562243938446045\n",
      "1536, train_loss: 0.7825262340215536, val_loss: 0.7361746191978454\n",
      "1537, train_loss: 0.7824537524810204, val_loss: 0.7496009469032288\n",
      "1538, train_loss: 0.7845141452092391, val_loss: 0.7637657165527344\n",
      "1539, train_loss: 0.7818691592950088, val_loss: 0.7531627058982849\n",
      "1540, train_loss: 0.7815693020820618, val_loss: 0.7683596134185791\n",
      "1541, train_loss: 0.7842962466753446, val_loss: 0.7498563528060913\n",
      "1542, train_loss: 0.7815870596812322, val_loss: 0.7579664349555969\n",
      "1543, train_loss: 0.7804201245307922, val_loss: 0.7406062722206116\n",
      "1544, train_loss: 0.7812763911027175, val_loss: 0.7356417417526245\n",
      "1545, train_loss: 0.7803376775521499, val_loss: 0.7626760125160217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1546, train_loss: 0.7809776228207809, val_loss: 0.7447516322135925\n",
      "1547, train_loss: 0.7805904539731833, val_loss: 0.7389465689659118\n",
      "1548, train_loss: 0.780295158808048, val_loss: 0.7504401564598083\n",
      "1549, train_loss: 0.7804923882851234, val_loss: 0.7500771045684814\n",
      "1550, train_loss: 0.7799597863967602, val_loss: 0.7499563694000244\n",
      "1551, train_loss: 0.7801685929298401, val_loss: 0.7476150274276734\n",
      "1552, train_loss: 0.782444532100971, val_loss: 0.7672320485115052\n",
      "1553, train_loss: 0.779531866312027, val_loss: 0.7466433882713318\n",
      "1554, train_loss: 0.779319201524441, val_loss: 0.7496979713439942\n",
      "1555, train_loss: 0.7787241362608396, val_loss: 0.7578823566436768\n",
      "1556, train_loss: 0.7792061773630289, val_loss: 0.7494479298591614\n",
      "1557, train_loss: 0.7807984535510724, val_loss: 0.746100389957428\n",
      "1558, train_loss: 0.778958607178468, val_loss: 0.7303309321403504\n",
      "1559, train_loss: 0.7787170249682206, val_loss: 0.7452054262161255\n",
      "1560, train_loss: 0.7780360946288476, val_loss: 0.7535595655441284\n",
      "1561, train_loss: 0.7780014024331019, val_loss: 0.7578503012657165\n",
      "1562, train_loss: 0.7779912444261404, val_loss: 0.7454447865486145\n",
      "1563, train_loss: 0.7779900752581083, val_loss: 0.745995032787323\n",
      "1564, train_loss: 0.7779637643924127, val_loss: 0.7330924987792968\n",
      "1565, train_loss: 0.7802417094890888, val_loss: 0.7644100666046143\n",
      "1566, train_loss: 0.7773984533089858, val_loss: 0.7472989082336425\n",
      "1567, train_loss: 0.7775148359628824, val_loss: 0.7582870602607727\n",
      "1568, train_loss: 0.7771208515534034, val_loss: 0.7624458312988281\n",
      "1569, train_loss: 0.7769259397800152, val_loss: 0.7465867280960083\n",
      "1570, train_loss: 0.7768934598335853, val_loss: 0.7288302183151245\n",
      "1571, train_loss: 0.7766357568594126, val_loss: 0.7644515037536621\n",
      "1572, train_loss: 0.7765100712959583, val_loss: 0.7337658643722534\n",
      "1573, train_loss: 0.7766783971052903, val_loss: 0.7506627202033996\n",
      "1574, train_loss: 0.7764769677932446, val_loss: 0.7551714420318604\n",
      "1575, train_loss: 0.776038605433244, val_loss: 0.7654672622680664\n",
      "1576, train_loss: 0.7758538218644949, val_loss: 0.732939350605011\n",
      "1577, train_loss: 0.7759612386043255, val_loss: 0.7476829409599304\n",
      "1578, train_loss: 0.7752270217125232, val_loss: 0.7419686794281006\n",
      "1579, train_loss: 0.7756515718423403, val_loss: 0.7326261758804321\n",
      "1580, train_loss: 0.7755343891107119, val_loss: 0.750644862651825\n",
      "1581, train_loss: 0.7775273621082306, val_loss: 0.7432701587677002\n",
      "1582, train_loss: 0.7749818907334254, val_loss: 0.7463173866271973\n",
      "1583, train_loss: 0.776780577806326, val_loss: 0.7351173520088196\n",
      "1584, train_loss: 0.7746735123487619, val_loss: 0.7440162062644958\n",
      "1585, train_loss: 0.7777232436033396, val_loss: 0.7541272282600403\n",
      "1586, train_loss: 0.7746400741430429, val_loss: 0.757529902458191\n",
      "1587, train_loss: 0.774474886747507, val_loss: 0.7417958617210388\n",
      "1588, train_loss: 0.7739126475957724, val_loss: 0.7396490812301636\n",
      "1589, train_loss: 0.7765278357725877, val_loss: 0.7431634187698364\n",
      "1590, train_loss: 0.7756371268859277, val_loss: 0.7375548839569092\n",
      "1591, train_loss: 0.7738100336148188, val_loss: 0.7548897504806519\n",
      "1592, train_loss: 0.7733457959615267, val_loss: 0.7419554829597473\n",
      "1593, train_loss: 0.7735412969039037, val_loss: 0.7413373351097107\n",
      "1594, train_loss: 0.773116797208786, val_loss: 0.7333751440048217\n",
      "1595, train_loss: 0.7728594587399409, val_loss: 0.7281835913658142\n",
      "1596, train_loss: 0.7725475636812357, val_loss: 0.7617569684982299\n",
      "1597, train_loss: 0.7727641967626718, val_loss: 0.7652166247367859\n",
      "1598, train_loss: 0.7752152337477758, val_loss: 0.7392701864242553\n",
      "1599, train_loss: 0.7725063516543462, val_loss: 0.7498865246772766\n",
      "1600, train_loss: 0.77237046452669, val_loss: 0.7396200656890869\n",
      "1601, train_loss: 0.7750999354399167, val_loss: 0.7435300946235657\n",
      "1602, train_loss: 0.7721686477844532, val_loss: 0.7423194169998169\n",
      "1603, train_loss: 0.771623785679157, val_loss: 0.7322230219841004\n",
      "1604, train_loss: 0.7737854673312261, val_loss: 0.7405460119247437\n",
      "1605, train_loss: 0.7714791297912598, val_loss: 0.7535701632499695\n",
      "1606, train_loss: 0.7713100841412177, val_loss: 0.7257325172424316\n",
      "1607, train_loss: 0.7713637604163244, val_loss: 0.7456809639930725\n",
      "1608, train_loss: 0.7712629299897414, val_loss: 0.7302039742469788\n",
      "1609, train_loss: 0.7710117789415213, val_loss: 0.7272704124450684\n",
      "1610, train_loss: 0.7726811262277457, val_loss: 0.7541844010353088\n",
      "1611, train_loss: 0.7697997276599591, val_loss: 0.7290910959243775\n",
      "1612, train_loss: 0.7728037283970759, val_loss: 0.726941704750061\n",
      "1613, train_loss: 0.772432973751655, val_loss: 0.7483449816703797\n",
      "1614, train_loss: 0.7701601477769705, val_loss: 0.740724790096283\n",
      "1615, train_loss: 0.771967901633336, val_loss: 0.7271134376525878\n",
      "1616, train_loss: 0.7701086195615622, val_loss: 0.7372775912284851\n",
      "1617, train_loss: 0.7699155142674079, val_loss: 0.7448347568511963\n",
      "1618, train_loss: 0.7715473495996915, val_loss: 0.7288690209388733\n",
      "1619, train_loss: 0.772043051627966, val_loss: 0.7363332986831665\n",
      "1620, train_loss: 0.7689672341713538, val_loss: 0.7279407143592834\n",
      "1621, train_loss: 0.7692146255419805, val_loss: 0.7486505150794983\n",
      "1622, train_loss: 0.7717189422020545, val_loss: 0.7392228364944458\n",
      "1623, train_loss: 0.7707158166628617, val_loss: 0.7345866322517395\n",
      "1624, train_loss: 0.7686420610317817, val_loss: 0.7564337849617004\n",
      "1625, train_loss: 0.7682146888512832, val_loss: 0.7439534544944764\n",
      "1626, train_loss: 0.7683969254677112, val_loss: 0.7381123661994934\n",
      "1627, train_loss: 0.767380939080165, val_loss: 0.7377188324928283\n",
      "1628, train_loss: 0.768067444746311, val_loss: 0.7278184413909912\n",
      "1629, train_loss: 0.7681167630048898, val_loss: 0.7383906841278076\n",
      "1630, train_loss: 0.7699065506458282, val_loss: 0.7423477530479431\n",
      "1631, train_loss: 0.7678023530886724, val_loss: 0.7271181225776673\n",
      "1632, train_loss: 0.7675008865503165, val_loss: 0.7509906888008118\n",
      "1633, train_loss: 0.7697101670962113, val_loss: 0.7354510307312012\n",
      "1634, train_loss: 0.7671818137168884, val_loss: 0.7269834518432617\n",
      "1635, train_loss: 0.7671228922330416, val_loss: 0.7352354168891907\n",
      "1636, train_loss: 0.7671005863409776, val_loss: 0.7347173929214478\n",
      "1637, train_loss: 0.7668369779219995, val_loss: 0.7388319373130798\n",
      "1638, train_loss: 0.7666155695915222, val_loss: 0.7265295147895813\n",
      "1639, train_loss: 0.7666608347342565, val_loss: 0.7373924016952514\n",
      "1640, train_loss: 0.7663391736837534, val_loss: 0.73536137342453\n",
      "1641, train_loss: 0.766079836166822, val_loss: 0.7388546347618103\n",
      "1642, train_loss: 0.7681437088893011, val_loss: 0.7331349968910217\n",
      "1643, train_loss: 0.7659174501895905, val_loss: 0.7237936854362488\n",
      "1644, train_loss: 0.765898720576213, val_loss: 0.7352237224578857\n",
      "1645, train_loss: 0.7676944824365469, val_loss: 0.7400949239730835\n",
      "1646, train_loss: 0.7654887460745298, val_loss: 0.725072193145752\n",
      "1647, train_loss: 0.7677708451564496, val_loss: 0.7254950761795044\n",
      "1648, train_loss: 0.7653352572367742, val_loss: 0.7516262173652649\n",
      "1649, train_loss: 0.7670762653534229, val_loss: 0.7206709504127502\n",
      "1650, train_loss: 0.764948695898056, val_loss: 0.722742235660553\n",
      "1651, train_loss: 0.7672196145241077, val_loss: 0.7330236554145813\n",
      "1652, train_loss: 0.7647025470550244, val_loss: 0.7460598587989807\n",
      "1653, train_loss: 0.7643537131639627, val_loss: 0.7459099173545838\n",
      "1654, train_loss: 0.7644788508231823, val_loss: 0.7421408534049988\n",
      "1655, train_loss: 0.7664062403715574, val_loss: 0.7349534034729004\n",
      "1656, train_loss: 0.764028203028899, val_loss: 0.7232827544212341\n",
      "1657, train_loss: 0.7635198992032272, val_loss: 0.7439543604850769\n",
      "1658, train_loss: 0.7638060771501981, val_loss: 0.7211456179618836\n",
      "1659, train_loss: 0.765500552379168, val_loss: 0.7453420519828796\n",
      "1660, train_loss: 0.7634398983075068, val_loss: 0.733110511302948\n",
      "1661, train_loss: 0.7633528663561895, val_loss: 0.7493089079856873\n",
      "1662, train_loss: 0.7630073428153992, val_loss: 0.7331431865692138\n",
      "1663, train_loss: 0.7630063730936784, val_loss: 0.7467049717903137\n",
      "1664, train_loss: 0.7653569006002866, val_loss: 0.7210070133209229\n",
      "1665, train_loss: 0.7628319653180929, val_loss: 0.7456773042678833\n",
      "1666, train_loss: 0.7654612637483157, val_loss: 0.7205453038215637\n",
      "1667, train_loss: 0.7625434352801397, val_loss: 0.7396314382553101\n",
      "1668, train_loss: 0.7640801759866568, val_loss: 0.7328354239463806\n",
      "1669, train_loss: 0.7621194628568796, val_loss: 0.7308887243270874\n",
      "1670, train_loss: 0.7618065361793225, val_loss: 0.7312673449516296\n",
      "1671, train_loss: 0.7643028222597562, val_loss: 0.7184226036071777\n",
      "1672, train_loss: 0.7614456048378577, val_loss: 0.7337592959403991\n",
      "1673, train_loss: 0.7640681702357072, val_loss: 0.7222048878669739\n",
      "1674, train_loss: 0.7634000892822559, val_loss: 0.7276925563812255\n",
      "1675, train_loss: 0.7610284181741568, val_loss: 0.738580334186554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1676, train_loss: 0.7610074602640592, val_loss: 0.7377497673034668\n",
      "1677, train_loss: 0.7609862822752732, val_loss: 0.7175687074661254\n",
      "1678, train_loss: 0.7609392931828132, val_loss: 0.7302608251571655\n",
      "1679, train_loss: 0.7607094874748817, val_loss: 0.7166801333427429\n",
      "1680, train_loss: 0.7606161420161908, val_loss: 0.7196713089942932\n",
      "1681, train_loss: 0.7624512268946722, val_loss: 0.7438713431358337\n",
      "1682, train_loss: 0.7601594833227304, val_loss: 0.7321866512298584\n",
      "1683, train_loss: 0.7602187738968775, val_loss: 0.7284170508384704\n",
      "1684, train_loss: 0.7625423142543206, val_loss: 0.7299580216407776\n",
      "1685, train_loss: 0.7621583984448359, val_loss: 0.7193740010261536\n",
      "1686, train_loss: 0.759721054480626, val_loss: 0.7266281485557556\n",
      "1687, train_loss: 0.76188525557518, val_loss: 0.7449180960655213\n",
      "1688, train_loss: 0.7594171647842114, val_loss: 0.7371510028839111\n",
      "1689, train_loss: 0.7592995327252609, val_loss: 0.7313937067985534\n",
      "1690, train_loss: 0.7590636610984802, val_loss: 0.729441249370575\n",
      "1691, train_loss: 0.7586827255212344, val_loss: 0.7314042568206787\n",
      "1692, train_loss: 0.7589434247750503, val_loss: 0.7267723083496094\n",
      "1693, train_loss: 0.7583665182957282, val_loss: 0.7279910802841186\n",
      "1694, train_loss: 0.758474588394165, val_loss: 0.7456143498420715\n",
      "1695, train_loss: 0.7582904902788309, val_loss: 0.7294245719909668\n",
      "1696, train_loss: 0.757489738556055, val_loss: 0.7284708619117737\n",
      "1697, train_loss: 0.7581721842288971, val_loss: 0.7177427411079407\n",
      "1698, train_loss: 0.760616293320289, val_loss: 0.7178675413131714\n",
      "1699, train_loss: 0.7602998178738815, val_loss: 0.7359222769737244\n",
      "1700, train_loss: 0.7602430284023285, val_loss: 0.7298262238502502\n",
      "1701, train_loss: 0.7575321724781623, val_loss: 0.7264559149742127\n",
      "1702, train_loss: 0.7574715293370761, val_loss: 0.7255574822425842\n",
      "1703, train_loss: 0.7573685760681446, val_loss: 0.7280255794525147\n",
      "1704, train_loss: 0.7592913370866042, val_loss: 0.7292199611663819\n",
      "1705, train_loss: 0.7570039354837858, val_loss: 0.7229706883430481\n",
      "1706, train_loss: 0.756883421769509, val_loss: 0.7157979965209961\n",
      "1707, train_loss: 0.7593217629652756, val_loss: 0.7156903147697449\n",
      "1708, train_loss: 0.7563181886306176, val_loss: 0.7130994915962219\n",
      "1709, train_loss: 0.7585807259266193, val_loss: 0.7162790894508362\n",
      "1710, train_loss: 0.7563643203331873, val_loss: 0.7240607380867005\n",
      "1711, train_loss: 0.7559206852546105, val_loss: 0.7242916703224183\n",
      "1712, train_loss: 0.7580010271989382, val_loss: 0.7168010115623474\n",
      "1713, train_loss: 0.755974659552941, val_loss: 0.7152491927146911\n",
      "1714, train_loss: 0.7558608788710374, val_loss: 0.7354790925979614\n",
      "1715, train_loss: 0.7575564086437225, val_loss: 0.7161063075065612\n",
      "1716, train_loss: 0.7579280688212469, val_loss: 0.7147243618965149\n",
      "1717, train_loss: 0.7553286735828106, val_loss: 0.7239278435707093\n",
      "1718, train_loss: 0.7551067196405851, val_loss: 0.7267278790473938\n",
      "1719, train_loss: 0.7550147336262923, val_loss: 0.7130539894104004\n",
      "1720, train_loss: 0.7550260539238269, val_loss: 0.738476574420929\n",
      "1721, train_loss: 0.7548549060638134, val_loss: 0.7286669373512268\n",
      "1722, train_loss: 0.7547294199466705, val_loss: 0.725522232055664\n",
      "1723, train_loss: 0.7545789869932028, val_loss: 0.7136759042739869\n",
      "1724, train_loss: 0.7566751837730408, val_loss: 0.7102374911308289\n",
      "1725, train_loss: 0.7535468431619498, val_loss: 0.711820125579834\n",
      "1726, train_loss: 0.7541797917622787, val_loss: 0.7222061634063721\n",
      "1727, train_loss: 0.7559267809757819, val_loss: 0.7320014476776123\n",
      "1728, train_loss: 0.7531055074471694, val_loss: 0.7145202279090881\n",
      "1729, train_loss: 0.7554912200340858, val_loss: 0.7241276860237121\n",
      "1730, train_loss: 0.7554969558349023, val_loss: 0.7129050493240356\n",
      "1731, train_loss: 0.7529772542990171, val_loss: 0.7124745011329651\n",
      "1732, train_loss: 0.7533496022224426, val_loss: 0.71364905834198\n",
      "1733, train_loss: 0.7530246124817774, val_loss: 0.7249303221702575\n",
      "1734, train_loss: 0.7549481048033788, val_loss: 0.7292823076248169\n",
      "1735, train_loss: 0.7529442837605109, val_loss: 0.7344946384429931\n",
      "1736, train_loss: 0.7550112215372232, val_loss: 0.7174509048461915\n",
      "1737, train_loss: 0.7526365564419673, val_loss: 0.7414031267166138\n",
      "1738, train_loss: 0.75245433816543, val_loss: 0.7203912138938904\n",
      "1739, train_loss: 0.7519826545165136, val_loss: 0.7302377104759217\n",
      "1740, train_loss: 0.7520138277457311, val_loss: 0.709673535823822\n",
      "1741, train_loss: 0.7519497573375702, val_loss: 0.7197853684425354\n",
      "1742, train_loss: 0.7550258636474609, val_loss: 0.7236833333969116\n",
      "1743, train_loss: 0.7534423447572268, val_loss: 0.7441109418869019\n",
      "1744, train_loss: 0.7514460935042455, val_loss: 0.7198760390281678\n",
      "1745, train_loss: 0.7515133390059838, val_loss: 0.7079419016838073\n",
      "1746, train_loss: 0.7531933922034043, val_loss: 0.7120410203933716\n",
      "1747, train_loss: 0.7540953296881455, val_loss: 0.7199605226516723\n",
      "1748, train_loss: 0.7509543895721436, val_loss: 0.7184597611427307\n",
      "1749, train_loss: 0.7528038712648245, val_loss: 0.7174888849258423\n",
      "1750, train_loss: 0.7506126807286189, val_loss: 0.7224526524543762\n",
      "1751, train_loss: 0.7507000061181875, val_loss: 0.7180484771728516\n",
      "1752, train_loss: 0.7529515555271735, val_loss: 0.71116201877594\n",
      "1753, train_loss: 0.7502958545318017, val_loss: 0.7198142886161805\n",
      "1754, train_loss: 0.7501254012951484, val_loss: 0.7199354052543641\n",
      "1755, train_loss: 0.7521776121396285, val_loss: 0.719570004940033\n",
      "1756, train_loss: 0.7496270950023944, val_loss: 0.7245030045509339\n",
      "1757, train_loss: 0.7498948528216436, val_loss: 0.720896315574646\n",
      "1758, train_loss: 0.7496994298238021, val_loss: 0.7192461490631104\n",
      "1759, train_loss: 0.7493993525321667, val_loss: 0.7174794435501098\n",
      "1760, train_loss: 0.7518289754023919, val_loss: 0.721137273311615\n",
      "1761, train_loss: 0.7492602215363429, val_loss: 0.7204041600227356\n",
      "1762, train_loss: 0.7490072319140801, val_loss: 0.7091954231262207\n",
      "1763, train_loss: 0.7514570263715891, val_loss: 0.7084226846694947\n",
      "1764, train_loss: 0.7488116851219764, val_loss: 0.7084631800651551\n",
      "1765, train_loss: 0.7483939643089588, val_loss: 0.708676528930664\n",
      "1766, train_loss: 0.7487198412418365, val_loss: 0.7351651191711426\n",
      "1767, train_loss: 0.748349095766361, val_loss: 0.7203452467918396\n",
      "1768, train_loss: 0.7502059936523438, val_loss: 0.7263184428215027\n",
      "1769, train_loss: 0.748180091381073, val_loss: 0.7192064642906189\n",
      "1770, train_loss: 0.7480720396225269, val_loss: 0.7254085183143616\n",
      "1771, train_loss: 0.7472357910413009, val_loss: 0.7158488154411315\n",
      "1772, train_loss: 0.7475586464771857, val_loss: 0.7229351878166199\n",
      "1773, train_loss: 0.7477459678283105, val_loss: 0.7345000386238099\n",
      "1774, train_loss: 0.7475443986745981, val_loss: 0.7249296307563782\n",
      "1775, train_loss: 0.7491259849988497, val_loss: 0.7257320880889893\n",
      "1776, train_loss: 0.7470657275273249, val_loss: 0.7243995785713195\n",
      "1777, train_loss: 0.7471889463754801, val_loss: 0.7151189923286438\n",
      "1778, train_loss: 0.7469502870853131, val_loss: 0.708492910861969\n",
      "1779, train_loss: 0.7467674314975739, val_loss: 0.7321485996246337\n",
      "1780, train_loss: 0.7490559678811294, val_loss: 0.7188305616378784\n",
      "1781, train_loss: 0.7463499330557309, val_loss: 0.7150614500045777\n",
      "1782, train_loss: 0.7463091841110816, val_loss: 0.7236688017845154\n",
      "1783, train_loss: 0.7481396748469427, val_loss: 0.7147174000740051\n",
      "1784, train_loss: 0.7485808523801657, val_loss: 0.7033430933952332\n",
      "1785, train_loss: 0.7459269418166234, val_loss: 0.7035564422607422\n",
      "1786, train_loss: 0.7460060394727267, val_loss: 0.722422182559967\n",
      "1787, train_loss: 0.7458680042853723, val_loss: 0.7031733870506287\n",
      "1788, train_loss: 0.7480319073567023, val_loss: 0.7059222340583802\n",
      "1789, train_loss: 0.7454031866330367, val_loss: 0.7181794166564941\n",
      "1790, train_loss: 0.7448315001451052, val_loss: 0.723469078540802\n",
      "1791, train_loss: 0.7479341809566205, val_loss: 0.7133468270301819\n",
      "1792, train_loss: 0.7475901544094086, val_loss: 0.7257628202438354\n",
      "1793, train_loss: 0.7448522631938641, val_loss: 0.7172343492507934\n",
      "1794, train_loss: 0.7449294168215531, val_loss: 0.7141514301300049\n",
      "1795, train_loss: 0.7447910423462207, val_loss: 0.7133918881416321\n",
      "1796, train_loss: 0.7441237316681788, val_loss: 0.7128896236419677\n",
      "1797, train_loss: 0.7445158660411835, val_loss: 0.7056499361991883\n",
      "1798, train_loss: 0.7444083186296316, val_loss: 0.7050013422966004\n",
      "1799, train_loss: 0.7442655311180995, val_loss: 0.7318482756614685\n",
      "1800, train_loss: 0.7440000612002152, val_loss: 0.7122424125671387\n",
      "1801, train_loss: 0.7438528927472922, val_loss: 0.7153574585914612\n",
      "1802, train_loss: 0.7456041803726783, val_loss: 0.7127215266227722\n",
      "1803, train_loss: 0.7452122133511764, val_loss: 0.7042430639266968\n",
      "1804, train_loss: 0.7458176429455097, val_loss: 0.7032748937606812\n",
      "1805, train_loss: 0.7434752927376673, val_loss: 0.7229605793952942\n",
      "1806, train_loss: 0.7452499660161825, val_loss: 0.7122212886810303\n",
      "1807, train_loss: 0.7449138302069443, val_loss: 0.7126773953437805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1808, train_loss: 0.7441818232719715, val_loss: 0.7147838473320007\n",
      "1809, train_loss: 0.7450597011126004, val_loss: 0.702906358242035\n",
      "1810, train_loss: 0.7443385009582226, val_loss: 0.7010120749473572\n",
      "1811, train_loss: 0.74252283343902, val_loss: 0.7025320649147033\n",
      "1812, train_loss: 0.7444298152740185, val_loss: 0.7033552169799805\n",
      "1813, train_loss: 0.742425799369812, val_loss: 0.7177360892295838\n",
      "1814, train_loss: 0.7419065947716053, val_loss: 0.701585841178894\n",
      "1815, train_loss: 0.7421887654524583, val_loss: 0.7026633381843567\n",
      "1816, train_loss: 0.7417923922722156, val_loss: 0.7122023940086365\n",
      "1817, train_loss: 0.7414167981881362, val_loss: 0.7168095350265503\n",
      "1818, train_loss: 0.7435086507063645, val_loss: 0.7017958760261536\n",
      "1819, train_loss: 0.7416868141064277, val_loss: 0.7123894214630127\n",
      "1820, train_loss: 0.7413379206107213, val_loss: 0.712082040309906\n",
      "1821, train_loss: 0.7414520245331985, val_loss: 0.7092817425727844\n",
      "1822, train_loss: 0.7407223467643445, val_loss: 0.7162022471427918\n",
      "1823, train_loss: 0.742908768928968, val_loss: 0.7097506642341613\n",
      "1824, train_loss: 0.7424654158262106, val_loss: 0.7014932870864868\n",
      "1825, train_loss: 0.7425829126284673, val_loss: 0.7101734399795532\n",
      "1826, train_loss: 0.7424572706222534, val_loss: 0.7115807890892029\n",
      "1827, train_loss: 0.7423271330503317, val_loss: 0.7036451816558837\n",
      "1828, train_loss: 0.7403356616313641, val_loss: 0.7121001601219177\n",
      "1829, train_loss: 0.739927025941702, val_loss: 0.7238764762878418\n",
      "1830, train_loss: 0.7402665019035339, val_loss: 0.7103681206703186\n",
      "1831, train_loss: 0.7423346684529231, val_loss: 0.7244366765022278\n",
      "1832, train_loss: 0.7399774996133951, val_loss: 0.7132717609405518\n",
      "1833, train_loss: 0.7392935431920565, val_loss: 0.7111702919006347\n",
      "1834, train_loss: 0.7393637184913342, val_loss: 0.7179403424263\n",
      "1835, train_loss: 0.739585477572221, val_loss: 0.7093618392944336\n",
      "1836, train_loss: 0.7392650407094222, val_loss: 0.7159406065940856\n",
      "1837, train_loss: 0.7386207855664767, val_loss: 0.7009613275527954\n",
      "1838, train_loss: 0.7412886642492734, val_loss: 0.7212376475334168\n",
      "1839, train_loss: 0.7390468877095443, val_loss: 0.7096203446388245\n",
      "1840, train_loss: 0.7389032359306629, val_loss: 0.6967898845672608\n",
      "1841, train_loss: 0.7404050208055056, val_loss: 0.699962604045868\n",
      "1842, train_loss: 0.7381259890703055, val_loss: 0.7159129858016968\n",
      "1843, train_loss: 0.7385598719120026, val_loss: 0.7082090377807617\n",
      "1844, train_loss: 0.7406031305973346, val_loss: 0.7142274141311645\n",
      "1845, train_loss: 0.7399517320669614, val_loss: 0.7102054953575134\n",
      "1846, train_loss: 0.7381391181395605, val_loss: 0.7104766011238098\n",
      "1847, train_loss: 0.7380531155146085, val_loss: 0.7269503712654114\n",
      "1848, train_loss: 0.7376098151390369, val_loss: 0.723254919052124\n",
      "1849, train_loss: 0.7393998687083905, val_loss: 0.7116329193115234\n",
      "1850, train_loss: 0.7372447962944324, val_loss: 0.7008822560310364\n",
      "1851, train_loss: 0.7396669181493613, val_loss: 0.7088090300559997\n",
      "1852, train_loss: 0.7371814228021182, val_loss: 0.7157257199287415\n",
      "1853, train_loss: 0.7367825347643632, val_loss: 0.7136449098587037\n",
      "1854, train_loss: 0.736856086896016, val_loss: 0.6982949137687683\n",
      "1855, train_loss: 0.7367480580623333, val_loss: 0.6976748585700989\n",
      "1856, train_loss: 0.7368891697663528, val_loss: 0.6956550121307373\n",
      "1857, train_loss: 0.7390378713607788, val_loss: 0.714328408241272\n",
      "1858, train_loss: 0.7366506136380709, val_loss: 0.7068672060966492\n",
      "1859, train_loss: 0.7361797140194819, val_loss: 0.6980225205421448\n",
      "1860, train_loss: 0.7357881894478431, val_loss: 0.7061524987220764\n",
      "1861, train_loss: 0.7362644924567296, val_loss: 0.6973462700843811\n",
      "1862, train_loss: 0.7361774742603302, val_loss: 0.6951962232589721\n",
      "1863, train_loss: 0.7360565020487859, val_loss: 0.705997884273529\n",
      "1864, train_loss: 0.737366490639173, val_loss: 0.6972025394439697\n",
      "1865, train_loss: 0.7373750163958623, val_loss: 0.7095591187477112\n",
      "1866, train_loss: 0.735045632490745, val_loss: 0.6968762755393982\n",
      "1867, train_loss: 0.7355820078116196, val_loss: 0.6981559038162232\n",
      "1868, train_loss: 0.7350080609321594, val_loss: 0.706988251209259\n",
      "1869, train_loss: 0.7373608694626734, val_loss: 0.6972751021385193\n",
      "1870, train_loss: 0.7344192885435544, val_loss: 0.7203432440757751\n",
      "1871, train_loss: 0.7346101494935843, val_loss: 0.7061491250991822\n",
      "1872, train_loss: 0.7349281379809747, val_loss: 0.6944618582725525\n",
      "1873, train_loss: 0.7370306780705085, val_loss: 0.703504228591919\n",
      "1874, train_loss: 0.7367174579547002, val_loss: 0.7234914064407348\n",
      "1875, train_loss: 0.7341764477583078, val_loss: 0.7054987668991088\n",
      "1876, train_loss: 0.7344107582018926, val_loss: 0.7125190973281861\n",
      "1877, train_loss: 0.7342759577127603, val_loss: 0.6952103257179261\n",
      "1878, train_loss: 0.7338923422189859, val_loss: 0.7043990135192871\n",
      "1879, train_loss: 0.7356495307042048, val_loss: 0.6953179478645325\n",
      "1880, train_loss: 0.733920122568424, val_loss: 0.7068670630455017\n",
      "1881, train_loss: 0.733504769893793, val_loss: 0.6970089673995972\n",
      "1882, train_loss: 0.7336464111621563, val_loss: 0.6951248168945312\n",
      "1883, train_loss: 0.7328466773033142, val_loss: 0.7058327078819275\n",
      "1884, train_loss: 0.7334401515813974, val_loss: 0.692948865890503\n",
      "1885, train_loss: 0.7330458416388586, val_loss: 0.7050377488136291\n",
      "1886, train_loss: 0.7354123088029715, val_loss: 0.7115510702133179\n",
      "1887, train_loss: 0.7330565177477323, val_loss: 0.7003240823745728\n",
      "1888, train_loss: 0.7329297799330491, val_loss: 0.7017196774482727\n",
      "1889, train_loss: 0.7323298935706799, val_loss: 0.7065253138542176\n",
      "1890, train_loss: 0.7342334160437951, val_loss: 0.7144928812980652\n",
      "1891, train_loss: 0.7322286642514743, val_loss: 0.6950884699821472\n",
      "1892, train_loss: 0.732053701694195, val_loss: 0.6961976766586304\n",
      "1893, train_loss: 0.7318993371266586, val_loss: 0.7074382901191711\n",
      "1894, train_loss: 0.7313463481572958, val_loss: 0.6916072487831115\n",
      "1895, train_loss: 0.7321014771094689, val_loss: 0.707103431224823\n",
      "1896, train_loss: 0.7335493106108445, val_loss: 0.7049771428108216\n",
      "1897, train_loss: 0.7311106599294223, val_loss: 0.6906997203826905\n",
      "1898, train_loss: 0.7314249185415415, val_loss: 0.7022633671760559\n",
      "1899, train_loss: 0.7313008629358732, val_loss: 0.7028838157653808\n",
      "1900, train_loss: 0.7315007494046137, val_loss: 0.7178098440170289\n",
      "1901, train_loss: 0.7341143167935885, val_loss: 0.690412175655365\n",
      "1902, train_loss: 0.733435896726755, val_loss: 0.7115536689758301\n",
      "1903, train_loss: 0.7324269368098333, val_loss: 0.7005178093910217\n",
      "1904, train_loss: 0.7309917670029861, val_loss: 0.6913017988204956\n",
      "1905, train_loss: 0.7304624227377084, val_loss: 0.6988282084465027\n",
      "1906, train_loss: 0.7322553831797379, val_loss: 0.7079669237136841\n",
      "1907, train_loss: 0.7304204014631418, val_loss: 0.7024408578872681\n",
      "1908, train_loss: 0.7301707749183362, val_loss: 0.7008944034576416\n",
      "1909, train_loss: 0.7300653090843787, val_loss: 0.7014158964157104\n",
      "1910, train_loss: 0.7295166208193853, val_loss: 0.700220274925232\n",
      "1911, train_loss: 0.7297047766355368, val_loss: 0.6997137665748596\n",
      "1912, train_loss: 0.7295067952229426, val_loss: 0.6981571197509766\n",
      "1913, train_loss: 0.7299215908233936, val_loss: 0.7023055911064148\n",
      "1914, train_loss: 0.7297788308216975, val_loss: 0.7022547841072082\n",
      "1915, train_loss: 0.7293189603548783, val_loss: 0.6982306480407715\n",
      "1916, train_loss: 0.7291768743441656, val_loss: 0.6935377478599548\n",
      "1917, train_loss: 0.7292184417064373, val_loss: 0.7033736109733582\n",
      "1918, train_loss: 0.7302199304103851, val_loss: 0.7024118661880493\n",
      "1919, train_loss: 0.7311056898190424, val_loss: 0.710830569267273\n",
      "1920, train_loss: 0.7286389309626359, val_loss: 0.717630410194397\n",
      "1921, train_loss: 0.7288844929291651, val_loss: 0.7073145747184754\n",
      "1922, train_loss: 0.7287862575971163, val_loss: 0.7056232452392578\n",
      "1923, train_loss: 0.7305947610965142, val_loss: 0.7014306426048279\n",
      "1924, train_loss: 0.7297407617935767, val_loss: 0.6992769122123719\n",
      "1925, train_loss: 0.7279821611367739, val_loss: 0.7082812905311584\n",
      "1926, train_loss: 0.7297305373045114, val_loss: 0.7117613554000854\n",
      "1927, train_loss: 0.7300546100506415, val_loss: 0.6876810789108276\n",
      "1928, train_loss: 0.7280005399997418, val_loss: 0.6981482625007629\n",
      "1929, train_loss: 0.7272438613268045, val_loss: 0.6980318784713745\n",
      "1930, train_loss: 0.7270069374487951, val_loss: 0.7045828104019165\n",
      "1931, train_loss: 0.7267174812463614, val_loss: 0.6957525491714478\n",
      "1932, train_loss: 0.7275353096998655, val_loss: 0.7075140357017518\n",
      "1933, train_loss: 0.7289008750365331, val_loss: 0.6984473466873169\n",
      "1934, train_loss: 0.7272855639457703, val_loss: 0.7125540256500245\n",
      "1935, train_loss: 0.7286359599003425, val_loss: 0.7045077085494995\n",
      "1936, train_loss: 0.7260631758433121, val_loss: 0.6872707009315491\n",
      "1937, train_loss: 0.7281134289044601, val_loss: 0.6971323609352111\n",
      "1938, train_loss: 0.7262625442101405, val_loss: 0.6900384306907654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1939, train_loss: 0.726663921888058, val_loss: 0.6993145823478699\n",
      "1940, train_loss: 0.7261586372668927, val_loss: 0.6991786122322082\n",
      "1941, train_loss: 0.7264315463029422, val_loss: 0.6888317704200745\n",
      "1942, train_loss: 0.7263298424390646, val_loss: 0.6968986749649048\n",
      "1943, train_loss: 0.7262118756771088, val_loss: 0.6985309004783631\n",
      "1944, train_loss: 0.7255915793088766, val_loss: 0.6943281650543213\n",
      "1945, train_loss: 0.7254248972122486, val_loss: 0.6954685330390931\n",
      "1946, train_loss: 0.7254261420323298, val_loss: 0.705202579498291\n",
      "1947, train_loss: 0.7271486131044534, val_loss: 0.6880630850791931\n",
      "1948, train_loss: 0.7251432698506576, val_loss: 0.6964576482772827\n",
      "1949, train_loss: 0.7255242329377395, val_loss: 0.6973559856414795\n",
      "1950, train_loss: 0.7253850927719703, val_loss: 0.6984996438026428\n",
      "1951, train_loss: 0.7252512207398047, val_loss: 0.6964159131050109\n",
      "1952, train_loss: 0.7263680008741525, val_loss: 0.7001759886741639\n",
      "1953, train_loss: 0.7244969079127679, val_loss: 0.7081329584121704\n",
      "1954, train_loss: 0.7268950480681199, val_loss: 0.6937028884887695\n",
      "1955, train_loss: 0.7240444352993598, val_loss: 0.6878402233123779\n",
      "1956, train_loss: 0.7242885140272287, val_loss: 0.6962427973747254\n",
      "1957, train_loss: 0.7258640481875493, val_loss: 0.7098337292671204\n",
      "1958, train_loss: 0.7263801854390365, val_loss: 0.6943659305572509\n",
      "1959, train_loss: 0.7253891046230609, val_loss: 0.6870096564292908\n",
      "1960, train_loss: 0.7236514641688421, val_loss: 0.6936051726341248\n",
      "1961, train_loss: 0.7257660191792709, val_loss: 0.7037266373634339\n",
      "1962, train_loss: 0.7232651435411893, val_loss: 0.6874305367469787\n",
      "1963, train_loss: 0.7233263643888327, val_loss: 0.6839784979820251\n",
      "1964, train_loss: 0.7252488250915821, val_loss: 0.6874686360359192\n",
      "1965, train_loss: 0.7231047107623174, val_loss: 0.6941086888313294\n",
      "1966, train_loss: 0.7234463003965524, val_loss: 0.6960598230361938\n",
      "1967, train_loss: 0.7228556665090414, val_loss: 0.6839185953140259\n",
      "1968, train_loss: 0.7232615787249345, val_loss: 0.6936899304389954\n",
      "1969, train_loss: 0.7244461614352006, val_loss: 0.7048247218132019\n",
      "1970, train_loss: 0.7224723146511958, val_loss: 0.6954156994819641\n",
      "1971, train_loss: 0.7228558865877298, val_loss: 0.6934947609901428\n",
      "1972, train_loss: 0.7227522501578698, val_loss: 0.693279480934143\n",
      "1973, train_loss: 0.7245188836867993, val_loss: 0.70203777551651\n",
      "1974, train_loss: 0.7219889324444991, val_loss: 0.6992591857910156\n",
      "1975, train_loss: 0.7217585146427155, val_loss: 0.7004746079444886\n",
      "1976, train_loss: 0.7216434134886816, val_loss: 0.6817497611045837\n",
      "1977, train_loss: 0.7221408188343048, val_loss: 0.7001374363899231\n",
      "1978, train_loss: 0.7214823617384984, val_loss: 0.6873211026191711\n",
      "1979, train_loss: 0.7219127393685855, val_loss: 0.7014743208885192\n",
      "1980, train_loss: 0.7213044923085433, val_loss: 0.6926402807235718\n",
      "1981, train_loss: 0.7231866992436923, val_loss: 0.6906371355056763\n",
      "1982, train_loss: 0.7214327294092912, val_loss: 0.7036167621612549\n",
      "1983, train_loss: 0.7214303864882543, val_loss: 0.6851203322410584\n",
      "1984, train_loss: 0.7238793212633866, val_loss: 0.692506468296051\n",
      "1985, train_loss: 0.7206887213083414, val_loss: 0.6928866386413575\n",
      "1986, train_loss: 0.7228830938155835, val_loss: 0.6930025815963745\n",
      "1987, train_loss: 0.7202885127984561, val_loss: 0.6914480686187744\n",
      "1988, train_loss: 0.7202456891536713, val_loss: 0.6965767860412597\n",
      "1989, train_loss: 0.7207104930510888, val_loss: 0.691314435005188\n",
      "1990, train_loss: 0.7222128739723792, val_loss: 0.6842257618904114\n",
      "1991, train_loss: 0.7204608389964471, val_loss: 0.6921643018722534\n",
      "1992, train_loss: 0.7218436919725858, val_loss: 0.7055564045906066\n",
      "1993, train_loss: 0.7197087590511029, val_loss: 0.6897260785102844\n",
      "1994, train_loss: 0.7214201642916753, val_loss: 0.6977849006652832\n",
      "1995, train_loss: 0.7199851526663854, val_loss: 0.6997475743293762\n",
      "1996, train_loss: 0.7193810779314774, val_loss: 0.6904579639434815\n",
      "1997, train_loss: 0.7213975993486551, val_loss: 0.6976860523223877\n",
      "1998, train_loss: 0.7217995386857253, val_loss: 0.6921201705932617\n",
      "1999, train_loss: 0.7185485500555772, val_loss: 0.6925149202346802\n",
      "2000, train_loss: 0.7188859306848966, val_loss: 0.7053579568862915\n",
      "2001, train_loss: 0.721075367469054, val_loss: 0.6850724816322327\n",
      "2002, train_loss: 0.7207788435312418, val_loss: 0.6948339939117432\n",
      "2003, train_loss: 0.7190112173557281, val_loss: 0.6892592906951904\n",
      "2004, train_loss: 0.720720662520482, val_loss: 0.6798229932785034\n",
      "2005, train_loss: 0.7187996529615842, val_loss: 0.6829528689384461\n",
      "2006, train_loss: 0.7203156374968015, val_loss: 0.691364336013794\n",
      "2007, train_loss: 0.7207407217759353, val_loss: 0.6852385044097901\n",
      "2008, train_loss: 0.7206977880918063, val_loss: 0.689867091178894\n",
      "2009, train_loss: 0.7176822699033297, val_loss: 0.7107161164283753\n",
      "2010, train_loss: 0.7176700188563421, val_loss: 0.6921922445297242\n",
      "2011, train_loss: 0.717561465043288, val_loss: 0.7000748872756958\n",
      "2012, train_loss: 0.717377034517435, val_loss: 0.6798178076744079\n",
      "2013, train_loss: 0.7178477025949038, val_loss: 0.6974262356758117\n",
      "2014, train_loss: 0.7177385710752927, val_loss: 0.6895461678504944\n",
      "2015, train_loss: 0.7167572700060331, val_loss: 0.6862712264060974\n",
      "2016, train_loss: 0.7193188094175779, val_loss: 0.7098496317863464\n",
      "2017, train_loss: 0.7167662932322576, val_loss: 0.6899113416671753\n",
      "2018, train_loss: 0.7171774735817542, val_loss: 0.6954578518867492\n",
      "2019, train_loss: 0.7171413692144247, val_loss: 0.7025369286537171\n",
      "2020, train_loss: 0.7162164449691772, val_loss: 0.6802685141563416\n",
      "2021, train_loss: 0.7188088756341201, val_loss: 0.690326726436615\n",
      "2022, train_loss: 0.7167083414701315, val_loss: 0.7022394418716431\n",
      "2023, train_loss: 0.7181960596488073, val_loss: 0.7060245156288147\n",
      "2024, train_loss: 0.7154671870745145, val_loss: 0.6975385904312134\n",
      "2025, train_loss: 0.7186134159564972, val_loss: 0.6883583068847656\n",
      "2026, train_loss: 0.7156262993812561, val_loss: 0.6988079667091369\n",
      "2027, train_loss: 0.7154537599820358, val_loss: 0.6944967627525329\n",
      "2028, train_loss: 0.7153894144755143, val_loss: 0.6810186982154847\n",
      "2029, train_loss: 0.7177774745684403, val_loss: 0.6771113395690918\n",
      "2030, train_loss: 0.7151408264270196, val_loss: 0.6917713284492493\n",
      "2031, train_loss: 0.7169567896769597, val_loss: 0.6873475790023804\n",
      "2032, train_loss: 0.7156152289647323, val_loss: 0.6877787113189697\n",
      "2033, train_loss: 0.714956826888598, val_loss: 0.6912937164306641\n",
      "2034, train_loss: 0.7153856295805711, val_loss: 0.6874776721000672\n",
      "2035, train_loss: 0.7152729905568637, val_loss: 0.680162513256073\n",
      "2036, train_loss: 0.7142480588876284, val_loss: 0.676577377319336\n",
      "2037, train_loss: 0.7151103042639219, val_loss: 0.6864566445350647\n",
      "2038, train_loss: 0.7138612545453585, val_loss: 0.7025529265403747\n",
      "2039, train_loss: 0.7142928724105542, val_loss: 0.6872458815574646\n",
      "2040, train_loss: 0.7141779546554272, val_loss: 0.6980078935623169\n",
      "2041, train_loss: 0.7163859903812408, val_loss: 0.6842291116714477\n",
      "2042, train_loss: 0.7138261726269355, val_loss: 0.7003579020500184\n",
      "2043, train_loss: 0.7162030981137202, val_loss: 0.6766662359237671\n",
      "2044, train_loss: 0.7142694936348841, val_loss: 0.6847574353218079\n",
      "2045, train_loss: 0.7138989476057199, val_loss: 0.692215371131897\n",
      "2046, train_loss: 0.7133629711774679, val_loss: 0.7016554832458496\n",
      "2047, train_loss: 0.7131223334715917, val_loss: 0.6861523747444153\n",
      "2048, train_loss: 0.7126348683467278, val_loss: 0.6944233536720276\n",
      "2049, train_loss: 0.7130325597066146, val_loss: 0.681557559967041\n",
      "2050, train_loss: 0.7124102138555967, val_loss: 0.6786698937416077\n",
      "2051, train_loss: 0.7129128987972553, val_loss: 0.6955398321151733\n",
      "2052, train_loss: 0.7125892043113708, val_loss: 0.6852597832679749\n",
      "2053, train_loss: 0.7132734174911792, val_loss: 0.6953628540039063\n",
      "2054, train_loss: 0.7130677608343271, val_loss: 0.6887802720069885\n",
      "2055, train_loss: 0.7130489830787365, val_loss: 0.6761243343353271\n",
      "2056, train_loss: 0.7129447208001063, val_loss: 0.6910193800926209\n",
      "2057, train_loss: 0.7122278488599337, val_loss: 0.7003144025802612\n",
      "2058, train_loss: 0.7127060569249667, val_loss: 0.6852905631065369\n",
      "2059, train_loss: 0.7120355528134567, val_loss: 0.6809308409690857\n",
      "2060, train_loss: 0.7118767018501575, val_loss: 0.6841193675994873\n",
      "2061, train_loss: 0.7122935446409079, val_loss: 0.6775466203689575\n",
      "2062, train_loss: 0.7122885653605828, val_loss: 0.6827993631362915\n",
      "2063, train_loss: 0.7121763848341428, val_loss: 0.7042155504226685\n",
      "2064, train_loss: 0.7110332411069137, val_loss: 0.6932299256324768\n",
      "2065, train_loss: 0.7113478252520928, val_loss: 0.6986955881118775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2066, train_loss: 0.7118124938928164, val_loss: 0.6882482528686523\n",
      "2067, train_loss: 0.7128523932053492, val_loss: 0.6728369355201721\n",
      "2068, train_loss: 0.710967079951213, val_loss: 0.6762141227722168\n",
      "2069, train_loss: 0.7126475297487699, val_loss: 0.6823283433914185\n",
      "2070, train_loss: 0.7113487307841961, val_loss: 0.6849806189537049\n",
      "2071, train_loss: 0.7105533366019909, val_loss: 0.683383560180664\n",
      "2072, train_loss: 0.7128704648751479, val_loss: 0.6836721897125244\n",
      "2073, train_loss: 0.7102236747741699, val_loss: 0.6801321268081665\n",
      "2074, train_loss: 0.7102921077838311, val_loss: 0.685454273223877\n",
      "2075, train_loss: 0.7103566458592048, val_loss: 0.6720413208007813\n",
      "2076, train_loss: 0.7100170804904058, val_loss: 0.6836230039596558\n",
      "2077, train_loss: 0.7105540839525369, val_loss: 0.6817385911941528\n",
      "2078, train_loss: 0.7113883747504308, val_loss: 0.6826247930526733\n",
      "2079, train_loss: 0.7103475125936362, val_loss: 0.6920970320701599\n",
      "2080, train_loss: 0.7102187367585989, val_loss: 0.671886658668518\n",
      "2081, train_loss: 0.7101395474030421, val_loss: 0.6798872232437134\n",
      "2082, train_loss: 0.711179256439209, val_loss: 0.6879678845405579\n",
      "2083, train_loss: 0.7092761236887711, val_loss: 0.6869122624397278\n",
      "2084, train_loss: 0.7091569992212149, val_loss: 0.6757543087005615\n",
      "2085, train_loss: 0.7086671315706693, val_loss: 0.6825932383537292\n",
      "2086, train_loss: 0.7087628818475283, val_loss: 0.6841947793960571\n",
      "2087, train_loss: 0.7111670489494617, val_loss: 0.6894464373588562\n",
      "2088, train_loss: 0.7085762551197639, val_loss: 0.6880239844322205\n",
      "2089, train_loss: 0.710384183205091, val_loss: 0.6840861558914184\n",
      "2090, train_loss: 0.7086863563610957, val_loss: 0.6739452123641968\n",
      "2091, train_loss: 0.7083448446713961, val_loss: 0.68731130361557\n",
      "2092, train_loss: 0.7105925931380346, val_loss: 0.669981038570404\n",
      "2093, train_loss: 0.708116508447207, val_loss: 0.686645758152008\n",
      "2094, train_loss: 0.7078165985070742, val_loss: 0.6904834508895874\n",
      "2095, train_loss: 0.7072872473643377, val_loss: 0.6868057966232299\n",
      "2096, train_loss: 0.7096177339553833, val_loss: 0.6725383043289185\n",
      "2097, train_loss: 0.7083775332340827, val_loss: 0.6733705997467041\n",
      "2098, train_loss: 0.7070088157287011, val_loss: 0.6722692728042603\n",
      "2099, train_loss: 0.7096300858717698, val_loss: 0.6797101736068726\n",
      "2100, train_loss: 0.7067559063434601, val_loss: 0.6760336995124817\n",
      "2101, train_loss: 0.707964138342784, val_loss: 0.6689181327819824\n",
      "2102, train_loss: 0.7072096856740805, val_loss: 0.6759076118469238\n",
      "2103, train_loss: 0.7077078590026269, val_loss: 0.6716589093208313\n",
      "2104, train_loss: 0.7069818881841806, val_loss: 0.6867291569709778\n",
      "2105, train_loss: 0.7067332955507132, val_loss: 0.6693813085556031\n",
      "2106, train_loss: 0.706607156074964, val_loss: 0.6666408538818359\n",
      "2107, train_loss: 0.7085022926330566, val_loss: 0.6680478453636169\n",
      "2108, train_loss: 0.7083200422617105, val_loss: 0.6932181358337403\n",
      "2109, train_loss: 0.7062342694172492, val_loss: 0.6933156013488769\n",
      "2110, train_loss: 0.7084474059251639, val_loss: 0.6814788341522217\n",
      "2111, train_loss: 0.7084291554414309, val_loss: 0.6827111721038819\n",
      "2112, train_loss: 0.708200202538417, val_loss: 0.6808080315589905\n",
      "2113, train_loss: 0.7059407165417304, val_loss: 0.6882508516311645\n",
      "2114, train_loss: 0.7079509427914252, val_loss: 0.6880856156349182\n",
      "2115, train_loss: 0.7051320901283851, val_loss: 0.6709367632865906\n",
      "2116, train_loss: 0.7056626310715308, val_loss: 0.6889285564422607\n",
      "2117, train_loss: 0.7053523384607755, val_loss: 0.6803649187088012\n",
      "2118, train_loss: 0.7052177832676814, val_loss: 0.6687497019767761\n",
      "2119, train_loss: 0.7070465615162482, val_loss: 0.6666586399078369\n",
      "2120, train_loss: 0.7058726663772876, val_loss: 0.6889546394348145\n",
      "2121, train_loss: 0.7069621842641097, val_loss: 0.6738920092582703\n",
      "2122, train_loss: 0.7056541259472187, val_loss: 0.6700638055801391\n",
      "2123, train_loss: 0.7071617933420035, val_loss: 0.6814904808998108\n",
      "2124, train_loss: 0.7052721289487985, val_loss: 0.6870277523994446\n",
      "2125, train_loss: 0.7045583839599903, val_loss: 0.6787237405776978\n",
      "2126, train_loss: 0.7044693346206958, val_loss: 0.670172917842865\n",
      "2127, train_loss: 0.7059304851752061, val_loss: 0.6675632715225219\n",
      "2128, train_loss: 0.703800400862327, val_loss: 0.6735432386398316\n",
      "2129, train_loss: 0.7042222435657794, val_loss: 0.6798711657524109\n",
      "2130, train_loss: 0.7061403118647062, val_loss: 0.6769413352012634\n",
      "2131, train_loss: 0.7046838907095102, val_loss: 0.6653838276863098\n",
      "2132, train_loss: 0.7058197259902954, val_loss: 0.6737450003623963\n",
      "2133, train_loss: 0.704487857910303, val_loss: 0.6799667239189148\n",
      "2134, train_loss: 0.7032298445701599, val_loss: 0.6792686343193054\n",
      "2135, train_loss: 0.7059248548287612, val_loss: 0.673464035987854\n",
      "2136, train_loss: 0.7057651304281675, val_loss: 0.6790572047233582\n",
      "2137, train_loss: 0.7050467271071214, val_loss: 0.6654166340827942\n",
      "2138, train_loss: 0.704971038378202, val_loss: 0.6794451951980591\n",
      "2139, train_loss: 0.7051962751608628, val_loss: 0.6771074414253235\n",
      "2140, train_loss: 0.7046876847743988, val_loss: 0.6689302563667298\n",
      "2141, train_loss: 0.7047650630657489, val_loss: 0.6688613891601562\n",
      "2142, train_loss: 0.7032847725428067, val_loss: 0.6740704298019409\n",
      "2143, train_loss: 0.7045720792733706, val_loss: 0.6725279688835144\n",
      "2144, train_loss: 0.7032903891343337, val_loss: 0.6682305097579956\n",
      "2145, train_loss: 0.7032157297317798, val_loss: 0.6743611931800843\n",
      "2146, train_loss: 0.7021601864924798, val_loss: 0.6772584438323974\n",
      "2147, train_loss: 0.701780589727255, val_loss: 0.6729252219200135\n",
      "2148, train_loss: 0.7028851256920741, val_loss: 0.678518009185791\n",
      "2149, train_loss: 0.7018678807295285, val_loss: 0.6765486121177673\n",
      "2150, train_loss: 0.7026685820176051, val_loss: 0.671065092086792\n",
      "2151, train_loss: 0.7015340328216553, val_loss: 0.6852039098739624\n",
      "2152, train_loss: 0.7032238359634693, val_loss: 0.6716241240501404\n",
      "2153, train_loss: 0.7014755079379449, val_loss: 0.6842737793922424\n",
      "2154, train_loss: 0.7014209628105164, val_loss: 0.6808241844177246\n",
      "2155, train_loss: 0.7036487047488873, val_loss: 0.6798557281494141\n",
      "2156, train_loss: 0.701992046374541, val_loss: 0.6738144516944885\n",
      "2157, train_loss: 0.7008256430809314, val_loss: 0.677195942401886\n",
      "2158, train_loss: 0.7004135182270637, val_loss: 0.6759905457496643\n",
      "2159, train_loss: 0.7017002724684201, val_loss: 0.6803001880645752\n",
      "2160, train_loss: 0.7015667855739594, val_loss: 0.6865546822547912\n",
      "2161, train_loss: 0.7014274826416602, val_loss: 0.6654651284217834\n",
      "2162, train_loss: 0.7012518850656656, val_loss: 0.6647634267807007\n",
      "2163, train_loss: 0.7031026436732366, val_loss: 0.6837916970252991\n",
      "2164, train_loss: 0.7003705891279074, val_loss: 0.6730788946151733\n",
      "2165, train_loss: 0.7017875199134533, val_loss: 0.6661656618118286\n",
      "2166, train_loss: 0.7019147070554587, val_loss: 0.6825899481773376\n",
      "2167, train_loss: 0.7008207027728741, val_loss: 0.6695481061935424\n",
      "2168, train_loss: 0.7003062963485718, val_loss: 0.6736730217933655\n",
      "2169, train_loss: 0.7019028480236347, val_loss: 0.670477545261383\n",
      "2170, train_loss: 0.7014634219499735, val_loss: 0.673451590538025\n",
      "2171, train_loss: 0.700396540073248, val_loss: 0.672382390499115\n",
      "2172, train_loss: 0.7011605501174927, val_loss: 0.6804117321968078\n",
      "2173, train_loss: 0.6992770662674537, val_loss: 0.6747597455978394\n",
      "2174, train_loss: 0.699645085976674, val_loss: 0.670792281627655\n",
      "2175, train_loss: 0.7010637338344867, val_loss: 0.6729221701622009\n",
      "2176, train_loss: 0.6996077207418588, val_loss: 0.6745435357093811\n",
      "2177, train_loss: 0.6997453020169184, val_loss: 0.6753961324691773\n",
      "2178, train_loss: 0.6996127802592057, val_loss: 0.6818323969841004\n",
      "2179, train_loss: 0.6995100791637714, val_loss: 0.6752565622329711\n",
      "2180, train_loss: 0.700402904015321, val_loss: 0.6670625686645508\n",
      "2181, train_loss: 0.6981730667444376, val_loss: 0.6611513257026672\n",
      "2182, train_loss: 0.699191907277474, val_loss: 0.6609320998191833\n",
      "2183, train_loss: 0.7006754141587478, val_loss: 0.6878240823745727\n",
      "2184, train_loss: 0.7004595994949341, val_loss: 0.6723119258880615\n",
      "2185, train_loss: 0.6988753034518316, val_loss: 0.6607298612594604\n",
      "2186, train_loss: 0.6987755665412316, val_loss: 0.6670460104942322\n",
      "2187, train_loss: 0.6999258674108065, val_loss: 0.6648553371429443\n",
      "2188, train_loss: 0.6986090219937838, val_loss: 0.6694353938102722\n",
      "2189, train_loss: 0.6970652800339919, val_loss: 0.6871784329414368\n",
      "2190, train_loss: 0.6984057036729959, val_loss: 0.6673752546310425\n",
      "2191, train_loss: 0.6973617810469407, val_loss: 0.6664438486099243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2192, train_loss: 0.6973320429141705, val_loss: 0.6833219289779663\n",
      "2193, train_loss: 0.697252638064898, val_loss: 0.6662058234214783\n",
      "2194, train_loss: 0.6973606967009031, val_loss: 0.6602661490440369\n",
      "2195, train_loss: 0.6968238032781161, val_loss: 0.6662031173706054\n",
      "2196, train_loss: 0.6971422021205609, val_loss: 0.6716322541236878\n",
      "2197, train_loss: 0.6976632865575644, val_loss: 0.6743599057197571\n",
      "2198, train_loss: 0.6988456638959738, val_loss: 0.6678492426872253\n",
      "2199, train_loss: 0.6970537602901459, val_loss: 0.6677324295043945\n",
      "2200, train_loss: 0.6973614211265857, val_loss: 0.6681267499923706\n",
      "2201, train_loss: 0.696430327800604, val_loss: 0.657560658454895\n",
      "2202, train_loss: 0.6971990901690263, val_loss: 0.6751006841659546\n",
      "2203, train_loss: 0.6962282772247608, val_loss: 0.6585816621780396\n",
      "2204, train_loss: 0.6969877275136801, val_loss: 0.6677165508270264\n",
      "2205, train_loss: 0.6959184729135953, val_loss: 0.6766165614128112\n",
      "2206, train_loss: 0.6966792895243719, val_loss: 0.6623835086822509\n",
      "2207, train_loss: 0.6966848006615272, val_loss: 0.6791634559631348\n",
      "2208, train_loss: 0.6969476021253146, val_loss: 0.6669137716293335\n",
      "2209, train_loss: 0.6964783439269433, val_loss: 0.682929515838623\n",
      "2210, train_loss: 0.6963860025772681, val_loss: 0.6689562797546387\n",
      "2211, train_loss: 0.6947100621003371, val_loss: 0.6702208995819092\n",
      "2212, train_loss: 0.6961444364144251, val_loss: 0.6731072187423706\n",
      "2213, train_loss: 0.6967023152571458, val_loss: 0.6718808650970459\n",
      "2214, train_loss: 0.6957204960859739, val_loss: 0.6787099838256836\n",
      "2215, train_loss: 0.6958263929073627, val_loss: 0.6762948989868164\n",
      "2216, train_loss: 0.6957256495952606, val_loss: 0.6576100349426269\n",
      "2217, train_loss: 0.6946559731776898, val_loss: 0.6623205304145813\n",
      "2218, train_loss: 0.6962507756856772, val_loss: 0.6696012258529663\n",
      "2219, train_loss: 0.6943578169896052, val_loss: 0.6728707551956177\n",
      "2220, train_loss: 0.6953396797180176, val_loss: 0.6776514530181885\n",
      "2221, train_loss: 0.6962500008252951, val_loss: 0.6687318205833435\n",
      "2222, train_loss: 0.6940033298272353, val_loss: 0.6634209990501404\n",
      "2223, train_loss: 0.6939643094172845, val_loss: 0.6551004528999329\n",
      "2224, train_loss: 0.6964441262758695, val_loss: 0.656425130367279\n",
      "2225, train_loss: 0.6939095556735992, val_loss: 0.6768252611160278\n",
      "2226, train_loss: 0.6947510838508606, val_loss: 0.6681395173072815\n",
      "2227, train_loss: 0.6932982481442965, val_loss: 0.6724967002868653\n",
      "2228, train_loss: 0.6954363103096302, val_loss: 0.6591430902481079\n",
      "2229, train_loss: 0.695643833050361, val_loss: 0.6543080568313598\n",
      "2230, train_loss: 0.6950588959913987, val_loss: 0.6687086343765258\n",
      "2231, train_loss: 0.6942124664783478, val_loss: 0.6655075788497925\n",
      "2232, train_loss: 0.6941492740924542, val_loss: 0.679214084148407\n",
      "2233, train_loss: 0.692920480783169, val_loss: 0.6763803362846375\n",
      "2234, train_loss: 0.6938935930912311, val_loss: 0.6658061981201172\n",
      "2235, train_loss: 0.692943451496271, val_loss: 0.6647557020187378\n",
      "2236, train_loss: 0.6950450929311606, val_loss: 0.6754560232162475\n",
      "2237, train_loss: 0.6931493511566749, val_loss: 0.6537420868873596\n",
      "2238, train_loss: 0.6935208393977239, val_loss: 0.6786684513092041\n",
      "2239, train_loss: 0.6934169897666345, val_loss: 0.6737872362136841\n",
      "2240, train_loss: 0.6923657311842992, val_loss: 0.6596205353736877\n",
      "2241, train_loss: 0.6943386770211734, val_loss: 0.6549464344978333\n",
      "2242, train_loss: 0.6930802556184622, val_loss: 0.6647622585296631\n",
      "2243, train_loss: 0.6930095209525182, val_loss: 0.6637604832649231\n",
      "2244, train_loss: 0.6919851417724903, val_loss: 0.663935911655426\n",
      "2245, train_loss: 0.6940102347960839, val_loss: 0.66275554895401\n",
      "2246, train_loss: 0.6913636647737943, val_loss: 0.6690291404724121\n",
      "2247, train_loss: 0.6932609654389895, val_loss: 0.6760392189025879\n",
      "2248, train_loss: 0.6941540287091181, val_loss: 0.6548083782196045\n",
      "2249, train_loss: 0.6938597559928894, val_loss: 0.6570064067840576\n",
      "2250, train_loss: 0.6911694934734931, val_loss: 0.6631555080413818\n",
      "2251, train_loss: 0.693090537419686, val_loss: 0.6675325274467468\n",
      "2252, train_loss: 0.6908611471836383, val_loss: 0.6630578637123108\n",
      "2253, train_loss: 0.6908612778553596, val_loss: 0.6646350979804992\n",
      "2254, train_loss: 0.6925243437290192, val_loss: 0.6584557294845581\n",
      "2255, train_loss: 0.6904521080163809, val_loss: 0.6556525945663452\n",
      "2256, train_loss: 0.6917034708536588, val_loss: 0.6581031799316406\n",
      "2257, train_loss: 0.6905856591004592, val_loss: 0.6677648186683655\n",
      "2258, train_loss: 0.69148188829422, val_loss: 0.6608978748321533\n",
      "2259, train_loss: 0.690404827778156, val_loss: 0.6650993466377259\n",
      "2260, train_loss: 0.6913211391522334, val_loss: 0.665776252746582\n",
      "2261, train_loss: 0.6902189277685605, val_loss: 0.6768790483474731\n",
      "2262, train_loss: 0.6920823592406052, val_loss: 0.6631492137908935\n",
      "2263, train_loss: 0.6909924906033736, val_loss: 0.6688471794128418\n",
      "2264, train_loss: 0.6908949407247397, val_loss: 0.6672392845153808\n",
      "2265, train_loss: 0.6892077601872958, val_loss: 0.6649417638778686\n",
      "2266, train_loss: 0.6918221345314612, val_loss: 0.6587819576263427\n",
      "2267, train_loss: 0.6913497402117803, val_loss: 0.6517897367477417\n",
      "2268, train_loss: 0.6904795009356278, val_loss: 0.6680278182029724\n",
      "2269, train_loss: 0.6917304236155289, val_loss: 0.6681312918663025\n",
      "2270, train_loss: 0.6891249418258667, val_loss: 0.6649951934814453\n",
      "2271, train_loss: 0.6918183267116547, val_loss: 0.6622504115104675\n",
      "2272, train_loss: 0.6908480960589188, val_loss: 0.6593552470207215\n",
      "2273, train_loss: 0.6899693149786729, val_loss: 0.6710140347480774\n",
      "2274, train_loss: 0.6905991320426648, val_loss: 0.6584845066070557\n",
      "2275, train_loss: 0.6911456470306103, val_loss: 0.6624242782592773\n",
      "2276, train_loss: 0.6886069889252002, val_loss: 0.6639103770256043\n",
      "2277, train_loss: 0.6895629969926981, val_loss: 0.6566242456436158\n",
      "2278, train_loss: 0.6880923280349145, val_loss: 0.6625554442405701\n",
      "2279, train_loss: 0.6893460269157703, val_loss: 0.655735433101654\n",
      "2280, train_loss: 0.689276608136984, val_loss: 0.6578580021858216\n",
      "2281, train_loss: 0.6901150850149301, val_loss: 0.6722597360610962\n",
      "2282, train_loss: 0.6880602951233203, val_loss: 0.6617690324783325\n",
      "2283, train_loss: 0.6880276340704697, val_loss: 0.6630092740058899\n",
      "2284, train_loss: 0.6888782244462234, val_loss: 0.6560146689414978\n",
      "2285, train_loss: 0.6888268910921537, val_loss: 0.6633636593818665\n",
      "2286, train_loss: 0.6898093888392816, val_loss: 0.6642629981040955\n",
      "2287, train_loss: 0.6874783635139465, val_loss: 0.6716637253761292\n",
      "2288, train_loss: 0.687186245734875, val_loss: 0.6637289524078369\n",
      "2289, train_loss: 0.6874037293287424, val_loss: 0.6598446488380432\n",
      "2290, train_loss: 0.6890011085913732, val_loss: 0.6500550627708435\n",
      "2291, train_loss: 0.6887489763590006, val_loss: 0.6672361731529236\n",
      "2292, train_loss: 0.6880847674149734, val_loss: 0.6745735168457031\n",
      "2293, train_loss: 0.6896557097251599, val_loss: 0.6716827869415283\n",
      "2294, train_loss: 0.6878512318317707, val_loss: 0.6554287314414978\n",
      "2295, train_loss: 0.6877456444960374, val_loss: 0.6600815415382385\n",
      "2296, train_loss: 0.6887735861998338, val_loss: 0.663514244556427\n",
      "2297, train_loss: 0.6865803920305692, val_loss: 0.667601215839386\n",
      "2298, train_loss: 0.6881979474654565, val_loss: 0.6601885795593262\n",
      "2299, train_loss: 0.6873555596058185, val_loss: 0.6593890070915223\n",
      "2300, train_loss: 0.6862598451284262, val_loss: 0.65873122215271\n",
      "2301, train_loss: 0.6861227796627924, val_loss: 0.6620667576789856\n",
      "2302, train_loss: 0.6870982509392959, val_loss: 0.6598046660423279\n",
      "2303, train_loss: 0.6870026748913985, val_loss: 0.6551936030387878\n",
      "2304, train_loss: 0.6869240196851584, val_loss: 0.6705599308013916\n",
      "2305, train_loss: 0.6852525105843177, val_loss: 0.6601429104804992\n",
      "2306, train_loss: 0.6865252485642066, val_loss: 0.657986867427826\n",
      "2307, train_loss: 0.6854194310995249, val_loss: 0.653922188282013\n",
      "2308, train_loss: 0.6854818898897904, val_loss: 0.6536976218223571\n",
      "2309, train_loss: 0.6853747780506427, val_loss: 0.6628265738487243\n",
      "2310, train_loss: 0.686354384972499, val_loss: 0.6578394293785095\n",
      "2311, train_loss: 0.6862559410241934, val_loss: 0.6730234026908875\n",
      "2312, train_loss: 0.6861699131818918, val_loss: 0.6580617666244507\n",
      "2313, train_loss: 0.6867907253595499, val_loss: 0.6646825671195984\n",
      "2314, train_loss: 0.685927675320552, val_loss: 0.6571769714355469\n",
      "2315, train_loss: 0.6848355875565455, val_loss: 0.6589865446090698\n",
      "2316, train_loss: 0.687118649482727, val_loss: 0.6532915472984314\n",
      "2317, train_loss: 0.686821495111172, val_loss: 0.6477840542793274\n",
      "2318, train_loss: 0.684273036626669, val_loss: 0.651873254776001\n",
      "2319, train_loss: 0.6861646908980149, val_loss: 0.6584825158119202\n",
      "2320, train_loss: 0.6841988448913281, val_loss: 0.6713624119758606\n",
      "2321, train_loss: 0.6839777254141294, val_loss: 0.6534857153892517\n",
      "2322, train_loss: 0.6862554962818439, val_loss: 0.6634222388267517\n",
      "2323, train_loss: 0.6851028754160955, val_loss: 0.6526532053947449\n",
      "2324, train_loss: 0.6836277704972488, val_loss: 0.6717902183532715\n",
      "2325, train_loss: 0.6855706755931561, val_loss: 0.6524823069572449\n",
      "2326, train_loss: 0.6830955743789673, val_loss: 0.6610493302345276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2327, train_loss: 0.6829356917968163, val_loss: 0.653759777545929\n",
      "2328, train_loss: 0.6835059523582458, val_loss: 0.6617749333381653\n",
      "2329, train_loss: 0.6846784101082728, val_loss: 0.656128191947937\n",
      "2330, train_loss: 0.6848901877036462, val_loss: 0.6602184653282166\n",
      "2331, train_loss: 0.6832378369111282, val_loss: 0.6657687067985535\n",
      "2332, train_loss: 0.6853426992893219, val_loss: 0.6598090171813965\n",
      "2333, train_loss: 0.684124054817053, val_loss: 0.6526298761367798\n",
      "2334, train_loss: 0.6844859742201291, val_loss: 0.6659539341926575\n",
      "2335, train_loss: 0.682191190811304, val_loss: 0.6631330490112305\n",
      "2336, train_loss: 0.682725571669065, val_loss: 0.6651087403297424\n",
      "2337, train_loss: 0.6826859277028304, val_loss: 0.6516713976860047\n",
      "2338, train_loss: 0.6836266265465663, val_loss: 0.6715660929679871\n",
      "2339, train_loss: 0.6835472927643702, val_loss: 0.6621246933937073\n",
      "2340, train_loss: 0.6823742366754092, val_loss: 0.661568558216095\n",
      "2341, train_loss: 0.6822578586064852, val_loss: 0.6655732989311218\n",
      "2342, train_loss: 0.682008867080395, val_loss: 0.6619921207427979\n",
      "2343, train_loss: 0.6829304832678574, val_loss: 0.6600401997566223\n",
      "2344, train_loss: 0.6830112406840692, val_loss: 0.660810899734497\n",
      "2345, train_loss: 0.68354499569306, val_loss: 0.6451303958892822\n",
      "2346, train_loss: 0.6817238399615655, val_loss: 0.6499179005622864\n",
      "2347, train_loss: 0.6813735113694117, val_loss: 0.6690284729003906\n",
      "2348, train_loss: 0.6815329216993772, val_loss: 0.644944965839386\n",
      "2349, train_loss: 0.6835596882379972, val_loss: 0.6551909208297729\n",
      "2350, train_loss: 0.6824945555283473, val_loss: 0.6448105096817016\n",
      "2351, train_loss: 0.6812108892660874, val_loss: 0.6575128674507141\n",
      "2352, train_loss: 0.683084834080476, val_loss: 0.652135968208313\n",
      "2353, train_loss: 0.6808131474715012, val_loss: 0.6525628566741943\n",
      "2354, train_loss: 0.6821922453550192, val_loss: 0.6501412391662598\n",
      "2355, train_loss: 0.6820172438254724, val_loss: 0.6596491813659668\n",
      "2356, train_loss: 0.6818937475864704, val_loss: 0.6641216397285461\n",
      "2357, train_loss: 0.6822721568437723, val_loss: 0.6629374265670777\n",
      "2358, train_loss: 0.6806536110547873, val_loss: 0.6536104798316955\n",
      "2359, train_loss: 0.6798630563112406, val_loss: 0.6609271168708801\n",
      "2360, train_loss: 0.6796959982468531, val_loss: 0.6521607398986816\n",
      "2361, train_loss: 0.6803719928631415, val_loss: 0.6476187229156494\n",
      "2362, train_loss: 0.6826271644005408, val_loss: 0.653229022026062\n",
      "2363, train_loss: 0.6812454370351938, val_loss: 0.6684143304824829\n",
      "2364, train_loss: 0.6800387501716614, val_loss: 0.6537393689155578\n",
      "2365, train_loss: 0.6817120749216813, val_loss: 0.6494108319282532\n",
      "2366, train_loss: 0.6802849150620974, val_loss: 0.6592787623405456\n",
      "2367, train_loss: 0.6812453613831446, val_loss: 0.6493694186210632\n",
      "2368, train_loss: 0.6818434871160067, val_loss: 0.6630814075469971\n",
      "2369, train_loss: 0.6806716918945312, val_loss: 0.6592212438583374\n",
      "2370, train_loss: 0.6805496926491077, val_loss: 0.6654812574386597\n",
      "2371, train_loss: 0.68044641155463, val_loss: 0.6628937244415283\n",
      "2372, train_loss: 0.6787270490939801, val_loss: 0.656780743598938\n",
      "2373, train_loss: 0.6791807550650376, val_loss: 0.662828242778778\n",
      "2374, train_loss: 0.6784878717019007, val_loss: 0.648861289024353\n",
      "2375, train_loss: 0.6788865740482624, val_loss: 0.6615448594093323\n",
      "2376, train_loss: 0.6795547375312219, val_loss: 0.6681562542915345\n",
      "2377, train_loss: 0.6806201224143689, val_loss: 0.650100314617157\n",
      "2378, train_loss: 0.678611356478471, val_loss: 0.6492892503738403\n",
      "2379, train_loss: 0.6784221598735223, val_loss: 0.6535171389579773\n",
      "2380, train_loss: 0.6795924947812007, val_loss: 0.6522843837738037\n",
      "2381, train_loss: 0.6782321746532733, val_loss: 0.662354052066803\n",
      "2382, train_loss: 0.6777789501043466, val_loss: 0.6582571387290954\n",
      "2383, train_loss: 0.6793258419403663, val_loss: 0.6524158000946045\n",
      "2384, train_loss: 0.6802630470349238, val_loss: 0.6608495712280273\n",
      "2385, train_loss: 0.6780215708109049, val_loss: 0.6405066013336181\n",
      "2386, train_loss: 0.6790373852619758, val_loss: 0.6479746341705322\n",
      "2387, train_loss: 0.678943510238941, val_loss: 0.6487245321273803\n",
      "2388, train_loss: 0.6777221331229577, val_loss: 0.660388445854187\n",
      "2389, train_loss: 0.6787404578465682, val_loss: 0.6535487532615661\n",
      "2390, train_loss: 0.678474451486881, val_loss: 0.6573765993118286\n",
      "2391, train_loss: 0.6799732584219712, val_loss: 0.6585598468780518\n",
      "2392, train_loss: 0.6784802400148832, val_loss: 0.6542424082756042\n",
      "2393, train_loss: 0.6771573676512792, val_loss: 0.6553521990776062\n",
      "2394, train_loss: 0.6782958003190848, val_loss: 0.6567691802978516\n",
      "2395, train_loss: 0.679186571102876, val_loss: 0.6579372406005859\n",
      "2396, train_loss: 0.6780663637014536, val_loss: 0.653209638595581\n",
      "2397, train_loss: 0.6767277878064376, val_loss: 0.6611334919929505\n",
      "2398, train_loss: 0.6779358799640949, val_loss: 0.6405265808105469\n",
      "2399, train_loss: 0.6778718783305242, val_loss: 0.648694121837616\n",
      "2400, train_loss: 0.6777517910187061, val_loss: 0.6563249588012695\n",
      "2401, train_loss: 0.6765346550024472, val_loss: 0.649566388130188\n",
      "2402, train_loss: 0.6775394127919123, val_loss: 0.6484891295433044\n",
      "2403, train_loss: 0.6775077810654273, val_loss: 0.6497601866722107\n",
      "2404, train_loss: 0.677387542449511, val_loss: 0.6505897283554077\n",
      "2405, train_loss: 0.6760360277616061, val_loss: 0.6569127082824707\n",
      "2406, train_loss: 0.6777666348677415, val_loss: 0.654883599281311\n",
      "2407, train_loss: 0.6764069107862619, val_loss: 0.6631390929222107\n",
      "2408, train_loss: 0.6769698766561655, val_loss: 0.6464516878128052\n",
      "2409, train_loss: 0.6769266655811896, val_loss: 0.640017855167389\n",
      "2410, train_loss: 0.675400225015787, val_loss: 0.6596199154853821\n",
      "2411, train_loss: 0.6777807772159576, val_loss: 0.6399217367172241\n",
      "2412, train_loss: 0.6765326353219839, val_loss: 0.6495586991310119\n",
      "2413, train_loss: 0.6771238033588116, val_loss: 0.6571736693382263\n",
      "2414, train_loss: 0.6751151978969574, val_loss: 0.6563668370246887\n",
      "2415, train_loss: 0.6744525547210987, val_loss: 0.6534386873245239\n",
      "2416, train_loss: 0.6768607726463904, val_loss: 0.6391067028045654\n",
      "2417, train_loss: 0.67620299412654, val_loss: 0.6454124808311462\n",
      "2418, train_loss: 0.6749182228858654, val_loss: 0.6592787981033326\n",
      "2419, train_loss: 0.6763297067238734, val_loss: 0.6458716630935669\n",
      "2420, train_loss: 0.6746835823242481, val_loss: 0.6442992091178894\n",
      "2421, train_loss: 0.6743142444353837, val_loss: 0.6599139928817749\n",
      "2422, train_loss: 0.6745562163683084, val_loss: 0.6630967020988464\n",
      "2423, train_loss: 0.6743150468056018, val_loss: 0.6549101233482361\n",
      "2424, train_loss: 0.6765465117417849, val_loss: 0.6548418641090393\n",
      "2425, train_loss: 0.6754722572289981, val_loss: 0.6630806565284729\n",
      "2426, train_loss: 0.6738700683300312, val_loss: 0.6557831168174744\n",
      "2427, train_loss: 0.6752651310884036, val_loss: 0.652101743221283\n",
      "2428, train_loss: 0.6758374892748319, val_loss: 0.6508628010749817\n",
      "2429, train_loss: 0.6755829086670508, val_loss: 0.6574179530143738\n",
      "2430, train_loss: 0.675454325400866, val_loss: 0.6552840113639832\n",
      "2431, train_loss: 0.6759386658668518, val_loss: 0.6471980452537537\n",
      "2432, train_loss: 0.6760926292492793, val_loss: 0.6551149487495422\n",
      "2433, train_loss: 0.674575367799172, val_loss: 0.6434706091880799\n",
      "2434, train_loss: 0.6745834281811347, val_loss: 0.6444661736488342\n",
      "2435, train_loss: 0.6732979279298049, val_loss: 0.6599202632904053\n",
      "2436, train_loss: 0.6744265854358673, val_loss: 0.649252998828888\n",
      "2437, train_loss: 0.6730735095647665, val_loss: 0.662985098361969\n",
      "2438, train_loss: 0.6741945583086747, val_loss: 0.6587156176567077\n",
      "2439, train_loss: 0.672776446892665, val_loss: 0.6604881048202514\n",
      "2440, train_loss: 0.6744063519514524, val_loss: 0.638211441040039\n",
      "2441, train_loss: 0.67456549176803, val_loss: 0.6441116213798523\n",
      "2442, train_loss: 0.6723792392473954, val_loss: 0.6437505841255188\n",
      "2443, train_loss: 0.674194526213866, val_loss: 0.6579846858978271\n",
      "2444, train_loss: 0.6724381653162149, val_loss: 0.6436519622802734\n",
      "2445, train_loss: 0.6719795534243951, val_loss: 0.6498546600341797\n",
      "2446, train_loss: 0.6720416866816007, val_loss: 0.6445553541183472\n",
      "2447, train_loss: 0.6748235523700714, val_loss: 0.6532492756843566\n",
      "2448, train_loss: 0.6731813549995422, val_loss: 0.6565863251686096\n",
      "2449, train_loss: 0.6732077369323144, val_loss: 0.644933545589447\n",
      "2450, train_loss: 0.6717383655217978, val_loss: 0.6439167022705078\n",
      "2451, train_loss: 0.6712252085025494, val_loss: 0.6515051007270813\n",
      "2452, train_loss: 0.6734140056830186, val_loss: 0.6507615566253662\n",
      "2453, train_loss: 0.6729114170257862, val_loss: 0.6472255945205688\n",
      "2454, train_loss: 0.6735638059102572, val_loss: 0.6437450051307678\n",
      "2455, train_loss: 0.6714178461294907, val_loss: 0.6454952478408813\n",
      "2456, train_loss: 0.6725053787231445, val_loss: 0.646882152557373\n",
      "2457, train_loss: 0.672519862651825, val_loss: 0.6442167282104492\n",
      "2458, train_loss: 0.6732205312985641, val_loss: 0.6386415958404541\n",
      "2459, train_loss: 0.6729498826540433, val_loss: 0.6490026235580444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2460, train_loss: 0.6720565282381498, val_loss: 0.6411229372024536\n",
      "2461, train_loss: 0.6708786923151749, val_loss: 0.6409164428710937\n",
      "2462, train_loss: 0.6725840889490567, val_loss: 0.642624294757843\n",
      "2463, train_loss: 0.670369606751662, val_loss: 0.6507640361785889\n",
      "2464, train_loss: 0.671902562563236, val_loss: 0.6502778887748718\n",
      "2465, train_loss: 0.6722529232501984, val_loss: 0.6559381604194641\n",
      "2466, train_loss: 0.6717094710239997, val_loss: 0.6380199551582336\n",
      "2467, train_loss: 0.6726469420469724, val_loss: 0.6494951367378234\n",
      "2468, train_loss: 0.6715676326018113, val_loss: 0.6553103208541871\n",
      "2469, train_loss: 0.6722264542029455, val_loss: 0.6499465823173523\n",
      "2470, train_loss: 0.671333773778035, val_loss: 0.6526564478874206\n",
      "2471, train_loss: 0.6712862826310672, val_loss: 0.6351151823997497\n",
      "2472, train_loss: 0.6711972287068, val_loss: 0.6554339289665222\n",
      "2473, train_loss: 0.6695422988671523, val_loss: 0.6332636713981629\n",
      "2474, train_loss: 0.6720104676026565, val_loss: 0.6437593698501587\n",
      "2475, train_loss: 0.6718836357960334, val_loss: 0.6479447603225708\n",
      "2476, train_loss: 0.6693467635374802, val_loss: 0.644694471359253\n",
      "2477, train_loss: 0.6707473580653851, val_loss: 0.6450364589691162\n",
      "2478, train_loss: 0.6693864235511193, val_loss: 0.6573006868362427\n",
      "2479, train_loss: 0.6690997320872086, val_loss: 0.6526504516601562\n",
      "2480, train_loss: 0.6691704094409943, val_loss: 0.6457069396972657\n",
      "2481, train_loss: 0.6690029708238748, val_loss: 0.6416364550590515\n",
      "2482, train_loss: 0.6688142097913302, val_loss: 0.6471385478973388\n",
      "2483, train_loss: 0.6690337657928467, val_loss: 0.6510510802268982\n",
      "2484, train_loss: 0.6701747087331918, val_loss: 0.6319348692893982\n",
      "2485, train_loss: 0.6709649196037879, val_loss: 0.6423029184341431\n",
      "2486, train_loss: 0.6686724103414096, val_loss: 0.6528682470321655\n",
      "2487, train_loss: 0.6698979735374451, val_loss: 0.6557592749595642\n",
      "2488, train_loss: 0.6683863768210778, val_loss: 0.6488933801651001\n",
      "2489, train_loss: 0.670088332432967, val_loss: 0.6517307996749878\n",
      "2490, train_loss: 0.6695923805236816, val_loss: 0.6410524010658264\n",
      "2491, train_loss: 0.6695207082308255, val_loss: 0.6441198825836182\n",
      "2492, train_loss: 0.6680841606396896, val_loss: 0.6582196593284607\n",
      "2493, train_loss: 0.6679406762123108, val_loss: 0.6474201440811157\n",
      "2494, train_loss: 0.6708115843626169, val_loss: 0.6432874917984008\n",
      "2495, train_loss: 0.6677342538650219, val_loss: 0.6405908942222596\n",
      "2496, train_loss: 0.6673211959692148, val_loss: 0.6492533802986145\n",
      "2497, train_loss: 0.6690224661276891, val_loss: 0.64004567861557\n",
      "2498, train_loss: 0.6689107876557571, val_loss: 0.6552720665931702\n",
      "2499, train_loss: 0.6675104796886444, val_loss: 0.6463412165641784\n",
      "2500, train_loss: 0.6693729162216187, val_loss: 0.6330915927886963\n",
      "2501, train_loss: 0.6686503038956568, val_loss: 0.6468716979026794\n",
      "2502, train_loss: 0.6685483341033642, val_loss: 0.6432865142822266\n",
      "2503, train_loss: 0.6686631693289831, val_loss: 0.6390897870063782\n",
      "2504, train_loss: 0.6670619684916276, val_loss: 0.6424052119255066\n",
      "2505, train_loss: 0.6667968791264755, val_loss: 0.6558405756950378\n",
      "2506, train_loss: 0.6667953133583069, val_loss: 0.6499222993850708\n",
      "2507, train_loss: 0.6686257513669821, val_loss: 0.6394430041313172\n",
      "2508, train_loss: 0.6664624580970178, val_loss: 0.6527143955230713\n",
      "2509, train_loss: 0.6678175376011775, val_loss: 0.646100115776062\n",
      "2510, train_loss: 0.6679454193665431, val_loss: 0.6387205362319947\n",
      "2511, train_loss: 0.6664344851787274, val_loss: 0.6390385389328003\n",
      "2512, train_loss: 0.6677208405274612, val_loss: 0.6462472200393676\n",
      "2513, train_loss: 0.6662447773493253, val_loss: 0.6478315591812134\n",
      "2514, train_loss: 0.6675032881590036, val_loss: 0.6411771297454834\n",
      "2515, train_loss: 0.6656314134597778, val_loss: 0.638085412979126\n",
      "2516, train_loss: 0.6659592069112338, val_loss: 0.6470386505126953\n",
      "2517, train_loss: 0.6682009444786952, val_loss: 0.6384292602539062\n",
      "2518, train_loss: 0.6655157666939956, val_loss: 0.6464804172515869\n",
      "2519, train_loss: 0.6657885565207555, val_loss: 0.6377528429031372\n",
      "2520, train_loss: 0.6670439885212824, val_loss: 0.6469989657402039\n",
      "2521, train_loss: 0.6669488090735215, val_loss: 0.6377393484115601\n",
      "2522, train_loss: 0.66686006463491, val_loss: 0.6567471981048584\n",
      "2523, train_loss: 0.6652939663483546, val_loss: 0.6391206026077271\n",
      "2524, train_loss: 0.6666967272758484, val_loss: 0.6377086877822876\n",
      "2525, train_loss: 0.6666350479309375, val_loss: 0.629858386516571\n",
      "2526, train_loss: 0.6672301246569707, val_loss: 0.6440187573432923\n",
      "2527, train_loss: 0.6647584530023428, val_loss: 0.6387579083442688\n",
      "2528, train_loss: 0.6663812880332654, val_loss: 0.6526132583618164\n",
      "2529, train_loss: 0.6666464438805213, val_loss: 0.6595381736755371\n",
      "2530, train_loss: 0.666178441964663, val_loss: 0.6454720973968506\n",
      "2531, train_loss: 0.6660686639639047, val_loss: 0.6471839904785156\n",
      "2532, train_loss: 0.664545666712981, val_loss: 0.6445476651191712\n",
      "2533, train_loss: 0.6674103324229901, val_loss: 0.6351014375686646\n",
      "2534, train_loss: 0.665799461878263, val_loss: 0.6360686421394348\n",
      "2535, train_loss: 0.6666309581353114, val_loss: 0.6436477065086365\n",
      "2536, train_loss: 0.6642234623432159, val_loss: 0.6442428469657898\n",
      "2537, train_loss: 0.6656787326702704, val_loss: 0.6442225217819214\n",
      "2538, train_loss: 0.6637417261417096, val_loss: 0.6458771228790283\n",
      "2539, train_loss: 0.6639630152628972, val_loss: 0.6369634389877319\n",
      "2540, train_loss: 0.6637105001853063, val_loss: 0.6379377961158752\n",
      "2541, train_loss: 0.6638656464906839, val_loss: 0.6378691554069519\n",
      "2542, train_loss: 0.6635423302650452, val_loss: 0.6423289895057678\n",
      "2543, train_loss: 0.6636440089115729, val_loss: 0.647063934803009\n",
      "2544, train_loss: 0.6649800951664264, val_loss: 0.6375857830047608\n",
      "2545, train_loss: 0.6656129245574658, val_loss: 0.6460034728050232\n",
      "2546, train_loss: 0.6647719534543844, val_loss: 0.6374712109565734\n",
      "2547, train_loss: 0.6631534466376672, val_loss: 0.6442902207374572\n",
      "2548, train_loss: 0.6630787459703592, val_loss: 0.6391097068786621\n",
      "2549, train_loss: 0.6651670863995185, val_loss: 0.645007050037384\n",
      "2550, train_loss: 0.6625076601138482, val_loss: 0.6460465669631958\n",
      "2551, train_loss: 0.6628387937178979, val_loss: 0.6452815890312195\n",
      "2552, train_loss: 0.6642407866624686, val_loss: 0.639208996295929\n",
      "2553, train_loss: 0.6641731032958398, val_loss: 0.6357869386672974\n",
      "2554, train_loss: 0.662492362352518, val_loss: 0.6379193782806396\n",
      "2555, train_loss: 0.6640299971287067, val_loss: 0.641330087184906\n",
      "2556, train_loss: 0.6623104168818548, val_loss: 0.6456538200378418\n",
      "2557, train_loss: 0.6638832000585703, val_loss: 0.6518992066383362\n",
      "2558, train_loss: 0.6637310018906226, val_loss: 0.6353671550750732\n",
      "2559, train_loss: 0.6643332013717065, val_loss: 0.63680340051651\n",
      "2560, train_loss: 0.6635649892000052, val_loss: 0.6457935571670532\n",
      "2561, train_loss: 0.6637468017064608, val_loss: 0.638282299041748\n",
      "2562, train_loss: 0.661631513100404, val_loss: 0.6416816473007202\n",
      "2563, train_loss: 0.6633063921561608, val_loss: 0.6467988014221191\n",
      "2564, train_loss: 0.6644089267804072, val_loss: 0.6353538990020752\n",
      "2565, train_loss: 0.6638680604787973, val_loss: 0.6482189774513245\n",
      "2566, train_loss: 0.6630214200570033, val_loss: 0.6440294742584228\n",
      "2567, train_loss: 0.662945419549942, val_loss: 0.6352076411247254\n",
      "2568, train_loss: 0.6628569181148822, val_loss: 0.6438133001327515\n",
      "2569, train_loss: 0.6613618869047898, val_loss: 0.6415635466575622\n",
      "2570, train_loss: 0.6627234197579898, val_loss: 0.6342836856842041\n",
      "2571, train_loss: 0.6630295698459332, val_loss: 0.6336680889129639\n",
      "2572, train_loss: 0.6610552324698522, val_loss: 0.6426805257797241\n",
      "2573, train_loss: 0.6606675799076374, val_loss: 0.6327948093414306\n",
      "2574, train_loss: 0.6625261237988105, val_loss: 0.6274037480354309\n",
      "2575, train_loss: 0.6608928121053256, val_loss: 0.6390244841575623\n",
      "2576, train_loss: 0.6622641797249134, val_loss: 0.633733582496643\n",
      "2577, train_loss: 0.6606177687644958, val_loss: 0.6310474753379822\n",
      "2578, train_loss: 0.6627185482245225, val_loss: 0.6349116325378418\n",
      "2579, train_loss: 0.6625715952653152, val_loss: 0.6432111740112305\n",
      "2580, train_loss: 0.660214765713765, val_loss: 0.6322814345359802\n",
      "2581, train_loss: 0.6600400461600378, val_loss: 0.6338149070739746\n",
      "2582, train_loss: 0.6617626295639918, val_loss: 0.6417272329330445\n",
      "2583, train_loss: 0.6616320930994474, val_loss: 0.6311710357666016\n",
      "2584, train_loss: 0.6593464246163001, val_loss: 0.6332972407341003\n",
      "2585, train_loss: 0.6598774630289811, val_loss: 0.6298382401466369\n",
      "2586, train_loss: 0.6607413498254923, val_loss: 0.6410157918930054\n",
      "2587, train_loss: 0.6599896916976342, val_loss: 0.6230156183242798\n",
      "2588, train_loss: 0.6622312000164619, val_loss: 0.6311162352561951\n",
      "2589, train_loss: 0.6614808165110074, val_loss: 0.6339426398277282\n",
      "2590, train_loss: 0.6596879133811364, val_loss: 0.6226402759552002\n",
      "2591, train_loss: 0.6618942228647379, val_loss: 0.6339593052864074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2592, train_loss: 0.6609956667973444, val_loss: 0.6300724267959594\n",
      "2593, train_loss: 0.659236864401744, val_loss: 0.6451852679252624\n",
      "2594, train_loss: 0.6612167793970841, val_loss: 0.6247947692871094\n",
      "2595, train_loss: 0.660771016891186, val_loss: 0.6248958230018615\n",
      "2596, train_loss: 0.6609438909934118, val_loss: 0.6343778967857361\n",
      "2597, train_loss: 0.6591158302930685, val_loss: 0.6312082052230835\n",
      "2598, train_loss: 0.660022898362233, val_loss: 0.6423009753227233\n",
      "2599, train_loss: 0.6589636137852302, val_loss: 0.6318392872810363\n",
      "2600, train_loss: 0.6603581125919635, val_loss: 0.6457253456115722\n",
      "2601, train_loss: 0.6584877303013434, val_loss: 0.6423930644989013\n",
      "2602, train_loss: 0.6603701412677765, val_loss: 0.6329899787902832\n",
      "2603, train_loss: 0.6607508705212519, val_loss: 0.6408947825431823\n",
      "2604, train_loss: 0.6610309825493739, val_loss: 0.6453558564186096\n",
      "2605, train_loss: 0.6605179951741145, val_loss: 0.6345741868019104\n",
      "2606, train_loss: 0.6580625497377836, val_loss: 0.6390641570091248\n",
      "2607, train_loss: 0.6598676374325385, val_loss: 0.634011447429657\n",
      "2608, train_loss: 0.6595985683111044, val_loss: 0.6336487293243408\n",
      "2609, train_loss: 0.659538365327395, val_loss: 0.6408287048339844\n",
      "2610, train_loss: 0.6577087732461783, val_loss: 0.6418025732040405\n",
      "2611, train_loss: 0.6596614649662604, val_loss: 0.642792820930481\n",
      "2612, train_loss: 0.6574295713351324, val_loss: 0.6443361878395081\n",
      "2613, train_loss: 0.6576477816471686, val_loss: 0.6409177184104919\n",
      "2614, train_loss: 0.6590283467219427, val_loss: 0.6373824954032898\n",
      "2615, train_loss: 0.6589551636805902, val_loss: 0.6420567274093628\n",
      "2616, train_loss: 0.6588633335553683, val_loss: 0.630820882320404\n",
      "2617, train_loss: 0.6588220710937793, val_loss: 0.6378412127494812\n",
      "2618, train_loss: 0.6570621430873871, val_loss: 0.6305925369262695\n",
      "2619, train_loss: 0.6586349858687475, val_loss: 0.6490948557853699\n",
      "2620, train_loss: 0.6584607867094187, val_loss: 0.6374720573425293\n",
      "2621, train_loss: 0.6585893493432265, val_loss: 0.6328914165496826\n",
      "2622, train_loss: 0.6583756391818707, val_loss: 0.6343730330467224\n",
      "2623, train_loss: 0.6567544341087341, val_loss: 0.6387590885162353\n",
      "2624, train_loss: 0.6581840377587539, val_loss: 0.6330732703208923\n",
      "2625, train_loss: 0.6591932360942547, val_loss: 0.6414730072021484\n",
      "2626, train_loss: 0.6559909169490521, val_loss: 0.6227066516876221\n",
      "2627, train_loss: 0.6579437897755549, val_loss: 0.6293104767799378\n",
      "2628, train_loss: 0.6561829929168408, val_loss: 0.6322393178939819\n",
      "2629, train_loss: 0.6576902453715985, val_loss: 0.6322158932685852\n",
      "2630, train_loss: 0.6562262383791116, val_loss: 0.630093801021576\n",
      "2631, train_loss: 0.6582499490334437, val_loss: 0.643930196762085\n",
      "2632, train_loss: 0.656102900321667, val_loss: 0.6305490493774414\n",
      "2633, train_loss: 0.6577576375924624, val_loss: 0.629854965209961\n",
      "2634, train_loss: 0.6553577391000894, val_loss: 0.6212301611900329\n",
      "2635, train_loss: 0.6573824882507324, val_loss: 0.6371115446090698\n",
      "2636, train_loss: 0.6557062153632824, val_loss: 0.6381918549537658\n",
      "2637, train_loss: 0.6555351248154273, val_loss: 0.6396574378013611\n",
      "2638, train_loss: 0.656642340696775, val_loss: 0.6371749043464661\n",
      "2639, train_loss: 0.6551597599799817, val_loss: 0.6394670963287353\n",
      "2640, train_loss: 0.6548871168723474, val_loss: 0.6350379824638367\n",
      "2641, train_loss: 0.6553228474580325, val_loss: 0.6353041410446167\n",
      "2642, train_loss: 0.6574260042263911, val_loss: 0.6396059155464172\n",
      "2643, train_loss: 0.6549144960366763, val_loss: 0.6418557047843934\n",
      "2644, train_loss: 0.6550141848050631, val_loss: 0.6355486750602722\n",
      "2645, train_loss: 0.6546214406306927, val_loss: 0.6426130890846252\n",
      "2646, train_loss: 0.6566100601966565, val_loss: 0.6348366022109986\n",
      "2647, train_loss: 0.6568227135218107, val_loss: 0.6277902364730835\n",
      "2648, train_loss: 0.6569744440225455, val_loss: 0.6329123020172119\n",
      "2649, train_loss: 0.6563220941103421, val_loss: 0.6450201272964478\n",
      "2650, train_loss: 0.654528810427739, val_loss: 0.6298479437828064\n",
      "2651, train_loss: 0.6560099262457627, val_loss: 0.6383450984954834\n",
      "2652, train_loss: 0.6558363070854774, val_loss: 0.634389591217041\n",
      "2653, train_loss: 0.654139023560744, val_loss: 0.6430560708045959\n",
      "2654, train_loss: 0.6566753570850079, val_loss: 0.6359726190567017\n",
      "2655, train_loss: 0.6557207703590393, val_loss: 0.6259231925010681\n",
      "2656, train_loss: 0.65555028961255, val_loss: 0.636003041267395\n",
      "2657, train_loss: 0.6534205560500805, val_loss: 0.6351585984230042\n",
      "2658, train_loss: 0.6554138018534734, val_loss: 0.6348305225372315\n",
      "2659, train_loss: 0.6553410383371207, val_loss: 0.644563353061676\n",
      "2660, train_loss: 0.6534872651100159, val_loss: 0.639050030708313\n",
      "2661, train_loss: 0.6549670856732589, val_loss: 0.6356640219688415\n",
      "2662, train_loss: 0.6558056404957404, val_loss: 0.6303196430206299\n",
      "2663, train_loss: 0.6531449327102075, val_loss: 0.6361144661903382\n",
      "2664, train_loss: 0.6549749993360959, val_loss: 0.6263123393058777\n",
      "2665, train_loss: 0.6543631278551542, val_loss: 0.639909315109253\n",
      "2666, train_loss: 0.6547407095248883, val_loss: 0.6301945805549621\n",
      "2667, train_loss: 0.6546583840480218, val_loss: 0.636554753780365\n",
      "2668, train_loss: 0.6530347581093128, val_loss: 0.6415270686149597\n",
      "2669, train_loss: 0.6526025121028607, val_loss: 0.637462830543518\n",
      "2670, train_loss: 0.6520509421825409, val_loss: 0.6291378974914551\n",
      "2671, train_loss: 0.6550315618515015, val_loss: 0.6268908262252808\n",
      "2672, train_loss: 0.6523451140293708, val_loss: 0.6280911564826965\n",
      "2673, train_loss: 0.6537321003583761, val_loss: 0.6178312540054322\n",
      "2674, train_loss: 0.6539678757007306, val_loss: 0.6348110318183899\n",
      "2675, train_loss: 0.6522371195829831, val_loss: 0.628242039680481\n",
      "2676, train_loss: 0.6544215495769794, val_loss: 0.6368349075317383\n",
      "2677, train_loss: 0.6537678150030283, val_loss: 0.6269169807434082\n",
      "2678, train_loss: 0.6538392488773053, val_loss: 0.6344849109649658\n",
      "2679, train_loss: 0.6537808890526111, val_loss: 0.6381224989891052\n",
      "2680, train_loss: 0.6536545134507693, val_loss: 0.6377315640449523\n",
      "2681, train_loss: 0.6535563698181739, val_loss: 0.6354737877845764\n",
      "2682, train_loss: 0.6535424658885369, val_loss: 0.6424698233604431\n",
      "2683, train_loss: 0.651784747838974, val_loss: 0.6402856349945069\n",
      "2684, train_loss: 0.651515204172868, val_loss: 0.6272925615310669\n",
      "2685, train_loss: 0.6513262551564437, val_loss: 0.628641664981842\n",
      "2686, train_loss: 0.6532218272869403, val_loss: 0.634785795211792\n",
      "2687, train_loss: 0.6514068796084478, val_loss: 0.6269154667854309\n",
      "2688, train_loss: 0.6511542109342722, val_loss: 0.636728048324585\n",
      "2689, train_loss: 0.6511772618843958, val_loss: 0.6309601306915283\n",
      "2690, train_loss: 0.6529089372891647, val_loss: 0.634397828578949\n",
      "2691, train_loss: 0.6525649405442752, val_loss: 0.642290461063385\n",
      "2692, train_loss: 0.6507647037506104, val_loss: 0.6424105048179627\n",
      "2693, train_loss: 0.6511155962944031, val_loss: 0.6343359470367431\n",
      "2694, train_loss: 0.6510016436760242, val_loss: 0.6224911689758301\n",
      "2695, train_loss: 0.6524678399929633, val_loss: 0.627029824256897\n",
      "2696, train_loss: 0.6507363892518557, val_loss: 0.6319514989852906\n",
      "2697, train_loss: 0.6507741579642663, val_loss: 0.633243203163147\n",
      "2698, train_loss: 0.6503234895376059, val_loss: 0.6242143750190735\n",
      "2699, train_loss: 0.6506546116792239, val_loss: 0.6235299229621887\n",
      "2700, train_loss: 0.6521110878540919, val_loss: 0.6333241939544678\n",
      "2701, train_loss: 0.6503271231284509, val_loss: 0.6168792843818665\n",
      "2702, train_loss: 0.6520666594688709, val_loss: 0.6373731374740601\n",
      "2703, train_loss: 0.6518651384573716, val_loss: 0.6341483116149902\n",
      "2704, train_loss: 0.6524709967466501, val_loss: 0.6302746772766114\n",
      "2705, train_loss: 0.6500630241173965, val_loss: 0.627559769153595\n",
      "2706, train_loss: 0.6516367128262153, val_loss: 0.6249518036842346\n",
      "2707, train_loss: 0.6510940446303441, val_loss: 0.6341815114021301\n",
      "2708, train_loss: 0.6514841157656449, val_loss: 0.6242113590240479\n",
      "2709, train_loss: 0.6497259392188146, val_loss: 0.6252041101455689\n",
      "2710, train_loss: 0.6513406932353973, val_loss: 0.6357988119125366\n",
      "2711, train_loss: 0.6515882427875812, val_loss: 0.6421156167984009\n",
      "2712, train_loss: 0.6511382735692538, val_loss: 0.6322742104530334\n",
      "2713, train_loss: 0.6486265911505773, val_loss: 0.6245352506637574\n",
      "2714, train_loss: 0.6512905107094691, val_loss: 0.6244722366333008\n",
      "2715, train_loss: 0.6508949078046359, val_loss: 0.6337287068367005\n",
      "2716, train_loss: 0.6505937759692852, val_loss: 0.6261966109275818\n",
      "2717, train_loss: 0.6491413162304804, val_loss: 0.6243088841438293\n",
      "2718, train_loss: 0.650661940758045, val_loss: 0.6335486650466919\n",
      "2719, train_loss: 0.6483228275409112, val_loss: 0.6242653131484985\n",
      "2720, train_loss: 0.6505171748308035, val_loss: 0.6345915794372559\n",
      "2721, train_loss: 0.6504373206542089, val_loss: 0.6240250825881958\n",
      "2722, train_loss: 0.6507085561752319, val_loss: 0.6314135313034057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2723, train_loss: 0.6485150800301478, val_loss: 0.6336251258850097\n",
      "2724, train_loss: 0.6501800486674676, val_loss: 0.6333133578300476\n",
      "2725, train_loss: 0.6484454365877005, val_loss: 0.633101224899292\n",
      "2726, train_loss: 0.6500114087875073, val_loss: 0.6249122500419617\n",
      "2727, train_loss: 0.6482018759617438, val_loss: 0.6322574615478516\n",
      "2728, train_loss: 0.648125593478863, val_loss: 0.635520589351654\n",
      "2729, train_loss: 0.6497747439604539, val_loss: 0.6264370322227478\n",
      "2730, train_loss: 0.6506294837364783, val_loss: 0.6310620546340943\n",
      "2731, train_loss: 0.6505193916650919, val_loss: 0.6318253636360168\n",
      "2732, train_loss: 0.649547143624379, val_loss: 0.6353261351585389\n",
      "2733, train_loss: 0.6477976212134728, val_loss: 0.6338794589042663\n",
      "2734, train_loss: 0.6494705791656787, val_loss: 0.6303926944732666\n",
      "2735, train_loss: 0.6492720406789046, val_loss: 0.6410328269004821\n",
      "2736, train_loss: 0.6496920929505274, val_loss: 0.6139338731765747\n",
      "2737, train_loss: 0.6491064704381503, val_loss: 0.6267133355140686\n",
      "2738, train_loss: 0.6473745657847478, val_loss: 0.6234060883522033\n",
      "2739, train_loss: 0.6471377840408912, val_loss: 0.6253620624542237\n",
      "2740, train_loss: 0.6488961714964646, val_loss: 0.6234866142272949\n",
      "2741, train_loss: 0.6488068195489737, val_loss: 0.6300193071365356\n",
      "2742, train_loss: 0.6484401867939875, val_loss: 0.6235604882240295\n",
      "2743, train_loss: 0.6486856043338776, val_loss: 0.6389864206314086\n",
      "2744, train_loss: 0.6485816767582526, val_loss: 0.6363341569900512\n",
      "2745, train_loss: 0.6484363629267766, val_loss: 0.6353203535079956\n",
      "2746, train_loss: 0.6484091373590323, val_loss: 0.6302271485328674\n",
      "2747, train_loss: 0.648717103096155, val_loss: 0.6323090195655823\n",
      "2748, train_loss: 0.6462548741927514, val_loss: 0.6334596991539001\n",
      "2749, train_loss: 0.6481681855825278, val_loss: 0.6219384670257568\n",
      "2750, train_loss: 0.6480678938902341, val_loss: 0.6335293173789978\n",
      "2751, train_loss: 0.6462019544381362, val_loss: 0.6248236060142517\n",
      "2752, train_loss: 0.6479232838520637, val_loss: 0.6290235161781311\n",
      "2753, train_loss: 0.6483315229415894, val_loss: 0.6327655911445618\n",
      "2754, train_loss: 0.6458874711623559, val_loss: 0.6220561027526855\n",
      "2755, train_loss: 0.6461161214571732, val_loss: 0.6137879848480224\n",
      "2756, train_loss: 0.6456614411794223, val_loss: 0.6283032298088074\n",
      "2757, train_loss: 0.6474737524986267, val_loss: 0.6290692567825318\n",
      "2758, train_loss: 0.6472912041040567, val_loss: 0.6319525599479675\n",
      "2759, train_loss: 0.6467150105879858, val_loss: 0.6311899900436402\n",
      "2760, train_loss: 0.645330779827558, val_loss: 0.6182692408561706\n",
      "2761, train_loss: 0.6455759406089783, val_loss: 0.6219398021697998\n",
      "2762, train_loss: 0.6446793767122122, val_loss: 0.6115770459175109\n",
      "2763, train_loss: 0.6454857954612145, val_loss: 0.6214978814125061\n",
      "2764, train_loss: 0.647001190827443, val_loss: 0.6136813282966613\n",
      "2765, train_loss: 0.6453463572722214, val_loss: 0.6349475502967834\n",
      "2766, train_loss: 0.6446065100339743, val_loss: 0.6218625068664551\n",
      "2767, train_loss: 0.6468910941710839, val_loss: 0.6345660924911499\n",
      "2768, train_loss: 0.646696728009444, val_loss: 0.6313629508018493\n",
      "2769, train_loss: 0.646893356855099, val_loss: 0.6314141154289246\n",
      "2770, train_loss: 0.6446074453684, val_loss: 0.6197162866592407\n",
      "2771, train_loss: 0.6465355776823484, val_loss: 0.6221651315689087\n",
      "2772, train_loss: 0.6445986995330224, val_loss: 0.6311177849769593\n",
      "2773, train_loss: 0.6464097637396592, val_loss: 0.6311092615127564\n",
      "2774, train_loss: 0.6468380483297201, val_loss: 0.6209923148155212\n",
      "2775, train_loss: 0.6466715129522177, val_loss: 0.6294273018836976\n",
      "2776, train_loss: 0.6444268478797033, val_loss: 0.629464840888977\n",
      "2777, train_loss: 0.6456735134124756, val_loss: 0.6319553256034851\n",
      "2778, train_loss: 0.6442525822382706, val_loss: 0.6130378007888794\n",
      "2779, train_loss: 0.6442583065766555, val_loss: 0.6287105560302735\n",
      "2780, train_loss: 0.6457376205004178, val_loss: 0.6205910801887512\n",
      "2781, train_loss: 0.6462039993359492, val_loss: 0.6340007781982422\n",
      "2782, train_loss: 0.643354629094784, val_loss: 0.6374162435531616\n",
      "2783, train_loss: 0.6460303297409644, val_loss: 0.6306020975112915\n",
      "2784, train_loss: 0.645939439535141, val_loss: 0.6403944492340088\n",
      "2785, train_loss: 0.6437611602819883, val_loss: 0.6210256695747376\n",
      "2786, train_loss: 0.643396427998176, val_loss: 0.6114845633506775\n",
      "2787, train_loss: 0.6463546409056737, val_loss: 0.6279109239578247\n",
      "2788, train_loss: 0.6444529478366559, val_loss: 0.6336637258529663\n",
      "2789, train_loss: 0.6450742551913629, val_loss: 0.6307492852210999\n",
      "2790, train_loss: 0.6433108540681692, val_loss: 0.6112230777740478\n",
      "2791, train_loss: 0.6449570930921115, val_loss: 0.6265495896339417\n",
      "2792, train_loss: 0.6426787536877853, val_loss: 0.6120111227035523\n",
      "2793, train_loss: 0.6431771379250747, val_loss: 0.6332195043563843\n",
      "2794, train_loss: 0.6430551661894872, val_loss: 0.6111124277114868\n",
      "2795, train_loss: 0.6446902866546924, val_loss: 0.6168993353843689\n",
      "2796, train_loss: 0.6439252426991096, val_loss: 0.6299733281135559\n",
      "2797, train_loss: 0.6428730831696436, val_loss: 0.6294755697250366\n",
      "2798, train_loss: 0.6443933179745307, val_loss: 0.6100424528121948\n",
      "2799, train_loss: 0.6425557526258322, val_loss: 0.620256221294403\n",
      "2800, train_loss: 0.6443627522541926, val_loss: 0.6249302744865417\n",
      "2801, train_loss: 0.6422170927891364, val_loss: 0.6192590355873108\n",
      "2802, train_loss: 0.6441916938011463, val_loss: 0.6278610348701477\n",
      "2803, train_loss: 0.6438684165477753, val_loss: 0.6292534112930298\n",
      "2804, train_loss: 0.6440300803918105, val_loss: 0.6236860632896424\n",
      "2805, train_loss: 0.6439248736088092, val_loss: 0.6170561790466309\n",
      "2806, train_loss: 0.6438613327649924, val_loss: 0.6095967650413513\n",
      "2807, train_loss: 0.6416880625944871, val_loss: 0.6093814849853516\n",
      "2808, train_loss: 0.6437653119747455, val_loss: 0.6320055246353149\n",
      "2809, train_loss: 0.6413673735581912, val_loss: 0.6156023621559144\n",
      "2810, train_loss: 0.6436258898331568, val_loss: 0.6284278273582459\n",
      "2811, train_loss: 0.6418518744982206, val_loss: 0.628836727142334\n",
      "2812, train_loss: 0.6413339880796579, val_loss: 0.6280656456947327\n",
      "2813, train_loss: 0.641692347251452, val_loss: 0.6184779286384583\n",
      "2814, train_loss: 0.6433165004620185, val_loss: 0.628576683998108\n",
      "2815, train_loss: 0.6434225898522598, val_loss: 0.6270986557006836\n",
      "2816, train_loss: 0.6414581789420202, val_loss: 0.6158184289932251\n",
      "2817, train_loss: 0.6413536690748655, val_loss: 0.6269703030586242\n",
      "2818, train_loss: 0.6430326860684615, val_loss: 0.6182587742805481\n",
      "2819, train_loss: 0.6436232397189507, val_loss: 0.6272082090377807\n",
      "2820, train_loss: 0.6426752117963938, val_loss: 0.617941153049469\n",
      "2821, train_loss: 0.642770189505357, val_loss: 0.618203055858612\n",
      "2822, train_loss: 0.6430040139418381, val_loss: 0.6343918085098267\n",
      "2823, train_loss: 0.64259073138237, val_loss: 0.6161168336868286\n",
      "2824, train_loss: 0.642494261264801, val_loss: 0.6277078747749328\n",
      "2825, train_loss: 0.642301999605619, val_loss: 0.6173265218734741\n",
      "2826, train_loss: 0.6423821036632245, val_loss: 0.6330722808837891\n",
      "2827, train_loss: 0.6400236120590796, val_loss: 0.6180543065071106\n",
      "2828, train_loss: 0.6414397519368392, val_loss: 0.6253797531127929\n",
      "2829, train_loss: 0.6402577711985662, val_loss: 0.6264412045478821\n",
      "2830, train_loss: 0.6427218340910398, val_loss: 0.6264686226844788\n",
      "2831, train_loss: 0.6419420334009024, val_loss: 0.6263907194137573\n",
      "2832, train_loss: 0.6418891663734729, val_loss: 0.6265494108200074\n",
      "2833, train_loss: 0.6418125193852645, val_loss: 0.6161060452461242\n",
      "2834, train_loss: 0.6419841165726001, val_loss: 0.6249014616012574\n",
      "2835, train_loss: 0.6416416626710159, val_loss: 0.6267261147499085\n",
      "2836, train_loss: 0.6411698162555695, val_loss: 0.6071414113044739\n",
      "2837, train_loss: 0.6414793042036203, val_loss: 0.6236246705055237\n",
      "2838, train_loss: 0.6406792448117182, val_loss: 0.6295122742652893\n",
      "2839, train_loss: 0.6393680595434629, val_loss: 0.6259410500526428\n",
      "2840, train_loss: 0.6412997222863711, val_loss: 0.6062116742134094\n",
      "2841, train_loss: 0.6395515295175406, val_loss: 0.6142378211021423\n",
      "2842, train_loss: 0.6409088808756608, val_loss: 0.6156819820404053\n",
      "2843, train_loss: 0.641085860820917, val_loss: 0.624157166481018\n",
      "2844, train_loss: 0.6417598632665781, val_loss: 0.6166599750518799\n",
      "2845, train_loss: 0.6409681164301358, val_loss: 0.6170189619064331\n",
      "2846, train_loss: 0.6409003872137803, val_loss: 0.6263699531555176\n",
      "2847, train_loss: 0.6387763298474826, val_loss: 0.6137932538986206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2848, train_loss: 0.6380956448041476, val_loss: 0.6150839328765869\n",
      "2849, train_loss: 0.6406814799858973, val_loss: 0.6146562337875366\n",
      "2850, train_loss: 0.6384461086529952, val_loss: 0.6139664888381958\n",
      "2851, train_loss: 0.6403614328457758, val_loss: 0.6230100750923157\n",
      "2852, train_loss: 0.6397828436814822, val_loss: 0.6317433834075927\n",
      "2853, train_loss: 0.6401949020532461, val_loss: 0.6252780556678772\n",
      "2854, train_loss: 0.6382160003368671, val_loss: 0.6210039973258972\n",
      "2855, train_loss: 0.6404483249554267, val_loss: 0.6152926921844483\n",
      "2856, train_loss: 0.6376481239612286, val_loss: 0.6225722551345825\n",
      "2857, train_loss: 0.6402262586813706, val_loss: 0.615861976146698\n",
      "2858, train_loss: 0.6397308776011834, val_loss: 0.6066856861114502\n",
      "2859, train_loss: 0.6398559739956489, val_loss: 0.6260006546974182\n",
      "2860, train_loss: 0.6400154737325815, val_loss: 0.6244664549827575\n",
      "2861, train_loss: 0.6397068798542023, val_loss: 0.619583249092102\n",
      "2862, train_loss: 0.637588232755661, val_loss: 0.6243144750595093\n",
      "2863, train_loss: 0.6395715841880212, val_loss: 0.6204577445983886\n",
      "2864, train_loss: 0.6398239181591914, val_loss: 0.6220523834228515\n",
      "2865, train_loss: 0.6373793138907506, val_loss: 0.6249883890151977\n",
      "2866, train_loss: 0.6393065383801093, val_loss: 0.6284605383872985\n",
      "2867, train_loss: 0.6372394057420584, val_loss: 0.6155002832412719\n",
      "2868, train_loss: 0.637304771405, val_loss: 0.6228229522705078\n",
      "2869, train_loss: 0.636997055548888, val_loss: 0.6162749052047729\n",
      "2870, train_loss: 0.6394334206214318, val_loss: 0.6226880788803101\n",
      "2871, train_loss: 0.6389654920651362, val_loss: 0.6147141218185425\n",
      "2872, train_loss: 0.6392537309573247, val_loss: 0.6181023716926575\n",
      "2873, train_loss: 0.6397740634588095, val_loss: 0.6154662609100342\n",
      "2874, train_loss: 0.638245552778244, val_loss: 0.6130175113677978\n",
      "2875, train_loss: 0.6380812892547021, val_loss: 0.6152815341949462\n",
      "2876, train_loss: 0.6386045423837808, val_loss: 0.622515869140625\n",
      "2877, train_loss: 0.638255972128648, val_loss: 0.6249884843826294\n",
      "2878, train_loss: 0.6384705007076263, val_loss: 0.6241718888282776\n",
      "2879, train_loss: 0.6384037824777457, val_loss: 0.6054495930671692\n",
      "2880, train_loss: 0.638325225848418, val_loss: 0.6177182555198669\n",
      "2881, train_loss: 0.638273897079321, val_loss: 0.6276884794235229\n",
      "2882, train_loss: 0.6379597370441144, val_loss: 0.6221208691596984\n",
      "2883, train_loss: 0.6380942372175363, val_loss: 0.6231484413146973\n",
      "2884, train_loss: 0.6362088253864875, val_loss: 0.6138087153434754\n",
      "2885, train_loss: 0.6378267613741068, val_loss: 0.6113295674324035\n",
      "2886, train_loss: 0.6360880549137409, val_loss: 0.6270692348480225\n",
      "2887, train_loss: 0.6351957504565899, val_loss: 0.6249329805374145\n",
      "2888, train_loss: 0.6377688760940845, val_loss: 0.6223974347114563\n",
      "2889, train_loss: 0.6352695066195267, val_loss: 0.6197544693946838\n",
      "2890, train_loss: 0.6376805855677679, val_loss: 0.6249295353889466\n",
      "2891, train_loss: 0.6377783211377951, val_loss: 0.6103692293167114\n",
      "2892, train_loss: 0.6372019052505493, val_loss: 0.6084694623947143\n",
      "2893, train_loss: 0.6371779097960546, val_loss: 0.6116797447204589\n",
      "2894, train_loss: 0.6367856951860281, val_loss: 0.6253743529319763\n",
      "2895, train_loss: 0.6371738085379968, val_loss: 0.6239934682846069\n",
      "2896, train_loss: 0.6369740642034091, val_loss: 0.608972680568695\n",
      "2897, train_loss: 0.6346158408201658, val_loss: 0.6270503997802734\n",
      "2898, train_loss: 0.636727871803137, val_loss: 0.624579918384552\n",
      "2899, train_loss: 0.6368972888359656, val_loss: 0.6140808701515198\n",
      "2900, train_loss: 0.6364949506062728, val_loss: 0.604447877407074\n",
      "2901, train_loss: 0.6340696238554441, val_loss: 0.6174621820449829\n",
      "2902, train_loss: 0.6366948599998767, val_loss: 0.6189948439598083\n",
      "2903, train_loss: 0.6366199392538804, val_loss: 0.6286704659461975\n",
      "2904, train_loss: 0.6365464925765991, val_loss: 0.6117622137069703\n",
      "2905, train_loss: 0.6365029857708857, val_loss: 0.6282275795936585\n",
      "2906, train_loss: 0.6364115866330954, val_loss: 0.6229021787643433\n",
      "2907, train_loss: 0.6345026859870324, val_loss: 0.6215952277183533\n",
      "2908, train_loss: 0.6359391189538516, val_loss: 0.6232184886932373\n",
      "2909, train_loss: 0.6362113104416773, val_loss: 0.6230733036994934\n",
      "2910, train_loss: 0.6341585883727441, val_loss: 0.6182114124298096\n",
      "2911, train_loss: 0.6341590812573066, val_loss: 0.6077210187911988\n",
      "2912, train_loss: 0.6356131480290339, val_loss: 0.6202826261520386\n",
      "2913, train_loss: 0.6359726236416743, val_loss: 0.6136708378791809\n",
      "2914, train_loss: 0.6335791303561285, val_loss: 0.6125211238861084\n",
      "2915, train_loss: 0.6357901715315305, val_loss: 0.628048050403595\n",
      "2916, train_loss: 0.6366141300935012, val_loss: 0.6209811687469482\n",
      "2917, train_loss: 0.6352527324969952, val_loss: 0.6220746755599975\n",
      "2918, train_loss: 0.6361940801143646, val_loss: 0.612841808795929\n",
      "2919, train_loss: 0.6357633379789499, val_loss: 0.6124869108200073\n",
      "2920, train_loss: 0.6360306900281173, val_loss: 0.622338342666626\n",
      "2921, train_loss: 0.6334577730068793, val_loss: 0.619748318195343\n",
      "2922, train_loss: 0.6331647015534915, val_loss: 0.6176593780517579\n",
      "2923, train_loss: 0.6358508651073163, val_loss: 0.6205547094345093\n",
      "2924, train_loss: 0.6350725912130796, val_loss: 0.6119538307189941\n",
      "2925, train_loss: 0.6350852663700397, val_loss: 0.6272935509681702\n",
      "2926, train_loss: 0.6349970216934497, val_loss: 0.6129485726356506\n",
      "2927, train_loss: 0.6324891768969022, val_loss: 0.612771499156952\n",
      "2928, train_loss: 0.6348764712993915, val_loss: 0.6198149085044861\n",
      "2929, train_loss: 0.6342259920560397, val_loss: 0.610055434703827\n",
      "2930, train_loss: 0.6347486055814303, val_loss: 0.6193294525146484\n",
      "2931, train_loss: 0.634044152039748, val_loss: 0.6195503234863281\n",
      "2932, train_loss: 0.6326748912151043, val_loss: 0.6175457000732422\n",
      "2933, train_loss: 0.6338766377705795, val_loss: 0.6107512712478638\n",
      "2934, train_loss: 0.6321208981367258, val_loss: 0.6217736840248108\n",
      "2935, train_loss: 0.634400718487226, val_loss: 0.6108474254608154\n",
      "2936, train_loss: 0.6342960298061371, val_loss: 0.6071000218391418\n",
      "2937, train_loss: 0.6323379369882437, val_loss: 0.6238679170608521\n",
      "2938, train_loss: 0.6341752387010134, val_loss: 0.6086554288864136\n",
      "2939, train_loss: 0.6316752869349259, val_loss: 0.60879967212677\n",
      "2940, train_loss: 0.6340115987337552, val_loss: 0.6081804394721985\n",
      "2941, train_loss: 0.6311459357921894, val_loss: 0.6005466699600219\n",
      "2942, train_loss: 0.6318874129882226, val_loss: 0.6098187565803528\n",
      "2943, train_loss: 0.631044688133093, val_loss: 0.6187048435211182\n",
      "2944, train_loss: 0.6331519530369685, val_loss: 0.6200943946838379\n",
      "2945, train_loss: 0.6336923081141251, val_loss: 0.61069815158844\n",
      "2946, train_loss: 0.6336612265843612, val_loss: 0.6155785918235779\n",
      "2947, train_loss: 0.6335834402304429, val_loss: 0.6157634973526\n",
      "2948, train_loss: 0.6334781027757205, val_loss: 0.6143169641494751\n",
      "2949, train_loss: 0.6309320651567899, val_loss: 0.6238938093185424\n",
      "2950, train_loss: 0.6335121209804828, val_loss: 0.6199648976325989\n",
      "2951, train_loss: 0.6332270755217626, val_loss: 0.6180261850357056\n",
      "2952, train_loss: 0.6312872492350065, val_loss: 0.6067340135574341\n",
      "2953, train_loss: 0.6306865765498235, val_loss: 0.6165576338768005\n",
      "2954, train_loss: 0.6329439442891341, val_loss: 0.6084122061729431\n",
      "2955, train_loss: 0.6305218086792872, val_loss: 0.6148321628570557\n",
      "2956, train_loss: 0.6301164329051971, val_loss: 0.6151782989501953\n",
      "2957, train_loss: 0.6328239463842832, val_loss: 0.6183334231376648\n",
      "2958, train_loss: 0.6327156699620761, val_loss: 0.618084168434143\n",
      "2959, train_loss: 0.632223170537215, val_loss: 0.6087112307548523\n",
      "2960, train_loss: 0.6303121608037215, val_loss: 0.6242691397666931\n",
      "2961, train_loss: 0.6325554343370291, val_loss: 0.6153188824653626\n",
      "2962, train_loss: 0.6324951167290027, val_loss: 0.6192141175270081\n",
      "2963, train_loss: 0.6321452489266028, val_loss: 0.6092069983482361\n",
      "2964, train_loss: 0.6319751349779276, val_loss: 0.6204943180084228\n",
      "2965, train_loss: 0.6321675594036396, val_loss: 0.6057754278182983\n",
      "2966, train_loss: 0.6321865709928366, val_loss: 0.60946706533432\n",
      "2967, train_loss: 0.6321049699416528, val_loss: 0.5993702054023743\n",
      "2968, train_loss: 0.6316833106371073, val_loss: 0.6120424509048462\n",
      "2969, train_loss: 0.6314000624876756, val_loss: 0.6147128343582153\n",
      "2970, train_loss: 0.6318223705658546, val_loss: 0.596659255027771\n",
      "2971, train_loss: 0.6318329503903022, val_loss: 0.6164315342903137\n",
      "2972, train_loss: 0.6295713415512671, val_loss: 0.617516303062439\n",
      "2973, train_loss: 0.6313054607464716, val_loss: 0.618829607963562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2974, train_loss: 0.631631965820606, val_loss: 0.6157801270484924\n",
      "2975, train_loss: 0.6314779886832604, val_loss: 0.6032212734222412\n",
      "2976, train_loss: 0.6289770213457254, val_loss: 0.5963453531265259\n",
      "2977, train_loss: 0.631453853387099, val_loss: 0.5984429597854615\n",
      "2978, train_loss: 0.6290091665891501, val_loss: 0.6055078506469727\n",
      "2979, train_loss: 0.6289574985320752, val_loss: 0.6157371163368225\n",
      "2980, train_loss: 0.6290368965038886, val_loss: 0.6177381873130798\n",
      "2981, train_loss: 0.6289913356304169, val_loss: 0.6130577802658081\n",
      "2982, train_loss: 0.6289287415834574, val_loss: 0.6180767297744751\n",
      "2983, train_loss: 0.6306384182893313, val_loss: 0.6088092803955079\n",
      "2984, train_loss: 0.6289204336129702, val_loss: 0.6057277321815491\n",
      "2985, train_loss: 0.6314784173782055, val_loss: 0.5973251461982727\n",
      "2986, train_loss: 0.6286356815925012, val_loss: 0.615312111377716\n",
      "2987, train_loss: 0.6282940346461076, val_loss: 0.614285159111023\n",
      "2988, train_loss: 0.6283472111591926, val_loss: 0.6160500168800354\n",
      "2989, train_loss: 0.6306624664710119, val_loss: 0.6068939447402955\n",
      "2990, train_loss: 0.6278067093629104, val_loss: 0.6054123759269714\n",
      "2991, train_loss: 0.6307414036530715, val_loss: 0.6118451237678528\n",
      "2992, train_loss: 0.6306795042294723, val_loss: 0.6158965229988098\n",
      "2993, train_loss: 0.6280562235758855, val_loss: 0.6067158460617066\n",
      "2994, train_loss: 0.6303276488414178, val_loss: 0.6181036829948425\n",
      "2995, train_loss: 0.6282878976601821, val_loss: 0.6195944905281067\n",
      "2996, train_loss: 0.6276646302296565, val_loss: 0.6154553413391113\n",
      "2997, train_loss: 0.6280374756226172, val_loss: 0.6070168733596801\n",
      "2998, train_loss: 0.6294443240532508, val_loss: 0.6224685668945312\n",
      "2999, train_loss: 0.6293401786914239, val_loss: 0.6061884164810181\n",
      "3000, train_loss: 0.6279749159629529, val_loss: 0.6158097386360168\n",
      "3001, train_loss: 0.6272695775215442, val_loss: 0.6167159914970398\n",
      "3002, train_loss: 0.6278294026851654, val_loss: 0.6145885109901428\n",
      "3003, train_loss: 0.629346645795382, val_loss: 0.6171648025512695\n",
      "3004, train_loss: 0.6270660391220679, val_loss: 0.5967406034469604\n",
      "3005, train_loss: 0.6273596378473135, val_loss: 0.6116097450256348\n",
      "3006, train_loss: 0.6295170187950134, val_loss: 0.6055628061294556\n",
      "3007, train_loss: 0.6294219746039464, val_loss: 0.6151983618736268\n",
      "3008, train_loss: 0.6292931689665868, val_loss: 0.6041737914085388\n",
      "3009, train_loss: 0.6270163907454565, val_loss: 0.6168528318405151\n",
      "3010, train_loss: 0.6292299009286441, val_loss: 0.6051946163177491\n",
      "3011, train_loss: 0.6291985786878146, val_loss: 0.6135558128356934\n",
      "3012, train_loss: 0.6268308598261613, val_loss: 0.60408935546875\n",
      "3013, train_loss: 0.6271144587260026, val_loss: 0.6143822431564331\n",
      "3014, train_loss: 0.6267874676447648, val_loss: 0.6107481956481934\n",
      "3015, train_loss: 0.6266637398646429, val_loss: 0.6058528780937195\n",
      "3016, train_loss: 0.6290954397274897, val_loss: 0.6140996098518372\n",
      "3017, train_loss: 0.6265014547568101, val_loss: 0.6008951783180236\n",
      "3018, train_loss: 0.6268459168764261, val_loss: 0.6107677221298218\n",
      "3019, train_loss: 0.6287131653382227, val_loss: 0.6128900647163391\n",
      "3020, train_loss: 0.6286667241499975, val_loss: 0.6106527805328369\n",
      "3021, train_loss: 0.6286697594019083, val_loss: 0.6040943145751954\n",
      "3022, train_loss: 0.6279922930093912, val_loss: 0.5933982133865356\n",
      "3023, train_loss: 0.6262372227815481, val_loss: 0.613739287853241\n",
      "3024, train_loss: 0.6257148270423596, val_loss: 0.602164113521576\n",
      "3025, train_loss: 0.626233343894665, val_loss: 0.6097653031349182\n",
      "3026, train_loss: 0.6262992803867047, val_loss: 0.6000322580337525\n",
      "3027, train_loss: 0.6256580650806427, val_loss: 0.6181772351264954\n",
      "3028, train_loss: 0.6274983997528369, val_loss: 0.6112749695777893\n",
      "3029, train_loss: 0.6279992209031031, val_loss: 0.6166193842887878\n",
      "3030, train_loss: 0.6259787541169387, val_loss: 0.6039967179298401\n",
      "3031, train_loss: 0.6255595340178564, val_loss: 0.6091807842254638\n",
      "3032, train_loss: 0.6278233528137207, val_loss: 0.6120270371437073\n",
      "3033, train_loss: 0.6252326506834763, val_loss: 0.6130282640457153\n",
      "3034, train_loss: 0.627696848832644, val_loss: 0.6089762330055237\n",
      "3035, train_loss: 0.627589049247595, val_loss: 0.6139562129974365\n",
      "3036, train_loss: 0.6277009638456198, val_loss: 0.5995894312858582\n",
      "3037, train_loss: 0.6274657524549044, val_loss: 0.6141135811805725\n",
      "3038, train_loss: 0.6251099017950205, val_loss: 0.6059473991394043\n",
      "3039, train_loss: 0.6272671383160812, val_loss: 0.614005184173584\n",
      "3040, train_loss: 0.6271782265259669, val_loss: 0.6024471402168274\n",
      "3041, train_loss: 0.6271208960276383, val_loss: 0.6036414861679077\n",
      "3042, train_loss: 0.627088012603613, val_loss: 0.6102277994155884\n",
      "3043, train_loss: 0.6275350313920242, val_loss: 0.6137632250785827\n",
      "3044, train_loss: 0.6264250920369074, val_loss: 0.6148600578308105\n",
      "3045, train_loss: 0.6268470952144036, val_loss: 0.614731740951538\n",
      "3046, train_loss: 0.6267742743858924, val_loss: 0.6073756217956543\n",
      "3047, train_loss: 0.6247017337725713, val_loss: 0.5972440123558045\n",
      "3048, train_loss: 0.6242534311918112, val_loss: 0.6012567639350891\n",
      "3049, train_loss: 0.625841335608409, val_loss: 0.6186099767684936\n",
      "3050, train_loss: 0.6235152964408581, val_loss: 0.6150056004524231\n",
      "3051, train_loss: 0.6239493030768174, val_loss: 0.6019538402557373\n",
      "3052, train_loss: 0.6242952644824982, val_loss: 0.6138339400291443\n",
      "3053, train_loss: 0.623991085932805, val_loss: 0.6033646583557128\n",
      "3054, train_loss: 0.626252878170747, val_loss: 0.6094153523445129\n",
      "3055, train_loss: 0.6239268596355731, val_loss: 0.6082075238227844\n",
      "3056, train_loss: 0.626130243906608, val_loss: 0.6107600331306458\n",
      "3057, train_loss: 0.6265295170820676, val_loss: 0.6035434126853942\n",
      "3058, train_loss: 0.6264631656500009, val_loss: 0.5990952491760254\n",
      "3059, train_loss: 0.6253986610816076, val_loss: 0.5926779508590698\n",
      "3060, train_loss: 0.6259763447137979, val_loss: 0.6163349390029907\n",
      "3061, train_loss: 0.6257869532475104, val_loss: 0.5903792381286621\n",
      "3062, train_loss: 0.6257458397975335, val_loss: 0.614030396938324\n",
      "3063, train_loss: 0.6255216300487518, val_loss: 0.6038748025894165\n",
      "3064, train_loss: 0.625549451662944, val_loss: 0.6015551924705506\n",
      "3065, train_loss: 0.6251837290250338, val_loss: 0.603019630908966\n",
      "3066, train_loss: 0.6250537175398606, val_loss: 0.5926679253578186\n",
      "3067, train_loss: 0.6248953938484192, val_loss: 0.5997058868408203\n",
      "3068, train_loss: 0.6249905159840217, val_loss: 0.6101346015930176\n",
      "3069, train_loss: 0.6231820033146784, val_loss: 0.6155799984931946\n",
      "3070, train_loss: 0.6241077528550074, val_loss: 0.591176962852478\n",
      "3071, train_loss: 0.622801654613935, val_loss: 0.6109036922454834\n",
      "3072, train_loss: 0.6251074946843661, val_loss: 0.6077532887458801\n",
      "3073, train_loss: 0.6245131286290976, val_loss: 0.5987144947052002\n",
      "3074, train_loss: 0.6244448927732614, val_loss: 0.6099339365959168\n",
      "3075, train_loss: 0.6242914979274456, val_loss: 0.6063188076019287\n",
      "3076, train_loss: 0.6249107122421265, val_loss: 0.6036186218261719\n",
      "3077, train_loss: 0.6247133119748189, val_loss: 0.6134323596954345\n",
      "3078, train_loss: 0.624613711467156, val_loss: 0.5924189329147339\n",
      "3079, train_loss: 0.6245697163618528, val_loss: 0.5993805527687073\n",
      "3080, train_loss: 0.6244953389351184, val_loss: 0.6107349514961242\n",
      "3081, train_loss: 0.6224602483786069, val_loss: 0.614860451221466\n",
      "3082, train_loss: 0.6235734338943775, val_loss: 0.5994748592376709\n",
      "3083, train_loss: 0.621787259211907, val_loss: 0.5988383412361145\n",
      "3084, train_loss: 0.6239074376913217, val_loss: 0.6001651883125305\n",
      "3085, train_loss: 0.621737920320951, val_loss: 0.6129925489425659\n",
      "3086, train_loss: 0.6241007286768693, val_loss: 0.6027348041534424\n",
      "3087, train_loss: 0.624047923546571, val_loss: 0.6074978947639466\n",
      "3088, train_loss: 0.6238239430464231, val_loss: 0.5963752150535584\n",
      "3089, train_loss: 0.6239760059576768, val_loss: 0.60804283618927\n",
      "3090, train_loss: 0.6214613708165976, val_loss: 0.6060938596725464\n",
      "3091, train_loss: 0.623749914077612, val_loss: 0.6098589062690735\n",
      "3092, train_loss: 0.6232459224187411, val_loss: 0.6073559761047364\n",
      "3093, train_loss: 0.6236197787981766, val_loss: 0.599714744091034\n",
      "3094, train_loss: 0.6214554011821747, val_loss: 0.6089715957641602\n",
      "3095, train_loss: 0.6210081485601572, val_loss: 0.6096820116043091\n",
      "3096, train_loss: 0.6214156425916232, val_loss: 0.6097583770751953\n",
      "3097, train_loss: 0.6213611616538122, val_loss: 0.6014967083930969\n",
      "3098, train_loss: 0.6233437405182765, val_loss: 0.6037844300270081\n",
      "3099, train_loss: 0.6230721771717072, val_loss: 0.6004879474639893\n",
      "3100, train_loss: 0.6204450497260461, val_loss: 0.6139423489570618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3101, train_loss: 0.6231645827109997, val_loss: 0.610492742061615\n",
      "3102, train_loss: 0.6230523013151609, val_loss: 0.6011194229125977\n",
      "3103, train_loss: 0.620949408182731, val_loss: 0.5897855043411255\n",
      "3104, train_loss: 0.622377104484118, val_loss: 0.5970019459724426\n",
      "3105, train_loss: 0.6224472110088055, val_loss: 0.6076520562171936\n",
      "3106, train_loss: 0.6200879170344427, val_loss: 0.5978766798973083\n",
      "3107, train_loss: 0.6203505144669459, val_loss: 0.6135515093803405\n",
      "3108, train_loss: 0.6224403404272519, val_loss: 0.5972381114959717\n",
      "3109, train_loss: 0.6226504215827355, val_loss: 0.6135140776634216\n",
      "3110, train_loss: 0.6225367944974166, val_loss: 0.6060255169868469\n",
      "3111, train_loss: 0.6198994173453405, val_loss: 0.6049753308296204\n",
      "3112, train_loss: 0.6217992649628565, val_loss: 0.5957513809204101\n",
      "3113, train_loss: 0.6202293932437897, val_loss: 0.601264488697052\n",
      "3114, train_loss: 0.6219922991899344, val_loss: 0.6068491578102112\n",
      "3115, train_loss: 0.6194265553584466, val_loss: 0.5995375633239746\n",
      "3116, train_loss: 0.6219333616586832, val_loss: 0.6117718577384949\n",
      "3117, train_loss: 0.6220099077774928, val_loss: 0.5984113335609436\n",
      "3118, train_loss: 0.6196280809549185, val_loss: 0.6065336227416992\n",
      "3119, train_loss: 0.6195063178355877, val_loss: 0.6110944032669068\n",
      "3120, train_loss: 0.619369626045227, val_loss: 0.596126663684845\n",
      "3121, train_loss: 0.6212267187925485, val_loss: 0.5945513367652893\n",
      "3122, train_loss: 0.6217301166974581, val_loss: 0.6073115229606628\n",
      "3123, train_loss: 0.6195619587714856, val_loss: 0.5881459474563598\n",
      "3124, train_loss: 0.6207720774870652, val_loss: 0.5948300361633301\n",
      "3125, train_loss: 0.6209631768556741, val_loss: 0.5971534967422485\n",
      "3126, train_loss: 0.6189495393863091, val_loss: 0.61095290184021\n",
      "3127, train_loss: 0.621403666642996, val_loss: 0.6094290494918824\n",
      "3128, train_loss: 0.6189639018132136, val_loss: 0.6103979587554932\n",
      "3129, train_loss: 0.6187969744205475, val_loss: 0.58812575340271\n",
      "3130, train_loss: 0.6205503378923123, val_loss: 0.5946922123432159\n",
      "3131, train_loss: 0.6211617520222297, val_loss: 0.6033357620239258\n",
      "3132, train_loss: 0.6209844786387223, val_loss: 0.6090953946113586\n",
      "3133, train_loss: 0.6183402973871964, val_loss: 0.6105525255203247\n",
      "3134, train_loss: 0.6202698006079748, val_loss: 0.5858372807502746\n",
      "3135, train_loss: 0.6188028042133038, val_loss: 0.6083415746688843\n",
      "3136, train_loss: 0.620839380300962, val_loss: 0.6032312870025635\n",
      "3137, train_loss: 0.6207921252800868, val_loss: 0.608815586566925\n",
      "3138, train_loss: 0.6207267298148229, val_loss: 0.6085646271705627\n",
      "3139, train_loss: 0.6184467535752517, val_loss: 0.6083199739456177\n",
      "3140, train_loss: 0.6181627397353833, val_loss: 0.6070138692855835\n",
      "3141, train_loss: 0.6199194972331707, val_loss: 0.6029774069786071\n",
      "3142, train_loss: 0.6210213762063247, val_loss: 0.6051746726036071\n",
      "3143, train_loss: 0.6177562727377965, val_loss: 0.603581964969635\n",
      "3144, train_loss: 0.617519736289978, val_loss: 0.5981653690338135\n",
      "3145, train_loss: 0.6202440972511585, val_loss: 0.6139110207557679\n",
      "3146, train_loss: 0.6202161289178408, val_loss: 0.5868794918060303\n",
      "3147, train_loss: 0.6201061079135308, val_loss: 0.5958079695701599\n",
      "3148, train_loss: 0.617903552376307, val_loss: 0.6065181136131287\n",
      "3149, train_loss: 0.6170920729637146, val_loss: 0.5918298959732056\n",
      "3150, train_loss: 0.6173625382093283, val_loss: 0.5859843969345093\n",
      "3151, train_loss: 0.6199396436031048, val_loss: 0.5937944173812866\n",
      "3152, train_loss: 0.619848356797145, val_loss: 0.6060800075531005\n",
      "3153, train_loss: 0.619784428523137, val_loss: 0.6093438625335693\n",
      "3154, train_loss: 0.6176625604812915, val_loss: 0.6019751191139221\n",
      "3155, train_loss: 0.6196877383268796, val_loss: 0.6014946579933167\n",
      "3156, train_loss: 0.6196087415401752, val_loss: 0.6049371719360351\n",
      "3157, train_loss: 0.6195116937160492, val_loss: 0.6106381058692932\n",
      "3158, train_loss: 0.6188213595977197, val_loss: 0.6084084510803223\n",
      "3159, train_loss: 0.6170857227765597, val_loss: 0.6027035117149353\n",
      "3160, train_loss: 0.616538439805691, val_loss: 0.5938546538352967\n",
      "3161, train_loss: 0.6192438121025379, val_loss: 0.6026445984840393\n",
      "3162, train_loss: 0.6191859130675976, val_loss: 0.6039240241050721\n",
      "3163, train_loss: 0.6167476704487433, val_loss: 0.6129040956497193\n",
      "3164, train_loss: 0.6193629274001489, val_loss: 0.5935334205627442\n",
      "3165, train_loss: 0.6189897358417511, val_loss: 0.6038594603538513\n",
      "3166, train_loss: 0.6189242876493014, val_loss: 0.6049776077270508\n",
      "3167, train_loss: 0.6188405293684739, val_loss: 0.5950288534164428\n",
      "3168, train_loss: 0.6166868668336135, val_loss: 0.5948727846145629\n",
      "3169, train_loss: 0.6166408107830927, val_loss: 0.5950366258621216\n",
      "3170, train_loss: 0.6160352883430628, val_loss: 0.6067914009094239\n",
      "3171, train_loss: 0.6186409271680392, val_loss: 0.6029657602310181\n",
      "3172, train_loss: 0.6162284543881049, val_loss: 0.6123809099197388\n",
      "3173, train_loss: 0.6163055988458487, val_loss: 0.5970639109611511\n",
      "3174, train_loss: 0.6184378839456118, val_loss: 0.6074784994125366\n",
      "3175, train_loss: 0.6159317447588994, val_loss: 0.5981460213661194\n",
      "3176, train_loss: 0.6183041540475992, val_loss: 0.5945563673973083\n",
      "3177, train_loss: 0.6156753851817205, val_loss: 0.5999187111854554\n",
      "3178, train_loss: 0.6181542850457705, val_loss: 0.6004153370857239\n",
      "3179, train_loss: 0.6180696441577032, val_loss: 0.6119973182678222\n",
      "3180, train_loss: 0.6155323936389043, val_loss: 0.6058738231658936\n",
      "3181, train_loss: 0.6155180770617265, val_loss: 0.5957786440849304\n",
      "3182, train_loss: 0.6156984682266529, val_loss: 0.5957918763160706\n",
      "3183, train_loss: 0.6157161043240473, val_loss: 0.5852770984172821\n",
      "3184, train_loss: 0.6155924980457013, val_loss: 0.589827036857605\n",
      "3185, train_loss: 0.6175981851724478, val_loss: 0.606582522392273\n",
      "3186, train_loss: 0.617673037143854, val_loss: 0.5945798516273498\n",
      "3187, train_loss: 0.6170269915690789, val_loss: 0.593859338760376\n",
      "3188, train_loss: 0.6175694717810705, val_loss: 0.5918153762817383\n",
      "3189, train_loss: 0.6178402029550992, val_loss: 0.5841930508613586\n",
      "3190, train_loss: 0.617460691011869, val_loss: 0.5994837403297424\n",
      "3191, train_loss: 0.6173935509645022, val_loss: 0.6029338717460633\n",
      "3192, train_loss: 0.6172878788067744, val_loss: 0.5928823351860046\n",
      "3193, train_loss: 0.6170340868142935, val_loss: 0.5951460003852844\n",
      "3194, train_loss: 0.6177591566856091, val_loss: 0.6028428316116333\n",
      "3195, train_loss: 0.6167980294961196, val_loss: 0.5924237608909607\n",
      "3196, train_loss: 0.6169854425466977, val_loss: 0.5832843899726867\n",
      "3197, train_loss: 0.6163009405136108, val_loss: 0.5947726011276245\n",
      "3198, train_loss: 0.614702011530216, val_loss: 0.6016977071762085\n",
      "3199, train_loss: 0.6137559276360732, val_loss: 0.5947451114654541\n",
      "3200, train_loss: 0.6146072424375094, val_loss: 0.6007057428359985\n",
      "3201, train_loss: 0.6167384363137759, val_loss: 0.5866981387138367\n",
      "3202, train_loss: 0.6163919132489425, val_loss: 0.5999623298645019\n",
      "3203, train_loss: 0.6166181587255918, val_loss: 0.6056068778038025\n",
      "3204, train_loss: 0.6137436513717358, val_loss: 0.602586317062378\n",
      "3205, train_loss: 0.6164840482748472, val_loss: 0.5982330560684204\n",
      "3206, train_loss: 0.6160277884740096, val_loss: 0.5960282802581787\n",
      "3207, train_loss: 0.6141581489489629, val_loss: 0.5832585334777832\n",
      "3208, train_loss: 0.6135776524360363, val_loss: 0.6019616484642029\n",
      "3209, train_loss: 0.6162442427415115, val_loss: 0.6017347991466522\n",
      "3210, train_loss: 0.615247524701632, val_loss: 0.593100392818451\n",
      "3211, train_loss: 0.6161210445257334, val_loss: 0.6003596425056458\n",
      "3212, train_loss: 0.6160275007669742, val_loss: 0.6041855454444885\n",
      "3213, train_loss: 0.6159331064957839, val_loss: 0.6040954113006591\n",
      "3214, train_loss: 0.6158711795623486, val_loss: 0.6045707702636719\n",
      "3215, train_loss: 0.615749180316925, val_loss: 0.5862925529479981\n",
      "3216, train_loss: 0.6126271050709945, val_loss: 0.594101631641388\n",
      "3217, train_loss: 0.6157313447732192, val_loss: 0.5999997735023499\n",
      "3218, train_loss: 0.6130098517124469, val_loss: 0.5917630434036255\n",
      "3219, train_loss: 0.6133670325462635, val_loss: 0.5811154007911682\n",
      "3220, train_loss: 0.6155732251130618, val_loss: 0.6040739297866822\n",
      "3221, train_loss: 0.6152409017086029, val_loss: 0.6004083752632141\n",
      "3222, train_loss: 0.6154245940538553, val_loss: 0.6023923993110657\n",
      "3223, train_loss: 0.615194708108902, val_loss: 0.5977485537528991\n",
      "3224, train_loss: 0.6127367787636243, val_loss: 0.6004117250442504\n",
      "3225, train_loss: 0.6149565485807565, val_loss: 0.5993544816970825\n",
      "3226, train_loss: 0.6122921407222748, val_loss: 0.5953032970428467\n",
      "3227, train_loss: 0.6128085828744448, val_loss: 0.5915199995040894\n",
      "3228, train_loss: 0.6127797090090238, val_loss: 0.5974296689033508\n",
      "3229, train_loss: 0.6124061712851891, val_loss: 0.5896841764450074\n",
      "3230, train_loss: 0.6122497205550854, val_loss: 0.5898005962371826\n",
      "3231, train_loss: 0.6148632925290328, val_loss: 0.5916297674179077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3232, train_loss: 0.614831255032466, val_loss: 0.5907859086990357\n",
      "3233, train_loss: 0.6143811494112015, val_loss: 0.5999549508094788\n",
      "3234, train_loss: 0.6125390896430383, val_loss: 0.5865084290504455\n",
      "3235, train_loss: 0.6138870395146884, val_loss: 0.5945384681224823\n",
      "3236, train_loss: 0.6123150908029996, val_loss: 0.6005514025688171\n",
      "3237, train_loss: 0.6149829901181735, val_loss: 0.5935739874839783\n",
      "3238, train_loss: 0.6146384110817542, val_loss: 0.5900236248970032\n",
      "3239, train_loss: 0.6148136693697709, val_loss: 0.5933968544006347\n",
      "3240, train_loss: 0.6119041397021368, val_loss: 0.5924967646598815\n",
      "3241, train_loss: 0.6142361622590286, val_loss: 0.6050990939140319\n",
      "3242, train_loss: 0.6114045748343835, val_loss: 0.5820369005203248\n",
      "3243, train_loss: 0.6133970664097712, val_loss: 0.5973896384239197\n",
      "3244, train_loss: 0.6114566463690537, val_loss: 0.5904992341995239\n",
      "3245, train_loss: 0.6117151081562042, val_loss: 0.5927931785583496\n",
      "3246, train_loss: 0.6135309086396143, val_loss: 0.5868398189544678\n",
      "3247, train_loss: 0.6116977643508178, val_loss: 0.5912799835205078\n",
      "3248, train_loss: 0.6138124294005908, val_loss: 0.5982144594192504\n",
      "3249, train_loss: 0.6137235279266651, val_loss: 0.5903550028800965\n",
      "3250, train_loss: 0.6136916692440326, val_loss: 0.602307939529419\n",
      "3251, train_loss: 0.6130004433485178, val_loss: 0.5984460532665252\n",
      "3252, train_loss: 0.6135391913927518, val_loss: 0.5927950978279114\n",
      "3253, train_loss: 0.6134990086922278, val_loss: 0.5952239155769348\n",
      "3254, train_loss: 0.6124406915444595, val_loss: 0.5867141485214233\n",
      "3255, train_loss: 0.6123262208241683, val_loss: 0.5897016048431396\n",
      "3256, train_loss: 0.6132925680050483, val_loss: 0.5914962649345398\n",
      "3257, train_loss: 0.6132546594509711, val_loss: 0.6020433783531189\n",
      "3258, train_loss: 0.6131872374277848, val_loss: 0.5930441498756409\n",
      "3259, train_loss: 0.6133762896060944, val_loss: 0.5974621534347534\n",
      "3260, train_loss: 0.61287083534094, val_loss: 0.6000876009464264\n",
      "3261, train_loss: 0.6126399200696212, val_loss: 0.5931797027587891\n",
      "3262, train_loss: 0.6104697653880486, val_loss: 0.5898914337158203\n",
      "3263, train_loss: 0.6105672292984449, val_loss: 0.5874288082122803\n",
      "3264, train_loss: 0.6104652938934473, val_loss: 0.5927034616470337\n",
      "3265, train_loss: 0.612367746921686, val_loss: 0.5792951107025146\n",
      "3266, train_loss: 0.609498876791734, val_loss: 0.5826948881149292\n",
      "3267, train_loss: 0.6125249610497401, val_loss: 0.6009097695350647\n",
      "3268, train_loss: 0.611614832511315, val_loss: 0.597880482673645\n",
      "3269, train_loss: 0.6124984209354107, val_loss: 0.5978408575057983\n",
      "3270, train_loss: 0.6115524677129892, val_loss: 0.5896423578262329\n",
      "3271, train_loss: 0.6123651036849389, val_loss: 0.5859129786491394\n",
      "3272, train_loss: 0.6095430151774333, val_loss: 0.5940315008163453\n",
      "3273, train_loss: 0.6096509924301734, val_loss: 0.5884066224098206\n",
      "3274, train_loss: 0.6122467196904696, val_loss: 0.595391309261322\n",
      "3275, train_loss: 0.6121946206459632, val_loss: 0.588842260837555\n",
      "3276, train_loss: 0.6121136248111725, val_loss: 0.5883935332298279\n",
      "3277, train_loss: 0.6092520837600415, val_loss: 0.5778310537338257\n",
      "3278, train_loss: 0.6117310913709494, val_loss: 0.589294946193695\n",
      "3279, train_loss: 0.6117918823774045, val_loss: 0.6003205060958863\n",
      "3280, train_loss: 0.6085446545710931, val_loss: 0.6030258417129517\n",
      "3281, train_loss: 0.6118027338614831, val_loss: 0.6010458946228028\n",
      "3282, train_loss: 0.6091142296791077, val_loss: 0.598760187625885\n",
      "3283, train_loss: 0.6108088585046622, val_loss: 0.600018835067749\n",
      "3284, train_loss: 0.6110546565972842, val_loss: 0.5883471250534058\n",
      "3285, train_loss: 0.609015588576977, val_loss: 0.6026665210723877\n",
      "3286, train_loss: 0.6111667431317843, val_loss: 0.5864127278327942\n",
      "3287, train_loss: 0.6114490742866809, val_loss: 0.5975552201271057\n",
      "3288, train_loss: 0.6107383920596197, val_loss: 0.5904965758323669\n",
      "3289, train_loss: 0.6105444798102746, val_loss: 0.5845835864543915\n",
      "3290, train_loss: 0.6104424779231732, val_loss: 0.5918095111846924\n",
      "3291, train_loss: 0.611165083371676, val_loss: 0.6027387142181396\n",
      "3292, train_loss: 0.6115993696909684, val_loss: 0.5762441039085389\n",
      "3293, train_loss: 0.6087362697491279, val_loss: 0.590271258354187\n",
      "3294, train_loss: 0.6101928914968784, val_loss: 0.5944391131401062\n",
      "3295, train_loss: 0.6109423580077978, val_loss: 0.5886853098869324\n",
      "3296, train_loss: 0.610854664674172, val_loss: 0.5956775188446045\n",
      "3297, train_loss: 0.6104832669863334, val_loss: 0.603050422668457\n",
      "3298, train_loss: 0.6084040942100378, val_loss: 0.6000092029571533\n",
      "3299, train_loss: 0.6104022998076218, val_loss: 0.5912008345127105\n",
      "3300, train_loss: 0.6105828342529444, val_loss: 0.5899650573730468\n",
      "3301, train_loss: 0.6101946739050058, val_loss: 0.5985291481018067\n",
      "3302, train_loss: 0.6104461390238541, val_loss: 0.5942193746566773\n",
      "3303, train_loss: 0.6080015508028177, val_loss: 0.590490996837616\n",
      "3304, train_loss: 0.6092106436307614, val_loss: 0.5966597199440002\n",
      "3305, train_loss: 0.6102486000611231, val_loss: 0.5833429455757141\n",
      "3306, train_loss: 0.6091961975281055, val_loss: 0.5911957621574402\n",
      "3307, train_loss: 0.6079663565525641, val_loss: 0.5895654439926148\n",
      "3308, train_loss: 0.609812115247433, val_loss: 0.58474041223526\n",
      "3309, train_loss: 0.6096509740902827, val_loss: 0.5899987101554871\n",
      "3310, train_loss: 0.6068839522508475, val_loss: 0.5963721156120301\n",
      "3311, train_loss: 0.6098883518805871, val_loss: 0.5938556432723999\n",
      "3312, train_loss: 0.609795331954956, val_loss: 0.6024268746376038\n",
      "3313, train_loss: 0.6094710391301376, val_loss: 0.60270094871521\n",
      "3314, train_loss: 0.609096158009309, val_loss: 0.5882456302642822\n",
      "3315, train_loss: 0.6091078794919528, val_loss: 0.5998615264892578\n",
      "3316, train_loss: 0.6065843265790206, val_loss: 0.5927386164665223\n",
      "3317, train_loss: 0.6092743885058624, val_loss: 0.5896416425704956\n",
      "3318, train_loss: 0.6079307725796332, val_loss: 0.6024194955825806\n",
      "3319, train_loss: 0.6066183058115152, val_loss: 0.6021609425544738\n",
      "3320, train_loss: 0.6059185839616336, val_loss: 0.5978903770446777\n",
      "3321, train_loss: 0.6066871445912582, val_loss: 0.5868633627891541\n",
      "3322, train_loss: 0.6091660971824939, val_loss: 0.5956130623817444\n",
      "3323, train_loss: 0.6063191753167373, val_loss: 0.5974595665931701\n",
      "3324, train_loss: 0.6060336117561047, val_loss: 0.5872523069381714\n",
      "3325, train_loss: 0.6090266750409052, val_loss: 0.5953319907188416\n",
      "3326, train_loss: 0.6063994925755721, val_loss: 0.6044385075569153\n",
      "3327, train_loss: 0.6065744390854468, val_loss: 0.5838879942893982\n",
      "3328, train_loss: 0.6061240686820104, val_loss: 0.5950278520584107\n",
      "3329, train_loss: 0.6087884639318173, val_loss: 0.5926363229751587\n",
      "3330, train_loss: 0.6058742140348141, val_loss: 0.5998996376991272\n",
      "3331, train_loss: 0.6081910053124795, val_loss: 0.584979796409607\n",
      "3332, train_loss: 0.6086109716158646, val_loss: 0.6014396190643311\n",
      "3333, train_loss: 0.6085274792634524, val_loss: 0.5817273616790771\n",
      "3334, train_loss: 0.6088410237660775, val_loss: 0.5890574812889099\n",
      "3335, train_loss: 0.6084175820534046, val_loss: 0.5980117440223693\n",
      "3336, train_loss: 0.6083596165363605, val_loss: 0.57418452501297\n",
      "3337, train_loss: 0.6083617370862228, val_loss: 0.5799904823303222\n",
      "3338, train_loss: 0.608252763748169, val_loss: 0.5815893769264221\n",
      "3339, train_loss: 0.6073700556388268, val_loss: 0.5921724319458008\n",
      "3340, train_loss: 0.6056512193037913, val_loss: 0.5846656680107116\n",
      "3341, train_loss: 0.6077511998323294, val_loss: 0.597623074054718\n",
      "3342, train_loss: 0.6080056497683892, val_loss: 0.5829631686210632\n",
      "3343, train_loss: 0.6076407042833475, val_loss: 0.5991860866546631\n",
      "3344, train_loss: 0.6053239978276767, val_loss: 0.5952751517295838\n",
      "3345, train_loss: 0.605009152339055, val_loss: 0.5851172089576722\n",
      "3346, train_loss: 0.6069080118949597, val_loss: 0.6000548958778381\n",
      "3347, train_loss: 0.6067727185212649, val_loss: 0.5832189083099365\n",
      "3348, train_loss: 0.6046038957742544, val_loss: 0.5846931219100953\n",
      "3349, train_loss: 0.6075713668878262, val_loss: 0.5963346600532532\n",
      "3350, train_loss: 0.6050189297932845, val_loss: 0.5971459031105042\n",
      "3351, train_loss: 0.6074579151777121, val_loss: 0.5839824557304383\n",
      "3352, train_loss: 0.6049982653214381, val_loss: 0.5949077010154724\n",
      "3353, train_loss: 0.6070487132439246, val_loss: 0.5949003458023071\n",
      "3354, train_loss: 0.604326048722634, val_loss: 0.5974780559539795\n",
      "3355, train_loss: 0.6072316605311173, val_loss: 0.5783868193626404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3356, train_loss: 0.6071771314510932, val_loss: 0.5783265233039856\n",
      "3357, train_loss: 0.6071681769994589, val_loss: 0.5842625975608826\n",
      "3358, train_loss: 0.6047144887539057, val_loss: 0.600297474861145\n",
      "3359, train_loss: 0.6046384618832514, val_loss: 0.592865240573883\n",
      "3360, train_loss: 0.606920219384707, val_loss: 0.5832849264144897\n",
      "3361, train_loss: 0.6060051734630878, val_loss: 0.5952784299850464\n",
      "3362, train_loss: 0.6068190313302554, val_loss: 0.5878047347068787\n",
      "3363, train_loss: 0.6067848388965313, val_loss: 0.5829904556274415\n",
      "3364, train_loss: 0.6044897024448102, val_loss: 0.5926199793815613\n",
      "3365, train_loss: 0.6066908400792342, val_loss: 0.5896785616874695\n",
      "3366, train_loss: 0.6041288926051214, val_loss: 0.5915903210639953\n",
      "3367, train_loss: 0.6041029657308872, val_loss: 0.5953838229179382\n",
      "3368, train_loss: 0.6057325349404261, val_loss: 0.5813980221748352\n",
      "3369, train_loss: 0.6038414377432603, val_loss: 0.5742828369140625\n",
      "3370, train_loss: 0.6038370453394376, val_loss: 0.5868685364723205\n",
      "3371, train_loss: 0.6063042099659259, val_loss: 0.5928196668624878\n",
      "3372, train_loss: 0.6062741600550138, val_loss: 0.5937339782714843\n",
      "3373, train_loss: 0.6038710750066317, val_loss: 0.5984814822673797\n",
      "3374, train_loss: 0.6027775750710413, val_loss: 0.6019775629043579\n",
      "3375, train_loss: 0.6053071858791205, val_loss: 0.5841604948043824\n",
      "3376, train_loss: 0.6032981482835916, val_loss: 0.5741828918457031\n",
      "3377, train_loss: 0.6059687321002667, val_loss: 0.5792820811271667\n",
      "3378, train_loss: 0.6050874556486423, val_loss: 0.5856607913970947\n",
      "3379, train_loss: 0.6031334423101865, val_loss: 0.5896146297454834\n",
      "3380, train_loss: 0.6033048790234786, val_loss: 0.5721249043941498\n",
      "3381, train_loss: 0.6057808341888281, val_loss: 0.5951400756835937\n",
      "3382, train_loss: 0.6052640091914397, val_loss: 0.5989101648330688\n",
      "3383, train_loss: 0.6053815506971799, val_loss: 0.5833312034606933\n",
      "3384, train_loss: 0.6032031659896557, val_loss: 0.579150116443634\n",
      "3385, train_loss: 0.6025717246990937, val_loss: 0.5869870781898499\n",
      "3386, train_loss: 0.6043529854370997, val_loss: 0.5735438108444214\n",
      "3387, train_loss: 0.6026548330600445, val_loss: 0.5900365352630615\n",
      "3388, train_loss: 0.6028746733298669, val_loss: 0.580749261379242\n",
      "3389, train_loss: 0.6046864780095907, val_loss: 0.5863379776477814\n",
      "3390, train_loss: 0.6040718142802899, val_loss: 0.5866956114768982\n",
      "3391, train_loss: 0.6051838214580829, val_loss: 0.5947996020317078\n",
      "3392, train_loss: 0.6051164315297053, val_loss: 0.5915811657905579\n",
      "3393, train_loss: 0.6024812379708657, val_loss: 0.5800102114677429\n",
      "3394, train_loss: 0.6023511508336434, val_loss: 0.5848296642303467\n",
      "3395, train_loss: 0.6049772500991821, val_loss: 0.5830806612968444\n",
      "3396, train_loss: 0.6023186995432928, val_loss: 0.5854283630847931\n",
      "3397, train_loss: 0.6039462089538574, val_loss: 0.5810325860977172\n",
      "3398, train_loss: 0.6019558402208182, val_loss: 0.594364595413208\n",
      "3399, train_loss: 0.6039646222041204, val_loss: 0.5948343753814698\n",
      "3400, train_loss: 0.601731986953662, val_loss: 0.5888964653015136\n",
      "3401, train_loss: 0.6040450517947857, val_loss: 0.5888680338859558\n",
      "3402, train_loss: 0.6039370756882888, val_loss: 0.5921883821487427\n",
      "3403, train_loss: 0.6035336003853724, val_loss: 0.5843491554260254\n",
      "3404, train_loss: 0.6044431775808334, val_loss: 0.5796350121498108\n",
      "3405, train_loss: 0.6042968699565301, val_loss: 0.5939927101135254\n",
      "3406, train_loss: 0.601408417408283, val_loss: 0.5962473750114441\n",
      "3407, train_loss: 0.6038345809166248, val_loss: 0.5911024808883667\n",
      "3408, train_loss: 0.6018180663769062, val_loss: 0.5802759408950806\n",
      "3409, train_loss: 0.6010380375843781, val_loss: 0.5860006093978882\n",
      "3410, train_loss: 0.6029462011960837, val_loss: 0.5978457927703857\n",
      "3411, train_loss: 0.6016100599215581, val_loss: 0.5881615161895752\n",
      "3412, train_loss: 0.6028521507978439, val_loss: 0.5771237850189209\n",
      "3413, train_loss: 0.6038785576820374, val_loss: 0.597652006149292\n",
      "3414, train_loss: 0.6014625143546325, val_loss: 0.589983868598938\n",
      "3415, train_loss: 0.6034378225986774, val_loss: 0.571281886100769\n",
      "3416, train_loss: 0.6012642521124619, val_loss: 0.597130537033081\n",
      "3417, train_loss: 0.6026797695801809, val_loss: 0.5994377613067627\n",
      "3418, train_loss: 0.6035603559934176, val_loss: 0.5707361400127411\n",
      "3419, train_loss: 0.6035692049906805, val_loss: 0.5970131039619446\n",
      "3420, train_loss: 0.6026072100951121, val_loss: 0.5905574560165405\n",
      "3421, train_loss: 0.6024654943209428, val_loss: 0.5775689363479615\n",
      "3422, train_loss: 0.6009981127885672, val_loss: 0.586532473564148\n",
      "3423, train_loss: 0.6008563477259415, val_loss: 0.5910690784454345\n",
      "3424, train_loss: 0.602908764894192, val_loss: 0.584550142288208\n",
      "3425, train_loss: 0.6005932711637937, val_loss: 0.5936679482460022\n",
      "3426, train_loss: 0.6005372244578141, val_loss: 0.5801446318626404\n",
      "3427, train_loss: 0.6030798176160226, val_loss: 0.5779244422912597\n",
      "3428, train_loss: 0.6030360334194623, val_loss: 0.5722891330718994\n",
      "3429, train_loss: 0.6021457692751517, val_loss: 0.5793285131454468\n",
      "3430, train_loss: 0.6029279770759436, val_loss: 0.5698988676071167\n",
      "3431, train_loss: 0.6000600801064417, val_loss: 0.5846282482147217\n",
      "3432, train_loss: 0.6028498583115064, val_loss: 0.5715271711349488\n",
      "3433, train_loss: 0.6027628022890824, val_loss: 0.5819690704345704\n",
      "3434, train_loss: 0.6019243242648932, val_loss: 0.5682877361774444\n",
      "3435, train_loss: 0.6027200428339151, val_loss: 0.5901872992515564\n",
      "3436, train_loss: 0.6026589709978837, val_loss: 0.5715637922286987\n",
      "3437, train_loss: 0.6028349686127442, val_loss: 0.5959367513656616\n",
      "3438, train_loss: 0.6025215077858704, val_loss: 0.5901050567626953\n",
      "3439, train_loss: 0.599933942923179, val_loss: 0.5887536406517029\n",
      "3440, train_loss: 0.6026431849369636, val_loss: 0.5831842422485352\n",
      "3441, train_loss: 0.5988815816549155, val_loss: 0.5840770602226257\n",
      "3442, train_loss: 0.5992877460443057, val_loss: 0.5925477147102356\n",
      "3443, train_loss: 0.6022274620257891, val_loss: 0.5857985138893127\n",
      "3444, train_loss: 0.601225441465011, val_loss: 0.5810784339904785\n",
      "3445, train_loss: 0.6011263567667741, val_loss: 0.5981433510780334\n",
      "3446, train_loss: 0.6020296204548615, val_loss: 0.5903307676315308\n",
      "3447, train_loss: 0.5985258233088714, val_loss: 0.5906728029251098\n",
      "3448, train_loss: 0.6019075558735774, val_loss: 0.594095778465271\n",
      "3449, train_loss: 0.6018466811913711, val_loss: 0.5904078960418702\n",
      "3450, train_loss: 0.5986796823831705, val_loss: 0.5781022429466247\n",
      "3451, train_loss: 0.5993182544524853, val_loss: 0.5697723984718323\n",
      "3452, train_loss: 0.600457373719949, val_loss: 0.5873525023460389\n",
      "3453, train_loss: 0.5988159420398566, val_loss: 0.5761495709419251\n",
      "3454, train_loss: 0.6015996955908262, val_loss: 0.583188509941101\n",
      "3455, train_loss: 0.5983612468609443, val_loss: 0.5834242105484009\n",
      "3456, train_loss: 0.6008411038380402, val_loss: 0.5767767548561096\n",
      "3457, train_loss: 0.6014193101571157, val_loss: 0.5892532110214234\n",
      "3458, train_loss: 0.6007921856183273, val_loss: 0.5695465683937073\n",
      "3459, train_loss: 0.5985113049928958, val_loss: 0.595223343372345\n",
      "3460, train_loss: 0.6012883278039786, val_loss: 0.5795603513717651\n",
      "3461, train_loss: 0.6012203853863937, val_loss: 0.5822155833244324\n",
      "3462, train_loss: 0.6011566118552134, val_loss: 0.5899345636367798\n",
      "3463, train_loss: 0.600415547306721, val_loss: 0.5914993405342102\n",
      "3464, train_loss: 0.6010196415277628, val_loss: 0.5971282720565796\n",
      "3465, train_loss: 0.6006338573419131, val_loss: 0.5874153971672058\n",
      "3466, train_loss: 0.5982277462115655, val_loss: 0.5950740337371826\n",
      "3467, train_loss: 0.5983023001597478, val_loss: 0.58576819896698\n",
      "3468, train_loss: 0.600780746111503, val_loss: 0.5744512200355529\n",
      "3469, train_loss: 0.5982921845637835, val_loss: 0.5970470190048218\n",
      "3470, train_loss: 0.6006970015855936, val_loss: 0.5664735853672027\n",
      "3471, train_loss: 0.6006776999968749, val_loss: 0.5825850367546082\n",
      "3472, train_loss: 0.5995845038157243, val_loss: 0.5826531171798706\n",
      "3473, train_loss: 0.5973403407977178, val_loss: 0.5967271566390991\n",
      "3474, train_loss: 0.597798418540221, val_loss: 0.5877436518669128\n",
      "3475, train_loss: 0.5974011948475471, val_loss: 0.5748169660568238\n",
      "3476, train_loss: 0.5974515389937621, val_loss: 0.5769709467887878\n",
      "3477, train_loss: 0.5978820060308163, val_loss: 0.573615825176239\n",
      "3478, train_loss: 0.5970386897142117, val_loss: 0.5758734583854676\n",
      "3479, train_loss: 0.6002449232798356, val_loss: 0.5767250180244445\n",
      "3480, train_loss: 0.5972728064427009, val_loss: 0.5798665881156921\n",
      "3481, train_loss: 0.6001689456976377, val_loss: 0.5940142750740052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3482, train_loss: 0.6001065694368802, val_loss: 0.5960353493690491\n",
      "3483, train_loss: 0.6000732802427732, val_loss: 0.5746853590011597\n",
      "3484, train_loss: 0.5999579165990536, val_loss: 0.5898321151733399\n",
      "3485, train_loss: 0.5972119248830355, val_loss: 0.5938898503780365\n",
      "3486, train_loss: 0.5998874111817434, val_loss: 0.5739524126052856\n",
      "3487, train_loss: 0.5997953300292675, val_loss: 0.573905074596405\n",
      "3488, train_loss: 0.5997486286438428, val_loss: 0.5851803541183471\n",
      "3489, train_loss: 0.5996720550151972, val_loss: 0.5878653287887573\n",
      "3490, train_loss: 0.599558215874892, val_loss: 0.5810265064239502\n",
      "3491, train_loss: 0.5990439366835815, val_loss: 0.5780839562416077\n",
      "3492, train_loss: 0.5965416156328641, val_loss: 0.591830050945282\n",
      "3493, train_loss: 0.5971187903330877, val_loss: 0.5781388938426971\n",
      "3494, train_loss: 0.5989664621078051, val_loss: 0.5723616600036621\n",
      "3495, train_loss: 0.5957414679802381, val_loss: 0.5732389569282532\n",
      "3496, train_loss: 0.5985245693188447, val_loss: 0.5735067486763\n",
      "3497, train_loss: 0.5992258787155151, val_loss: 0.5917301416397095\n",
      "3498, train_loss: 0.5966205929334347, val_loss: 0.5763413310050964\n",
      "3499, train_loss: 0.5962291703774378, val_loss: 0.5859786868095398\n",
      "3500, train_loss: 0.5954419202529467, val_loss: 0.5891210794448852\n",
      "3501, train_loss: 0.598968954040454, val_loss: 0.5748738288879395\n",
      "3502, train_loss: 0.5986296339676931, val_loss: 0.5631938457489014\n",
      "3503, train_loss: 0.5960645469335409, val_loss: 0.5866600811481476\n",
      "3504, train_loss: 0.5988213408451813, val_loss: 0.5665518164634704\n",
      "3505, train_loss: 0.5979124043996518, val_loss: 0.5856589198112487\n",
      "3506, train_loss: 0.5975227046471375, val_loss: 0.5923964381217957\n",
      "3507, train_loss: 0.5977107641788629, val_loss: 0.5833427667617798\n",
      "3508, train_loss: 0.597629189491272, val_loss: 0.5845453977584839\n",
      "3509, train_loss: 0.5958068462518545, val_loss: 0.5679601550102233\n",
      "3510, train_loss: 0.5949500363606673, val_loss: 0.5868492841720581\n",
      "3511, train_loss: 0.5984100630650153, val_loss: 0.574892795085907\n",
      "3512, train_loss: 0.5973246578986828, val_loss: 0.5877031922340393\n",
      "3513, train_loss: 0.5947888493537903, val_loss: 0.5704143285751343\n",
      "3514, train_loss: 0.5958068336431797, val_loss: 0.5910582900047302\n",
      "3515, train_loss: 0.5971830429939123, val_loss: 0.5845651268959046\n",
      "3516, train_loss: 0.5948643592687753, val_loss: 0.5910074353218079\n",
      "3517, train_loss: 0.5980322338067569, val_loss: 0.574376928806305\n",
      "3518, train_loss: 0.5976814111837974, val_loss: 0.5845185458660126\n",
      "3519, train_loss: 0.5953883597484002, val_loss: 0.5798120737075806\n",
      "3520, train_loss: 0.5973993379336137, val_loss: 0.5902483940124512\n",
      "3521, train_loss: 0.5945996745274618, val_loss: 0.5766268014907837\n",
      "3522, train_loss: 0.5942788261633652, val_loss: 0.5886653780937194\n",
      "3523, train_loss: 0.5971717903247247, val_loss: 0.5731755018234252\n",
      "3524, train_loss: 0.5974820531331576, val_loss: 0.5746245145797729\n",
      "3525, train_loss: 0.5971254683457888, val_loss: 0.5723082423210144\n",
      "3526, train_loss: 0.5947730655853565, val_loss: 0.5871612071990967\n",
      "3527, train_loss: 0.5938492738283597, val_loss: 0.5745135188102722\n",
      "3528, train_loss: 0.5944732966331335, val_loss: 0.5765208721160888\n",
      "3529, train_loss: 0.5968292710872797, val_loss: 0.5869223594665527\n",
      "3530, train_loss: 0.5973300498265487, val_loss: 0.5802552282810212\n",
      "3531, train_loss: 0.5946011657898242, val_loss: 0.5878750562667847\n",
      "3532, train_loss: 0.5972498873105416, val_loss: 0.569678807258606\n",
      "3533, train_loss: 0.5946644739462779, val_loss: 0.5654792964458466\n",
      "3534, train_loss: 0.597200041780105, val_loss: 0.5704593420028686\n",
      "3535, train_loss: 0.5941168310550543, val_loss: 0.59366215467453\n",
      "3536, train_loss: 0.5939364020641034, val_loss: 0.5835540652275085\n",
      "3537, train_loss: 0.5959037244319916, val_loss: 0.5743123233318329\n",
      "3538, train_loss: 0.5961849597784189, val_loss: 0.569907832145691\n",
      "3539, train_loss: 0.5937826656378232, val_loss: 0.5856102764606476\n",
      "3540, train_loss: 0.595135184434744, val_loss: 0.5719898819923401\n",
      "3541, train_loss: 0.5967629024615655, val_loss: 0.5781612157821655\n",
      "3542, train_loss: 0.5953621795544257, val_loss: 0.5780676245689392\n",
      "3543, train_loss: 0.5955177981119889, val_loss: 0.5916396737098694\n",
      "3544, train_loss: 0.5965950213945829, val_loss: 0.5916216015815735\n",
      "3545, train_loss: 0.596565645474654, val_loss: 0.5849907457828522\n",
      "3546, train_loss: 0.5964585989713669, val_loss: 0.5770491123199463\n",
      "3547, train_loss: 0.5957245058738269, val_loss: 0.5635160803794861\n",
      "3548, train_loss: 0.5956773379674325, val_loss: 0.5696159839630127\n",
      "3549, train_loss: 0.5961048981318107, val_loss: 0.5696489095687867\n",
      "3550, train_loss: 0.593362746330408, val_loss: 0.5701804876327514\n",
      "3551, train_loss: 0.5962401319008607, val_loss: 0.5896266341209412\n",
      "3552, train_loss: 0.5962122357808627, val_loss: 0.580016028881073\n",
      "3553, train_loss: 0.5960895957855078, val_loss: 0.577671754360199\n",
      "3554, train_loss: 0.5960963265253947, val_loss: 0.572946834564209\n",
      "3555, train_loss: 0.5956995716461768, val_loss: 0.5781525254249573\n",
      "3556, train_loss: 0.5959605563145417, val_loss: 0.5861246228218079\n",
      "3557, train_loss: 0.5958738762598771, val_loss: 0.5703198194503785\n",
      "3558, train_loss: 0.5953409041349704, val_loss: 0.5708465337753296\n",
      "3559, train_loss: 0.5947495584304516, val_loss: 0.5740194320678711\n",
      "3560, train_loss: 0.5943119502984561, val_loss: 0.5807911634445191\n",
      "3561, train_loss: 0.5950710555681815, val_loss: 0.5868285655975342\n",
      "3562, train_loss: 0.5955631480767176, val_loss: 0.5846275329589844\n",
      "3563, train_loss: 0.5923584734018033, val_loss: 0.5703346610069275\n",
      "3564, train_loss: 0.5954393171347104, val_loss: 0.5685613989830017\n",
      "3565, train_loss: 0.594655957359534, val_loss: 0.582771611213684\n",
      "3566, train_loss: 0.5951642588927195, val_loss: 0.574668037891388\n",
      "3567, train_loss: 0.5952268815957583, val_loss: 0.586003041267395\n",
      "3568, train_loss: 0.5951608224556997, val_loss: 0.5689422845840454\n",
      "3569, train_loss: 0.594589636876033, val_loss: 0.5789613962173462\n",
      "3570, train_loss: 0.5939156092130221, val_loss: 0.5711483836174012\n",
      "3571, train_loss: 0.5938765188822379, val_loss: 0.5759258985519409\n",
      "3572, train_loss: 0.5949381589889526, val_loss: 0.5799049735069275\n",
      "3573, train_loss: 0.593482160797486, val_loss: 0.5733304142951965\n",
      "3574, train_loss: 0.5941607791643876, val_loss: 0.581294310092926\n",
      "3575, train_loss: 0.5923715027479025, val_loss: 0.589538037776947\n",
      "3576, train_loss: 0.5912957237317011, val_loss: 0.5797499299049378\n",
      "3577, train_loss: 0.5935469911648676, val_loss: 0.5850099205970765\n",
      "3578, train_loss: 0.5938831693851031, val_loss: 0.5842907786369324\n",
      "3579, train_loss: 0.5916156218602107, val_loss: 0.5639523148536683\n",
      "3580, train_loss: 0.5944872899697378, val_loss: 0.5850121140480041\n",
      "3581, train_loss: 0.5919511513068125, val_loss: 0.5866595029830932\n",
      "3582, train_loss: 0.5914694781486804, val_loss: 0.5784146547317505\n",
      "3583, train_loss: 0.5933625606390146, val_loss: 0.579871141910553\n",
      "3584, train_loss: 0.5916877194092824, val_loss: 0.5705499172210693\n",
      "3585, train_loss: 0.5930537936779169, val_loss: 0.5776758432388306\n",
      "3586, train_loss: 0.5934511079238012, val_loss: 0.5678227066993713\n",
      "3587, train_loss: 0.5941328050998541, val_loss: 0.5666354179382325\n",
      "3588, train_loss: 0.5913611100270197, val_loss: 0.5845046639442444\n",
      "3589, train_loss: 0.5940384211448523, val_loss: 0.5847326576709747\n",
      "3590, train_loss: 0.5939454768712704, val_loss: 0.5641891181468963\n",
      "3591, train_loss: 0.5913451256660315, val_loss: 0.571015989780426\n",
      "3592, train_loss: 0.5911524639679835, val_loss: 0.5818570733070374\n",
      "3593, train_loss: 0.5908782080962107, val_loss: 0.5871520400047302\n",
      "3594, train_loss: 0.5913196859451441, val_loss: 0.5830853939056396\n",
      "3595, train_loss: 0.5906051741196559, val_loss: 0.5742421388626099\n",
      "3596, train_loss: 0.5902235129704843, val_loss: 0.5774292469024658\n",
      "3597, train_loss: 0.591105424440824, val_loss: 0.5828332781791687\n",
      "3598, train_loss: 0.5936342603885211, val_loss: 0.5737110257148743\n",
      "3599, train_loss: 0.5932581287163955, val_loss: 0.5809465527534485\n",
      "3600, train_loss: 0.5905808370846969, val_loss: 0.589712631702423\n",
      "3601, train_loss: 0.59235197191055, val_loss: 0.5625767588615418\n",
      "3602, train_loss: 0.5903652333296262, val_loss: 0.5819950699806213\n",
      "3603, train_loss: 0.5899023344883552, val_loss: 0.5849344372749329\n",
      "3604, train_loss: 0.5927810428234247, val_loss: 0.573563951253891\n",
      "3605, train_loss: 0.5932383159032235, val_loss: 0.5718133807182312\n",
      "3606, train_loss: 0.5932119878438803, val_loss: 0.5622273683547974\n",
      "3607, train_loss: 0.5920212532465274, val_loss: 0.5877260327339172\n",
      "3608, train_loss: 0.5905928978553185, val_loss: 0.5752448320388794\n",
      "3609, train_loss: 0.590312143931022, val_loss: 0.5843088507652283\n",
      "3610, train_loss: 0.5903941014638314, val_loss: 0.5802335858345031\n",
      "3611, train_loss: 0.5923769714740607, val_loss: 0.5683465838432312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3612, train_loss: 0.5895917025896219, val_loss: 0.5846343159675598\n",
      "3613, train_loss: 0.5928380512274228, val_loss: 0.5890433430671692\n",
      "3614, train_loss: 0.5927854673220561, val_loss: 0.5873716354370118\n",
      "3615, train_loss: 0.5900438061127296, val_loss: 0.5889758467674255\n",
      "3616, train_loss: 0.5927013777769529, val_loss: 0.5689740657806397\n",
      "3617, train_loss: 0.5899395552965311, val_loss: 0.5740151286125184\n",
      "3618, train_loss: 0.5926228406337591, val_loss: 0.5819481790065766\n",
      "3619, train_loss: 0.592545836017682, val_loss: 0.5625060677528382\n",
      "3620, train_loss: 0.5925398274109914, val_loss: 0.5751654505729675\n",
      "3621, train_loss: 0.5912502660201147, val_loss: 0.5826136350631714\n",
      "3622, train_loss: 0.5924886350448315, val_loss: 0.5765455484390258\n",
      "3623, train_loss: 0.5897318468644068, val_loss: 0.588680100440979\n",
      "3624, train_loss: 0.5894591751006933, val_loss: 0.5739591598510743\n",
      "3625, train_loss: 0.589452191041066, val_loss: 0.5675281763076783\n",
      "3626, train_loss: 0.5892423379879731, val_loss: 0.5801044821739196\n",
      "3627, train_loss: 0.5893448373446097, val_loss: 0.5868342757225037\n",
      "3628, train_loss: 0.5895539224147797, val_loss: 0.5747309327125549\n",
      "3629, train_loss: 0.5917429912548798, val_loss: 0.5868991792201996\n",
      "3630, train_loss: 0.5891810689981167, val_loss: 0.5832693696022033\n",
      "3631, train_loss: 0.5892289819625708, val_loss: 0.5717302083969116\n",
      "3632, train_loss: 0.5918866556424361, val_loss: 0.5866743326187134\n",
      "3633, train_loss: 0.5915376360599811, val_loss: 0.5747552573680877\n",
      "3634, train_loss: 0.5917450120815864, val_loss: 0.5881982445716858\n",
      "3635, train_loss: 0.5904706888473951, val_loss: 0.5811134457588196\n",
      "3636, train_loss: 0.5890558705880091, val_loss: 0.5894375324249268\n",
      "3637, train_loss: 0.5890759779856756, val_loss: 0.5821800827980042\n",
      "3638, train_loss: 0.5915325364241233, val_loss: 0.588106107711792\n",
      "3639, train_loss: 0.5899814436068902, val_loss: 0.5867317914962769\n",
      "3640, train_loss: 0.5910797096215762, val_loss: 0.5834959268569946\n",
      "3641, train_loss: 0.5887150328892928, val_loss: 0.5819110631942749\n",
      "3642, train_loss: 0.5913176158299813, val_loss: 0.5670393168926239\n",
      "3643, train_loss: 0.5912503611582977, val_loss: 0.5692691087722779\n",
      "3644, train_loss: 0.5877869266730088, val_loss: 0.5878662586212158\n",
      "3645, train_loss: 0.5880896196915553, val_loss: 0.5878435015678406\n",
      "3646, train_loss: 0.5902911092226322, val_loss: 0.5728810071945191\n",
      "3647, train_loss: 0.5898655309126928, val_loss: 0.573509418964386\n",
      "3648, train_loss: 0.5883130041452554, val_loss: 0.5876105606555939\n",
      "3649, train_loss: 0.5910038970983945, val_loss: 0.5684992074966431\n",
      "3650, train_loss: 0.5909577275698001, val_loss: 0.5641172409057618\n",
      "3651, train_loss: 0.590892106294632, val_loss: 0.5736181974411011\n",
      "3652, train_loss: 0.5882159861234518, val_loss: 0.564773678779602\n",
      "3653, train_loss: 0.5895425299039254, val_loss: 0.587467634677887\n",
      "3654, train_loss: 0.5907120475402245, val_loss: 0.5705901801586151\n",
      "3655, train_loss: 0.587924070083178, val_loss: 0.5669569969177246\n",
      "3656, train_loss: 0.5907037510321691, val_loss: 0.5809711873531341\n",
      "3657, train_loss: 0.5905695546131867, val_loss: 0.5792376518249511\n",
      "3658, train_loss: 0.5892374446758857, val_loss: 0.5730031967163086\n",
      "3659, train_loss: 0.5867555714570559, val_loss: 0.5873907804489136\n",
      "3660, train_loss: 0.5903746760808505, val_loss: 0.5595721483230591\n",
      "3661, train_loss: 0.58734553364607, val_loss: 0.5817311406135559\n",
      "3662, train_loss: 0.5903090593906549, val_loss: 0.5802121758460999\n",
      "3663, train_loss: 0.5902109616077863, val_loss: 0.5817886233329773\n",
      "3664, train_loss: 0.5886716338304373, val_loss: 0.581857967376709\n",
      "3665, train_loss: 0.5901211798191071, val_loss: 0.5779960989952088\n",
      "3666, train_loss: 0.5900583989345111, val_loss: 0.5714875340461731\n",
      "3667, train_loss: 0.5900324892539245, val_loss: 0.5572718262672425\n",
      "3668, train_loss: 0.5891896440432622, val_loss: 0.5751387000083923\n",
      "3669, train_loss: 0.5883970512793615, val_loss: 0.5656587898731231\n",
      "3670, train_loss: 0.5868461154974424, val_loss: 0.5794319987297059\n",
      "3671, train_loss: 0.5886810020758555, val_loss: 0.5805076003074646\n",
      "3672, train_loss: 0.5897494394045609, val_loss: 0.5642404139041901\n",
      "3673, train_loss: 0.5896579909783143, val_loss: 0.575548279285431\n",
      "3674, train_loss: 0.5881091551138804, val_loss: 0.5723480701446533\n",
      "3675, train_loss: 0.5889770549077255, val_loss: 0.5686397850513458\n",
      "3676, train_loss: 0.589524642779277, val_loss: 0.5824519574642182\n",
      "3677, train_loss: 0.5894466661489927, val_loss: 0.5878316402435303\n",
      "3678, train_loss: 0.5863069341732905, val_loss: 0.573729956150055\n",
      "3679, train_loss: 0.5893171601570569, val_loss: 0.5819900035858154\n",
      "3680, train_loss: 0.58591228723526, val_loss: 0.5608783483505249\n",
      "3681, train_loss: 0.589257144010984, val_loss: 0.5785636663436889\n",
      "3682, train_loss: 0.5859590470790863, val_loss: 0.5673159003257752\n",
      "3683, train_loss: 0.5879037964802521, val_loss: 0.5730387926101684\n",
      "3684, train_loss: 0.5860671951220586, val_loss: 0.5746473789215087\n",
      "3685, train_loss: 0.5877900880116683, val_loss: 0.5676140546798706\n",
      "3686, train_loss: 0.5889814415803323, val_loss: 0.5811298966407776\n",
      "3687, train_loss: 0.5874348592299682, val_loss: 0.5585789322853089\n",
      "3688, train_loss: 0.5875500922019665, val_loss: 0.5864941239356994\n",
      "3689, train_loss: 0.5888264500177823, val_loss: 0.5799994349479676\n",
      "3690, train_loss: 0.5857482414979202, val_loss: 0.5809413909912109\n",
      "3691, train_loss: 0.5857549779690229, val_loss: 0.5732571065425873\n",
      "3692, train_loss: 0.5875410231260153, val_loss: 0.5671618819236756\n",
      "3693, train_loss: 0.5886101883191329, val_loss: 0.5769118785858154\n",
      "3694, train_loss: 0.5854979959818033, val_loss: 0.5796540260314942\n",
      "3695, train_loss: 0.5878410029869813, val_loss: 0.5568373918533325\n",
      "3696, train_loss: 0.5855339673849252, val_loss: 0.5659969091415405\n",
      "3697, train_loss: 0.5852305728655595, val_loss: 0.5765263319015503\n",
      "3698, train_loss: 0.5884213390258642, val_loss: 0.5688268542289734\n",
      "3699, train_loss: 0.5853528116758053, val_loss: 0.5673686265945435\n",
      "3700, train_loss: 0.588274210691452, val_loss: 0.5673060774803161\n",
      "3701, train_loss: 0.5866952400941116, val_loss: 0.5859710574150085\n",
      "3702, train_loss: 0.5850521452151812, val_loss: 0.5582827568054199\n",
      "3703, train_loss: 0.584955843595358, val_loss: 0.5616732656955719\n",
      "3704, train_loss: 0.5881326748774602, val_loss: 0.5611194491386413\n",
      "3705, train_loss: 0.5868181849901493, val_loss: 0.5735806941986084\n",
      "3706, train_loss: 0.5854234454723505, val_loss: 0.5862934350967407\n",
      "3707, train_loss: 0.5879248151412377, val_loss: 0.566901683807373\n",
      "3708, train_loss: 0.5875894140738708, val_loss: 0.564179539680481\n",
      "3709, train_loss: 0.5844175311235281, val_loss: 0.5860571742057801\n",
      "3710, train_loss: 0.5848036305262492, val_loss: 0.564315402507782\n",
      "3711, train_loss: 0.5877718329429626, val_loss: 0.569802749156952\n",
      "3712, train_loss: 0.5842345975912534, val_loss: 0.5755658149719238\n",
      "3713, train_loss: 0.5877143007058364, val_loss: 0.5705042719841004\n",
      "3714, train_loss: 0.5876507529845605, val_loss: 0.579253089427948\n",
      "3715, train_loss: 0.5863294521203408, val_loss: 0.5646418452262878\n",
      "3716, train_loss: 0.5875407973161111, val_loss: 0.5711495041847229\n",
      "3717, train_loss: 0.5874561942540683, val_loss: 0.5715286254882812\n",
      "3718, train_loss: 0.5845028448563355, val_loss: 0.5728796362876892\n",
      "3719, train_loss: 0.5844858953585992, val_loss: 0.5601551413536072\n",
      "3720, train_loss: 0.5873121607762116, val_loss: 0.5660735011100769\n",
      "3721, train_loss: 0.5843739796143311, val_loss: 0.5791382014751434\n",
      "3722, train_loss: 0.5872358519297379, val_loss: 0.5751191258430481\n",
      "3723, train_loss: 0.5871536892194015, val_loss: 0.5642484724521637\n",
      "3724, train_loss: 0.5856855568977503, val_loss: 0.5830682039260864\n",
      "3725, train_loss: 0.5861750955765064, val_loss: 0.5704378366470337\n",
      "3726, train_loss: 0.5832351503463892, val_loss: 0.5779953479766846\n",
      "3727, train_loss: 0.5869439049408987, val_loss: 0.580391240119934\n",
      "3728, train_loss: 0.5868418423029093, val_loss: 0.5803130865097046\n",
      "3729, train_loss: 0.5857516550100766, val_loss: 0.5752810120582581\n",
      "3730, train_loss: 0.5867082809026425, val_loss: 0.5641842603683471\n",
      "3731, train_loss: 0.585542020889429, val_loss: 0.5796895146369934\n",
      "3732, train_loss: 0.582772087592345, val_loss: 0.5758218884468078\n",
      "3733, train_loss: 0.5865727365016937, val_loss: 0.5773507237434388\n",
      "3734, train_loss: 0.5838082948556313, val_loss: 0.5621922016143799\n",
      "3735, train_loss: 0.5864745504581012, val_loss: 0.5746854364871978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3736, train_loss: 0.5834678422946197, val_loss: 0.5657595753669739\n",
      "3737, train_loss: 0.585018093769367, val_loss: 0.5835347890853881\n",
      "3738, train_loss: 0.5830381959676743, val_loss: 0.5640587568283081\n",
      "3739, train_loss: 0.5831601252922645, val_loss: 0.5617002844810486\n",
      "3740, train_loss: 0.5859156869924985, val_loss: 0.5697418451309204\n",
      "3741, train_loss: 0.5861551692852607, val_loss: 0.5788312077522277\n",
      "3742, train_loss: 0.5861002630912341, val_loss: 0.5771941900253296\n",
      "3743, train_loss: 0.5829145747881669, val_loss: 0.561653196811676\n",
      "3744, train_loss: 0.5844849072969877, val_loss: 0.5786446809768677\n",
      "3745, train_loss: 0.5859236361888739, val_loss: 0.5845152854919433\n",
      "3746, train_loss: 0.5859077240412052, val_loss: 0.5540391981601716\n",
      "3747, train_loss: 0.5827498057713876, val_loss: 0.5686247229576111\n",
      "3748, train_loss: 0.5831914463868508, val_loss: 0.5847513556480408\n",
      "3749, train_loss: 0.5829839133299314, val_loss: 0.5841250419616699\n",
      "3750, train_loss: 0.5857192094509418, val_loss: 0.5695264458656311\n",
      "3751, train_loss: 0.5840718986896368, val_loss: 0.5611779391765594\n",
      "3752, train_loss: 0.5818782162207824, val_loss: 0.5748327136039734\n",
      "3753, train_loss: 0.5824146947035422, val_loss: 0.5689760923385621\n",
      "3754, train_loss: 0.5855356626785718, val_loss: 0.5757446408271789\n",
      "3755, train_loss: 0.5842222915245936, val_loss: 0.5719689011573792\n",
      "3756, train_loss: 0.5854209810495377, val_loss: 0.5731158137321473\n",
      "3757, train_loss: 0.5853547728978671, val_loss: 0.5772372603416442\n",
      "3758, train_loss: 0.5849910412843411, val_loss: 0.5838993072509766\n",
      "3759, train_loss: 0.5822856964973303, val_loss: 0.5566709160804748\n",
      "3760, train_loss: 0.5822641402482986, val_loss: 0.5681244254112243\n",
      "3761, train_loss: 0.5839326324371191, val_loss: 0.577686357498169\n",
      "3762, train_loss: 0.5822164530937488, val_loss: 0.5817911267280579\n",
      "3763, train_loss: 0.5851366760639044, val_loss: 0.5548410475254059\n",
      "3764, train_loss: 0.5850798716911902, val_loss: 0.5639802932739257\n",
      "3765, train_loss: 0.5850664766935202, val_loss: 0.5607266783714294\n",
      "3766, train_loss: 0.583959814447623, val_loss: 0.5665888786315918\n",
      "3767, train_loss: 0.5816159076415576, val_loss: 0.5606944799423218\n",
      "3768, train_loss: 0.5821740994086633, val_loss: 0.5749553978443146\n",
      "3769, train_loss: 0.5816505046991202, val_loss: 0.5624945163726807\n",
      "3770, train_loss: 0.5808960015957172, val_loss: 0.5691128611564636\n",
      "3771, train_loss: 0.5832460236090881, val_loss: 0.5586369276046753\n",
      "3772, train_loss: 0.5843672156333923, val_loss: 0.5679170966148377\n",
      "3773, train_loss: 0.5846178577496455, val_loss: 0.5834866881370544\n",
      "3774, train_loss: 0.5842592211870047, val_loss: 0.5615356981754303\n",
      "3775, train_loss: 0.5814595153698554, val_loss: 0.5523407459259033\n",
      "3776, train_loss: 0.5845193026157526, val_loss: 0.5683187484741211\n",
      "3777, train_loss: 0.5815238539989178, val_loss: 0.5687089204788208\n",
      "3778, train_loss: 0.5827783552499918, val_loss: 0.5617141842842102\n",
      "3779, train_loss: 0.5832463915531452, val_loss: 0.5599825978279114\n",
      "3780, train_loss: 0.5809394533817585, val_loss: 0.5670958638191224\n",
      "3781, train_loss: 0.5842277934918036, val_loss: 0.5588053703308106\n",
      "3782, train_loss: 0.5806611340779525, val_loss: 0.5560742735862731\n",
      "3783, train_loss: 0.5810182449909357, val_loss: 0.5682324945926667\n",
      "3784, train_loss: 0.5841348423407628, val_loss: 0.5752009391784668\n",
      "3785, train_loss: 0.5840982427963843, val_loss: 0.564377737045288\n",
      "3786, train_loss: 0.5826471493794367, val_loss: 0.5589957952499389\n",
      "3787, train_loss: 0.5812110121433551, val_loss: 0.5706509470939636\n",
      "3788, train_loss: 0.5839143372499026, val_loss: 0.561553132534027\n",
      "3789, train_loss: 0.583893881394313, val_loss: 0.5594840228557587\n",
      "3790, train_loss: 0.5823277097481948, val_loss: 0.5627007603645324\n",
      "3791, train_loss: 0.5837403512918032, val_loss: 0.5619783759117126\n",
      "3792, train_loss: 0.5826644542125555, val_loss: 0.5699242949485779\n",
      "3793, train_loss: 0.5808049371609321, val_loss: 0.5647932529449463\n",
      "3794, train_loss: 0.5836077149097736, val_loss: 0.5751170217990875\n",
      "3795, train_loss: 0.5822533575388101, val_loss: 0.5509908318519592\n",
      "3796, train_loss: 0.5834968984127045, val_loss: 0.5664768218994141\n",
      "3797, train_loss: 0.5826142774178431, val_loss: 0.5612226128578186\n",
      "3798, train_loss: 0.5831324526896844, val_loss: 0.5610056042671203\n",
      "3799, train_loss: 0.5834051324771001, val_loss: 0.5794188380241394\n",
      "3800, train_loss: 0.5800934227613302, val_loss: 0.5645489811897277\n",
      "3801, train_loss: 0.5832898868964269, val_loss: 0.5657688736915588\n",
      "3802, train_loss: 0.583245494044744, val_loss: 0.5655436277389526\n",
      "3803, train_loss: 0.5818433188475095, val_loss: 0.5681152582168579\n",
      "3804, train_loss: 0.582805546430441, val_loss: 0.5679912447929383\n",
      "3805, train_loss: 0.5821573161161863, val_loss: 0.560435128211975\n",
      "3806, train_loss: 0.5802757866107501, val_loss: 0.563203501701355\n",
      "3807, train_loss: 0.5829765980060284, val_loss: 0.57153799533844\n",
      "3808, train_loss: 0.5798094215301367, val_loss: 0.5741498827934265\n",
      "3809, train_loss: 0.5819583936379507, val_loss: 0.5486722469329834\n",
      "3810, train_loss: 0.5828351997412168, val_loss: 0.5639856815338135\n",
      "3811, train_loss: 0.5818154766009405, val_loss: 0.5675696969032288\n",
      "3812, train_loss: 0.5827419333733045, val_loss: 0.5696869969367981\n",
      "3813, train_loss: 0.5787005974696233, val_loss: 0.5813370287418366\n",
      "3814, train_loss: 0.5794329918347872, val_loss: 0.5659068942070007\n",
      "3815, train_loss: 0.5797113306247271, val_loss: 0.5502179503440857\n",
      "3816, train_loss: 0.5825978758243414, val_loss: 0.5769867599010468\n",
      "3817, train_loss: 0.5814764224565946, val_loss: 0.5598066091537476\n",
      "3818, train_loss: 0.5810646850329179, val_loss: 0.5595290541648865\n",
      "3819, train_loss: 0.5790398946175208, val_loss: 0.5668092727661133\n",
      "3820, train_loss: 0.5823755115270615, val_loss: 0.5736071586608886\n",
      "3821, train_loss: 0.582277679672608, val_loss: 0.5676956593990325\n",
      "3822, train_loss: 0.5805324751597184, val_loss: 0.5750872373580933\n",
      "3823, train_loss: 0.5821159092279581, val_loss: 0.5813087821006775\n",
      "3824, train_loss: 0.5819788735646468, val_loss: 0.5795740962028504\n",
      "3825, train_loss: 0.5806603867274064, val_loss: 0.549585485458374\n",
      "3826, train_loss: 0.579135061456607, val_loss: 0.5501828789710999\n",
      "3827, train_loss: 0.5820066814239209, val_loss: 0.5668891906738281\n",
      "3828, train_loss: 0.5785354719712184, val_loss: 0.5575808167457581\n",
      "3829, train_loss: 0.5805045366287231, val_loss: 0.5528656542301178\n",
      "3830, train_loss: 0.5804161486717371, val_loss: 0.5704991459846497\n",
      "3831, train_loss: 0.5808540743130904, val_loss: 0.5631488621234894\n",
      "3832, train_loss: 0.5817369956236619, val_loss: 0.5788599610328674\n",
      "3833, train_loss: 0.580570638179779, val_loss: 0.547104150056839\n",
      "3834, train_loss: 0.5789010604986777, val_loss: 0.5677383661270141\n",
      "3835, train_loss: 0.5785732189050088, val_loss: 0.5647149682044983\n",
      "3836, train_loss: 0.5783439198365579, val_loss: 0.548617708683014\n",
      "3837, train_loss: 0.5815783739089966, val_loss: 0.5623253285884857\n",
      "3838, train_loss: 0.5781292307835358, val_loss: 0.5704936861991883\n",
      "3839, train_loss: 0.5784653895176374, val_loss: 0.5773597717285156\n",
      "3840, train_loss: 0.5814702270122675, val_loss: 0.5621018171310425\n",
      "3841, train_loss: 0.5783194899559021, val_loss: 0.5734059929847717\n",
      "3842, train_loss: 0.578516226548415, val_loss: 0.565217113494873\n",
      "3843, train_loss: 0.5813581336003083, val_loss: 0.5677514433860779\n",
      "3844, train_loss: 0.5778530285908625, val_loss: 0.5557624936103821\n",
      "3845, train_loss: 0.5812137126922607, val_loss: 0.559560763835907\n",
      "3846, train_loss: 0.5811766053621585, val_loss: 0.5676591157913208\n",
      "3847, train_loss: 0.5806680069519923, val_loss: 0.5572914600372314\n",
      "3848, train_loss: 0.5802575659293395, val_loss: 0.5741773545742035\n",
      "3849, train_loss: 0.5778636668737118, val_loss: 0.5733865737915039\n",
      "3850, train_loss: 0.5809452338860586, val_loss: 0.5738461136817932\n",
      "3851, train_loss: 0.5777337860602599, val_loss: 0.5664697647094726\n",
      "3852, train_loss: 0.577505390231426, val_loss: 0.5704450249671936\n",
      "3853, train_loss: 0.580842599272728, val_loss: 0.5720944285392762\n",
      "3854, train_loss: 0.5774871615263132, val_loss: 0.5493655443191529\n",
      "3855, train_loss: 0.5807492022330945, val_loss: 0.5778847217559815\n",
      "3856, train_loss: 0.5772259602179894, val_loss: 0.5632144689559937\n",
      "3857, train_loss: 0.5772987707303121, val_loss: 0.550965428352356\n",
      "3858, train_loss: 0.5770371338495841, val_loss: 0.5698336243629456\n",
      "3859, train_loss: 0.5776506536282026, val_loss: 0.5612839698791504\n",
      "3860, train_loss: 0.5775372615227332, val_loss: 0.5788577198982239\n",
      "3861, train_loss: 0.5790589039142315, val_loss: 0.5556110262870788\n",
      "3862, train_loss: 0.5789829916678942, val_loss: 0.5533517360687256\n",
      "3863, train_loss: 0.579345248066462, val_loss: 0.5628089070320129\n",
      "3864, train_loss: 0.5802981624236474, val_loss: 0.5547627925872802\n",
      "3865, train_loss: 0.5802500087481278, val_loss: 0.5629121720790863\n",
      "3866, train_loss: 0.5786424221900793, val_loss: 0.5466007947921753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3867, train_loss: 0.5767139861216912, val_loss: 0.5650018751621246\n",
      "3868, train_loss: 0.5770917683839798, val_loss: 0.5627259731292724\n",
      "3869, train_loss: 0.5785126181749197, val_loss: 0.5647520303726197\n",
      "3870, train_loss: 0.5769353887209525, val_loss: 0.5625563502311707\n",
      "3871, train_loss: 0.5799603038109266, val_loss: 0.5606549620628357\n",
      "3872, train_loss: 0.5762891391148934, val_loss: 0.5629741668701171\n",
      "3873, train_loss: 0.579956904053688, val_loss: 0.5782600820064545\n",
      "3874, train_loss: 0.5770533566291516, val_loss: 0.5562100946903229\n",
      "3875, train_loss: 0.5781308091603793, val_loss: 0.5781150579452514\n",
      "3876, train_loss: 0.5763284265995026, val_loss: 0.5618448138237\n",
      "3877, train_loss: 0.5797727406024933, val_loss: 0.5723315596580505\n",
      "3878, train_loss: 0.578299866272853, val_loss: 0.5626889824867248\n",
      "3879, train_loss: 0.5788947126040092, val_loss: 0.5569935441017151\n",
      "3880, train_loss: 0.5762950583146169, val_loss: 0.5626349449157715\n",
      "3881, train_loss: 0.5781568116866626, val_loss: 0.5683986186981201\n",
      "3882, train_loss: 0.5764901420244803, val_loss: 0.5717748284339905\n",
      "3883, train_loss: 0.5759640828921244, val_loss: 0.5778512120246887\n",
      "3884, train_loss: 0.5760191747775445, val_loss: 0.576165235042572\n",
      "3885, train_loss: 0.5793774047723184, val_loss: 0.5675202131271362\n",
      "3886, train_loss: 0.5793283845369632, val_loss: 0.5495279431343079\n",
      "3887, train_loss: 0.5778649128400363, val_loss: 0.5778800129890442\n",
      "3888, train_loss: 0.5757447389455942, val_loss: 0.5535137295722962\n",
      "3889, train_loss: 0.5778727451196084, val_loss: 0.5632306873798371\n",
      "3890, train_loss: 0.5780404485188998, val_loss: 0.5541022598743439\n",
      "3891, train_loss: 0.5790516711198367, val_loss: 0.5718548059463501\n",
      "3892, train_loss: 0.5789820001675532, val_loss: 0.5713120639324188\n",
      "3893, train_loss: 0.5757212123045554, val_loss: 0.5555644392967224\n",
      "3894, train_loss: 0.578883368235368, val_loss: 0.5598129868507385\n",
      "3895, train_loss: 0.5788288655189368, val_loss: 0.5683189392089844\n",
      "3896, train_loss: 0.5774926646397665, val_loss: 0.555837619304657\n",
      "3897, train_loss: 0.5787450590958962, val_loss: 0.5630173802375793\n",
      "3898, train_loss: 0.5746330458384293, val_loss: 0.5652230858802796\n",
      "3899, train_loss: 0.5754645466804504, val_loss: 0.5709320783615113\n",
      "3900, train_loss: 0.5755972782006631, val_loss: 0.5618587970733643\n",
      "3901, train_loss: 0.5774723199697641, val_loss: 0.5605033040046692\n",
      "3902, train_loss: 0.5771179611866291, val_loss: 0.5532030999660492\n",
      "3903, train_loss: 0.5784281675632184, val_loss: 0.5545327544212342\n",
      "3904, train_loss: 0.5783617714276681, val_loss: 0.5433468341827392\n",
      "3905, train_loss: 0.5783202430376639, val_loss: 0.5466080665588379\n",
      "3906, train_loss: 0.5750488971288388, val_loss: 0.5707283556461334\n",
      "3907, train_loss: 0.5782580478833272, val_loss: 0.5652940273284912\n",
      "3908, train_loss: 0.5782011919296705, val_loss: 0.5449368476867675\n",
      "3909, train_loss: 0.5781792872227155, val_loss: 0.5542126774787903\n",
      "3910, train_loss: 0.5781355041723985, val_loss: 0.5557590067386627\n",
      "3911, train_loss: 0.575422384417974, val_loss: 0.547470235824585\n",
      "3912, train_loss: 0.5772299537291894, val_loss: 0.5753769516944885\n",
      "3913, train_loss: 0.5749370593291062, val_loss: 0.5740971982479095\n",
      "3914, train_loss: 0.5749891423262082, val_loss: 0.5768682956695557\n",
      "3915, train_loss: 0.575029581785202, val_loss: 0.5612111210823059\n",
      "3916, train_loss: 0.5778803424193308, val_loss: 0.5447257161140442\n",
      "3917, train_loss: 0.5743440630344244, val_loss: 0.5560133814811706\n",
      "3918, train_loss: 0.5778383177060348, val_loss: 0.5690638184547424\n",
      "3919, train_loss: 0.5777571029387988, val_loss: 0.5617664217948913\n",
      "3920, train_loss: 0.577708254639919, val_loss: 0.5602372646331787\n",
      "3921, train_loss: 0.5776921579471002, val_loss: 0.5762044548988342\n",
      "3922, train_loss: 0.5762238227404081, val_loss: 0.5580991566181183\n",
      "3923, train_loss: 0.574171285216625, val_loss: 0.5520137190818787\n",
      "3924, train_loss: 0.5744421447698886, val_loss: 0.5655576229095459\n",
      "3925, train_loss: 0.5746462012712772, val_loss: 0.5673568189144135\n",
      "3926, train_loss: 0.5774587748142389, val_loss: 0.5540282964706421\n",
      "3927, train_loss: 0.5737539793436344, val_loss: 0.5472824335098266\n",
      "3928, train_loss: 0.5742093485135299, val_loss: 0.5611572265625\n",
      "3929, train_loss: 0.577317225245329, val_loss: 0.56717609167099\n",
      "3930, train_loss: 0.5773010104894638, val_loss: 0.5514907002449035\n",
      "3931, train_loss: 0.5737076355860784, val_loss: 0.5628380060195923\n",
      "3932, train_loss: 0.5743581159756734, val_loss: 0.54893838763237\n",
      "3933, train_loss: 0.5771202387718054, val_loss: 0.561663031578064\n",
      "3934, train_loss: 0.5742002897537671, val_loss: 0.5683041453361511\n",
      "3935, train_loss: 0.5761767877982213, val_loss: 0.5692801713943482\n",
      "3936, train_loss: 0.5735870817532907, val_loss: 0.5576810956001281\n",
      "3937, train_loss: 0.5735304997517512, val_loss: 0.5535771965980529\n",
      "3938, train_loss: 0.5755162250537139, val_loss: 0.5741330742835998\n",
      "3939, train_loss: 0.5751265115462817, val_loss: 0.5617687821388244\n",
      "3940, train_loss: 0.5767371299175116, val_loss: 0.5505685925483703\n",
      "3941, train_loss: 0.5766987319176013, val_loss: 0.5698010563850403\n",
      "3942, train_loss: 0.5737881373900634, val_loss: 0.5622815251350403\n",
      "3943, train_loss: 0.5756827203127054, val_loss: 0.5528520226478577\n",
      "3944, train_loss: 0.5765571961036096, val_loss: 0.5576454520225524\n",
      "3945, train_loss: 0.5733789962071639, val_loss: 0.550379467010498\n",
      "3946, train_loss: 0.5749785361381677, val_loss: 0.569044041633606\n",
      "3947, train_loss: 0.5763789461209223, val_loss: 0.5525665163993836\n",
      "3948, train_loss: 0.5753635546335807, val_loss: 0.5629271268844604\n",
      "3949, train_loss: 0.5728831841395452, val_loss: 0.5650863170623779\n",
      "3950, train_loss: 0.5761944032632388, val_loss: 0.5567410826683045\n",
      "3951, train_loss: 0.5749556353458991, val_loss: 0.5653050541877747\n",
      "3952, train_loss: 0.5760805022258025, val_loss: 0.5518114447593689\n",
      "3953, train_loss: 0.5756299633246201, val_loss: 0.5515784502029419\n",
      "3954, train_loss: 0.5727089402767328, val_loss: 0.5728585362434387\n",
      "3955, train_loss: 0.5753935793271432, val_loss: 0.5532041728496552\n",
      "3956, train_loss: 0.5749832620987525, val_loss: 0.5532050907611847\n",
      "3957, train_loss: 0.5758389750352273, val_loss: 0.5668002486228942\n",
      "3958, train_loss: 0.5725507472570126, val_loss: 0.5485369145870209\n",
      "3959, train_loss: 0.5739490768084159, val_loss: 0.5599351644515991\n",
      "3960, train_loss: 0.5756760858572446, val_loss: 0.5573455214500427\n",
      "3961, train_loss: 0.5740644496220809, val_loss: 0.5755449056625366\n",
      "3962, train_loss: 0.5755684754023185, val_loss: 0.5603560328483581\n",
      "3963, train_loss: 0.5744349956512451, val_loss: 0.5665616631507874\n",
      "3964, train_loss: 0.5743873898799603, val_loss: 0.5657224893569947\n",
      "3965, train_loss: 0.5719039222368827, val_loss: 0.5528454780578613\n",
      "3966, train_loss: 0.5722377884846467, val_loss: 0.5607635498046875\n",
      "3967, train_loss: 0.5743770553515508, val_loss: 0.5753892302513123\n",
      "3968, train_loss: 0.5752404492634994, val_loss: 0.5506282150745392\n",
      "3969, train_loss: 0.5740241167637018, val_loss: 0.548555999994278\n",
      "3970, train_loss: 0.5716549249795767, val_loss: 0.5633661985397339\n",
      "3971, train_loss: 0.5741922213481023, val_loss: 0.5575733780860901\n",
      "3972, train_loss: 0.575044626226792, val_loss: 0.574208551645279\n",
      "3973, train_loss: 0.5734500105564411, val_loss: 0.5412983655929565\n",
      "3974, train_loss: 0.5727971711984048, val_loss: 0.5497852623462677\n",
      "3975, train_loss: 0.574477031826973, val_loss: 0.5613246202468872\n",
      "3976, train_loss: 0.5749177256455789, val_loss: 0.569104266166687\n",
      "3977, train_loss: 0.57485598554978, val_loss: 0.5641294002532959\n",
      "3978, train_loss: 0.5747472334366578, val_loss: 0.560733151435852\n",
      "3979, train_loss: 0.5707239439854255, val_loss: 0.5753078699111939\n",
      "3980, train_loss: 0.5737782338490853, val_loss: 0.5752821207046509\n",
      "3981, train_loss: 0.5744071453809738, val_loss: 0.5689689755439759\n",
      "3982, train_loss: 0.5715637436279883, val_loss: 0.5607239723205566\n",
      "3983, train_loss: 0.5733689883580575, val_loss: 0.5612608551979065\n",
      "3984, train_loss: 0.5707407123767413, val_loss: 0.5596936166286468\n",
      "3985, train_loss: 0.5744880747336608, val_loss: 0.561199426651001\n",
      "3986, train_loss: 0.5712867425038264, val_loss: 0.5590100288391113\n",
      "3987, train_loss: 0.5743890255689621, val_loss: 0.5589770913124085\n",
      "3988, train_loss: 0.5734085876208085, val_loss: 0.5589065730571747\n",
      "3989, train_loss: 0.5713695631577418, val_loss: 0.5737607717514038\n",
      "3990, train_loss: 0.5723871623094265, val_loss: 0.5537905097007751\n",
      "3991, train_loss: 0.5741519847741494, val_loss: 0.5641329348087311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3992, train_loss: 0.5712366149975703, val_loss: 0.5577612400054932\n",
      "3993, train_loss: 0.5740404014404004, val_loss: 0.5421988248825074\n",
      "3994, train_loss: 0.5740274076278393, val_loss: 0.5638727247714996\n",
      "3995, train_loss: 0.5734324489648526, val_loss: 0.5574634313583374\n",
      "3996, train_loss: 0.5723351412094556, val_loss: 0.556446498632431\n",
      "3997, train_loss: 0.5725690378592565, val_loss: 0.5680541157722473\n",
      "3998, train_loss: 0.5705836931100259, val_loss: 0.5563452482223511\n",
      "3999, train_loss: 0.5725763784005091, val_loss: 0.5428196251392364\n",
      "4000, train_loss: 0.5721231870926343, val_loss: 0.5645686745643616\n",
      "4001, train_loss: 0.570428694670017, val_loss: 0.5602522969245911\n",
      "4002, train_loss: 0.5736385652652154, val_loss: 0.5561754047870636\n",
      "4003, train_loss: 0.5700346678495407, val_loss: 0.5637704312801362\n",
      "4004, train_loss: 0.5735177363340671, val_loss: 0.559367573261261\n",
      "4005, train_loss: 0.5700395898177073, val_loss: 0.5742439866065979\n",
      "4006, train_loss: 0.5704476913580527, val_loss: 0.5582366108894348\n",
      "4007, train_loss: 0.5699764249416498, val_loss: 0.549252986907959\n",
      "4008, train_loss: 0.5733639231094947, val_loss: 0.5558396100997924\n",
      "4009, train_loss: 0.5732990938883561, val_loss: 0.5493060111999511\n",
      "4010, train_loss: 0.5729517180186051, val_loss: 0.5569666147232055\n",
      "4011, train_loss: 0.5700873950353036, val_loss: 0.5523383617401123\n",
      "4012, train_loss: 0.5731821243579571, val_loss: 0.5529110193252563\n",
      "4013, train_loss: 0.569964682826629, val_loss: 0.5561450541019439\n",
      "4014, train_loss: 0.5720676286862447, val_loss: 0.5577158808708191\n",
      "4015, train_loss: 0.5692952206501594, val_loss: 0.5503029704093934\n",
      "4016, train_loss: 0.5713881930479636, val_loss: 0.5537649035453797\n",
      "4017, train_loss: 0.5688772774659671, val_loss: 0.5476829707622528\n",
      "4018, train_loss: 0.5698557026111163, val_loss: 0.5658419966697693\n",
      "4019, train_loss: 0.5689853979991033, val_loss: 0.5735231041908264\n",
      "4020, train_loss: 0.569273577286647, val_loss: 0.5420014202594757\n",
      "4021, train_loss: 0.5686179708976012, val_loss: 0.5654457926750183\n",
      "4022, train_loss: 0.5693977429316595, val_loss: 0.5594546854496002\n",
      "4023, train_loss: 0.5698322550608561, val_loss: 0.5497665405273438\n",
      "4024, train_loss: 0.5727155082500898, val_loss: 0.5592699587345124\n",
      "4025, train_loss: 0.5726785591015449, val_loss: 0.5734017431735993\n",
      "4026, train_loss: 0.5714404869538087, val_loss: 0.5487220227718353\n",
      "4027, train_loss: 0.5694446093761004, val_loss: 0.562191116809845\n",
      "4028, train_loss: 0.57109367618194, val_loss: 0.5644702672958374\n",
      "4029, train_loss: 0.572447460431319, val_loss: 0.5487197637557983\n",
      "4030, train_loss: 0.5697179895180923, val_loss: 0.5556178510189056\n",
      "4031, train_loss: 0.5690093407264123, val_loss: 0.5512619256973267\n",
      "4032, train_loss: 0.5712310729118494, val_loss: 0.5734068512916565\n",
      "4033, train_loss: 0.5722824552884469, val_loss: 0.5661580681800842\n",
      "4034, train_loss: 0.5694784911779257, val_loss: 0.5552836894989014\n",
      "4035, train_loss: 0.5722000335271542, val_loss: 0.563187038898468\n",
      "4036, train_loss: 0.5690222531557083, val_loss: 0.5582458317279816\n",
      "4037, train_loss: 0.5691812072808926, val_loss: 0.5731013894081116\n",
      "4038, train_loss: 0.5685042773301785, val_loss: 0.566418182849884\n",
      "4039, train_loss: 0.5720117321381202, val_loss: 0.5585709095001221\n",
      "4040, train_loss: 0.5686316730884405, val_loss: 0.5563061356544494\n",
      "4041, train_loss: 0.5685267196251795, val_loss: 0.5645156979560852\n",
      "4042, train_loss: 0.5710488168092874, val_loss: 0.558929705619812\n",
      "4043, train_loss: 0.5688534333155706, val_loss: 0.5527709066867829\n",
      "4044, train_loss: 0.5682540329603049, val_loss: 0.5655551314353943\n",
      "4045, train_loss: 0.5715488527829831, val_loss: 0.5475247919559478\n",
      "4046, train_loss: 0.5682574418874887, val_loss: 0.5547664999961853\n",
      "4047, train_loss: 0.5679301161032456, val_loss: 0.5479052543640137\n",
      "4048, train_loss: 0.571677667590288, val_loss: 0.5471854150295258\n",
      "4049, train_loss: 0.5697634563996241, val_loss: 0.5481010735034942\n",
      "4050, train_loss: 0.5688133491919591, val_loss: 0.5558899700641632\n",
      "4051, train_loss: 0.5715862558438227, val_loss: 0.5614911437034606\n",
      "4052, train_loss: 0.5699614871006745, val_loss: 0.5441718339920044\n",
      "4053, train_loss: 0.5696156449042834, val_loss: 0.552283889055252\n",
      "4054, train_loss: 0.5676233585064228, val_loss: 0.5388281643390656\n",
      "4055, train_loss: 0.5713649197266653, val_loss: 0.5626550555229187\n",
      "4056, train_loss: 0.5713168061696566, val_loss: 0.5576132416725159\n",
      "4057, train_loss: 0.5712759964741193, val_loss: 0.5707039833068848\n",
      "4058, train_loss: 0.5712603433774068, val_loss: 0.5685674786567688\n",
      "4059, train_loss: 0.5697587453402005, val_loss: 0.5547848343849182\n",
      "4060, train_loss: 0.5672046347306325, val_loss: 0.5617650508880615\n",
      "4061, train_loss: 0.5711031395655412, val_loss: 0.5531907379627228\n",
      "4062, train_loss: 0.5697606492501038, val_loss: 0.5552475154399872\n",
      "4063, train_loss: 0.568011883359689, val_loss: 0.5567299842834472\n",
      "4064, train_loss: 0.5710171323556167, val_loss: 0.5565938353538513\n",
      "4065, train_loss: 0.5709555401251867, val_loss: 0.5442692995071411\n",
      "4066, train_loss: 0.5679549093429859, val_loss: 0.546438330411911\n",
      "4067, train_loss: 0.5708433137490199, val_loss: 0.5432784020900726\n",
      "4068, train_loss: 0.5708333987456101, val_loss: 0.5602437138557435\n",
      "4069, train_loss: 0.5707775297073218, val_loss: 0.5488083839416504\n",
      "4070, train_loss: 0.5698147817299917, val_loss: 0.5715157151222229\n",
      "4071, train_loss: 0.5706908634075751, val_loss: 0.5714095890522003\n",
      "4072, train_loss: 0.5691579832480504, val_loss: 0.5632687091827393\n",
      "4073, train_loss: 0.5676764375888385, val_loss: 0.555327832698822\n",
      "4074, train_loss: 0.5705705651870141, val_loss: 0.561937415599823\n",
      "4075, train_loss: 0.5705122374571286, val_loss: 0.5356035351753234\n",
      "4076, train_loss: 0.5673169447825506, val_loss: 0.5626087546348572\n",
      "4077, train_loss: 0.5668238206551626, val_loss: 0.5604102075099945\n",
      "4078, train_loss: 0.5689474665201627, val_loss: 0.5510473430156708\n",
      "4079, train_loss: 0.5667103918699118, val_loss: 0.5554966926574707\n",
      "4080, train_loss: 0.5660409606420077, val_loss: 0.5451066434383393\n",
      "4081, train_loss: 0.5686623878203906, val_loss: 0.5563613533973694\n",
      "4082, train_loss: 0.5702057251563439, val_loss: 0.5547301173210144\n",
      "4083, train_loss: 0.568288043141365, val_loss: 0.5512880623340607\n",
      "4084, train_loss: 0.5682047147017258, val_loss: 0.5448113799095153\n",
      "4085, train_loss: 0.5701210326873339, val_loss: 0.5400964200496674\n",
      "4086, train_loss: 0.5684738136254824, val_loss: 0.5626164317131043\n",
      "4087, train_loss: 0.5700163210813816, val_loss: 0.5484595775604248\n",
      "4088, train_loss: 0.5683027574649224, val_loss: 0.5384935021400452\n",
      "4089, train_loss: 0.5687599583314016, val_loss: 0.5515619575977325\n",
      "4090, train_loss: 0.5663811747844403, val_loss: 0.5423321068286896\n",
      "4091, train_loss: 0.5667913750960276, val_loss: 0.5592264950275421\n",
      "4092, train_loss: 0.5697535001314603, val_loss: 0.5610232710838318\n",
      "4093, train_loss: 0.5697330098885757, val_loss: 0.5368361175060272\n",
      "4094, train_loss: 0.5696828296551337, val_loss: 0.5585409820079803\n",
      "4095, train_loss: 0.5664051220967219, val_loss: 0.5374643266201019\n",
      "4096, train_loss: 0.5666463959675568, val_loss: 0.5510353803634643\n",
      "4097, train_loss: 0.569562730880884, val_loss: 0.5528419494628907\n",
      "4098, train_loss: 0.5695270655246881, val_loss: 0.5594984531402588\n",
      "4099, train_loss: 0.5678819738901578, val_loss: 0.5345764398574829\n",
      "4100, train_loss: 0.5694430527778772, val_loss: 0.5618523359298706\n",
      "4101, train_loss: 0.5694121420383453, val_loss: 0.5481691777706146\n",
      "4102, train_loss: 0.5693836945753831, val_loss: 0.5536402940750123\n",
      "4103, train_loss: 0.569310710980342, val_loss: 0.5519696474075317\n",
      "4104, train_loss: 0.5657368416969593, val_loss: 0.5624828636646271\n",
      "4105, train_loss: 0.5692581740709451, val_loss: 0.5473074793815613\n",
      "4106, train_loss: 0.5688899915951949, val_loss: 0.5584520816802978\n",
      "4107, train_loss: 0.5681626498699188, val_loss: 0.5517810225486756\n",
      "4108, train_loss: 0.5690495773003652, val_loss: 0.5525160193443298\n",
      "4109, train_loss: 0.5651218535808417, val_loss: 0.5518041014671325\n",
      "4110, train_loss: 0.5689493646988502, val_loss: 0.5516994833946228\n",
      "4111, train_loss: 0.5679234610154078, val_loss: 0.5701741218566895\n",
      "4112, train_loss: 0.5678797261073039, val_loss: 0.5447578668594361\n",
      "4113, train_loss: 0.5655984041782526, val_loss: 0.5608681082725525\n",
      "4114, train_loss: 0.5686926371776141, val_loss: 0.5701404750347138\n",
      "4115, train_loss: 0.5656887109463031, val_loss: 0.5605140447616577\n",
      "4116, train_loss: 0.5686253125850971, val_loss: 0.548567819595337\n",
      "4117, train_loss: 0.565591601225046, val_loss: 0.5663356184959412\n",
      "4118, train_loss: 0.5653376682446554, val_loss: 0.552894127368927\n",
      "4119, train_loss: 0.5668434993578837, val_loss: 0.5554029107093811\n",
      "4120, train_loss: 0.5653529339111768, val_loss: 0.5449586987495423\n",
      "4121, train_loss: 0.5671635980789478, val_loss: 0.5549288392066956\n",
      "4122, train_loss: 0.564928140777808, val_loss: 0.5552758574485779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4123, train_loss: 0.565137491776393, val_loss: 0.5582116961479187\n",
      "4124, train_loss: 0.5652135954453394, val_loss: 0.5483590960502625\n",
      "4125, train_loss: 0.564680679486348, val_loss: 0.5576663374900818\n",
      "4126, train_loss: 0.5641437069727824, val_loss: 0.5535151898860932\n",
      "4127, train_loss: 0.5668584131277524, val_loss: 0.5610708177089692\n",
      "4128, train_loss: 0.5680558486626699, val_loss: 0.557301115989685\n",
      "4129, train_loss: 0.5643340062636596, val_loss: 0.5698618531227112\n",
      "4130, train_loss: 0.5647513178678659, val_loss: 0.5612219214439392\n",
      "4131, train_loss: 0.5644857814678779, val_loss: 0.5696839034557343\n",
      "4132, train_loss: 0.5679276493879465, val_loss: 0.5586620807647705\n",
      "4133, train_loss: 0.5678697973489761, val_loss: 0.5587756991386413\n",
      "4134, train_loss: 0.5678075276888334, val_loss: 0.5599778890609741\n",
      "4135, train_loss: 0.5658038854598999, val_loss: 0.5507515072822571\n",
      "4136, train_loss: 0.5645055770874023, val_loss: 0.5406560838222504\n",
      "4137, train_loss: 0.5648752531180015, val_loss: 0.5539590537548065\n",
      "4138, train_loss: 0.5634533579532917, val_loss: 0.5540207684040069\n",
      "4139, train_loss: 0.5661138960948358, val_loss: 0.5580377757549286\n",
      "4140, train_loss: 0.5671301931142807, val_loss: 0.5566122651100158\n",
      "4141, train_loss: 0.56747361100637, val_loss: 0.5452057123184204\n",
      "4142, train_loss: 0.5674669467485868, val_loss: 0.5580368518829346\n",
      "4143, train_loss: 0.563949642273096, val_loss: 0.5608317136764527\n",
      "4144, train_loss: 0.5634432366261115, val_loss: 0.541443133354187\n",
      "4145, train_loss: 0.5673160621753106, val_loss: 0.5463480770587921\n",
      "4146, train_loss: 0.5638118993777496, val_loss: 0.5537929654121398\n",
      "4147, train_loss: 0.5641985879494593, val_loss: 0.5668971538543701\n",
      "4148, train_loss: 0.5657082394911692, val_loss: 0.5433219790458679\n",
      "4149, train_loss: 0.5641516435604829, val_loss: 0.5652577042579651\n",
      "4150, train_loss: 0.5640744670079305, val_loss: 0.5541847944259644\n",
      "4151, train_loss: 0.5659456447913096, val_loss: 0.5590184330940247\n",
      "4152, train_loss: 0.5670080471497315, val_loss: 0.5603601336479187\n",
      "4153, train_loss: 0.5634706937349759, val_loss: 0.5689217746257782\n",
      "4154, train_loss: 0.5658642821587049, val_loss: 0.5578520894050598\n",
      "4155, train_loss: 0.5658851667092397, val_loss: 0.5562682211399078\n",
      "4156, train_loss: 0.5661861644341395, val_loss: 0.546766173839569\n",
      "4157, train_loss: 0.5630833391959851, val_loss: 0.5601513743400574\n",
      "4158, train_loss: 0.5639019826283822, val_loss: 0.5521027684211731\n",
      "4159, train_loss: 0.5638061968179849, val_loss: 0.5419247150421143\n",
      "4160, train_loss: 0.5632141347114856, val_loss: 0.5461482524871826\n",
      "4161, train_loss: 0.5662273512436793, val_loss: 0.5664669632911682\n",
      "4162, train_loss: 0.5666075704189447, val_loss: 0.5687714576721191\n",
      "4163, train_loss: 0.563082109277065, val_loss: 0.5522728323936462\n",
      "4164, train_loss: 0.5630293866762748, val_loss: 0.5489687561988831\n",
      "4165, train_loss: 0.5630920472053381, val_loss: 0.5426514923572541\n",
      "4166, train_loss: 0.5644533393474725, val_loss: 0.5512480437755585\n",
      "4167, train_loss: 0.5659826203034475, val_loss: 0.541791045665741\n",
      "4168, train_loss: 0.5643717623673953, val_loss: 0.5404211282730103\n",
      "4169, train_loss: 0.5663100389333872, val_loss: 0.5605764925479889\n",
      "4170, train_loss: 0.5645213104211367, val_loss: 0.5674007654190063\n",
      "4171, train_loss: 0.5628598916989106, val_loss: 0.5571567952632904\n",
      "4172, train_loss: 0.5659561260388448, val_loss: 0.5374265789985657\n",
      "4173, train_loss: 0.5629622122416129, val_loss: 0.5490390121936798\n",
      "4174, train_loss: 0.5629339114977763, val_loss: 0.5522050499916077\n",
      "4175, train_loss: 0.5643802434206009, val_loss: 0.5436610877513885\n",
      "4176, train_loss: 0.5660009177831503, val_loss: 0.5603963553905487\n",
      "4177, train_loss: 0.5648740209065951, val_loss: 0.5440336406230927\n",
      "4178, train_loss: 0.5648241318189181, val_loss: 0.5562489688396454\n",
      "4179, train_loss: 0.5640460883195584, val_loss: 0.5594825863838195\n",
      "4180, train_loss: 0.5628405454067084, val_loss: 0.5409444868564606\n",
      "4181, train_loss: 0.5615052512058845, val_loss: 0.542644488811493\n",
      "4182, train_loss: 0.5646641495136114, val_loss: 0.5602974355220794\n",
      "4183, train_loss: 0.5622217792731065, val_loss: 0.5514427542686462\n",
      "4184, train_loss: 0.5625404188266168, val_loss: 0.5602235555648803\n",
      "4185, train_loss: 0.5645646819701562, val_loss: 0.5413038611412049\n",
      "4186, train_loss: 0.5634805605961726, val_loss: 0.5567025721073151\n",
      "4187, train_loss: 0.565445017356139, val_loss: 0.5433052539825439\n",
      "4188, train_loss: 0.5653908069317157, val_loss: 0.5592600464820862\n",
      "4189, train_loss: 0.5653399767783972, val_loss: 0.5507552623748779\n",
      "4190, train_loss: 0.5653356726352985, val_loss: 0.5418805241584778\n",
      "4191, train_loss: 0.5624196517925996, val_loss: 0.5536025524139404\n",
      "4192, train_loss: 0.561642696078007, val_loss: 0.5404121279716492\n",
      "4193, train_loss: 0.5621796915164361, val_loss: 0.5525682449340821\n",
      "4194, train_loss: 0.565149860886427, val_loss: 0.5503248453140259\n",
      "4195, train_loss: 0.5614032424413241, val_loss: 0.5591980397701264\n",
      "4196, train_loss: 0.5642851556722934, val_loss: 0.5586433053016663\n",
      "4197, train_loss: 0.5650119850268731, val_loss: 0.5638619005680084\n",
      "4198, train_loss: 0.5605876342608378, val_loss: 0.5524939715862274\n",
      "4199, train_loss: 0.5631692386590518, val_loss: 0.5332761228084564\n",
      "4200, train_loss: 0.561807210628803, val_loss: 0.5512611627578735\n",
      "4201, train_loss: 0.5615309041280013, val_loss: 0.5485811054706573\n",
      "4202, train_loss: 0.5641527187365752, val_loss: 0.5663878202438355\n",
      "4203, train_loss: 0.5614968721683209, val_loss: 0.5561773359775544\n",
      "4204, train_loss: 0.5610337956593587, val_loss: 0.5515524446964264\n",
      "4205, train_loss: 0.5647005931689189, val_loss: 0.5553957521915436\n",
      "4206, train_loss: 0.5646113157272339, val_loss: 0.5416997373104095\n",
      "4207, train_loss: 0.5645856032004724, val_loss: 0.5586136221885681\n",
      "4208, train_loss: 0.5645514050355325, val_loss: 0.55592041015625\n",
      "4209, train_loss: 0.56405475964913, val_loss: 0.5513421177864075\n",
      "4210, train_loss: 0.5605415873802625, val_loss: 0.5393767714500427\n",
      "4211, train_loss: 0.5612221921865757, val_loss: 0.5549701571464538\n",
      "4212, train_loss: 0.5605355329238452, val_loss: 0.5401169061660767\n",
      "4213, train_loss: 0.5643720810229962, val_loss: 0.5588183641433716\n",
      "4214, train_loss: 0.5643412436430271, val_loss: 0.5584082126617431\n",
      "4215, train_loss: 0.5607153922319412, val_loss: 0.5568428754806518\n",
      "4216, train_loss: 0.5625495841869941, val_loss: 0.5658852458000183\n",
      "4217, train_loss: 0.5599105518597823, val_loss: 0.5657519459724426\n",
      "4218, train_loss: 0.5606191593867081, val_loss: 0.5505841791629791\n",
      "4219, train_loss: 0.5634221090720251, val_loss: 0.5396189451217651\n",
      "4220, train_loss: 0.5627230302645609, val_loss: 0.5348659932613373\n",
      "4221, train_loss: 0.5601845372181672, val_loss: 0.5414268016815186\n",
      "4222, train_loss: 0.5623839749739721, val_loss: 0.5422632455825805\n",
      "4223, train_loss: 0.5596652787465316, val_loss: 0.5586002409458161\n",
      "4224, train_loss: 0.5603555268966235, val_loss: 0.5531456649303437\n",
      "4225, train_loss: 0.560758174611972, val_loss: 0.5465558886528015\n",
      "4226, train_loss: 0.561723014483085, val_loss: 0.5574239015579223\n",
      "4227, train_loss: 0.5607398003339767, val_loss: 0.5666375041007996\n",
      "4228, train_loss: 0.5637137660613427, val_loss: 0.5391510665416718\n",
      "4229, train_loss: 0.5597601842421752, val_loss: 0.5409324765205383\n",
      "4230, train_loss: 0.5599248500970694, val_loss: 0.5574340224266052\n",
      "4231, train_loss: 0.5600732473226694, val_loss: 0.5487848460674286\n",
      "4232, train_loss: 0.5635582632743396, val_loss: 0.546417111158371\n",
      "4233, train_loss: 0.5635625135440093, val_loss: 0.5661461591720581\n",
      "4234, train_loss: 0.5615189602741828, val_loss: 0.553976571559906\n",
      "4235, train_loss: 0.5599983070905392, val_loss: 0.5476814031600952\n",
      "4236, train_loss: 0.5622591284605173, val_loss: 0.5486981987953186\n",
      "4237, train_loss: 0.5620089803750699, val_loss: 0.5511308908462524\n",
      "4238, train_loss: 0.5622637799152961, val_loss: 0.5530291676521302\n",
      "4239, train_loss: 0.5621446027205541, val_loss: 0.5662077307701111\n",
      "4240, train_loss: 0.5632287814066961, val_loss: 0.5526674449443817\n",
      "4241, train_loss: 0.5610700329908958, val_loss: 0.550087833404541\n",
      "4242, train_loss: 0.5630441330946409, val_loss: 0.5540785729885102\n",
      "4243, train_loss: 0.5630474388599396, val_loss: 0.5581955909729004\n",
      "4244, train_loss: 0.5593638167931483, val_loss: 0.5663025379180908\n",
      "4245, train_loss: 0.5618048092493644, val_loss: 0.5493755042552948\n",
      "4246, train_loss: 0.5610897506658847, val_loss: 0.545542585849762\n",
      "4247, train_loss: 0.5597149981902196, val_loss: 0.5442097067832947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4248, train_loss: 0.559723253433521, val_loss: 0.5496693551540375\n",
      "4249, train_loss: 0.5587903903080866, val_loss: 0.5292249917984009\n",
      "4250, train_loss: 0.5614459296831718, val_loss: 0.5398385465145111\n",
      "4251, train_loss: 0.5591718290860836, val_loss: 0.5334914743900299\n",
      "4252, train_loss: 0.5614298708163775, val_loss: 0.5507169604301453\n",
      "4253, train_loss: 0.562675539117593, val_loss: 0.5399805068969726\n",
      "4254, train_loss: 0.5593083191376466, val_loss: 0.5484205722808838\n",
      "4255, train_loss: 0.5612660749600484, val_loss: 0.565593671798706\n",
      "4256, train_loss: 0.5625739854115707, val_loss: 0.5285504877567291\n",
      "4257, train_loss: 0.5625292395169919, val_loss: 0.5522873520851135\n",
      "4258, train_loss: 0.5591821005711188, val_loss: 0.5562916040420532\n",
      "4259, train_loss: 0.5612938667719181, val_loss: 0.5529823064804077\n",
      "4260, train_loss: 0.5606724310379761, val_loss: 0.5315313279628754\n",
      "4261, train_loss: 0.5612663294260318, val_loss: 0.5516211450099945\n",
      "4262, train_loss: 0.5604904156464797, val_loss: 0.5504393637180328\n",
      "4263, train_loss: 0.5590662784301318, val_loss: 0.5484358489513397\n",
      "4264, train_loss: 0.5602348057123331, val_loss: 0.5484874188899994\n",
      "4265, train_loss: 0.558751677091305, val_loss: 0.5460768342018127\n",
      "4266, train_loss: 0.5620720867927258, val_loss: 0.5577771782875061\n",
      "4267, train_loss: 0.5576509879185603, val_loss: 0.5309667944908142\n",
      "4268, train_loss: 0.561602730017442, val_loss: 0.5470808744430542\n",
      "4269, train_loss: 0.5619994149758265, val_loss: 0.5500925064086915\n",
      "4270, train_loss: 0.5612240972427222, val_loss: 0.5494094252586365\n",
      "4271, train_loss: 0.5619347359125431, val_loss: 0.5402194738388062\n",
      "4272, train_loss: 0.5607429181153958, val_loss: 0.547042965888977\n",
      "4273, train_loss: 0.5617974354670598, val_loss: 0.5468660116195678\n",
      "4274, train_loss: 0.5587797256616446, val_loss: 0.5567995607852936\n",
      "4275, train_loss: 0.5584449607592362, val_loss: 0.5440924525260925\n",
      "4276, train_loss: 0.5599249337728207, val_loss: 0.5364732503890991\n",
      "4277, train_loss: 0.56016383262781, val_loss: 0.5543275594711303\n",
      "4278, train_loss: 0.5616035702136847, val_loss: 0.5464537978172302\n",
      "4279, train_loss: 0.5599172069476201, val_loss: 0.5566336631774902\n",
      "4280, train_loss: 0.5598678543017461, val_loss: 0.5542733669281006\n",
      "4281, train_loss: 0.5577762493720422, val_loss: 0.5566309928894043\n",
      "4282, train_loss: 0.5603534017617886, val_loss: 0.5460286438465118\n",
      "4283, train_loss: 0.5582856788085058, val_loss: 0.5489594399929046\n",
      "4284, train_loss: 0.5579609779211191, val_loss: 0.5641516327857972\n",
      "4285, train_loss: 0.5573315173387527, val_loss: 0.5479355931282044\n",
      "4286, train_loss: 0.561283141374588, val_loss: 0.5372431159019471\n",
      "4287, train_loss: 0.5608756072246112, val_loss: 0.5452555477619171\n",
      "4288, train_loss: 0.5590652158627143, val_loss: 0.5487579286098481\n",
      "4289, train_loss: 0.5592194715371499, val_loss: 0.5366059482097626\n",
      "4290, train_loss: 0.5601799533917353, val_loss: 0.564820921421051\n",
      "4291, train_loss: 0.5610078768088267, val_loss: 0.5489104330539704\n",
      "4292, train_loss: 0.5585014831561309, val_loss: 0.544802439212799\n",
      "4293, train_loss: 0.5609297397044989, val_loss: 0.5497061491012574\n",
      "4294, train_loss: 0.5597674009891657, val_loss: 0.5496016263961792\n",
      "4295, train_loss: 0.5570748345210002, val_loss: 0.5493502974510193\n",
      "4296, train_loss: 0.5572020847063798, val_loss: 0.5477274775505065\n",
      "4297, train_loss: 0.5567630277230189, val_loss: 0.5455441236495971\n",
      "4298, train_loss: 0.5607211807599435, val_loss: 0.5560118436813355\n",
      "4299, train_loss: 0.5569277038941016, val_loss: 0.5447857856750489\n",
      "4300, train_loss: 0.5582080196875793, val_loss: 0.5543751895427704\n",
      "4301, train_loss: 0.5606374671825995, val_loss: 0.5386953592300415\n",
      "4302, train_loss: 0.5605686398652884, val_loss: 0.5559412598609924\n",
      "4303, train_loss: 0.5566190779209137, val_loss: 0.5558320224285126\n",
      "4304, train_loss: 0.560518001134579, val_loss: 0.5445729613304138\n",
      "4305, train_loss: 0.5589433770913345, val_loss: 0.5556457042694092\n",
      "4306, train_loss: 0.5604076236486435, val_loss: 0.5450242042541504\n",
      "4307, train_loss: 0.5591829694234408, val_loss: 0.5597958922386169\n",
      "4308, train_loss: 0.5603243055251929, val_loss: 0.5315509915351868\n",
      "4309, train_loss: 0.5587796855431336, val_loss: 0.546052896976471\n",
      "4310, train_loss: 0.5570107675515689, val_loss: 0.5346889019012451\n",
      "4311, train_loss: 0.556217794234936, val_loss: 0.5417671799659729\n",
      "4312, train_loss: 0.5565662590356973, val_loss: 0.5632162690162659\n",
      "4313, train_loss: 0.5601499860103314, val_loss: 0.5397443175315857\n",
      "4314, train_loss: 0.5586285109703357, val_loss: 0.5394122958183288\n",
      "4315, train_loss: 0.556218010874895, val_loss: 0.548680180311203\n",
      "4316, train_loss: 0.5561932703623405, val_loss: 0.55544114112854\n",
      "4317, train_loss: 0.5577956930949137, val_loss: 0.5360763549804688\n",
      "4318, train_loss: 0.5567595018790319, val_loss: 0.5523983359336853\n",
      "4319, train_loss: 0.5590899082330557, val_loss: 0.5317124485969543\n",
      "4320, train_loss: 0.5598130352222003, val_loss: 0.5423166394233704\n",
      "4321, train_loss: 0.5598256037785456, val_loss: 0.5383258700370789\n",
      "4322, train_loss: 0.5565958366944239, val_loss: 0.5627506971359253\n",
      "4323, train_loss: 0.5597314020762076, val_loss: 0.5345815122127533\n",
      "4324, train_loss: 0.5597131252288818, val_loss: 0.5458648085594178\n",
      "4325, train_loss: 0.5596880316734314, val_loss: 0.5284559428691864\n",
      "4326, train_loss: 0.5596928172386609, val_loss: 0.5459793090820313\n",
      "4327, train_loss: 0.5576794800850061, val_loss: 0.5460532426834106\n",
      "4328, train_loss: 0.5553208543704107, val_loss: 0.5259719133377075\n",
      "4329, train_loss: 0.5564719197841791, val_loss: 0.5510207533836364\n",
      "4330, train_loss: 0.5594781373555844, val_loss: 0.5613437116146087\n",
      "4331, train_loss: 0.5594152028744037, val_loss: 0.5450963079929352\n",
      "4332, train_loss: 0.5585435411104789, val_loss: 0.5402766704559326\n",
      "4333, train_loss: 0.5556297760743362, val_loss: 0.5328144311904908\n",
      "4334, train_loss: 0.5579379808444244, val_loss: 0.5372499465942383\n",
      "4335, train_loss: 0.5550753256449332, val_loss: 0.5449084520339966\n",
      "4336, train_loss: 0.5557192449386303, val_loss: 0.5342843294143677\n",
      "4337, train_loss: 0.5579945479448025, val_loss: 0.5367438852787018\n",
      "4338, train_loss: 0.5577712792616624, val_loss: 0.5625905752182007\n",
      "4339, train_loss: 0.5591170306389148, val_loss: 0.545593935251236\n",
      "4340, train_loss: 0.559098591025059, val_loss: 0.5624399423599243\n",
      "4341, train_loss: 0.5553150440637882, val_loss: 0.5481908619403839\n",
      "4342, train_loss: 0.5590183356633553, val_loss: 0.5418559193611145\n",
      "4343, train_loss: 0.5569453033117148, val_loss: 0.5437880158424377\n",
      "4344, train_loss: 0.5552753783189334, val_loss: 0.5387181222438813\n",
      "4345, train_loss: 0.5588674625525107, val_loss: 0.544493556022644\n",
      "4346, train_loss: 0.5576594930428725, val_loss: 0.5469891488552093\n",
      "4347, train_loss: 0.556922510266304, val_loss: 0.5325143575668335\n",
      "4348, train_loss: 0.555142308656986, val_loss: 0.5622217416763305\n",
      "4349, train_loss: 0.5587230347670041, val_loss: 0.5543650686740875\n",
      "4350, train_loss: 0.5546093457020246, val_loss: 0.550151240825653\n",
      "4351, train_loss: 0.5586165602390583, val_loss: 0.5494048535823822\n",
      "4352, train_loss: 0.555214775296358, val_loss: 0.5543117761611939\n",
      "4353, train_loss: 0.5585575768580804, val_loss: 0.5268150806427002\n",
      "4354, train_loss: 0.5585762182107339, val_loss: 0.5322296500205994\n",
      "4355, train_loss: 0.5584838562286817, val_loss: 0.5618135929107666\n",
      "4356, train_loss: 0.558459820655676, val_loss: 0.5517225503921509\n",
      "4357, train_loss: 0.5569346352265432, val_loss: 0.5602050304412842\n",
      "4358, train_loss: 0.558321529856095, val_loss: 0.5528152227401734\n",
      "4359, train_loss: 0.5583157459130654, val_loss: 0.5425832986831665\n",
      "4360, train_loss: 0.5556824172918613, val_loss: 0.5421849608421325\n",
      "4361, train_loss: 0.5563098341226578, val_loss: 0.5534851372241973\n",
      "4362, train_loss: 0.5562760898700128, val_loss: 0.5510825037956237\n",
      "4363, train_loss: 0.5548273989787469, val_loss: 0.5619837880134583\n",
      "4364, train_loss: 0.557733681339484, val_loss: 0.547509491443634\n",
      "4365, train_loss: 0.5558526664972305, val_loss: 0.5387875199317932\n",
      "4366, train_loss: 0.556796310039667, val_loss: 0.5525750696659089\n",
      "4367, train_loss: 0.5560716413534604, val_loss: 0.5376220285892487\n",
      "4368, train_loss: 0.555703450854008, val_loss: 0.5431757211685181\n",
      "4369, train_loss: 0.5577760499257308, val_loss: 0.5437747895717621\n",
      "4370, train_loss: 0.5577749220224527, val_loss: 0.5620197057723999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4371, train_loss: 0.5565517842769623, val_loss: 0.5467433094978332\n",
      "4372, train_loss: 0.5541367943470294, val_loss: 0.561272144317627\n",
      "4373, train_loss: 0.5576809209126693, val_loss: 0.5570531785488129\n",
      "4374, train_loss: 0.5540682971477509, val_loss: 0.5599409222602845\n",
      "4375, train_loss: 0.5556854674449334, val_loss: 0.5242950320243835\n",
      "4376, train_loss: 0.5544417454646184, val_loss: 0.5443012475967407\n",
      "4377, train_loss: 0.5575197545381693, val_loss: 0.5366880059242248\n",
      "4378, train_loss: 0.5555852674520932, val_loss: 0.5434512078762055\n",
      "4379, train_loss: 0.5538642750336573, val_loss: 0.5487181782722473\n",
      "4380, train_loss: 0.5537703300897892, val_loss: 0.533043485879898\n",
      "4381, train_loss: 0.5542653386409466, val_loss: 0.540952342748642\n",
      "4382, train_loss: 0.5537034490933785, val_loss: 0.5405456304550171\n",
      "4383, train_loss: 0.557262115753614, val_loss: 0.5445943951606751\n",
      "4384, train_loss: 0.5554584665940359, val_loss: 0.5522886157035828\n",
      "4385, train_loss: 0.5535983741283417, val_loss: 0.5615982413291931\n",
      "4386, train_loss: 0.5571333112624975, val_loss: 0.5527455866336822\n",
      "4387, train_loss: 0.553075237916066, val_loss: 0.5533203601837158\n",
      "4388, train_loss: 0.5556533313714541, val_loss: 0.5526861727237702\n",
      "4389, train_loss: 0.5569777053136092, val_loss: 0.5305753469467163\n",
      "4390, train_loss: 0.5569670234735196, val_loss: 0.5409011960029602\n",
      "4391, train_loss: 0.5557719365908549, val_loss: 0.5457995891571045\n",
      "4392, train_loss: 0.5551723493979528, val_loss: 0.5414680957794189\n",
      "4393, train_loss: 0.5528656576688473, val_loss: 0.5563930809497833\n",
      "4394, train_loss: 0.5531879250819867, val_loss: 0.5393393516540528\n",
      "4395, train_loss: 0.5535052762581751, val_loss: 0.5277401149272919\n",
      "4396, train_loss: 0.5567473757725495, val_loss: 0.558975100517273\n",
      "4397, train_loss: 0.5528416645068389, val_loss: 0.5390829026699067\n",
      "4398, train_loss: 0.5530357842261975, val_loss: 0.5602603793144226\n",
      "4399, train_loss: 0.5548114352501355, val_loss: 0.551193106174469\n",
      "4400, train_loss: 0.5526631187934142, val_loss: 0.5507550537586212\n",
      "4401, train_loss: 0.556568789940614, val_loss: 0.5424031257629395\n",
      "4402, train_loss: 0.5533522608188483, val_loss: 0.5297130346298218\n",
      "4403, train_loss: 0.5564544567695031, val_loss: 0.5477165102958679\n",
      "4404, train_loss: 0.5564404428005219, val_loss: 0.5381896495819092\n",
      "4405, train_loss: 0.5542032145536863, val_loss: 0.5395862460136414\n",
      "4406, train_loss: 0.5545665507133191, val_loss: 0.5473209679126739\n",
      "4407, train_loss: 0.5562958041062722, val_loss: 0.5388052940368653\n",
      "4408, train_loss: 0.5520331194767585, val_loss: 0.5506638288497925\n",
      "4409, train_loss: 0.5539385217886704, val_loss: 0.5357308626174927\n",
      "4410, train_loss: 0.5561099900649145, val_loss: 0.5476996421813964\n",
      "4411, train_loss: 0.5551072576871285, val_loss: 0.5412604629993438\n",
      "4412, train_loss: 0.5560195434551972, val_loss: 0.5317103147506714\n",
      "4413, train_loss: 0.5538865006886996, val_loss: 0.5496562063694\n",
      "4414, train_loss: 0.5515492661641195, val_loss: 0.5407013058662414\n",
      "4415, train_loss: 0.5559017577996621, val_loss: 0.5495588898658752\n",
      "4416, train_loss: 0.5543601444134345, val_loss: 0.5316891074180603\n",
      "4417, train_loss: 0.5538574388393989, val_loss: 0.5477396607398987\n",
      "4418, train_loss: 0.5544649225014907, val_loss: 0.5511684477329254\n",
      "4419, train_loss: 0.5524585350201681, val_loss: 0.5515152394771576\n",
      "4420, train_loss: 0.5517025119983233, val_loss: 0.5557960271835327\n",
      "4421, train_loss: 0.5537652900585761, val_loss: 0.5427106320858002\n",
      "4422, train_loss: 0.5524069792949237, val_loss: 0.5354055762290955\n",
      "4423, train_loss: 0.5536016214352387, val_loss: 0.5518774688243866\n",
      "4424, train_loss: 0.5555194593392886, val_loss: 0.5340672612190247\n",
      "4425, train_loss: 0.5513751426568398, val_loss: 0.5450685381889343\n",
      "4426, train_loss: 0.553819579573778, val_loss: 0.537896728515625\n",
      "4427, train_loss: 0.5519373760773585, val_loss: 0.5318478763103485\n",
      "4428, train_loss: 0.5517759655530636, val_loss: 0.5425631582736969\n",
      "4429, train_loss: 0.5538250379837476, val_loss: 0.5328816771507263\n",
      "4430, train_loss: 0.5520930313147031, val_loss: 0.5581054270267487\n",
      "4431, train_loss: 0.5552786187483714, val_loss: 0.546277540922165\n",
      "4432, train_loss: 0.553794366809038, val_loss: 0.5518985867500306\n",
      "4433, train_loss: 0.5551524861500814, val_loss: 0.5418067157268525\n",
      "4434, train_loss: 0.5551492365506979, val_loss: 0.5222638845443726\n",
      "4435, train_loss: 0.5551341611605424, val_loss: 0.537001657485962\n",
      "4436, train_loss: 0.5514440215550936, val_loss: 0.5467491745948792\n",
      "4437, train_loss: 0.5515702882638345, val_loss: 0.5323057115077973\n",
      "4438, train_loss: 0.5537350991597543, val_loss: 0.5485460042953492\n",
      "4439, train_loss: 0.5516060625131314, val_loss: 0.5367784619331359\n",
      "4440, train_loss: 0.5512677075771185, val_loss: 0.53707834482193\n",
      "4441, train_loss: 0.5548996810729687, val_loss: 0.534343546628952\n",
      "4442, train_loss: 0.5548815371898504, val_loss: 0.5547342360019684\n",
      "4443, train_loss: 0.550957325559396, val_loss: 0.529914504289627\n",
      "4444, train_loss: 0.5515093608544424, val_loss: 0.5413774251937866\n",
      "4445, train_loss: 0.5529669844187223, val_loss: 0.5407893180847168\n",
      "4446, train_loss: 0.5514194999749844, val_loss: 0.5422774672508239\n",
      "4447, train_loss: 0.5511374060924237, val_loss: 0.5403945207595825\n",
      "4448, train_loss: 0.5543010716254895, val_loss: 0.5433770835399627\n",
      "4449, train_loss: 0.5513786616233679, val_loss: 0.537323635816574\n",
      "4450, train_loss: 0.554524961572427, val_loss: 0.5437682330608368\n",
      "4451, train_loss: 0.5542512226563233, val_loss: 0.541031289100647\n",
      "4452, train_loss: 0.5544973245033851, val_loss: 0.5438875198364258\n",
      "4453, train_loss: 0.5544389325838822, val_loss: 0.5428538143634796\n",
      "4454, train_loss: 0.5541107918207462, val_loss: 0.5388572871685028\n",
      "4455, train_loss: 0.5497850569394919, val_loss: 0.5350380063056945\n",
      "4456, train_loss: 0.5531527606340555, val_loss: 0.5295442521572113\n",
      "4457, train_loss: 0.5504291298297735, val_loss: 0.5488091826438903\n",
      "4458, train_loss: 0.5511230035470083, val_loss: 0.5373321294784545\n",
      "4459, train_loss: 0.5532879760632148, val_loss: 0.5505801677703858\n",
      "4460, train_loss: 0.5509060357625668, val_loss: 0.542550778388977\n",
      "4461, train_loss: 0.5527317225933075, val_loss: 0.5568167686462402\n",
      "4462, train_loss: 0.5501687228679657, val_loss: 0.5587863266468048\n",
      "4463, train_loss: 0.5523175150156021, val_loss: 0.5374914228916168\n",
      "4464, train_loss: 0.5539569109678268, val_loss: 0.5407920479774475\n",
      "4465, train_loss: 0.5520782906275529, val_loss: 0.5381293654441833\n",
      "4466, train_loss: 0.5539430792515094, val_loss: 0.5364956438541413\n",
      "4467, train_loss: 0.5504491317730683, val_loss: 0.5398784160614014\n",
      "4468, train_loss: 0.553845960360307, val_loss: 0.5452958405017853\n",
      "4469, train_loss: 0.5504068227914664, val_loss: 0.529613995552063\n",
      "4470, train_loss: 0.5498569940145199, val_loss: 0.538009524345398\n",
      "4471, train_loss: 0.5505195397597092, val_loss: 0.5459566831588745\n",
      "4472, train_loss: 0.5537164406134532, val_loss: 0.5401804506778717\n",
      "4473, train_loss: 0.550242373576531, val_loss: 0.5426218569278717\n",
      "4474, train_loss: 0.5536853900322547, val_loss: 0.5583062887191772\n",
      "4475, train_loss: 0.5536692623908703, val_loss: 0.5407383143901825\n",
      "4476, train_loss: 0.5513955561014322, val_loss: 0.5380373060703277\n",
      "4477, train_loss: 0.5535783928174239, val_loss: 0.5396464109420777\n",
      "4478, train_loss: 0.5498691384608929, val_loss: 0.541405189037323\n",
      "4479, train_loss: 0.551579298881384, val_loss: 0.5349661350250244\n",
      "4480, train_loss: 0.5521577459115249, val_loss: 0.5459887981414795\n",
      "4481, train_loss: 0.553427598797358, val_loss: 0.5282433748245239\n",
      "4482, train_loss: 0.5533497333526611, val_loss: 0.5398670315742493\n",
      "4483, train_loss: 0.5503032310650899, val_loss: 0.5493605613708497\n",
      "4484, train_loss: 0.5506885934334534, val_loss: 0.523347806930542\n",
      "4485, train_loss: 0.5533113548388848, val_loss: 0.5379800438880921\n",
      "4486, train_loss: 0.5531997520190018, val_loss: 0.5577332258224488\n",
      "4487, train_loss: 0.5499152392148972, val_loss: 0.5412229120731353\n",
      "4488, train_loss: 0.5493794599404702, val_loss: 0.5442286133766174\n",
      "4489, train_loss: 0.553134214419585, val_loss: 0.5571955859661102\n",
      "4490, train_loss: 0.549219623208046, val_loss: 0.528033459186554\n",
      "4491, train_loss: 0.5510922635977085, val_loss: 0.5483196794986724\n",
      "4492, train_loss: 0.5508582122050799, val_loss: 0.5471795320510864\n",
      "4493, train_loss: 0.5529394677052131, val_loss: 0.54485182762146\n",
      "4494, train_loss: 0.5529385621731098, val_loss: 0.5358925282955169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4495, train_loss: 0.5527796940161631, val_loss: 0.552490496635437\n",
      "4496, train_loss: 0.552796449798804, val_loss: 0.5553808987140656\n",
      "4497, train_loss: 0.5527639698523742, val_loss: 0.5371273100376129\n",
      "4498, train_loss: 0.5527542783663824, val_loss: 0.5397009015083313\n",
      "4499, train_loss: 0.5485184800166351, val_loss: 0.5317368149757385\n",
      "4500, train_loss: 0.5516725090833811, val_loss: 0.5483035743236542\n",
      "4501, train_loss: 0.5488713727547572, val_loss: 0.5369976162910461\n",
      "4502, train_loss: 0.5493733871441621, val_loss: 0.5482097864151001\n",
      "4503, train_loss: 0.5525567485735967, val_loss: 0.534530621767044\n",
      "4504, train_loss: 0.5525217537696545, val_loss: 0.5467110097408294\n",
      "4505, train_loss: 0.5519135789229319, val_loss: 0.5406024932861329\n",
      "4506, train_loss: 0.5506289784724896, val_loss: 0.5299242019653321\n",
      "4507, train_loss: 0.5486829005754911, val_loss: 0.5232816934585571\n",
      "4508, train_loss: 0.5523965163872793, val_loss: 0.539422333240509\n",
      "4509, train_loss: 0.5523260946457202, val_loss: 0.5366100370883942\n",
      "4510, train_loss: 0.5503668360985242, val_loss: 0.5358483195304871\n",
      "4511, train_loss: 0.5509350838569494, val_loss: 0.5301282107830048\n",
      "4512, train_loss: 0.5487359040058576, val_loss: 0.5231635332107544\n",
      "4513, train_loss: 0.552193705852215, val_loss: 0.5360950291156769\n",
      "4514, train_loss: 0.5486428198906091, val_loss: 0.5567156076431274\n",
      "4515, train_loss: 0.5521086225142846, val_loss: 0.528257018327713\n",
      "4516, train_loss: 0.5501166582107544, val_loss: 0.5363103032112122\n",
      "4517, train_loss: 0.5505143587405865, val_loss: 0.5467307567596436\n",
      "4518, train_loss: 0.548504636837886, val_loss: 0.5544795632362366\n",
      "4519, train_loss: 0.5519018849501243, val_loss: 0.545104694366455\n",
      "4520, train_loss: 0.5519163253215643, val_loss: 0.5384662270545959\n",
      "4521, train_loss: 0.5471810469260583, val_loss: 0.534604287147522\n",
      "4522, train_loss: 0.5486011573901544, val_loss: 0.5438029527664184\n",
      "4523, train_loss: 0.550917427127178, val_loss: 0.5565749645233155\n",
      "4524, train_loss: 0.5479946996156986, val_loss: 0.5561097383499145\n",
      "4525, train_loss: 0.547970705307447, val_loss: 0.5296331942081451\n",
      "4526, train_loss: 0.5482736378908157, val_loss: 0.5329335629940033\n",
      "4527, train_loss: 0.5516502731121503, val_loss: 0.5372777819633484\n",
      "4528, train_loss: 0.5493802107297457, val_loss: 0.5559975743293762\n",
      "4529, train_loss: 0.5500653833150864, val_loss: 0.5357684254646301\n",
      "4530, train_loss: 0.551520980321444, val_loss: 0.5268741488456726\n",
      "4531, train_loss: 0.5500678614928172, val_loss: 0.5373555719852448\n",
      "4532, train_loss: 0.551417643061051, val_loss: 0.5460511088371277\n",
      "4533, train_loss: 0.5513760069241891, val_loss: 0.5370273232460022\n",
      "4534, train_loss: 0.5486364708496974, val_loss: 0.5478885173797607\n",
      "4535, train_loss: 0.5512480346056131, val_loss: 0.5478013038635254\n",
      "4536, train_loss: 0.551197289274289, val_loss: 0.5270432829856873\n",
      "4537, train_loss: 0.5511713211353009, val_loss: 0.5562924385070801\n",
      "4538, train_loss: 0.5498093171761587, val_loss: 0.5412628829479218\n",
      "4539, train_loss: 0.5511371481877106, val_loss: 0.547774875164032\n",
      "4540, train_loss: 0.5472724323089306, val_loss: 0.5539971351623535\n",
      "4541, train_loss: 0.5487198474315497, val_loss: 0.5458540678024292\n",
      "4542, train_loss: 0.5494179106675662, val_loss: 0.5564289093017578\n",
      "4543, train_loss: 0.5509082835454208, val_loss: 0.5342941641807556\n",
      "4544, train_loss: 0.5508338751701208, val_loss: 0.5345640122890473\n",
      "4545, train_loss: 0.5508055159678826, val_loss: 0.5366439461708069\n",
      "4546, train_loss: 0.547558069229126, val_loss: 0.5244004964828491\n",
      "4547, train_loss: 0.5488577336072922, val_loss: 0.5541521549224854\n",
      "4548, train_loss: 0.5506666153669357, val_loss: 0.5342646062374115\n",
      "4549, train_loss: 0.5468386560678482, val_loss: 0.5408508658409119\n",
      "4550, train_loss: 0.5475692817798028, val_loss: 0.5317379474639893\n",
      "4551, train_loss: 0.5474023188535984, val_loss: 0.5252414643764496\n",
      "4552, train_loss: 0.5469622313976288, val_loss: 0.5386881113052369\n",
      "4553, train_loss: 0.5472871833122693, val_loss: 0.5468037843704223\n",
      "4554, train_loss: 0.5472006316368396, val_loss: 0.5401744186878205\n",
      "4555, train_loss: 0.5491782289284927, val_loss: 0.5430891513824463\n",
      "4556, train_loss: 0.5457198344744169, val_loss: 0.535199636220932\n",
      "4557, train_loss: 0.5483286690253478, val_loss: 0.5466852426528931\n",
      "4558, train_loss: 0.5469891933294443, val_loss: 0.5344816267490387\n",
      "4559, train_loss: 0.548247278882907, val_loss: 0.5292035460472106\n",
      "4560, train_loss: 0.5502061465611825, val_loss: 0.5278145253658295\n",
      "4561, train_loss: 0.5481654990177888, val_loss: 0.5457446336746216\n",
      "4562, train_loss: 0.550118048603718, val_loss: 0.5378195643424988\n",
      "4563, train_loss: 0.5468427928594443, val_loss: 0.5394403278827667\n",
      "4564, train_loss: 0.5460959982413512, val_loss: 0.5470554113388062\n",
      "4565, train_loss: 0.5500775243227298, val_loss: 0.5262753069400787\n",
      "4566, train_loss: 0.550029593018385, val_loss: 0.5329277396202088\n",
      "4567, train_loss: 0.5499437806697992, val_loss: 0.5375948190689087\n",
      "4568, train_loss: 0.5499103516340256, val_loss: 0.5376409411430358\n",
      "4569, train_loss: 0.5459299821120042, val_loss: 0.5356670916080475\n",
      "4570, train_loss: 0.5462613770594964, val_loss: 0.5278853595256805\n",
      "4571, train_loss: 0.5497815631903135, val_loss: 0.5389983654022217\n",
      "4572, train_loss: 0.5470409439160273, val_loss: 0.5396296620368958\n",
      "4573, train_loss: 0.5496749900854551, val_loss: 0.5556108891963959\n",
      "4574, train_loss: 0.5459297734957475, val_loss: 0.5335063099861145\n",
      "4575, train_loss: 0.5496444014402536, val_loss: 0.525102573633194\n",
      "4576, train_loss: 0.5479059471533849, val_loss: 0.5412166893482209\n",
      "4577, train_loss: 0.546287436897938, val_loss: 0.5448892474174499\n",
      "4578, train_loss: 0.5458827637709104, val_loss: 0.5416635751724244\n",
      "4579, train_loss: 0.5475760044959875, val_loss: 0.5369939088821412\n",
      "4580, train_loss: 0.5457190217880102, val_loss: 0.5280356526374816\n",
      "4581, train_loss: 0.5447401220981891, val_loss: 0.5550433158874511\n",
      "4582, train_loss: 0.5456718779527224, val_loss: 0.5266166567802429\n",
      "4583, train_loss: 0.547703491953703, val_loss: 0.5382762432098389\n",
      "4584, train_loss: 0.5493518056777807, val_loss: 0.5282446146011353\n",
      "4585, train_loss: 0.5459263175725937, val_loss: 0.5365809321403503\n",
      "4586, train_loss: 0.5492933507149036, val_loss: 0.523541784286499\n",
      "4587, train_loss: 0.5482109979941294, val_loss: 0.5285276770591736\n",
      "4588, train_loss: 0.5472159076195496, val_loss: 0.5327405810356141\n",
      "4589, train_loss: 0.549152637903507, val_loss: 0.5250031113624573\n",
      "4590, train_loss: 0.5481926684196179, val_loss: 0.5247285306453705\n",
      "4591, train_loss: 0.5463584306148382, val_loss: 0.5315615713596344\n",
      "4592, train_loss: 0.5476442311818783, val_loss: 0.5429595708847046\n",
      "4593, train_loss: 0.5456821551689734, val_loss: 0.5318502306938171\n",
      "4594, train_loss: 0.5456670362215775, val_loss: 0.5157768666744232\n",
      "4595, train_loss: 0.5450964501270881, val_loss: 0.5313747942447662\n",
      "4596, train_loss: 0.5489080685835618, val_loss: 0.5407067060470581\n",
      "4597, train_loss: 0.5469693128879254, val_loss: 0.5414135932922364\n",
      "4598, train_loss: 0.5474263464029019, val_loss: 0.5289932131767273\n",
      "4599, train_loss: 0.5487717963182009, val_loss: 0.5544199585914612\n",
      "4600, train_loss: 0.5451575001844993, val_loss: 0.5262766480445862\n",
      "4601, train_loss: 0.5486852274491236, val_loss: 0.5448095917701721\n",
      "4602, train_loss: 0.5471229897095606, val_loss: 0.5265482187271118\n",
      "4603, train_loss: 0.5479872593512902, val_loss: 0.5352145671844483\n",
      "4604, train_loss: 0.54652562049719, val_loss: 0.5381278038024903\n",
      "4605, train_loss: 0.5485617541349851, val_loss: 0.5302931308746338\n",
      "4606, train_loss: 0.5447306724695059, val_loss: 0.5340495705604553\n",
      "4607, train_loss: 0.5461092407886798, val_loss: 0.5264320373535156\n",
      "4608, train_loss: 0.5484027862548828, val_loss: 0.5541971862316132\n",
      "4609, train_loss: 0.5448698137815182, val_loss: 0.5303302049636841\n",
      "4610, train_loss: 0.5483307185081335, val_loss: 0.5383153438568116\n",
      "4611, train_loss: 0.5483283194211813, val_loss: 0.5485955357551575\n",
      "4612, train_loss: 0.545069966178674, val_loss: 0.5332919001579285\n",
      "4613, train_loss: 0.5467212074078046, val_loss: 0.5291330635547637\n",
      "4614, train_loss: 0.5441040167441735, val_loss: 0.5449860036373139\n",
      "4615, train_loss: 0.544899162191611, val_loss: 0.5280278563499451\n",
      "4616, train_loss: 0.5481422050641134, val_loss: 0.5399172306060791\n",
      "4617, train_loss: 0.5465285388322977, val_loss: 0.5371425151824951\n",
      "4618, train_loss: 0.5440758375021127, val_loss: 0.5369669914245605\n",
      "4619, train_loss: 0.5442385650598086, val_loss: 0.5510670483112335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4620, train_loss: 0.5445707107965763, val_loss: 0.5226156413555145\n",
      "4621, train_loss: 0.5433796621285952, val_loss: 0.5401949346065521\n",
      "4622, train_loss: 0.547951354430272, val_loss: 0.5365962505340576\n",
      "4623, train_loss: 0.5445814224389883, val_loss: 0.5532918393611908\n",
      "4624, train_loss: 0.5463100087184173, val_loss: 0.5287091255187988\n",
      "4625, train_loss: 0.5443245195425473, val_loss: 0.5413758158683777\n",
      "4626, train_loss: 0.5468897383946639, val_loss: 0.5311283767223358\n",
      "4627, train_loss: 0.5439855674138436, val_loss: 0.518567168712616\n",
      "4628, train_loss: 0.5453839634473507, val_loss: 0.5254029750823974\n",
      "4629, train_loss: 0.5463636230963927, val_loss: 0.5342179477214813\n",
      "4630, train_loss: 0.5463431580708578, val_loss: 0.550858736038208\n",
      "4631, train_loss: 0.5475535816871203, val_loss: 0.5365636706352234\n",
      "4632, train_loss: 0.5475610804099303, val_loss: 0.5330003440380097\n",
      "4633, train_loss: 0.5474946441558691, val_loss: 0.5300486981868744\n",
      "4634, train_loss: 0.5439341148504844, val_loss: 0.547720068693161\n",
      "4635, train_loss: 0.5474818486433762, val_loss: 0.5329266726970673\n",
      "4636, train_loss: 0.5474017331233392, val_loss: 0.5392719507217407\n",
      "4637, train_loss: 0.5457275899556967, val_loss: 0.5336080312728881\n",
      "4638, train_loss: 0.5452203865234668, val_loss: 0.5373145818710328\n",
      "4639, train_loss: 0.5472451322353803, val_loss: 0.543656837940216\n",
      "4640, train_loss: 0.5433264030860021, val_loss: 0.531833815574646\n",
      "4641, train_loss: 0.5430030478880956, val_loss: 0.5476020693778991\n",
      "4642, train_loss: 0.5471434283715028, val_loss: 0.5278104245662689\n",
      "4643, train_loss: 0.5432860931524863, val_loss: 0.5529903531074524\n",
      "4644, train_loss: 0.5468758298800542, val_loss: 0.5364479422569275\n",
      "4645, train_loss: 0.5470569844429309, val_loss: 0.5368970513343811\n",
      "4646, train_loss: 0.5470225111796305, val_loss: 0.5294926047325135\n",
      "4647, train_loss: 0.5436834314694772, val_loss: 0.5341587543487549\n",
      "4648, train_loss: 0.5469537067871827, val_loss: 0.5347706854343415\n",
      "4649, train_loss: 0.5453832504840997, val_loss: 0.5438511729240417\n",
      "4650, train_loss: 0.5468684079555365, val_loss: 0.5394281446933746\n",
      "4651, train_loss: 0.5468919747150861, val_loss: 0.5394556164741516\n",
      "4652, train_loss: 0.5468197969289926, val_loss: 0.5366656064987183\n",
      "4653, train_loss: 0.5467761835226645, val_loss: 0.542196762561798\n",
      "4654, train_loss: 0.5451202954237278, val_loss: 0.5394618272781372\n",
      "4655, train_loss: 0.5466685318029844, val_loss: 0.523025631904602\n",
      "4656, train_loss: 0.5466308651062158, val_loss: 0.5366617381572724\n",
      "4657, train_loss: 0.542884926383312, val_loss: 0.5224966645240784\n",
      "4658, train_loss: 0.5445346981287003, val_loss: 0.5345480799674988\n",
      "4659, train_loss: 0.5451687264900941, val_loss: 0.5389970779418946\n",
      "4660, train_loss: 0.5431879976621041, val_loss: 0.5434100151062011\n",
      "4661, train_loss: 0.5431853475478979, val_loss: 0.5403115689754486\n",
      "4662, train_loss: 0.5426390778559905, val_loss: 0.549774956703186\n",
      "4663, train_loss: 0.5464133024215698, val_loss: 0.5245909035205841\n",
      "4664, train_loss: 0.542521521449089, val_loss: 0.5127656519412994\n",
      "4665, train_loss: 0.5427101300312922, val_loss: 0.5195694625377655\n",
      "4666, train_loss: 0.5445995731995656, val_loss: 0.5519423604011535\n",
      "4667, train_loss: 0.5463347056737313, val_loss: 0.5249821305274963\n",
      "4668, train_loss: 0.5428685202048376, val_loss: 0.5337356746196746\n",
      "4669, train_loss: 0.5447619144733136, val_loss: 0.5427811026573182\n",
      "4670, train_loss: 0.5429826046411808, val_loss: 0.5216071546077728\n",
      "4671, train_loss: 0.5461684236159692, val_loss: 0.5234438657760621\n",
      "4672, train_loss: 0.5450704166522393, val_loss: 0.5234770119190216\n",
      "4673, train_loss: 0.5444334390071722, val_loss: 0.5117879211902618\n",
      "4674, train_loss: 0.5426729126618459, val_loss: 0.5299594700336456\n",
      "4675, train_loss: 0.546057267830922, val_loss: 0.5458779990673065\n",
      "4676, train_loss: 0.5446180552244186, val_loss: 0.5188924729824066\n",
      "4677, train_loss: 0.5459444431158212, val_loss: 0.5350407123565674\n",
      "4678, train_loss: 0.5415887649242694, val_loss: 0.5255854845046997\n",
      "4679, train_loss: 0.541992663190915, val_loss: 0.5513195335865021\n",
      "4680, train_loss: 0.5425263287929388, val_loss: 0.5283884227275848\n",
      "4681, train_loss: 0.5424867524550512, val_loss: 0.5199279069900513\n",
      "4682, train_loss: 0.545786874798628, val_loss: 0.5119969069957733\n",
      "4683, train_loss: 0.5444519817829132, val_loss: 0.5390114963054657\n",
      "4684, train_loss: 0.5421625157961478, val_loss: 0.5162701368331909\n",
      "4685, train_loss: 0.545721451823528, val_loss: 0.5483921349048615\n",
      "4686, train_loss: 0.5456852053220456, val_loss: 0.5369031131267548\n",
      "4687, train_loss: 0.541708855674817, val_loss: 0.5165536165237427\n",
      "4688, train_loss: 0.5456301661638113, val_loss: 0.5412613749504089\n",
      "4689, train_loss: 0.5420627937867091, val_loss: 0.5368354439735412\n",
      "4690, train_loss: 0.5455645620822906, val_loss: 0.5291119575500488\n",
      "4691, train_loss: 0.5406674536374899, val_loss: 0.5176288485527039\n",
      "4692, train_loss: 0.5454544000900708, val_loss: 0.5336874485015869\n",
      "4693, train_loss: 0.5430516508909372, val_loss: 0.5355947136878967\n",
      "4694, train_loss: 0.5453597330130063, val_loss: 0.5316265642642974\n",
      "4695, train_loss: 0.5453900259274703, val_loss: 0.5505994439125061\n",
      "4696, train_loss: 0.5412317502957124, val_loss: 0.5301415681838989\n",
      "4697, train_loss: 0.541210610132951, val_loss: 0.5409046530723571\n",
      "4698, train_loss: 0.5433380982050529, val_loss: 0.5314915895462036\n",
      "4699, train_loss: 0.5431373566389084, val_loss: 0.5304826617240905\n",
      "4700, train_loss: 0.5403354167938232, val_loss: 0.5396574914455414\n",
      "4701, train_loss: 0.5412927671120717, val_loss: 0.5504649043083191\n",
      "4702, train_loss: 0.5428330439787644, val_loss: 0.532289731502533\n",
      "4703, train_loss: 0.5406868629730665, val_loss: 0.5243826985359192\n",
      "4704, train_loss: 0.5450677963403555, val_loss: 0.5502058506011963\n",
      "4705, train_loss: 0.5449903756380081, val_loss: 0.5369276642799378\n",
      "4706, train_loss: 0.5430177106307104, val_loss: 0.531574034690857\n",
      "4707, train_loss: 0.5415582725634942, val_loss: 0.5411877691745758\n",
      "4708, train_loss: 0.5414096942314734, val_loss: 0.5193550705909729\n",
      "4709, train_loss: 0.5413873699995188, val_loss: 0.5378356277942657\n",
      "4710, train_loss: 0.5448506336945754, val_loss: 0.5288260221481323\n",
      "4711, train_loss: 0.5427085298758286, val_loss: 0.523259699344635\n",
      "4712, train_loss: 0.5447193040297582, val_loss: 0.5366572558879852\n",
      "4713, train_loss: 0.54470338844336, val_loss: 0.533725893497467\n",
      "4714, train_loss: 0.543336061330942, val_loss: 0.5269858539104462\n",
      "4715, train_loss: 0.5404917884331483, val_loss: 0.5499692797660828\n",
      "4716, train_loss: 0.5443432147686298, val_loss: 0.5338340163230896\n",
      "4717, train_loss: 0.5410323418103732, val_loss: 0.5499182939529419\n",
      "4718, train_loss: 0.5403864108599149, val_loss: 0.5401730060577392\n",
      "4719, train_loss: 0.5416806993576196, val_loss: 0.5286651909351349\n",
      "4720, train_loss: 0.5431287689850881, val_loss: 0.5392796397209167\n",
      "4721, train_loss: 0.5444128398711865, val_loss: 0.5203015327453613\n",
      "4722, train_loss: 0.5434161459024136, val_loss: 0.5401906132698059\n",
      "4723, train_loss: 0.5425728421944839, val_loss: 0.5394093871116639\n",
      "4724, train_loss: 0.5442410466762689, val_loss: 0.5139997839927674\n",
      "4725, train_loss: 0.5442624355737979, val_loss: 0.5471987903118134\n",
      "4726, train_loss: 0.5413968219206884, val_loss: 0.509601604938507\n",
      "4727, train_loss: 0.5424610330508306, val_loss: 0.5332653641700744\n",
      "4728, train_loss: 0.5394370487103095, val_loss: 0.5254284858703613\n",
      "4729, train_loss: 0.5407396463247446, val_loss: 0.5496747434139252\n",
      "4730, train_loss: 0.5423428725737792, val_loss: 0.5293945431709289\n",
      "4731, train_loss: 0.543983681843831, val_loss: 0.5306421399116517\n",
      "4732, train_loss: 0.5399812104610296, val_loss: 0.5283374667167664\n",
      "4733, train_loss: 0.5439498722553253, val_loss: 0.5124051332473755\n",
      "4734, train_loss: 0.5405561029911041, val_loss: 0.5382318019866943\n",
      "4735, train_loss: 0.5406262748516523, val_loss: 0.5267155706882477\n",
      "4736, train_loss: 0.5417596445633814, val_loss: 0.5491999745368957\n",
      "4737, train_loss: 0.5438374349704156, val_loss: 0.5254206895828247\n",
      "4738, train_loss: 0.543758090872031, val_loss: 0.5300533771514893\n",
      "4739, train_loss: 0.543775465625983, val_loss: 0.5247954189777374\n",
      "4740, train_loss: 0.5393266207896746, val_loss: 0.5465389728546143\n",
      "4741, train_loss: 0.5415668407311807, val_loss: 0.5358261883258819\n",
      "4742, train_loss: 0.538777585213001, val_loss: 0.5303163409233094\n",
      "4743, train_loss: 0.5436022499432931, val_loss: 0.5297779262065887\n",
      "4744, train_loss: 0.539954233628053, val_loss: 0.5184335291385651\n",
      "4745, train_loss: 0.5435761832273923, val_loss: 0.5354644775390625\n",
      "4746, train_loss: 0.5411306825967935, val_loss: 0.5300913393497467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4747, train_loss: 0.5435211681402646, val_loss: 0.5249600887298584\n",
      "4748, train_loss: 0.5392542022925156, val_loss: 0.5325270175933838\n",
      "4749, train_loss: 0.5434232732424369, val_loss: 0.5339905738830566\n",
      "4750, train_loss: 0.5433510289742396, val_loss: 0.548772644996643\n",
      "4751, train_loss: 0.5433483605201428, val_loss: 0.5173445761203765\n",
      "4752, train_loss: 0.5432666884018824, val_loss: 0.5273482441902161\n",
      "4753, train_loss: 0.5423420472786977, val_loss: 0.539653193950653\n",
      "4754, train_loss: 0.5398835161557565, val_loss: 0.5338638365268707\n",
      "4755, train_loss: 0.5393214970827103, val_loss: 0.5261309683322907\n",
      "4756, train_loss: 0.5392704468507034, val_loss: 0.5217714190483094\n",
      "4757, train_loss: 0.5413694588037637, val_loss: 0.5201439261436462\n",
      "4758, train_loss: 0.5430402343089764, val_loss: 0.5219889223575592\n",
      "4759, train_loss: 0.5388626834520927, val_loss: 0.5351593494415283\n",
      "4760, train_loss: 0.5388447298453405, val_loss: 0.5272211492061615\n",
      "4761, train_loss: 0.5415636851237371, val_loss: 0.5159625470638275\n",
      "4762, train_loss: 0.5382215678691864, val_loss: 0.5184395670890808\n",
      "4763, train_loss: 0.5404744239953848, val_loss: 0.537301504611969\n",
      "4764, train_loss: 0.5415225842824349, val_loss: 0.5377874493598938\n",
      "4765, train_loss: 0.5418108804867818, val_loss: 0.5342939853668213\n",
      "4766, train_loss: 0.5427585461964974, val_loss: 0.5275764465332031\n",
      "4767, train_loss: 0.541120796249463, val_loss: 0.5281341910362244\n",
      "4768, train_loss: 0.5426361411809921, val_loss: 0.5352255702018738\n",
      "4769, train_loss: 0.5426065726922109, val_loss: 0.5281636893749238\n",
      "4770, train_loss: 0.5392191925874124, val_loss: 0.5389553129673004\n",
      "4771, train_loss: 0.539136324937527, val_loss: 0.5245560824871063\n",
      "4772, train_loss: 0.5401047514035151, val_loss: 0.5220691084861755\n",
      "4773, train_loss: 0.5423817829443858, val_loss: 0.5116132438182831\n",
      "4774, train_loss: 0.538925636273164, val_loss: 0.53600315451622\n",
      "4775, train_loss: 0.5423463537142827, val_loss: 0.5317738592624665\n",
      "4776, train_loss: 0.5382185165698712, val_loss: 0.5286039710044861\n",
      "4777, train_loss: 0.5411311537027359, val_loss: 0.5295211732387543\n",
      "4778, train_loss: 0.540135165819755, val_loss: 0.5429915845394134\n",
      "4779, train_loss: 0.5387064092434369, val_loss: 0.5488520443439484\n",
      "4780, train_loss: 0.5421437036532623, val_loss: 0.5318155646324157\n",
      "4781, train_loss: 0.5396364617806214, val_loss: 0.5217738568782806\n",
      "4782, train_loss: 0.538598344876216, val_loss: 0.5175292074680329\n",
      "4783, train_loss: 0.5420173142965024, val_loss: 0.5485592007637023\n",
      "4784, train_loss: 0.5383164424162644, val_loss: 0.5484251022338867\n",
      "4785, train_loss: 0.542016863822937, val_loss: 0.5171848714351654\n",
      "4786, train_loss: 0.5378352071230228, val_loss: 0.5277442216873169\n",
      "4787, train_loss: 0.5419218689203262, val_loss: 0.5390881657600403\n",
      "4788, train_loss: 0.5418876936802497, val_loss: 0.5424786865711212\n",
      "4789, train_loss: 0.538396037541903, val_loss: 0.515563839673996\n",
      "4790, train_loss: 0.5401451988862112, val_loss: 0.5136724710464478\n",
      "4791, train_loss: 0.5386642515659332, val_loss: 0.5186445713043213\n",
      "4792, train_loss: 0.5417396563750047, val_loss: 0.5344508111476898\n",
      "4793, train_loss: 0.5377982212946966, val_loss: 0.5152880191802979\n",
      "4794, train_loss: 0.5415074011454215, val_loss: 0.5291022300720215\n",
      "4795, train_loss: 0.5416809549698463, val_loss: 0.5183642268180847\n",
      "4796, train_loss: 0.5383314547630457, val_loss: 0.526629775762558\n",
      "4797, train_loss: 0.5416228496111356, val_loss: 0.5378739893436432\n",
      "4798, train_loss: 0.5415479093790054, val_loss: 0.5151536583900451\n",
      "4799, train_loss: 0.5404168103749936, val_loss: 0.5215242981910706\n",
      "4800, train_loss: 0.5393597575334402, val_loss: 0.5272813022136689\n",
      "4801, train_loss: 0.5377981181328113, val_loss: 0.5478155493736268\n",
      "4802, train_loss: 0.5377849672849362, val_loss: 0.5214545726776123\n",
      "4803, train_loss: 0.5374762060550543, val_loss: 0.5225091278553009\n",
      "4804, train_loss: 0.5413313427796731, val_loss: 0.5162269532680511\n",
      "4805, train_loss: 0.5406022037451084, val_loss: 0.5417616724967956\n",
      "4806, train_loss: 0.5378992293889706, val_loss: 0.5178071975708007\n",
      "4807, train_loss: 0.5369581465537732, val_loss: 0.5375331401824951\n",
      "4808, train_loss: 0.5412686994442573, val_loss: 0.5117499172687531\n",
      "4809, train_loss: 0.5411736300358405, val_loss: 0.5168624341487884\n",
      "4810, train_loss: 0.5387164170925434, val_loss: 0.5243724286556244\n",
      "4811, train_loss: 0.5361854640337137, val_loss: 0.5473668277263641\n",
      "4812, train_loss: 0.5367366247452222, val_loss: 0.5327616453170776\n",
      "4813, train_loss: 0.5371498018503189, val_loss: 0.5344240427017212\n",
      "4814, train_loss: 0.5410191347965827, val_loss: 0.5193195164203643\n",
      "4815, train_loss: 0.5370466422576171, val_loss: 0.5238803386688232\n",
      "4816, train_loss: 0.54096053311458, val_loss: 0.5258866608142853\n",
      "4817, train_loss: 0.538399318089852, val_loss: 0.5414705276489258\n",
      "4818, train_loss: 0.5387953462509009, val_loss: 0.5222151517868042\n",
      "4819, train_loss: 0.5407835634855124, val_loss: 0.54443399310112\n",
      "4820, train_loss: 0.5373240445668881, val_loss: 0.518311494588852\n",
      "4821, train_loss: 0.5397003017939054, val_loss: 0.5280084192752839\n",
      "4822, train_loss: 0.5389669652168567, val_loss: 0.52346431016922\n",
      "4823, train_loss: 0.5382393965354333, val_loss: 0.5373042166233063\n",
      "4824, train_loss: 0.5376687943935394, val_loss: 0.5261766016483307\n",
      "4825, train_loss: 0.5405375349980134, val_loss: 0.5222116231918335\n",
      "4826, train_loss: 0.5405038320101224, val_loss: 0.5472868204116821\n",
      "4827, train_loss: 0.5379805668042257, val_loss: 0.5176023662090301\n",
      "4828, train_loss: 0.5365262868312689, val_loss: 0.5283030152320862\n",
      "4829, train_loss: 0.5390322311566427, val_loss: 0.5346190333366394\n",
      "4830, train_loss: 0.5364643908463992, val_loss: 0.5286654949188232\n",
      "4831, train_loss: 0.5403612840634126, val_loss: 0.5185504019260406\n",
      "4832, train_loss: 0.5381680211195579, val_loss: 0.5368788182735443\n",
      "4833, train_loss: 0.5380980338041599, val_loss: 0.5190295934677124\n",
      "4834, train_loss: 0.5401962640193793, val_loss: 0.5197051346302033\n",
      "4835, train_loss: 0.5402219157952529, val_loss: 0.5275133848190308\n",
      "4836, train_loss: 0.5379852744249197, val_loss: 0.5412279844284058\n",
      "4837, train_loss: 0.5389261234265107, val_loss: 0.5094909548759461\n",
      "4838, train_loss: 0.537891570192117, val_loss: 0.5361376106739044\n",
      "4839, train_loss: 0.5359046482122861, val_loss: 0.5280908882617951\n",
      "4840, train_loss: 0.5378544296209629, val_loss: 0.5275619029998779\n",
      "4841, train_loss: 0.5366090123470013, val_loss: 0.5159184455871582\n",
      "4842, train_loss: 0.5377625421835825, val_loss: 0.5253931164741517\n",
      "4843, train_loss: 0.5364008385401505, val_loss: 0.5276164293289185\n",
      "4844, train_loss: 0.5399510058072897, val_loss: 0.5080715119838715\n",
      "4845, train_loss: 0.5378947510169103, val_loss: 0.5124292492866516\n",
      "4846, train_loss: 0.5398632746476394, val_loss: 0.533782160282135\n",
      "4847, train_loss: 0.5398293607510053, val_loss: 0.5216940402984619\n",
      "4848, train_loss: 0.5383386864111974, val_loss: 0.5435501098632812\n",
      "4849, train_loss: 0.5362300838415439, val_loss: 0.5155401885509491\n",
      "4850, train_loss: 0.5396679181319016, val_loss: 0.5145064353942871\n",
      "4851, train_loss: 0.5378754746455413, val_loss: 0.5165486216545105\n",
      "4852, train_loss: 0.5360229932344877, val_loss: 0.5175243973731994\n",
      "4853, train_loss: 0.5395813905275785, val_loss: 0.5247346580028533\n",
      "4854, train_loss: 0.53805872797966, val_loss: 0.5353619813919067\n",
      "4855, train_loss: 0.5361261780445392, val_loss: 0.521307396888733\n",
      "4856, train_loss: 0.5354288954001206, val_loss: 0.5267896294593811\n",
      "4857, train_loss: 0.5354054421186447, val_loss: 0.5286247730255127\n",
      "4858, train_loss: 0.5355809044379455, val_loss: 0.5275647044181824\n",
      "4859, train_loss: 0.5373196842578741, val_loss: 0.5265361964702606\n",
      "4860, train_loss: 0.539392848427479, val_loss: 0.5141583800315856\n",
      "4861, train_loss: 0.5354314847634389, val_loss: 0.5311551511287689\n",
      "4862, train_loss: 0.5358912176810778, val_loss: 0.5397903263568878\n",
      "4863, train_loss: 0.5375506866436738, val_loss: 0.5147455871105194\n",
      "4864, train_loss: 0.5375931217120244, val_loss: 0.5348110198974609\n",
      "4865, train_loss: 0.5392089474659699, val_loss: 0.5286473631858826\n",
      "4866, train_loss: 0.5391707385961826, val_loss: 0.5355346739292145\n",
      "4867, train_loss: 0.5391088678286626, val_loss: 0.5311397194862366\n",
      "4868, train_loss: 0.5390918736274426, val_loss: 0.5311074018478393\n",
      "4869, train_loss: 0.5373820490561999, val_loss: 0.54577716588974\n",
      "4870, train_loss: 0.5373119173141626, val_loss: 0.5148009121417999\n",
      "4871, train_loss: 0.5389842689037323, val_loss: 0.5212855041027069\n",
      "4872, train_loss: 0.5389457723269095, val_loss: 0.5101062715053558\n",
      "4873, train_loss: 0.5349605679512024, val_loss: 0.5188453197479248\n",
      "4874, train_loss: 0.5389361163744559, val_loss: 0.5328425705432892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4875, train_loss: 0.5347941919015005, val_loss: 0.51230309009552\n",
      "4876, train_loss: 0.53496608711206, val_loss: 0.5351432085037231\n",
      "4877, train_loss: 0.5347193869260641, val_loss: 0.5288766920566559\n",
      "4878, train_loss: 0.5388019245404464, val_loss: 0.5095442533493042\n",
      "4879, train_loss: 0.5387848317623138, val_loss: 0.5235491394996643\n",
      "4880, train_loss: 0.538744262777842, val_loss: 0.5348463177680969\n",
      "4881, train_loss: 0.5384854766038748, val_loss: 0.5233588814735413\n",
      "4882, train_loss: 0.5362317470403818, val_loss: 0.5284669876098633\n",
      "4883, train_loss: 0.5386470269698364, val_loss: 0.51144939661026\n",
      "4884, train_loss: 0.5346755843896133, val_loss: 0.526193380355835\n",
      "4885, train_loss: 0.5373724607320932, val_loss: 0.5092763185501099\n",
      "4886, train_loss: 0.5371152689823737, val_loss: 0.5335035681724548\n",
      "4887, train_loss: 0.534562274813652, val_loss: 0.5196698427200317\n",
      "4888, train_loss: 0.5350060302477616, val_loss: 0.5387585759162903\n",
      "4889, train_loss: 0.5372549994633748, val_loss: 0.5277614712715148\n",
      "4890, train_loss: 0.5349369496107101, val_loss: 0.5352632164955139\n",
      "4891, train_loss: 0.5384115462119763, val_loss: 0.5136874854564667\n",
      "4892, train_loss: 0.5361597537994385, val_loss: 0.5320631086826324\n",
      "4893, train_loss: 0.5360784989136916, val_loss: 0.5202835857868194\n",
      "4894, train_loss: 0.5360908668774825, val_loss: 0.5154415965080261\n",
      "4895, train_loss: 0.5381645296628659, val_loss: 0.5225363194942474\n",
      "4896, train_loss: 0.5370828027908618, val_loss: 0.5257516026496887\n",
      "4897, train_loss: 0.5380690957491214, val_loss: 0.5187607169151306\n",
      "4898, train_loss: 0.5336151810792776, val_loss: 0.5128780782222748\n",
      "4899, train_loss: 0.5332584449878106, val_loss: 0.5250935912132263\n",
      "4900, train_loss: 0.5373012480827478, val_loss: 0.5084972321987152\n",
      "4901, train_loss: 0.5344820286218936, val_loss: 0.5202061653137207\n",
      "4902, train_loss: 0.537977411196782, val_loss: 0.5342058002948761\n",
      "4903, train_loss: 0.537915988610341, val_loss: 0.5444589614868164\n",
      "4904, train_loss: 0.5364022896840022, val_loss: 0.5162321925163269\n",
      "4905, train_loss: 0.5354379862546921, val_loss: 0.5245171368122101\n",
      "4906, train_loss: 0.5338438416902835, val_loss: 0.5087645351886749\n",
      "4907, train_loss: 0.5338212870634519, val_loss: 0.5256851494312287\n",
      "4908, train_loss: 0.534404877286691, val_loss: 0.5163925468921662\n",
      "4909, train_loss: 0.5363188924697729, val_loss: 0.5441983342170715\n",
      "4910, train_loss: 0.5337225290445181, val_loss: 0.5274789869785309\n",
      "4911, train_loss: 0.5334477906043713, val_loss: 0.543867027759552\n",
      "4912, train_loss: 0.5377043313705004, val_loss: 0.5120118379592895\n",
      "4913, train_loss: 0.5339636390025799, val_loss: 0.5139403581619263\n",
      "4914, train_loss: 0.5351408490767846, val_loss: 0.5106564998626709\n",
      "4915, train_loss: 0.5375504871973624, val_loss: 0.5336190521717071\n",
      "4916, train_loss: 0.535310929784408, val_loss: 0.5267104625701904\n",
      "4917, train_loss: 0.5375080085717715, val_loss: 0.5221486985683441\n",
      "4918, train_loss: 0.534123896406247, val_loss: 0.5234536707401276\n",
      "4919, train_loss: 0.5357189052380048, val_loss: 0.5337212204933166\n",
      "4920, train_loss: 0.5373236789153173, val_loss: 0.5103083670139312\n",
      "4921, train_loss: 0.5373501181602478, val_loss: 0.5312474608421326\n",
      "4922, train_loss: 0.5372655643866613, val_loss: 0.5439792752265931\n",
      "4923, train_loss: 0.5328248979953619, val_loss: 0.5335694015026092\n",
      "4924, train_loss: 0.533772852558356, val_loss: 0.5219207167625427\n",
      "4925, train_loss: 0.5348148930531281, val_loss: 0.5214449286460876\n",
      "4926, train_loss: 0.5326320070486802, val_loss: 0.5437770426273346\n",
      "4927, train_loss: 0.537098744740853, val_loss: 0.5025833785533905\n",
      "4928, train_loss: 0.5363250477955892, val_loss: 0.5122177243232727\n",
      "4929, train_loss: 0.53239984695728, val_loss: 0.5293583750724793\n",
      "4930, train_loss: 0.5370189249515533, val_loss: 0.52336745262146\n",
      "4931, train_loss: 0.5347343419606869, val_loss: 0.5185401678085327\n",
      "4932, train_loss: 0.536959551847898, val_loss: 0.5129014015197754\n",
      "4933, train_loss: 0.5368788058941181, val_loss: 0.5046624839305878\n",
      "4934, train_loss: 0.5346757483023864, val_loss: 0.5333202719688416\n",
      "4935, train_loss: 0.5346150787977072, val_loss: 0.5128667175769805\n",
      "4936, train_loss: 0.5353197203232691, val_loss: 0.5295757591724396\n",
      "4937, train_loss: 0.5318914319460208, val_loss: 0.5030765533447266\n",
      "4938, train_loss: 0.5367416189267085, val_loss: 0.5121794044971466\n",
      "4939, train_loss: 0.5330361815599295, val_loss: 0.5260936617851257\n",
      "4940, train_loss: 0.5344871993248279, val_loss: 0.5145339965820312\n",
      "4941, train_loss: 0.5332319530156943, val_loss: 0.5180503010749817\n",
      "4942, train_loss: 0.5365735189272807, val_loss: 0.5165739238262177\n",
      "4943, train_loss: 0.5331345601723745, val_loss: 0.5317031919956208\n",
      "4944, train_loss: 0.5365179845919976, val_loss: 0.5260802388191224\n",
      "4945, train_loss: 0.532806484745099, val_loss: 0.5315957069396973\n",
      "4946, train_loss: 0.5364566078552833, val_loss: 0.5400584161281585\n",
      "4947, train_loss: 0.5330961736348959, val_loss: 0.530351173877716\n",
      "4948, train_loss: 0.5340678095817566, val_loss: 0.5432060360908508\n",
      "4949, train_loss: 0.5328002996169604, val_loss: 0.521239185333252\n",
      "4950, train_loss: 0.5341163885134917, val_loss: 0.5152882039546967\n",
      "4951, train_loss: 0.5322112773473446, val_loss: 0.5115496993064881\n",
      "4952, train_loss: 0.5345305089767163, val_loss: 0.5429999113082886\n",
      "4953, train_loss: 0.5325926622519126, val_loss: 0.5239710330963134\n",
      "4954, train_loss: 0.5361730719988163, val_loss: 0.5255853474140167\n",
      "4955, train_loss: 0.5361211414520557, val_loss: 0.5301993489265442\n",
      "4956, train_loss: 0.5360551682802347, val_loss: 0.5192871689796448\n",
      "4957, train_loss: 0.532484925710238, val_loss: 0.5238273620605469\n",
      "4958, train_loss: 0.5324030346595324, val_loss: 0.5138145506381988\n",
      "4959, train_loss: 0.5317690819501877, val_loss: 0.5325350284576416\n",
      "4960, train_loss: 0.5359949458103913, val_loss: 0.5324470162391662\n",
      "4961, train_loss: 0.5359347783602201, val_loss: 0.5428348839282989\n",
      "4962, train_loss: 0.5344431583697979, val_loss: 0.5256675720214844\n",
      "4963, train_loss: 0.5358593005400437, val_loss: 0.5209154546260834\n",
      "4964, train_loss: 0.5358321597942939, val_loss: 0.5197458386421203\n",
      "4965, train_loss: 0.5317897555919794, val_loss: 0.5057589054107666\n",
      "4966, train_loss: 0.534039413699737, val_loss: 0.5313378214836121\n",
      "4967, train_loss: 0.5323008344723628, val_loss: 0.5284023940563202\n",
      "4968, train_loss: 0.5319853149927579, val_loss: 0.5297142505645752\n",
      "4969, train_loss: 0.5356789827346802, val_loss: 0.510908716917038\n",
      "4970, train_loss: 0.5356224282429769, val_loss: 0.5425070345401763\n",
      "4971, train_loss: 0.5356512837685071, val_loss: 0.5140616834163666\n",
      "4972, train_loss: 0.5318320920834174, val_loss: 0.5094536364078521\n",
      "4973, train_loss: 0.5335140686768752, val_loss: 0.501053261756897\n",
      "4974, train_loss: 0.535529932150474, val_loss: 0.5112388730049133\n",
      "4975, train_loss: 0.5355029323926339, val_loss: 0.512461256980896\n",
      "4976, train_loss: 0.5354731713350003, val_loss: 0.5292393028736114\n",
      "4977, train_loss: 0.5354003275816257, val_loss: 0.5360090255737304\n",
      "4978, train_loss: 0.5354140687447327, val_loss: 0.5318024754524231\n",
      "4979, train_loss: 0.5313103405328897, val_loss: 0.5242834389209747\n",
      "4980, train_loss: 0.5353201352632962, val_loss: 0.5390974164009095\n",
      "4981, train_loss: 0.531237699664556, val_loss: 0.5142928779125213\n",
      "4982, train_loss: 0.5339955297800211, val_loss: 0.5423332154750824\n",
      "4983, train_loss: 0.5317851201846049, val_loss: 0.5256716787815094\n",
      "4984, train_loss: 0.5311848165897223, val_loss: 0.5270507156848907\n",
      "4985, train_loss: 0.5309144006325648, val_loss: 0.5065965771675109\n",
      "4986, train_loss: 0.5351934146422607, val_loss: 0.513507628440857\n",
      "4987, train_loss: 0.5350936559530405, val_loss: 0.5269378364086151\n",
      "4988, train_loss: 0.5307576346855897, val_loss: 0.5321494579315186\n",
      "4989, train_loss: 0.5350272678411924, val_loss: 0.5282434046268463\n",
      "4990, train_loss: 0.5313755995952166, val_loss: 0.5150910913944244\n",
      "4991, train_loss: 0.5327113098823107, val_loss: 0.5104976058006286\n",
      "4992, train_loss: 0.5312187809210557, val_loss: 0.5037398874759674\n",
      "4993, train_loss: 0.5305841095172442, val_loss: 0.5386489748954773\n",
      "4994, train_loss: 0.5325732299914727, val_loss: 0.5124822139739991\n",
      "4995, train_loss: 0.5348226072696539, val_loss: 0.5288867592811585\n",
      "4996, train_loss: 0.5329787272673386, val_loss: 0.523718786239624\n",
      "4997, train_loss: 0.53071739925788, val_loss: 0.5244880557060242\n",
      "4998, train_loss: 0.534617162667788, val_loss: 0.5158517479896545\n",
      "4999, train_loss: 0.5308842406823084, val_loss: 0.5127012372016907\n",
      "5000, train_loss: 0.5303192551319416, val_loss: 0.507103580236435\n",
      "5001, train_loss: 0.5345951662613795, val_loss: 0.5313116848468781\n",
      "5002, train_loss: 0.5323259624151083, val_loss: 0.5418976008892059\n",
      "5003, train_loss: 0.5344684341779122, val_loss: 0.5287505149841308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5004, train_loss: 0.5324057099910883, val_loss: 0.5200605630874634\n",
      "5005, train_loss: 0.5343823879957199, val_loss: 0.5227056860923767\n",
      "5006, train_loss: 0.5332563943587817, val_loss: 0.5101342976093293\n",
      "5007, train_loss: 0.5300818693179351, val_loss: 0.5147982716560364\n",
      "5008, train_loss: 0.5306584032682272, val_loss: 0.5086634933948517\n",
      "5009, train_loss: 0.5308265410936795, val_loss: 0.5219456195831299\n",
      "5010, train_loss: 0.530696798975651, val_loss: 0.5284037888050079\n",
      "5011, train_loss: 0.5324514554097102, val_loss: 0.5416624486446381\n",
      "5012, train_loss: 0.5294714054236045, val_loss: 0.5220245599746705\n",
      "5013, train_loss: 0.5319472356484487, val_loss: 0.5101521492004395\n",
      "5014, train_loss: 0.5302189118587054, val_loss: 0.5192975759506225\n",
      "5015, train_loss: 0.5341202628154021, val_loss: 0.5117821514606475\n",
      "5016, train_loss: 0.5323724586230058, val_loss: 0.5096578657627105\n",
      "5017, train_loss: 0.5324076081697757, val_loss: 0.5028030455112458\n",
      "5018, train_loss: 0.5295800371811941, val_loss: 0.5192184984683991\n",
      "5019, train_loss: 0.5339974336899244, val_loss: 0.5189884245395661\n",
      "5020, train_loss: 0.5322506060967078, val_loss: 0.5110018730163575\n",
      "5021, train_loss: 0.533938963825886, val_loss: 0.5314899384975433\n",
      "5022, train_loss: 0.5327964299000226, val_loss: 0.5348840475082397\n",
      "5023, train_loss: 0.5338276131795003, val_loss: 0.5154624581336975\n",
      "5024, train_loss: 0.5295149523478287, val_loss: 0.5086796939373016\n",
      "5025, train_loss: 0.5293512653846008, val_loss: 0.5179682314395905\n",
      "5026, train_loss: 0.5314954599508872, val_loss: 0.5153185784816742\n",
      "5027, train_loss: 0.5336643503262446, val_loss: 0.5186600148677826\n",
      "5028, train_loss: 0.5310243952732819, val_loss: 0.5140988409519196\n",
      "5029, train_loss: 0.5324177386669012, val_loss: 0.5314205884933472\n",
      "5030, train_loss: 0.5295164883136749, val_loss: 0.5240821719169617\n",
      "5031, train_loss: 0.5300707083482009, val_loss: 0.5378203570842743\n",
      "5032, train_loss: 0.5313744304271845, val_loss: 0.5234059929847718\n",
      "5033, train_loss: 0.5308659156927695, val_loss: 0.5260588943958282\n",
      "5034, train_loss: 0.5310570746660233, val_loss: 0.5113477945327759\n",
      "5035, train_loss: 0.5333536576766235, val_loss: 0.5215217769145966\n",
      "5036, train_loss: 0.5333294570446014, val_loss: 0.5041591823101044\n",
      "5037, train_loss: 0.5294035982627135, val_loss: 0.5080107867717742\n",
      "5038, train_loss: 0.5282024236825796, val_loss: 0.5235550284385682\n",
      "5039, train_loss: 0.5292884569901687, val_loss: 0.5342950046062469\n",
      "5040, train_loss: 0.5300621252793533, val_loss: 0.5012690901756287\n",
      "5041, train_loss: 0.5314037352800369, val_loss: 0.5299443244934082\n",
      "5042, train_loss: 0.5296374089442767, val_loss: 0.5220388829708099\n",
      "5043, train_loss: 0.5315662416128012, val_loss: 0.5185860514640808\n",
      "5044, train_loss: 0.5320036434210264, val_loss: 0.5018756926059723\n",
      "5045, train_loss: 0.5300844128315265, val_loss: 0.5404967784881591\n",
      "5046, train_loss: 0.5328556895256042, val_loss: 0.5234871625900268\n",
      "5047, train_loss: 0.5300083893996018, val_loss: 0.520998191833496\n",
      "5048, train_loss: 0.5290220116193478, val_loss: 0.5406566739082337\n",
      "5049, train_loss: 0.5288658623511975, val_loss: 0.5184462547302247\n",
      "5050, train_loss: 0.5292294541230569, val_loss: 0.5339675664901733\n",
      "5051, train_loss: 0.5329245099654565, val_loss: 0.5404296875\n",
      "5052, train_loss: 0.5313086567016748, val_loss: 0.5138382494449616\n",
      "5053, train_loss: 0.5296442245061581, val_loss: 0.5105857014656067\n",
      "5054, train_loss: 0.5288401601406244, val_loss: 0.5369704365730286\n",
      "5055, train_loss: 0.5325956528003399, val_loss: 0.5196762025356293\n",
      "5056, train_loss: 0.527977466583252, val_loss: 0.5096960425376892\n",
      "5057, train_loss: 0.5326861819395652, val_loss: 0.5059275925159454\n",
      "5058, train_loss: 0.5326998657905139, val_loss: 0.5076198697090148\n",
      "5059, train_loss: 0.531541510270192, val_loss: 0.5250017404556274\n",
      "5060, train_loss: 0.5285242669857465, val_loss: 0.5136978805065155\n",
      "5061, train_loss: 0.5280611652594346, val_loss: 0.5286428689956665\n",
      "5062, train_loss: 0.5307187094138219, val_loss: 0.5150461375713349\n",
      "5063, train_loss: 0.5288901649988614, val_loss: 0.525862193107605\n",
      "5064, train_loss: 0.5323936010782535, val_loss: 0.5170314311981201\n",
      "5065, train_loss: 0.5283814920828893, val_loss: 0.5061540961265564\n",
      "5066, train_loss: 0.5323875798628881, val_loss: 0.504542863368988\n",
      "5067, train_loss: 0.5281234647218997, val_loss: 0.5078431844711304\n",
      "5068, train_loss: 0.5305316815009484, val_loss: 0.5334758639335633\n",
      "5069, train_loss: 0.5304895066297971, val_loss: 0.5301067650318145\n",
      "5070, train_loss: 0.5320325172864474, val_loss: 0.5246056079864502\n",
      "5071, train_loss: 0.5319686669569749, val_loss: 0.522825288772583\n",
      "5072, train_loss: 0.5321908318079435, val_loss: 0.5292811572551728\n",
      "5073, train_loss: 0.529779219856629, val_loss: 0.5234800815582276\n",
      "5074, train_loss: 0.5312412427021906, val_loss: 0.5205520153045654\n",
      "5075, train_loss: 0.528397139448386, val_loss: 0.5152665913105011\n",
      "5076, train_loss: 0.5320420700770158, val_loss: 0.5365889012813568\n",
      "5077, train_loss: 0.5294695737270209, val_loss: 0.5028479337692261\n",
      "5078, train_loss: 0.5319560754757661, val_loss: 0.5078912019729614\n",
      "5079, train_loss: 0.5276398097093289, val_loss: 0.516468632221222\n",
      "5080, train_loss: 0.5295806595912347, val_loss: 0.5281283140182496\n",
      "5081, train_loss: 0.5282381887619312, val_loss: 0.5198092103004456\n",
      "5082, train_loss: 0.5318512068344996, val_loss: 0.5206455945968628\n",
      "5083, train_loss: 0.5278143229392859, val_loss: 0.5287715077400208\n",
      "5084, train_loss: 0.5277904409628648, val_loss: 0.5287704706192017\n",
      "5085, train_loss: 0.5300101144955709, val_loss: 0.5394905626773834\n",
      "5086, train_loss: 0.5297655726854618, val_loss: 0.5222653388977051\n",
      "5087, train_loss: 0.5295724089329059, val_loss: 0.5194557905197144\n",
      "5088, train_loss: 0.5316970462982471, val_loss: 0.5174991667270661\n",
      "5089, train_loss: 0.5290633279543656, val_loss: 0.5395022392272949\n",
      "5090, train_loss: 0.5268601752244509, val_loss: 0.5131192147731781\n",
      "5091, train_loss: 0.5315708506565827, val_loss: 0.5285953342914581\n",
      "5092, train_loss: 0.5277999421724906, val_loss: 0.5247726798057556\n",
      "5093, train_loss: 0.5314823916325202, val_loss: 0.5119228482246398\n",
      "5094, train_loss: 0.5314629146685967, val_loss: 0.522061550617218\n",
      "5095, train_loss: 0.5314190536737442, val_loss: 0.5359583258628845\n",
      "5096, train_loss: 0.5276098492053839, val_loss: 0.5293364286422729\n",
      "5097, train_loss: 0.5294616314081045, val_loss: 0.5394604325294494\n",
      "5098, train_loss: 0.5313286792773467, val_loss: 0.522141283750534\n",
      "5099, train_loss: 0.5297031929859748, val_loss: 0.5074024558067322\n",
      "5100, train_loss: 0.5293283221813349, val_loss: 0.5181740164756775\n",
      "5101, train_loss: 0.5311675816774368, val_loss: 0.5164240837097168\n",
      "5102, train_loss: 0.5309416984136288, val_loss: 0.5278093218803406\n",
      "5103, train_loss: 0.5269898325204849, val_loss: 0.5050521552562713\n",
      "5104, train_loss: 0.5274291027050751, val_loss: 0.5082958519458771\n",
      "5105, train_loss: 0.5280025933797543, val_loss: 0.512419444322586\n",
      "5106, train_loss: 0.53105129301548, val_loss: 0.5172322630882263\n",
      "5107, train_loss: 0.5291373638006357, val_loss: 0.49985954761505125\n",
      "5108, train_loss: 0.5309726985601279, val_loss: 0.517019534111023\n",
      "5109, train_loss: 0.5262032655569223, val_loss: 0.5255189180374146\n",
      "5110, train_loss: 0.5282672998996881, val_loss: 0.5202918410301208\n",
      "5111, train_loss: 0.5308558413615594, val_loss: 0.5164190292358398\n",
      "5112, train_loss: 0.5270310949820739, val_loss: 0.5074469566345214\n",
      "5113, train_loss: 0.5292155169523679, val_loss: 0.5390953600406647\n",
      "5114, train_loss: 0.5267160397309524, val_loss: 0.5134521126747131\n",
      "5115, train_loss: 0.5280842712292304, val_loss: 0.5200615286827087\n",
      "5116, train_loss: 0.5271506687769523, val_loss: 0.5187957048416137\n",
      "5117, train_loss: 0.528098559150329, val_loss: 0.5241572201251984\n",
      "5118, train_loss: 0.526448578788684, val_loss: 0.5240060031414032\n",
      "5119, train_loss: 0.5265474972816614, val_loss: 0.517560476064682\n",
      "5120, train_loss: 0.5293309344695165, val_loss: 0.5321607410907745\n",
      "5121, train_loss: 0.5305534727298297, val_loss: 0.5132520318031311\n",
      "5122, train_loss: 0.5305233173645459, val_loss: 0.5387872517108917\n",
      "5123, train_loss: 0.5264153182506561, val_loss: 0.49633421301841735\n",
      "5124, train_loss: 0.5281958190294412, val_loss: 0.5195959448814392\n",
      "5125, train_loss: 0.5304563813484632, val_loss: 0.5274755120277405\n",
      "5126, train_loss: 0.5264105166380222, val_loss: 0.5081794857978821\n",
      "5127, train_loss: 0.5282056366021817, val_loss: 0.5147906303405761\n",
      "5128, train_loss: 0.5281504255074722, val_loss: 0.5118568897247314\n",
      "5129, train_loss: 0.5303083108021662, val_loss: 0.5240585923194885\n",
      "5130, train_loss: 0.5276947136108692, val_loss: 0.5252249479293823\n",
      "5131, train_loss: 0.5285843530526528, val_loss: 0.5129687666893006\n",
      "5132, train_loss: 0.5282529856149967, val_loss: 0.5142434537410736\n",
      "5133, train_loss: 0.5301303416490555, val_loss: 0.5098148226737976\n",
      "5134, train_loss: 0.5300746170374063, val_loss: 0.5284796059131622\n",
      "5135, train_loss: 0.5300217660573813, val_loss: 0.5386997759342194\n",
      "5136, train_loss: 0.530003819328088, val_loss: 0.5166356086730957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5137, train_loss: 0.527981257209411, val_loss: 0.5153230428695679\n",
      "5138, train_loss: 0.5280548116335502, val_loss: 0.5165760695934296\n",
      "5139, train_loss: 0.5299133578172097, val_loss: 0.5237535834312439\n",
      "5140, train_loss: 0.5298772431336917, val_loss: 0.527666574716568\n",
      "5141, train_loss: 0.5298591737563794, val_loss: 0.5209045290946961\n",
      "5142, train_loss: 0.526336052096807, val_loss: 0.5076531231403351\n",
      "5143, train_loss: 0.5259392250042695, val_loss: 0.5276305973529816\n",
      "5144, train_loss: 0.5262662825676111, val_loss: 0.5151553213596344\n",
      "5145, train_loss: 0.5259243043569418, val_loss: 0.496256023645401\n",
      "5146, train_loss: 0.5297633420962554, val_loss: 0.5382480502128602\n",
      "5147, train_loss: 0.5257945908949926, val_loss: 0.5232895374298095\n",
      "5148, train_loss: 0.5280709793934455, val_loss: 0.503645795583725\n",
      "5149, train_loss: 0.5260820927528235, val_loss: 0.5114465117454529\n",
      "5150, train_loss: 0.525828446333225, val_loss: 0.5225958526134491\n",
      "5151, train_loss: 0.529586720925111, val_loss: 0.5381893217563629\n",
      "5152, train_loss: 0.5286722756349124, val_loss: 0.5009562611579895\n",
      "5153, train_loss: 0.5271147913657702, val_loss: 0.5061876535415649\n",
      "5154, train_loss: 0.525148209470969, val_loss: 0.5223124086856842\n",
      "5155, train_loss: 0.529422966333536, val_loss: 0.5163500308990479\n",
      "5156, train_loss: 0.5291908807479418, val_loss: 0.5097291171550751\n",
      "5157, train_loss: 0.525229240839298, val_loss: 0.5269049525260925\n",
      "5158, train_loss: 0.5255854886311752, val_loss: 0.5073209643363953\n",
      "5159, train_loss: 0.5292598501994059, val_loss: 0.5185933291912079\n",
      "5160, train_loss: 0.5292301441614444, val_loss: 0.526056706905365\n",
      "5161, train_loss: 0.5252137550940881, val_loss: 0.5230605959892273\n",
      "5162, train_loss: 0.528283396592507, val_loss: 0.515259325504303\n",
      "5163, train_loss: 0.5291437518138152, val_loss: 0.507679146528244\n",
      "5164, train_loss: 0.524939545072042, val_loss: 0.5039969325065613\n",
      "5165, train_loss: 0.5266923572008426, val_loss: 0.5156357169151307\n",
      "5166, train_loss: 0.5267992374988703, val_loss: 0.5259867310523987\n",
      "5167, train_loss: 0.5267767184055768, val_loss: 0.5101315140724182\n",
      "5168, train_loss: 0.5274177273878684, val_loss: 0.5078653991222382\n",
      "5169, train_loss: 0.5289168036901034, val_loss: 0.5275383412837982\n",
      "5170, train_loss: 0.5269814454592191, val_loss: 0.5229816675186157\n",
      "5171, train_loss: 0.5288467120665771, val_loss: 0.5012099981307984\n",
      "5172, train_loss: 0.5288104839049853, val_loss: 0.5241175591945648\n",
      "5173, train_loss: 0.5246416479349136, val_loss: 0.5219681441783905\n",
      "5174, train_loss: 0.5268736802614652, val_loss: 0.5340815722942353\n",
      "5175, train_loss: 0.5268548211226096, val_loss: 0.5178412318229675\n",
      "5176, train_loss: 0.5255689678283838, val_loss: 0.5220008492469788\n",
      "5177, train_loss: 0.5286473712095847, val_loss: 0.5063857913017273\n",
      "5178, train_loss: 0.528632898743336, val_loss: 0.5273023784160614\n",
      "5179, train_loss: 0.5261385842011526, val_loss: 0.5240308582782746\n",
      "5180, train_loss: 0.5285262385239968, val_loss: 0.5205025792121887\n",
      "5181, train_loss: 0.5249551030305716, val_loss: 0.5063971698284149\n",
      "5182, train_loss: 0.52853373839305, val_loss: 0.5255147218704224\n",
      "5183, train_loss: 0.5257739986364658, val_loss: 0.5064278066158294\n",
      "5184, train_loss: 0.5265356061550287, val_loss: 0.5265632033348083\n",
      "5185, train_loss: 0.528376688177769, val_loss: 0.5033664107322693\n",
      "5186, train_loss: 0.524282578092355, val_loss: 0.5264046788215637\n",
      "5187, train_loss: 0.5283516668356382, val_loss: 0.520130068063736\n",
      "5188, train_loss: 0.5283341396313447, val_loss: 0.5185721755027771\n",
      "5189, train_loss: 0.5255395162564057, val_loss: 0.5201958179473877\n",
      "5190, train_loss: 0.5246568368031428, val_loss: 0.5131356358528137\n",
      "5191, train_loss: 0.5262474291599714, val_loss: 0.5270490705966949\n",
      "5192, train_loss: 0.5257198145756354, val_loss: 0.5250982344150543\n",
      "5193, train_loss: 0.5235207802974261, val_loss: 0.5185075342655182\n",
      "5194, train_loss: 0.523942884344321, val_loss: 0.5262377500534058\n",
      "5195, train_loss: 0.5280433686879965, val_loss: 0.51244637966156\n",
      "5196, train_loss: 0.5280223683669016, val_loss: 0.5237163007259369\n",
      "5197, train_loss: 0.5262749458734806, val_loss: 0.512504768371582\n",
      "5198, train_loss: 0.5278894477165662, val_loss: 0.5250141561031342\n",
      "5199, train_loss: 0.5238239512993739, val_loss: 0.5119033217430115\n",
      "5200, train_loss: 0.5238485244604257, val_loss: 0.5064020454883575\n",
      "5201, train_loss: 0.5253871908554664, val_loss: 0.5186044335365295\n",
      "5202, train_loss: 0.5260521620512009, val_loss: 0.5110694468021393\n",
      "5203, train_loss: 0.5241567423710456, val_loss: 0.5063888490200043\n",
      "5204, train_loss: 0.5277267832022446, val_loss: 0.5216187477111817\n",
      "5205, train_loss: 0.5252394699133359, val_loss: 0.5070460498332977\n",
      "5206, train_loss: 0.5248803347349167, val_loss: 0.5137528836727142\n",
      "5207, train_loss: 0.5275559860926408, val_loss: 0.49589540958404543\n",
      "5208, train_loss: 0.5234884585325534, val_loss: 0.5184336185455323\n",
      "5209, train_loss: 0.5256565992648785, val_loss: 0.5373908996582031\n",
      "5210, train_loss: 0.5239594005621396, val_loss: 0.5259087264537812\n",
      "5211, train_loss: 0.527513427230028, val_loss: 0.5101561784744263\n",
      "5212, train_loss: 0.5239005180505606, val_loss: 0.5136482357978821\n",
      "5213, train_loss: 0.523831409903673, val_loss: 0.5371333718299866\n",
      "5214, train_loss: 0.5274673883731549, val_loss: 0.5060594558715821\n",
      "5215, train_loss: 0.5231316227179307, val_loss: 0.5208406150341034\n",
      "5216, train_loss: 0.5226381340852151, val_loss: 0.5133483946323395\n",
      "5217, train_loss: 0.5273708024850259, val_loss: 0.521693229675293\n",
      "5218, train_loss: 0.5229905946896627, val_loss: 0.5254465878009796\n",
      "5219, train_loss: 0.5273502125189855, val_loss: 0.5253886342048645\n",
      "5220, train_loss: 0.5234874143050268, val_loss: 0.5087756276130676\n",
      "5221, train_loss: 0.5253658546851232, val_loss: 0.5063000380992889\n",
      "5222, train_loss: 0.5230141339393762, val_loss: 0.5226552128791809\n",
      "5223, train_loss: 0.5251974027890426, val_loss: 0.5175032138824462\n",
      "5224, train_loss: 0.5233725573007877, val_loss: 0.5034180462360383\n",
      "5225, train_loss: 0.5237614546830838, val_loss: 0.5161088705062866\n",
      "5226, train_loss: 0.5250764179688233, val_loss: 0.5006373167037964\n",
      "5227, train_loss: 0.5270982155433068, val_loss: 0.5202695310115815\n",
      "5228, train_loss: 0.5246468610488452, val_loss: 0.5137947261333465\n",
      "5229, train_loss: 0.5247045858548238, val_loss: 0.5153517246246337\n",
      "5230, train_loss: 0.5234046303308927, val_loss: 0.499045604467392\n",
      "5231, train_loss: 0.5254003772368798, val_loss: 0.5089166700839997\n",
      "5232, train_loss: 0.5231596609720817, val_loss: 0.5122296154499054\n",
      "5233, train_loss: 0.5259762452198908, val_loss: 0.516483622789383\n",
      "5234, train_loss: 0.5244204321732888, val_loss: 0.516999113559723\n",
      "5235, train_loss: 0.5237338474163642, val_loss: 0.5360948622226716\n",
      "5236, train_loss: 0.5244715729585061, val_loss: 0.5050395965576172\n",
      "5237, train_loss: 0.5268105004842465, val_loss: 0.5193838536739349\n",
      "5238, train_loss: 0.5243179282316794, val_loss: 0.5252878844738007\n",
      "5239, train_loss: 0.5226193185035999, val_loss: 0.5162194073200226\n",
      "5240, train_loss: 0.5266935584636835, val_loss: 0.5094112277030944\n",
      "5241, train_loss: 0.5226200073957443, val_loss: 0.5198801219463348\n",
      "5242, train_loss: 0.5224594233127741, val_loss: 0.5236868381500244\n",
      "5243, train_loss: 0.5227409555361822, val_loss: 0.5197275936603546\n",
      "5244, train_loss: 0.5265617003807654, val_loss: 0.5020875334739685\n",
      "5245, train_loss: 0.5241400507780222, val_loss: 0.5005746185779572\n",
      "5246, train_loss: 0.5223292135275327, val_loss: 0.5182414293289185\n",
      "5247, train_loss: 0.5240770303286039, val_loss: 0.5243324995040893\n",
      "5248, train_loss: 0.5264340765201129, val_loss: 0.5065132558345795\n",
      "5249, train_loss: 0.5223282587069732, val_loss: 0.5154090523719788\n",
      "5250, train_loss: 0.5213865729478689, val_loss: 0.5090695321559906\n",
      "5251, train_loss: 0.5213863482842078, val_loss: 0.5163144946098328\n",
      "5252, train_loss: 0.5221985498299966, val_loss: 0.5141436398029328\n",
      "5253, train_loss: 0.52229454769538, val_loss: 0.51784947514534\n",
      "5254, train_loss: 0.5263228897865002, val_loss: 0.5057119011878968\n",
      "5255, train_loss: 0.5221816072097192, val_loss: 0.507698929309845\n",
      "5256, train_loss: 0.5239908339885565, val_loss: 0.5153775691986084\n",
      "5257, train_loss: 0.5261844064180667, val_loss: 0.5192170679569245\n",
      "5258, train_loss: 0.5237579334240693, val_loss: 0.5126397430896759\n",
      "5259, train_loss: 0.5261525557591364, val_loss: 0.5086991548538208\n",
      "5260, train_loss: 0.5228596925735474, val_loss: 0.5238731861114502\n",
      "5261, train_loss: 0.5216972415263836, val_loss: 0.5350748062133789\n",
      "5262, train_loss: 0.5241250304075388, val_loss: 0.5114357352256775\n",
      "5263, train_loss: 0.5240946194300284, val_loss: 0.508736652135849\n",
      "5264, train_loss: 0.5259439681585019, val_loss: 0.521133279800415\n",
      "5265, train_loss: 0.5259117231919215, val_loss: 0.51541166305542\n",
      "5266, train_loss: 0.5241781232448725, val_loss: 0.512595021724701\n",
      "5267, train_loss: 0.5231033540689028, val_loss: 0.49503902792930604\n",
      "5268, train_loss: 0.5216805843206552, val_loss: 0.4983234405517578\n",
      "5269, train_loss: 0.5258412544543927, val_loss: 0.5115791499614716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5270, train_loss: 0.5216468205818763, val_loss: 0.507933896780014\n",
      "5271, train_loss: 0.5257915625205407, val_loss: 0.5074329078197479\n",
      "5272, train_loss: 0.5247894995487653, val_loss: 0.5178802132606506\n",
      "5273, train_loss: 0.5215883587415402, val_loss: 0.507149589061737\n",
      "5274, train_loss: 0.5237985069935138, val_loss: 0.5233811736106873\n",
      "5275, train_loss: 0.5244655505968974, val_loss: 0.5038304269313812\n",
      "5276, train_loss: 0.5220232468384963, val_loss: 0.5186202764511109\n",
      "5277, train_loss: 0.5255997066314404, val_loss: 0.5072450459003448\n",
      "5278, train_loss: 0.521191234772022, val_loss: 0.5241073727607727\n",
      "5279, train_loss: 0.5219632662259616, val_loss: 0.5137042880058289\n",
      "5280, train_loss: 0.5254646860636197, val_loss: 0.5219619810581207\n",
      "5281, train_loss: 0.523501748075852, val_loss: 0.5059834778308868\n",
      "5282, train_loss: 0.5215358699743564, val_loss: 0.49173412322998045\n",
      "5283, train_loss: 0.5254079286868756, val_loss: 0.4992681324481964\n",
      "5284, train_loss: 0.5212076868002231, val_loss: 0.5229736626148224\n",
      "5285, train_loss: 0.5229332848237112, val_loss: 0.5238117814064026\n",
      "5286, train_loss: 0.5252565294504166, val_loss: 0.5222173213958741\n",
      "5287, train_loss: 0.5252580998035578, val_loss: 0.5062801361083984\n",
      "5288, train_loss: 0.5252320445500888, val_loss: 0.5205162107944489\n",
      "5289, train_loss: 0.5227662565616461, val_loss: 0.5231316745281219\n",
      "5290, train_loss: 0.5231978790118144, val_loss: 0.5085257291793823\n",
      "5291, train_loss: 0.5250855890604166, val_loss: 0.5345857083797455\n",
      "5292, train_loss: 0.5212260633707047, val_loss: 0.5145929336547852\n",
      "5293, train_loss: 0.5226145558632337, val_loss: 0.5204137146472931\n",
      "5294, train_loss: 0.5212677201399436, val_loss: 0.4982475399971008\n",
      "5295, train_loss: 0.5250193832012323, val_loss: 0.5093801558017731\n",
      "5296, train_loss: 0.5249896817482435, val_loss: 0.506223052740097\n",
      "5297, train_loss: 0.5205395508270997, val_loss: 0.5169400274753571\n",
      "5298, train_loss: 0.5231703015474173, val_loss: 0.5220057427883148\n",
      "5299, train_loss: 0.5248692815120404, val_loss: 0.5174210906028748\n",
      "5300, train_loss: 0.5211076851074512, val_loss: 0.5121663689613343\n",
      "5301, train_loss: 0.5248036281420634, val_loss: 0.5188430190086365\n",
      "5302, train_loss: 0.524725290445181, val_loss: 0.5138777077198029\n",
      "5303, train_loss: 0.5215111191456134, val_loss: 0.49731879830360415\n",
      "5304, train_loss: 0.521941908276998, val_loss: 0.5171373426914215\n",
      "5305, train_loss: 0.5210543263417023, val_loss: 0.5210848987102509\n",
      "5306, train_loss: 0.5211606381031183, val_loss: 0.529981118440628\n",
      "5307, train_loss: 0.5246474674114814, val_loss: 0.5110825181007386\n",
      "5308, train_loss: 0.5246041451509182, val_loss: 0.5164146423339844\n",
      "5309, train_loss: 0.5245908865561852, val_loss: 0.5138794422149658\n",
      "5310, train_loss: 0.5245627864049032, val_loss: 0.5136854648590088\n",
      "5311, train_loss: 0.5245623324926083, val_loss: 0.5095854282379151\n",
      "5312, train_loss: 0.5206552801223902, val_loss: 0.51069296002388\n",
      "5313, train_loss: 0.5217748433351517, val_loss: 0.5194366633892059\n",
      "5314, train_loss: 0.5202831236215738, val_loss: 0.4991642475128174\n",
      "5315, train_loss: 0.523228631569789, val_loss: 0.5134035348892212\n",
      "5316, train_loss: 0.5220283877391082, val_loss: 0.5072255492210388\n",
      "5317, train_loss: 0.522432281420781, val_loss: 0.5092904150485993\n",
      "5318, train_loss: 0.524348612015064, val_loss: 0.5334131121635437\n",
      "5319, train_loss: 0.5242909101339487, val_loss: 0.5334141492843628\n",
      "5320, train_loss: 0.5242668241262436, val_loss: 0.510122549533844\n",
      "5321, train_loss: 0.5242466066892331, val_loss: 0.503604131937027\n",
      "5322, train_loss: 0.524227995138902, val_loss: 0.5294397473335266\n",
      "5323, train_loss: 0.5202297671483114, val_loss: 0.5009070038795471\n",
      "5324, train_loss: 0.5205040986721332, val_loss: 0.5191177725791931\n",
      "5325, train_loss: 0.5206013677211908, val_loss: 0.5161976099014283\n",
      "5326, train_loss: 0.5205613615421149, val_loss: 0.5124143064022064\n",
      "5327, train_loss: 0.5190506955752006, val_loss: 0.5201433598995209\n",
      "5328, train_loss: 0.524064478965906, val_loss: 0.5205979406833648\n",
      "5329, train_loss: 0.5223913685633585, val_loss: 0.501513546705246\n",
      "5330, train_loss: 0.5197468342689368, val_loss: 0.5061000347137451\n",
      "5331, train_loss: 0.5204041233429542, val_loss: 0.5187511265277862\n",
      "5332, train_loss: 0.5239297163027984, val_loss: 0.5034542679786682\n",
      "5333, train_loss: 0.5239118658579313, val_loss: 0.5290694236755371\n",
      "5334, train_loss: 0.5238452141101544, val_loss: 0.5060548663139344\n",
      "5335, train_loss: 0.5199300830180829, val_loss: 0.5101005136966705\n",
      "5336, train_loss: 0.5194097619790298, val_loss: 0.5290690660476685\n",
      "5337, train_loss: 0.5201351252885965, val_loss: 0.5157543420791626\n",
      "5338, train_loss: 0.5218790448628939, val_loss: 0.5151319086551667\n",
      "5339, train_loss: 0.5193009869410441, val_loss: 0.5065962374210358\n",
      "5340, train_loss: 0.520017086313321, val_loss: 0.5050370335578919\n",
      "5341, train_loss: 0.519986880513338, val_loss: 0.5286287128925323\n",
      "5342, train_loss: 0.5198998520007501, val_loss: 0.4976449489593506\n",
      "5343, train_loss: 0.5236576474629916, val_loss: 0.5095199823379517\n",
      "5344, train_loss: 0.5200122858469303, val_loss: 0.4989515244960785\n",
      "5345, train_loss: 0.521342227092156, val_loss: 0.5168660283088684\n",
      "5346, train_loss: 0.5213012213890369, val_loss: 0.5147730827331543\n",
      "5347, train_loss: 0.5235105042274182, val_loss: 0.5116623282432556\n",
      "5348, train_loss: 0.5234964753572757, val_loss: 0.516089916229248\n",
      "5349, train_loss: 0.5234707123958148, val_loss: 0.508834856748581\n",
      "5350, train_loss: 0.5209756344556808, val_loss: 0.5007954180240631\n",
      "5351, train_loss: 0.5217193021224096, val_loss: 0.5172106742858886\n",
      "5352, train_loss: 0.519311242378675, val_loss: 0.5202168524265289\n",
      "5353, train_loss: 0.5219762004338778, val_loss: 0.48980691432952883\n",
      "5354, train_loss: 0.5232219925293555, val_loss: 0.5120002150535583\n",
      "5355, train_loss: 0.5216043568574465, val_loss: 0.5183377504348755\n",
      "5356, train_loss: 0.5231933215489755, val_loss: 0.5285262167453766\n",
      "5357, train_loss: 0.521160846719375, val_loss: 0.49961700439453127\n",
      "5358, train_loss: 0.5205682676572067, val_loss: 0.5183905601501465\n",
      "5359, train_loss: 0.5230277008735217, val_loss: 0.5068946480751038\n",
      "5360, train_loss: 0.5182857639514483, val_loss: 0.5178856968879699\n",
      "5361, train_loss: 0.5229455748429666, val_loss: 0.5102126896381378\n",
      "5362, train_loss: 0.5229163101086249, val_loss: 0.515766578912735\n",
      "5363, train_loss: 0.5228871256113052, val_loss: 0.5285812616348267\n",
      "5364, train_loss: 0.5215700853329438, val_loss: 0.5139017224311828\n",
      "5365, train_loss: 0.522761997122031, val_loss: 0.5158050775527954\n",
      "5366, train_loss: 0.5227914899587631, val_loss: 0.4974163770675659\n",
      "5367, train_loss: 0.5227698122079556, val_loss: 0.5325279414653779\n",
      "5368, train_loss: 0.5227102236105845, val_loss: 0.49789974093437195\n",
      "5369, train_loss: 0.5227399216248438, val_loss: 0.4969982743263245\n",
      "5370, train_loss: 0.5226733271892254, val_loss: 0.494414484500885\n",
      "5371, train_loss: 0.5208092698684106, val_loss: 0.5207126259803772\n",
      "5372, train_loss: 0.522599628338447, val_loss: 0.5032102704048157\n",
      "5373, train_loss: 0.5201247712740531, val_loss: 0.5051352083683014\n",
      "5374, train_loss: 0.5187092732924682, val_loss: 0.5321976780891419\n",
      "5375, train_loss: 0.5223770279150742, val_loss: 0.4957894206047058\n",
      "5376, train_loss: 0.5200986816332891, val_loss: 0.48882001638412476\n",
      "5377, train_loss: 0.5205747622710007, val_loss: 0.49258873462677\n",
      "5378, train_loss: 0.522458784855329, val_loss: 0.5203616976737976\n",
      "5379, train_loss: 0.5224971496141874, val_loss: 0.5113860785961151\n",
      "5380, train_loss: 0.5224810597988275, val_loss: 0.5088219165802002\n",
      "5381, train_loss: 0.5186522121612842, val_loss: 0.5135199129581451\n",
      "5382, train_loss: 0.522375898865553, val_loss: 0.5026053071022034\n",
      "5383, train_loss: 0.5186576350377157, val_loss: 0.5277448058128357\n",
      "5384, train_loss: 0.5191192695727715, val_loss: 0.5025039672851562\n",
      "5385, train_loss: 0.5184875027491496, val_loss: 0.5026775419712066\n",
      "5386, train_loss: 0.5222714806978519, val_loss: 0.5317479848861695\n",
      "5387, train_loss: 0.5185426072432444, val_loss: 0.5069212436676025\n",
      "5388, train_loss: 0.5201904567388388, val_loss: 0.4991404414176941\n",
      "5389, train_loss: 0.5180336695451003, val_loss: 0.5070816576480865\n",
      "5390, train_loss: 0.5221198946237564, val_loss: 0.49199855923652647\n",
      "5391, train_loss: 0.520373516357862, val_loss: 0.5070274472236633\n",
      "5392, train_loss: 0.5173479719803884, val_loss: 0.49717759490013125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5393, train_loss: 0.5220327010521522, val_loss: 0.5151076197624207\n",
      "5394, train_loss: 0.5219904906474627, val_loss: 0.5003930985927582\n",
      "5395, train_loss: 0.519825925047581, val_loss: 0.5200275480747223\n",
      "5396, train_loss: 0.5174893679527136, val_loss: 0.5151568710803985\n",
      "5397, train_loss: 0.5202159629418299, val_loss: 0.5275858640670776\n",
      "5398, train_loss: 0.5180759934278635, val_loss: 0.5199243009090424\n",
      "5399, train_loss: 0.5217826458124014, val_loss: 0.5110345005989074\n",
      "5400, train_loss: 0.5217839055336438, val_loss: 0.5118051946163178\n",
      "5401, train_loss: 0.5197745114564896, val_loss: 0.4923188924789429\n",
      "5402, train_loss: 0.5216783812412848, val_loss: 0.5275235295295715\n",
      "5403, train_loss: 0.5179755229216355, val_loss: 0.4993411660194397\n",
      "5404, train_loss: 0.519936217711522, val_loss: 0.5190094113349915\n",
      "5405, train_loss: 0.5179497542289587, val_loss: 0.493805980682373\n",
      "5406, train_loss: 0.517118731370339, val_loss: 0.5117355167865754\n",
      "5407, train_loss: 0.5177795760906659, val_loss: 0.5186254024505615\n",
      "5408, train_loss: 0.5215666729670304, val_loss: 0.520330834388733\n",
      "5409, train_loss: 0.5202582661922162, val_loss: 0.507120794057846\n",
      "5410, train_loss: 0.5197973067943866, val_loss: 0.5313086807727814\n",
      "5411, train_loss: 0.5214249457304294, val_loss: 0.5033737659454346\n",
      "5412, train_loss: 0.5214762916931739, val_loss: 0.5239802896976471\n",
      "5413, train_loss: 0.5176692524781594, val_loss: 0.5202977061271667\n",
      "5414, train_loss: 0.5176548017905309, val_loss: 0.5038680672645569\n",
      "5415, train_loss: 0.5213484087815652, val_loss: 0.5018105030059814\n",
      "5416, train_loss: 0.5168344298234353, val_loss: 0.5059990763664246\n",
      "5417, train_loss: 0.5191989311805139, val_loss: 0.5313947319984436\n",
      "5418, train_loss: 0.5191256472697625, val_loss: 0.5084880471229554\n",
      "5419, train_loss: 0.5188425951279126, val_loss: 0.4932145714759827\n",
      "5420, train_loss: 0.5176995580012982, val_loss: 0.5113531947135925\n",
      "5421, train_loss: 0.521106291275758, val_loss: 0.49815191626548766\n",
      "5422, train_loss: 0.5210839899686667, val_loss: 0.5081276535987854\n",
      "5423, train_loss: 0.5191032691643789, val_loss: 0.5237470686435699\n",
      "5424, train_loss: 0.5210787791472214, val_loss: 0.4939930081367493\n",
      "5425, train_loss: 0.5172444238112524, val_loss: 0.5137690424919128\n",
      "5426, train_loss: 0.5190643129440454, val_loss: 0.4923384845256805\n",
      "5427, train_loss: 0.5209826437326578, val_loss: 0.49220024347305297\n",
      "5428, train_loss: 0.5173685527764834, val_loss: 0.4999264895915985\n",
      "5429, train_loss: 0.5172265733663852, val_loss: 0.49770702719688414\n",
      "5430, train_loss: 0.5208620681212499, val_loss: 0.5109785437583924\n",
      "5431, train_loss: 0.5172403133832492, val_loss: 0.5182236731052399\n",
      "5432, train_loss: 0.5173562730734165, val_loss: 0.4996153235435486\n",
      "5433, train_loss: 0.5160939120329343, val_loss: 0.5089627385139466\n",
      "5434, train_loss: 0.5168767181726602, val_loss: 0.5175661206245422\n",
      "5435, train_loss: 0.5164903723276578, val_loss: 0.5039256811141968\n",
      "5436, train_loss: 0.5188782983101331, val_loss: 0.5100506126880646\n",
      "5437, train_loss: 0.5182819240368329, val_loss: 0.4958623707294464\n",
      "5438, train_loss: 0.5161031622153062, val_loss: 0.526591420173645\n",
      "5439, train_loss: 0.5163677266010871, val_loss: 0.49455046057701113\n",
      "5440, train_loss: 0.5180253443809656, val_loss: 0.5014894902706146\n",
      "5441, train_loss: 0.5172654023537269, val_loss: 0.49804928302764895\n",
      "5442, train_loss: 0.5204533957518064, val_loss: 0.5044740855693817\n",
      "5443, train_loss: 0.516538061774694, val_loss: 0.5079380869865417\n",
      "5444, train_loss: 0.5183541568425986, val_loss: 0.5045217335224151\n",
      "5445, train_loss: 0.5177858964754984, val_loss: 0.5267635226249695\n",
      "5446, train_loss: 0.5203035748921908, val_loss: 0.5071930468082428\n",
      "5447, train_loss: 0.5202569388426267, val_loss: 0.49339832067489625\n",
      "5448, train_loss: 0.5202341194336231, val_loss: 0.5065814673900604\n",
      "5449, train_loss: 0.5163210699191461, val_loss: 0.4900073170661926\n",
      "5450, train_loss: 0.5157778927913079, val_loss: 0.5304694175720215\n",
      "5451, train_loss: 0.5157864002081064, val_loss: 0.4975328385829926\n",
      "5452, train_loss: 0.5165084050251887, val_loss: 0.502802038192749\n",
      "5453, train_loss: 0.5159260619145173, val_loss: 0.526175731420517\n",
      "5454, train_loss: 0.5201524461691196, val_loss: 0.5099937200546265\n",
      "5455, train_loss: 0.518341173346226, val_loss: 0.513466066122055\n",
      "5456, train_loss: 0.5165841029240534, val_loss: 0.5096090912818909\n",
      "5457, train_loss: 0.5162152166549976, val_loss: 0.486702162027359\n",
      "5458, train_loss: 0.5181786406498688, val_loss: 0.5169084072113037\n",
      "5459, train_loss: 0.520014919913732, val_loss: 0.5115813672542572\n",
      "5460, train_loss: 0.518726035952568, val_loss: 0.5227311074733734\n",
      "5461, train_loss: 0.51822924384704, val_loss: 0.5094785094261169\n",
      "5462, train_loss: 0.5199445096346048, val_loss: 0.5189477145671845\n",
      "5463, train_loss: 0.5178464181148089, val_loss: 0.5156442224979401\n",
      "5464, train_loss: 0.5173141016409948, val_loss: 0.49820894598960874\n",
      "5465, train_loss: 0.5161822174604123, val_loss: 0.496439653635025\n",
      "5466, train_loss: 0.5153039361421878, val_loss: 0.517272663116455\n",
      "5467, train_loss: 0.5149869219614909, val_loss: 0.5067954182624816\n",
      "5468, train_loss: 0.5180534181686548, val_loss: 0.5166698157787323\n",
      "5469, train_loss: 0.5196553147756137, val_loss: 0.5042987525463104\n",
      "5470, train_loss: 0.5196383927877133, val_loss: 0.510686582326889\n",
      "5471, train_loss: 0.5195792122529104, val_loss: 0.5071210980415344\n",
      "5472, train_loss: 0.5195737148706729, val_loss: 0.5062852025032043\n",
      "5473, train_loss: 0.519496792784104, val_loss: 0.5141813278198242\n",
      "5474, train_loss: 0.5175106811981934, val_loss: 0.5013171911239624\n",
      "5475, train_loss: 0.5156870656288587, val_loss: 0.48944419622421265\n",
      "5476, train_loss: 0.5194603158877447, val_loss: 0.49343460202217104\n",
      "5477, train_loss: 0.5194368866773752, val_loss: 0.5011336743831635\n",
      "5478, train_loss: 0.5179500339122919, val_loss: 0.49777151346206666\n",
      "5479, train_loss: 0.5193357123778417, val_loss: 0.5138329327106476\n",
      "5480, train_loss: 0.5156173866528732, val_loss: 0.5097671985626221\n",
      "5481, train_loss: 0.5151933133602142, val_loss: 0.4888394117355347\n",
      "5482, train_loss: 0.5192928807093546, val_loss: 0.5184275090694428\n",
      "5483, train_loss: 0.5167493201219119, val_loss: 0.5294910550117493\n",
      "5484, train_loss: 0.51923601100078, val_loss: 0.5136162161827087\n",
      "5485, train_loss: 0.516675726725505, val_loss: 0.500191867351532\n",
      "5486, train_loss: 0.5154382437467575, val_loss: 0.5295081734657288\n",
      "5487, train_loss: 0.5166155191568228, val_loss: 0.49665786027908326\n",
      "5488, train_loss: 0.5154978747551258, val_loss: 0.5175894379615784\n",
      "5489, train_loss: 0.5145133011616193, val_loss: 0.49156628251075746\n",
      "5490, train_loss: 0.5191085235430644, val_loss: 0.5174863338470459\n",
      "5491, train_loss: 0.5190086559607432, val_loss: 0.49937968254089354\n",
      "5492, train_loss: 0.5153792958993179, val_loss: 0.5182150721549987\n",
      "5493, train_loss: 0.5189031614707067, val_loss: 0.5082111239433289\n",
      "5494, train_loss: 0.5189353582950739, val_loss: 0.5160317122936249\n",
      "5495, train_loss: 0.5164441844591727, val_loss: 0.5042852580547332\n",
      "5496, train_loss: 0.5160012394189835, val_loss: 0.5184435486793518\n",
      "5497, train_loss: 0.5167430708041558, val_loss: 0.5133689641952515\n",
      "5498, train_loss: 0.5187123337617288, val_loss: 0.4993093967437744\n",
      "5499, train_loss: 0.5150137612452874, val_loss: 0.5093534290790558\n",
      "5500, train_loss: 0.5152385303607354, val_loss: 0.4915884256362915\n",
      "5501, train_loss: 0.5140692878227967, val_loss: 0.5119948804378509\n",
      "5502, train_loss: 0.5187257906565299, val_loss: 0.5289585828781128\n",
      "5503, train_loss: 0.5147915723232123, val_loss: 0.49693453311920166\n",
      "5504, train_loss: 0.5186491826405892, val_loss: 0.4958889722824097\n",
      "5505, train_loss: 0.5149195801753265, val_loss: 0.5050479292869567\n",
      "5506, train_loss: 0.5173188138466615, val_loss: 0.5156335592269897\n",
      "5507, train_loss: 0.5185384417955692, val_loss: 0.5058976650238037\n",
      "5508, train_loss: 0.5185301258013799, val_loss: 0.4939602673053741\n",
      "5509, train_loss: 0.5142601682589605, val_loss: 0.4940309882164001\n",
      "5510, train_loss: 0.5184642901787391, val_loss: 0.5111921608448029\n",
      "5511, train_loss: 0.5184330470286883, val_loss: 0.5118927657604218\n",
      "5512, train_loss: 0.5183873692384133, val_loss: 0.5102142930030823\n",
      "5513, train_loss: 0.5183269610771766, val_loss: 0.5169171154499054\n",
      "5514, train_loss: 0.5182889321675668, val_loss: 0.5092281103134155\n",
      "5515, train_loss: 0.5162103531452326, val_loss: 0.5093843162059783\n",
      "5516, train_loss: 0.5145401163743093, val_loss: 0.5143072187900544\n",
      "5517, train_loss: 0.5140642707164471, val_loss: 0.5085420250892639\n",
      "5518, train_loss: 0.5182335342352207, val_loss: 0.4922068178653717\n",
      "5519, train_loss: 0.5182150785739605, val_loss: 0.5054587960243225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5520, train_loss: 0.514606868991485, val_loss: 0.5107278764247895\n",
      "5521, train_loss: 0.5128383716711631, val_loss: 0.4911938965320587\n",
      "5522, train_loss: 0.5148583627664126, val_loss: 0.5207187533378601\n",
      "5523, train_loss: 0.5181757406546519, val_loss: 0.5009605586528778\n",
      "5524, train_loss: 0.5157187179877207, val_loss: 0.49969697594642637\n",
      "5525, train_loss: 0.5151687115430832, val_loss: 0.5082485795021057\n",
      "5526, train_loss: 0.5180015518115118, val_loss: 0.5172597289085388\n",
      "5527, train_loss: 0.5179588955182296, val_loss: 0.5241377294063568\n",
      "5528, train_loss: 0.5179343670606613, val_loss: 0.5156275629997253\n",
      "5529, train_loss: 0.5160401486433469, val_loss: 0.5241828978061676\n",
      "5530, train_loss: 0.5145276360786878, val_loss: 0.5053933322429657\n",
      "5531, train_loss: 0.5160905810502859, val_loss: 0.49067515730857847\n",
      "5532, train_loss: 0.5178165137767792, val_loss: 0.5074951589107514\n",
      "5533, train_loss: 0.5141612749833328, val_loss: 0.5002379536628723\n",
      "5534, train_loss: 0.517721814604906, val_loss: 0.5084682166576385\n",
      "5535, train_loss: 0.5135124807174389, val_loss: 0.5033140480518341\n",
      "5536, train_loss: 0.5177113390885867, val_loss: 0.49943832159042356\n",
      "5537, train_loss: 0.5166754115086335, val_loss: 0.5240857005119324\n",
      "5538, train_loss: 0.5176384884577531, val_loss: 0.5004273414611816\n",
      "5539, train_loss: 0.5134529895507373, val_loss: 0.5085115909576416\n",
      "5540, train_loss: 0.5136645298737746, val_loss: 0.49440100193023684\n",
      "5541, train_loss: 0.5175584703683853, val_loss: 0.4903793454170227\n",
      "5542, train_loss: 0.5157125798555521, val_loss: 0.5091811358928681\n",
      "5543, train_loss: 0.5155106954849683, val_loss: 0.523914235830307\n",
      "5544, train_loss: 0.5174258603499486, val_loss: 0.4901125907897949\n",
      "5545, train_loss: 0.5132778825668188, val_loss: 0.4900949001312256\n",
      "5546, train_loss: 0.5137847639047183, val_loss: 0.5046422362327576\n",
      "5547, train_loss: 0.5163827996987563, val_loss: 0.5033404350280761\n",
      "5548, train_loss: 0.5134429782629013, val_loss: 0.5151730954647065\n",
      "5549, train_loss: 0.5125760722618836, val_loss: 0.49982979893684387\n",
      "5550, train_loss: 0.51364466547966, val_loss: 0.5069113850593567\n",
      "5551, train_loss: 0.517279674227421, val_loss: 0.4948155045509338\n",
      "5552, train_loss: 0.5172235770867422, val_loss: 0.507323944568634\n",
      "5553, train_loss: 0.5152110572044666, val_loss: 0.5031572341918945\n",
      "5554, train_loss: 0.5171438134633578, val_loss: 0.4993976950645447\n",
      "5555, train_loss: 0.5171245428232046, val_loss: 0.5099976539611817\n",
      "5556, train_loss: 0.5128376071269696, val_loss: 0.5071860134601593\n",
      "5557, train_loss: 0.5161675157455298, val_loss: 0.5156183183193207\n",
      "5558, train_loss: 0.5170578773205097, val_loss: 0.507107937335968\n",
      "5559, train_loss: 0.5170430644200399, val_loss: 0.5232484936714172\n",
      "5560, train_loss: 0.5121673185091752, val_loss: 0.4905131638050079\n",
      "5561, train_loss: 0.5169929632773766, val_loss: 0.5102987647056579\n",
      "5562, train_loss: 0.513246686412738, val_loss: 0.49555034637451173\n",
      "5563, train_loss: 0.516964390873909, val_loss: 0.527262806892395\n",
      "5564, train_loss: 0.5169317378447607, val_loss: 0.5138714909553528\n",
      "5565, train_loss: 0.5168771480138485, val_loss: 0.5112776041030884\n",
      "5566, train_loss: 0.512601192180927, val_loss: 0.5038451313972473\n",
      "5567, train_loss: 0.5143379259567994, val_loss: 0.5196385085582733\n",
      "5568, train_loss: 0.5128922359301493, val_loss: 0.5123932778835296\n",
      "5569, train_loss: 0.5126041792906247, val_loss: 0.503898423910141\n",
      "5570, train_loss: 0.514206832418075, val_loss: 0.5137667834758759\n",
      "5571, train_loss: 0.5166659641724366, val_loss: 0.5151888012886048\n",
      "5572, train_loss: 0.5128573225094721, val_loss: 0.5271270751953125\n",
      "5573, train_loss: 0.5121068220872146, val_loss: 0.5022209763526917\n",
      "5574, train_loss: 0.5165814298849839, val_loss: 0.5229135632514954\n",
      "5575, train_loss: 0.5165645869878622, val_loss: 0.48767638206481934\n",
      "5576, train_loss: 0.514495740716274, val_loss: 0.4933187186717987\n",
      "5577, train_loss: 0.5123138026549265, val_loss: 0.5066799640655517\n",
      "5578, train_loss: 0.512964584506475, val_loss: 0.5039128482341766\n",
      "5579, train_loss: 0.5121800039823239, val_loss: 0.513667368888855\n",
      "5580, train_loss: 0.5150687316289315, val_loss: 0.5108615696430207\n",
      "5581, train_loss: 0.5162280029975451, val_loss: 0.5124598205089569\n",
      "5582, train_loss: 0.5127098697882432, val_loss: 0.49386581778526306\n",
      "5583, train_loss: 0.5162866081182773, val_loss: 0.5271954417228699\n",
      "5584, train_loss: 0.5123651841512094, val_loss: 0.5157080292701721\n",
      "5585, train_loss: 0.5136687652422831, val_loss: 0.5194854617118836\n",
      "5586, train_loss: 0.5126968862918707, val_loss: 0.5001716256141663\n",
      "5587, train_loss: 0.5132175718362515, val_loss: 0.5228619754314423\n",
      "5588, train_loss: 0.5161064083759601, val_loss: 0.4933606028556824\n",
      "5589, train_loss: 0.512524425983429, val_loss: 0.4917138874530792\n",
      "5590, train_loss: 0.5161005419034225, val_loss: 0.5107929885387421\n",
      "5591, train_loss: 0.5160514196524253, val_loss: 0.5148761630058288\n",
      "5592, train_loss: 0.5160316022542807, val_loss: 0.5226612448692322\n",
      "5593, train_loss: 0.5122888076763886, val_loss: 0.49648759365081785\n",
      "5594, train_loss: 0.5135364475158545, val_loss: 0.5099529683589935\n",
      "5595, train_loss: 0.5114179287965481, val_loss: 0.5192550837993621\n",
      "5596, train_loss: 0.5140650639167199, val_loss: 0.48909883499145507\n",
      "5597, train_loss: 0.5122617196578246, val_loss: 0.5065325915813446\n",
      "5598, train_loss: 0.5132368470613773, val_loss: 0.5096675634384156\n",
      "5599, train_loss: 0.5158659987724744, val_loss: 0.500369381904602\n",
      "5600, train_loss: 0.5122739993608915, val_loss: 0.5058570444583893\n",
      "5601, train_loss: 0.5157873194951278, val_loss: 0.5011097550392151\n",
      "5602, train_loss: 0.5143907047235049, val_loss: 0.5138104438781739\n",
      "5603, train_loss: 0.5156978517770767, val_loss: 0.5105236947536469\n",
      "5604, train_loss: 0.5156487879844812, val_loss: 0.5191071987152099\n",
      "5605, train_loss: 0.5155836905424411, val_loss: 0.5267285943031311\n",
      "5606, train_loss: 0.5117827069300872, val_loss: 0.49923567175865174\n",
      "5607, train_loss: 0.5155733904013267, val_loss: 0.5032956719398498\n",
      "5608, train_loss: 0.5113469431033502, val_loss: 0.49256551861763\n",
      "5609, train_loss: 0.5155846591179187, val_loss: 0.49211395978927613\n",
      "5610, train_loss: 0.5155723897310404, val_loss: 0.5038714230060577\n",
      "5611, train_loss: 0.5137806408680402, val_loss: 0.4882861375808716\n",
      "5612, train_loss: 0.5154745338054804, val_loss: 0.5101347267627716\n",
      "5613, train_loss: 0.5154105333181528, val_loss: 0.48604856133461\n",
      "5614, train_loss: 0.5111455424473836, val_loss: 0.4934786081314087\n",
      "5615, train_loss: 0.5153996027432955, val_loss: 0.5140218496322632\n",
      "5616, train_loss: 0.5114046633243561, val_loss: 0.5091023027896882\n",
      "5617, train_loss: 0.5139760191623981, val_loss: 0.5084526896476745\n",
      "5618, train_loss: 0.515278445986601, val_loss: 0.49764458537101747\n",
      "5619, train_loss: 0.5119435065067731, val_loss: 0.5126246511936188\n",
      "5620, train_loss: 0.5100152228887265, val_loss: 0.49826844334602355\n",
      "5621, train_loss: 0.5110099097857108, val_loss: 0.5140209674835206\n",
      "5622, train_loss: 0.5109164921137003, val_loss: 0.5088799357414245\n",
      "5623, train_loss: 0.5115623932618362, val_loss: 0.5145716488361358\n",
      "5624, train_loss: 0.5151076580469425, val_loss: 0.4960051417350769\n",
      "5625, train_loss: 0.5111671995658141, val_loss: 0.500590467453003\n",
      "5626, train_loss: 0.5126652889526807, val_loss: 0.49757137298583987\n",
      "5627, train_loss: 0.5150397442854368, val_loss: 0.5008185565471649\n",
      "5628, train_loss: 0.5149963417878518, val_loss: 0.5053646743297577\n",
      "5629, train_loss: 0.514977005811838, val_loss: 0.49489356875419616\n",
      "5630, train_loss: 0.5103713812736365, val_loss: 0.5258577644824982\n",
      "5631, train_loss: 0.5149419066997675, val_loss: 0.4905571758747101\n",
      "5632, train_loss: 0.5111686243460729, val_loss: 0.5214406490325928\n",
      "5633, train_loss: 0.5148417697503016, val_loss: 0.5257215142250061\n",
      "5634, train_loss: 0.5148641214920924, val_loss: 0.4964119613170624\n",
      "5635, train_loss: 0.511271500816712, val_loss: 0.5047394871711731\n",
      "5636, train_loss: 0.5110474675893784, val_loss: 0.4948212742805481\n",
      "5637, train_loss: 0.511024873990279, val_loss: 0.5066466689109802\n",
      "5638, train_loss: 0.5125210365423789, val_loss: 0.5136461138725281\n",
      "5639, train_loss: 0.5092547902694116, val_loss: 0.49291692972183226\n",
      "5640, train_loss: 0.5122587761053672, val_loss: 0.48239989280700685\n",
      "5641, train_loss: 0.5146684302733495, val_loss: 0.5003641784191132\n",
      "5642, train_loss: 0.5145961367166959, val_loss: 0.5055787801742554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5643, train_loss: 0.5102989708001797, val_loss: 0.5018047273159028\n",
      "5644, train_loss: 0.5095818249078897, val_loss: 0.49435330033302305\n",
      "5645, train_loss: 0.5145753644979917, val_loss: 0.5102199971675873\n",
      "5646, train_loss: 0.5145535595141925, val_loss: 0.4989787697792053\n",
      "5647, train_loss: 0.510808065533638, val_loss: 0.5130714774131775\n",
      "5648, train_loss: 0.5097682097783456, val_loss: 0.49018009305000304\n",
      "5649, train_loss: 0.5107891192803016, val_loss: 0.5129245162010193\n",
      "5650, train_loss: 0.5144351331087259, val_loss: 0.48050073981285096\n",
      "5651, train_loss: 0.5108310156143628, val_loss: 0.4922034204006195\n",
      "5652, train_loss: 0.5143798291683197, val_loss: 0.5126805663108825\n",
      "5653, train_loss: 0.5143923048789685, val_loss: 0.49456769824028013\n",
      "5654, train_loss: 0.5143519571194282, val_loss: 0.5127086639404297\n",
      "5655, train_loss: 0.5107658459590032, val_loss: 0.5037254631519318\n",
      "5656, train_loss: 0.5129485393945987, val_loss: 0.5119637548923492\n",
      "5657, train_loss: 0.5116978792043833, val_loss: 0.49721814393997193\n",
      "5658, train_loss: 0.5142294924992782, val_loss: 0.5070478200912476\n",
      "5659, train_loss: 0.5141334121043866, val_loss: 0.5085467994213104\n",
      "5660, train_loss: 0.5140878466459421, val_loss: 0.5204777419567108\n",
      "5661, train_loss: 0.514097219476333, val_loss: 0.5075439572334289\n",
      "5662, train_loss: 0.5140574952730765, val_loss: 0.4859816193580627\n",
      "5663, train_loss: 0.5101129114627838, val_loss: 0.5046183884143829\n",
      "5664, train_loss: 0.511902779340744, val_loss: 0.4959097743034363\n",
      "5665, train_loss: 0.5121783316135406, val_loss: 0.4886388897895813\n",
      "5666, train_loss: 0.5119193769418277, val_loss: 0.4900801420211792\n",
      "5667, train_loss: 0.510436434012193, val_loss: 0.4939437747001648\n",
      "5668, train_loss: 0.5138988300011709, val_loss: 0.49891034364700315\n",
      "5669, train_loss: 0.5105548604176595, val_loss: 0.4925161063671112\n",
      "5670, train_loss: 0.5138738029278241, val_loss: 0.496062821149826\n",
      "5671, train_loss: 0.5119777161341447, val_loss: 0.5083159446716309\n",
      "5672, train_loss: 0.50944916674724, val_loss: 0.48752412796020506\n",
      "5673, train_loss: 0.5109362762707931, val_loss: 0.5082478880882263\n",
      "5674, train_loss: 0.5099263489246368, val_loss: 0.5245217263698578\n",
      "5675, train_loss: 0.5118833596889789, val_loss: 0.5040645599365234\n",
      "5676, train_loss: 0.5093688987768613, val_loss: 0.5109109997749328\n",
      "5677, train_loss: 0.5093609541654587, val_loss: 0.5008451044559479\n",
      "5678, train_loss: 0.5098603986776792, val_loss: 0.5122573494911193\n",
      "5679, train_loss: 0.509820201075994, val_loss: 0.5000490427017212\n",
      "5680, train_loss: 0.5134975210978434, val_loss: 0.4865411937236786\n",
      "5681, train_loss: 0.5109594475764495, val_loss: 0.5167425870895386\n",
      "5682, train_loss: 0.5094287028679481, val_loss: 0.49158769845962524\n",
      "5683, train_loss: 0.5116574007731217, val_loss: 0.524319052696228\n",
      "5684, train_loss: 0.5134394478339416, val_loss: 0.5243396401405335\n",
      "5685, train_loss: 0.5134305862280039, val_loss: 0.48587862253189085\n",
      "5686, train_loss: 0.5097913535741659, val_loss: 0.523939061164856\n",
      "5687, train_loss: 0.5091483891010284, val_loss: 0.49385230541229247\n",
      "5688, train_loss: 0.511579264815037, val_loss: 0.5024294018745422\n",
      "5689, train_loss: 0.5095831625736676, val_loss: 0.5028162360191345\n",
      "5690, train_loss: 0.513341560959816, val_loss: 0.5102603554725647\n",
      "5691, train_loss: 0.5078164304678257, val_loss: 0.49875170588493345\n",
      "5692, train_loss: 0.5133258860844833, val_loss: 0.5115614414215088\n",
      "5693, train_loss: 0.5132105637055177, val_loss: 0.5237047493457794\n",
      "5694, train_loss: 0.5132180956693796, val_loss: 0.49244422316551206\n",
      "5695, train_loss: 0.5094733020434012, val_loss: 0.4953185021877289\n",
      "5696, train_loss: 0.5088221648564706, val_loss: 0.5001599788665771\n",
      "5697, train_loss: 0.5088055615241711, val_loss: 0.4925092339515686\n",
      "5698, train_loss: 0.5130669428752019, val_loss: 0.5124263882637023\n",
      "5699, train_loss: 0.5086937283094113, val_loss: 0.5030575931072235\n",
      "5700, train_loss: 0.5092308349334277, val_loss: 0.4790708363056183\n",
      "5701, train_loss: 0.51299749314785, val_loss: 0.49989656209945676\n",
      "5702, train_loss: 0.5082500187250284, val_loss: 0.5098334908485412\n",
      "5703, train_loss: 0.5103854491160467, val_loss: 0.508663934469223\n",
      "5704, train_loss: 0.5128944264008448, val_loss: 0.4980693757534027\n",
      "5705, train_loss: 0.5080931209600889, val_loss: 0.49847076535224916\n",
      "5706, train_loss: 0.5108171609731821, val_loss: 0.4922090172767639\n",
      "5707, train_loss: 0.5102376926403779, val_loss: 0.502548736333847\n",
      "5708, train_loss: 0.5107116378270663, val_loss: 0.5064535975456238\n",
      "5709, train_loss: 0.5100764976097987, val_loss: 0.5193328261375427\n",
      "5710, train_loss: 0.5126619923573273, val_loss: 0.507282155752182\n",
      "5711, train_loss: 0.5091281223755616, val_loss: 0.48784269094467164\n",
      "5712, train_loss: 0.5083418156091983, val_loss: 0.5234921693801879\n",
      "5713, train_loss: 0.5126206336113123, val_loss: 0.5071041405200958\n",
      "5714, train_loss: 0.5126050343880286, val_loss: 0.4825312077999115\n",
      "5715, train_loss: 0.5125694802174201, val_loss: 0.5111195266246795\n",
      "5716, train_loss: 0.5086947530508041, val_loss: 0.5033493578433991\n",
      "5717, train_loss: 0.5081874647965798, val_loss: 0.5111170828342437\n",
      "5718, train_loss: 0.510661964233105, val_loss: 0.48970388770103457\n",
      "5719, train_loss: 0.5124103724956512, val_loss: 0.5023740530014038\n",
      "5720, train_loss: 0.5077757376890916, val_loss: 0.49887710213661196\n",
      "5721, train_loss: 0.5080859798651475, val_loss: 0.5189321279525757\n",
      "5722, train_loss: 0.5085892918018194, val_loss: 0.5059113144874573\n",
      "5723, train_loss: 0.5088041298664533, val_loss: 0.5117662012577057\n",
      "5724, train_loss: 0.5102337392476889, val_loss: 0.5155023694038391\n",
      "5725, train_loss: 0.5122600633364457, val_loss: 0.4831655263900757\n",
      "5726, train_loss: 0.508003926047912, val_loss: 0.49217880368232725\n",
      "5727, train_loss: 0.5084593399212911, val_loss: 0.5186425983905792\n",
      "5728, train_loss: 0.5122281668277887, val_loss: 0.48655667901039124\n",
      "5729, train_loss: 0.5072826468027555, val_loss: 0.5098659992218018\n",
      "5730, train_loss: 0.5077967288402411, val_loss: 0.5017039716243744\n",
      "5731, train_loss: 0.5111265377356455, val_loss: 0.48811357617378237\n",
      "5732, train_loss: 0.5076636305222144, val_loss: 0.5091072916984558\n",
      "5733, train_loss: 0.5106101677967951, val_loss: 0.49870182275772096\n",
      "5734, train_loss: 0.5120408557928525, val_loss: 0.4887259006500244\n",
      "5735, train_loss: 0.5084425027553852, val_loss: 0.482651025056839\n",
      "5736, train_loss: 0.5119935228274419, val_loss: 0.5227521300315857\n",
      "5737, train_loss: 0.5094366726967005, val_loss: 0.5227162063121795\n",
      "5738, train_loss: 0.5064563453197479, val_loss: 0.5052351415157318\n",
      "5739, train_loss: 0.511924161360814, val_loss: 0.5094984471797943\n",
      "5740, train_loss: 0.5118078623826687, val_loss: 0.5061824083328247\n",
      "5741, train_loss: 0.5118557409598277, val_loss: 0.5018615067005158\n",
      "5742, train_loss: 0.5118923370654767, val_loss: 0.48729796409606935\n",
      "5743, train_loss: 0.5100264778504005, val_loss: 0.498146116733551\n",
      "5744, train_loss: 0.5116885522237191, val_loss: 0.4938467085361481\n",
      "5745, train_loss: 0.5082120929773037, val_loss: 0.5102205276489258\n",
      "5746, train_loss: 0.5117315741685721, val_loss: 0.5024514138698578\n",
      "5747, train_loss: 0.5091214856276145, val_loss: 0.5147858381271362\n",
      "5748, train_loss: 0.5082212147804407, val_loss: 0.5052942574024201\n",
      "5749, train_loss: 0.5116412272820106, val_loss: 0.49801700115203856\n",
      "5750, train_loss: 0.5086832298682287, val_loss: 0.5095539629459381\n",
      "5751, train_loss: 0.5089698456800901, val_loss: 0.4847700595855713\n",
      "5752, train_loss: 0.5088269378130252, val_loss: 0.5104909777641297\n",
      "5753, train_loss: 0.5063534367543, val_loss: 0.5026977062225342\n",
      "5754, train_loss: 0.5093614734136142, val_loss: 0.5019979059696198\n",
      "5755, train_loss: 0.5093436458936105, val_loss: 0.5226015329360962\n",
      "5756, train_loss: 0.5080555195991809, val_loss: 0.4858094096183777\n",
      "5757, train_loss: 0.5113636759611276, val_loss: 0.49280703663825987\n",
      "5758, train_loss: 0.5113420234276698, val_loss: 0.5101980268955231\n",
      "5759, train_loss: 0.5076663803595763, val_loss: 0.5102218627929688\n",
      "5760, train_loss: 0.5074573732339419, val_loss: 0.4875473499298096\n",
      "5761, train_loss: 0.5112630232022359, val_loss: 0.4912819921970367\n",
      "5762, train_loss: 0.5085787016611832, val_loss: 0.49011185169219973\n",
      "5763, train_loss: 0.5073122760424247, val_loss: 0.5057029664516449\n",
      "5764, train_loss: 0.5097563140667402, val_loss: 0.5074107766151428\n",
      "5765, train_loss: 0.5074203770894271, val_loss: 0.5075612425804138\n",
      "5766, train_loss: 0.509679621228805, val_loss: 0.5074612319469451\n",
      "5767, train_loss: 0.5066867998013129, val_loss: 0.48377583622932435\n",
      "5768, train_loss: 0.5076804447632569, val_loss: 0.48522869348526\n",
      "5769, train_loss: 0.506317851635126, val_loss: 0.4784822344779968\n",
      "5770, train_loss: 0.5083729853996863, val_loss: 0.5143593788146973\n",
      "5771, train_loss: 0.5072677250091846, val_loss: 0.5009666204452514\n",
      "5772, train_loss: 0.5109449006043948, val_loss: 0.5082627296447754\n",
      "5773, train_loss: 0.5072399859245007, val_loss: 0.48669461607933046\n",
      "5774, train_loss: 0.5061130718542979, val_loss: 0.5044318914413453\n",
      "5775, train_loss: 0.5082464149365058, val_loss: 0.4875517725944519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5776, train_loss: 0.5108414601821166, val_loss: 0.47722246050834655\n",
      "5777, train_loss: 0.5082965665138685, val_loss: 0.49779253005981444\n",
      "5778, train_loss: 0.5082492874218867, val_loss: 0.5084905922412872\n",
      "5779, train_loss: 0.5107425714914615, val_loss: 0.5172759473323822\n",
      "5780, train_loss: 0.5107415948922818, val_loss: 0.5043205082416534\n",
      "5781, train_loss: 0.5089841198462707, val_loss: 0.5009440898895263\n",
      "5782, train_loss: 0.5106701598717616, val_loss: 0.5215752243995666\n",
      "5783, train_loss: 0.5093383353490096, val_loss: 0.5139073610305787\n",
      "5784, train_loss: 0.5069773357648116, val_loss: 0.5050992488861084\n",
      "5785, train_loss: 0.5105243416932913, val_loss: 0.5015565693378449\n",
      "5786, train_loss: 0.5067484252727948, val_loss: 0.5006686210632324\n",
      "5787, train_loss: 0.508435165652862, val_loss: 0.501481294631958\n",
      "5788, train_loss: 0.5105114315564816, val_loss: 0.4912690281867981\n",
      "5789, train_loss: 0.5084550793354328, val_loss: 0.5215780556201934\n",
      "5790, train_loss: 0.5090621881760083, val_loss: 0.5216286182403564\n",
      "5791, train_loss: 0.5104395437699097, val_loss: 0.48295979499816893\n",
      "5792, train_loss: 0.5058310295526798, val_loss: 0.5039226531982421\n",
      "5793, train_loss: 0.5104104234622076, val_loss: 0.5038183689117431\n",
      "5794, train_loss: 0.5077771808092411, val_loss: 0.48872536420822144\n",
      "5795, train_loss: 0.5103312100355442, val_loss: 0.5089398205280304\n",
      "5796, train_loss: 0.5074458019091532, val_loss: 0.5007264316082001\n",
      "5797, train_loss: 0.507334821499311, val_loss: 0.5033071100711822\n",
      "5798, train_loss: 0.5076512533884782, val_loss: 0.5038112819194793\n",
      "5799, train_loss: 0.5072010858700826, val_loss: 0.5081661164760589\n",
      "5800, train_loss: 0.507531368961701, val_loss: 0.5136456847190857\n",
      "5801, train_loss: 0.5101229823552645, val_loss: 0.5098829567432404\n",
      "5802, train_loss: 0.505714476108551, val_loss: 0.4827753186225891\n",
      "5803, train_loss: 0.5065176154558475, val_loss: 0.5091017007827758\n",
      "5804, train_loss: 0.5063939621815314, val_loss: 0.5096745967864991\n",
      "5805, train_loss: 0.5086618077296478, val_loss: 0.4900525569915771\n",
      "5806, train_loss: 0.5080034308708631, val_loss: 0.5039617359638214\n",
      "5807, train_loss: 0.5052942243906168, val_loss: 0.5007202386856079\n",
      "5808, train_loss: 0.5063835176137778, val_loss: 0.483869332075119\n",
      "5809, train_loss: 0.5098660164154493, val_loss: 0.5088946461677551\n",
      "5810, train_loss: 0.5050527006387711, val_loss: 0.4836690366268158\n",
      "5811, train_loss: 0.5072628488907447, val_loss: 0.4994836330413818\n",
      "5812, train_loss: 0.5067949948402551, val_loss: 0.521187025308609\n",
      "5813, train_loss: 0.5059600392213235, val_loss: 0.5211767315864563\n",
      "5814, train_loss: 0.5097311872702378, val_loss: 0.48566247820854186\n",
      "5815, train_loss: 0.5072816839584937, val_loss: 0.4992629110813141\n",
      "5816, train_loss: 0.5050864529151183, val_loss: 0.49060994386672974\n",
      "5817, train_loss: 0.504374792942634, val_loss: 0.4917580485343933\n",
      "5818, train_loss: 0.507230879022525, val_loss: 0.47644442319869995\n",
      "5819, train_loss: 0.5078176798728796, val_loss: 0.4848888099193573\n",
      "5820, train_loss: 0.5095981015608861, val_loss: 0.4853741765022278\n",
      "5821, train_loss: 0.509586057983912, val_loss: 0.4837458908557892\n",
      "5822, train_loss: 0.5051387846469879, val_loss: 0.4967602491378784\n",
      "5823, train_loss: 0.5051830067084386, val_loss: 0.48610183596611023\n",
      "5824, train_loss: 0.509514535848911, val_loss: 0.4916530787944794\n",
      "5825, train_loss: 0.5095019455139453, val_loss: 0.5054425358772278\n",
      "5826, train_loss: 0.5072971123915452, val_loss: 0.5207589507102967\n",
      "5827, train_loss: 0.5063862594274374, val_loss: 0.5038979768753051\n",
      "5828, train_loss: 0.5072371134391198, val_loss: 0.4853582262992859\n",
      "5829, train_loss: 0.5065704274636048, val_loss: 0.5209457397460937\n",
      "5830, train_loss: 0.5043121541921909, val_loss: 0.5075885891914368\n",
      "5831, train_loss: 0.5053617575993905, val_loss: 0.48841133117675783\n",
      "5832, train_loss: 0.5081769331143453, val_loss: 0.5055082321166993\n",
      "5833, train_loss: 0.505317862217243, val_loss: 0.4969611406326294\n",
      "5834, train_loss: 0.5057194863374417, val_loss: 0.4907908320426941\n",
      "5835, train_loss: 0.5091280742333486, val_loss: 0.4880341112613678\n",
      "5836, train_loss: 0.5076152796928699, val_loss: 0.5206991851329803\n",
      "5837, train_loss: 0.5041891485452652, val_loss: 0.5001933753490448\n",
      "5838, train_loss: 0.5090314516654382, val_loss: 0.5037559151649476\n",
      "5839, train_loss: 0.508999187212724, val_loss: 0.5074114382266999\n",
      "5840, train_loss: 0.5051649063825607, val_loss: 0.5026520907878875\n",
      "5841, train_loss: 0.504262931071795, val_loss: 0.5081112921237946\n",
      "5842, train_loss: 0.5070751378169427, val_loss: 0.49677165746688845\n",
      "5843, train_loss: 0.5045850643744836, val_loss: 0.500653088092804\n",
      "5844, train_loss: 0.5068031813089664, val_loss: 0.48131123185157776\n",
      "5845, train_loss: 0.5039237359395394, val_loss: 0.491711300611496\n",
      "5846, train_loss: 0.5051470341590735, val_loss: 0.48696873188018797\n",
      "5847, train_loss: 0.5050273892971185, val_loss: 0.4791259229183197\n",
      "5848, train_loss: 0.5032866723262347, val_loss: 0.5074481010437012\n",
      "5849, train_loss: 0.5044958545611455, val_loss: 0.5066477298736572\n",
      "5850, train_loss: 0.5088009020456901, val_loss: 0.4996074318885803\n",
      "5851, train_loss: 0.5087984318916614, val_loss: 0.5059706568717957\n",
      "5852, train_loss: 0.5067251840463052, val_loss: 0.49903648495674136\n",
      "5853, train_loss: 0.5074154241726949, val_loss: 0.4958828389644623\n",
      "5854, train_loss: 0.5087274553684088, val_loss: 0.47824695110321047\n",
      "5855, train_loss: 0.5067136104290302, val_loss: 0.4882945895195007\n",
      "5856, train_loss: 0.504993193424665, val_loss: 0.5059094309806824\n",
      "5857, train_loss: 0.5048730808954972, val_loss: 0.4813264012336731\n",
      "5858, train_loss: 0.5085849853662344, val_loss: 0.47757211327552795\n",
      "5859, train_loss: 0.5037320794967505, val_loss: 0.4843766212463379\n",
      "5860, train_loss: 0.5049569790179913, val_loss: 0.5116835355758667\n",
      "5861, train_loss: 0.5041749213750546, val_loss: 0.4906270980834961\n",
      "5862, train_loss: 0.505633953672189, val_loss: 0.4854690670967102\n",
      "5863, train_loss: 0.5084690233835807, val_loss: 0.5054637312889099\n",
      "5864, train_loss: 0.5071041595477325, val_loss: 0.4838260531425476\n",
      "5865, train_loss: 0.5084094565648299, val_loss: 0.48804702758789065\n",
      "5866, train_loss: 0.5063438472839502, val_loss: 0.5062000632286072\n",
      "5867, train_loss: 0.5083285799393287, val_loss: 0.4931495666503906\n",
      "5868, train_loss: 0.5061400005450616, val_loss: 0.5015354633331299\n",
      "5869, train_loss: 0.5082536649245483, val_loss: 0.48601565361022947\n",
      "5870, train_loss: 0.5082481732735267, val_loss: 0.5078017294406891\n",
      "5871, train_loss: 0.5038444227897204, val_loss: 0.5115716338157654\n",
      "5872, train_loss: 0.5081760126810807, val_loss: 0.4842950165271759\n",
      "5873, train_loss: 0.5071097314357758, val_loss: 0.48754832744598386\n",
      "5874, train_loss: 0.5067137433932378, val_loss: 0.49497878551483154\n",
      "5875, train_loss: 0.5035997182130814, val_loss: 0.4854065477848053\n",
      "5876, train_loss: 0.5042304178843131, val_loss: 0.505590283870697\n",
      "5877, train_loss: 0.5033820752914135, val_loss: 0.501939845085144\n",
      "5878, train_loss: 0.5079737729751147, val_loss: 0.4972533702850342\n",
      "5879, train_loss: 0.5053477642627863, val_loss: 0.5194641411304474\n",
      "5880, train_loss: 0.5079365384120208, val_loss: 0.4853287398815155\n",
      "5881, train_loss: 0.5079053342342377, val_loss: 0.4847486078739166\n",
      "5882, train_loss: 0.5044952699771295, val_loss: 0.5054326176643371\n",
      "5883, train_loss: 0.5034647503724465, val_loss: 0.5068349123001099\n",
      "5884, train_loss: 0.5064237129229766, val_loss: 0.48037460446357727\n",
      "5885, train_loss: 0.5042100927004447, val_loss: 0.4990104794502258\n",
      "5886, train_loss: 0.5078061165717932, val_loss: 0.5066509425640107\n",
      "5887, train_loss: 0.50279967716107, val_loss: 0.5037663996219635\n",
      "5888, train_loss: 0.5077335169682136, val_loss: 0.48904397487640383\n",
      "5889, train_loss: 0.5040926933288574, val_loss: 0.49519097805023193\n",
      "5890, train_loss: 0.5076791987969325, val_loss: 0.49372501373291017\n",
      "5891, train_loss: 0.5036114454269409, val_loss: 0.5063864588737488\n",
      "5892, train_loss: 0.5038885531517175, val_loss: 0.4910763442516327\n",
      "5893, train_loss: 0.5061047375202179, val_loss: 0.4807408332824707\n",
      "5894, train_loss: 0.5054635405540466, val_loss: 0.5010029196739196\n",
      "5895, train_loss: 0.5075489385769918, val_loss: 0.48833987712860105\n",
      "5896, train_loss: 0.5037440428367028, val_loss: 0.49484952688217165\n",
      "5897, train_loss: 0.5031953969827065, val_loss: 0.5061638355255127\n",
      "5898, train_loss: 0.502787695481227, val_loss: 0.4809416472911835\n",
      "5899, train_loss: 0.5036563976452901, val_loss: 0.4990527808666229\n",
      "5900, train_loss: 0.5018344487135227, val_loss: 0.4887744665145874\n",
      "5901, train_loss: 0.5074229389429092, val_loss: 0.5004007637500762\n",
      "5902, train_loss: 0.5036315459471482, val_loss: 0.518441355228424\n",
      "5903, train_loss: 0.5047617164941934, val_loss: 0.4974405884742737\n",
      "5904, train_loss: 0.5035857902123377, val_loss: 0.5007046163082123\n",
      "5905, train_loss: 0.5073380791223966, val_loss: 0.48904321789741517\n",
      "5906, train_loss: 0.5035344648819703, val_loss: 0.4767102062702179\n",
      "5907, train_loss: 0.507270159629675, val_loss: 0.4789381444454193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5908, train_loss: 0.5045909652343163, val_loss: 0.5183518767356873\n",
      "5909, train_loss: 0.5028896457873858, val_loss: 0.5104643344879151\n",
      "5910, train_loss: 0.5072043125446026, val_loss: 0.5057224988937378\n",
      "5911, train_loss: 0.507128105713771, val_loss: 0.4940477848052979\n",
      "5912, train_loss: 0.5032124542273008, val_loss: 0.4738823354244232\n",
      "5913, train_loss: 0.5026703327894211, val_loss: 0.5056086659431458\n",
      "5914, train_loss: 0.503278503051171, val_loss: 0.5056045591831207\n",
      "5915, train_loss: 0.5056471400536023, val_loss: 0.49998719692230226\n",
      "5916, train_loss: 0.5043831307154435, val_loss: 0.4983636736869812\n",
      "5917, train_loss: 0.506940136735256, val_loss: 0.5043700814247132\n",
      "5918, train_loss: 0.5050989653055484, val_loss: 0.47392686605453493\n",
      "5919, train_loss: 0.5030404810722058, val_loss: 0.4880263149738312\n",
      "5920, train_loss: 0.5033232363370749, val_loss: 0.4998329222202301\n",
      "5921, train_loss: 0.5031811067691216, val_loss: 0.4974208533763885\n",
      "5922, train_loss: 0.5049594262471566, val_loss: 0.48472349643707274\n",
      "5923, train_loss: 0.5034305648161814, val_loss: 0.47985775470733644\n",
      "5924, train_loss: 0.5031009866641118, val_loss: 0.5044702887535095\n",
      "5925, train_loss: 0.5037658042632617, val_loss: 0.5010945200920105\n",
      "5926, train_loss: 0.5067170686446704, val_loss: 0.49144603610038756\n",
      "5927, train_loss: 0.5020232842518733, val_loss: 0.48713014721870423\n",
      "5928, train_loss: 0.5029106403772647, val_loss: 0.5040123939514161\n",
      "5929, train_loss: 0.5066641179414896, val_loss: 0.5039835333824157\n",
      "5930, train_loss: 0.5065861871609321, val_loss: 0.4884950041770935\n",
      "5931, train_loss: 0.5009455726696894, val_loss: 0.4796049058437347\n",
      "5932, train_loss: 0.5065358143586379, val_loss: 0.4788040518760681\n",
      "5933, train_loss: 0.5065462199541239, val_loss: 0.48407356142997743\n",
      "5934, train_loss: 0.5065218313382223, val_loss: 0.47939645051956176\n",
      "5935, train_loss: 0.5016536357311102, val_loss: 0.5096908390522004\n",
      "5936, train_loss: 0.5033947172073218, val_loss: 0.48479546308517457\n",
      "5937, train_loss: 0.5027567079434028, val_loss: 0.48825153708457947\n",
      "5938, train_loss: 0.5025800913572311, val_loss: 0.489398717880249\n",
      "5939, train_loss: 0.50186564716009, val_loss: 0.4997457981109619\n",
      "5940, train_loss: 0.5042083102923173, val_loss: 0.4817559659481049\n",
      "5941, train_loss: 0.5063103024776165, val_loss: 0.48088744282722473\n",
      "5942, train_loss: 0.5043899703484315, val_loss: 0.4915502667427063\n",
      "5943, train_loss: 0.5022173649989642, val_loss: 0.493238240480423\n",
      "5944, train_loss: 0.501713405434902, val_loss: 0.49315969944000243\n",
      "5945, train_loss: 0.5040637185940375, val_loss: 0.48599056601524354\n",
      "5946, train_loss: 0.5031054249176612, val_loss: 0.4974574685096741\n",
      "5947, train_loss: 0.501463227547132, val_loss: 0.49345457553863525\n",
      "5948, train_loss: 0.5040796158405451, val_loss: 0.5006357431411743\n",
      "5949, train_loss: 0.5060885262030822, val_loss: 0.5050197064876556\n",
      "5950, train_loss: 0.5060188116935583, val_loss: 0.4780694365501404\n",
      "5951, train_loss: 0.5060455546929286, val_loss: 0.48428799510002135\n",
      "5952, train_loss: 0.502456376185784, val_loss: 0.48693329095840454\n",
      "5953, train_loss: 0.5037096268855609, val_loss: 0.49361551403999326\n",
      "5954, train_loss: 0.5058875095385772, val_loss: 0.49974011182785033\n",
      "5955, train_loss: 0.5032008450764877, val_loss: 0.48330103754997256\n",
      "5956, train_loss: 0.5019012150856165, val_loss: 0.48317384719848633\n",
      "5957, train_loss: 0.501443203825217, val_loss: 0.5128813683986664\n",
      "5958, train_loss: 0.504453223485213, val_loss: 0.5005537092685699\n",
      "5959, train_loss: 0.5057557614950033, val_loss: 0.4859700739383698\n",
      "5960, train_loss: 0.5032180203841283, val_loss: 0.4908192574977875\n",
      "5961, train_loss: 0.5018811214428681, val_loss: 0.5005837678909302\n",
      "5962, train_loss: 0.5056328211839383, val_loss: 0.5001963555812836\n",
      "5963, train_loss: 0.5056451650766226, val_loss: 0.4965203464031219\n",
      "5964, train_loss: 0.5042491337427726, val_loss: 0.4992982268333435\n",
      "5965, train_loss: 0.5056073333208377, val_loss: 0.4964486360549927\n",
      "5966, train_loss: 0.501715572980734, val_loss: 0.4875013530254364\n",
      "5967, train_loss: 0.5025032999423834, val_loss: 0.49320181012153624\n",
      "5968, train_loss: 0.5028829047313104, val_loss: 0.4997247338294983\n",
      "5969, train_loss: 0.502858796944985, val_loss: 0.5031249403953553\n",
      "5970, train_loss: 0.5040766356083063, val_loss: 0.4877315700054169\n",
      "5971, train_loss: 0.5014880047394679, val_loss: 0.48460071086883544\n",
      "5972, train_loss: 0.5020430970650452, val_loss: 0.5037470877170562\n",
      "5973, train_loss: 0.50352942943573, val_loss: 0.5045850992202758\n",
      "5974, train_loss: 0.5006754914155374, val_loss: 0.5126197636127472\n",
      "5975, train_loss: 0.5053205260863671, val_loss: 0.50020991563797\n",
      "5976, train_loss: 0.5006137020312823, val_loss: 0.4858566462993622\n",
      "5977, train_loss: 0.505287223137342, val_loss: 0.5002683877944947\n",
      "5978, train_loss: 0.5005751412648421, val_loss: 0.4852116882801056\n",
      "5979, train_loss: 0.5025049654337076, val_loss: 0.48663637042045593\n",
      "5980, train_loss: 0.5051565915346146, val_loss: 0.498599773645401\n",
      "5981, train_loss: 0.5051003717459165, val_loss: 0.4995057761669159\n",
      "5982, train_loss: 0.5029474657315475, val_loss: 0.4972516059875488\n",
      "5983, train_loss: 0.502512969649755, val_loss: 0.48412084579467773\n",
      "5984, train_loss: 0.5050132950911155, val_loss: 0.48239641785621645\n",
      "5985, train_loss: 0.5010248640408883, val_loss: 0.4991218984127045\n",
      "5986, train_loss: 0.5023246522133167, val_loss: 0.49621607065200807\n",
      "5987, train_loss: 0.4995395518266238, val_loss: 0.4908703088760376\n",
      "5988, train_loss: 0.5049824932446847, val_loss: 0.474928742647171\n",
      "5989, train_loss: 0.5011934580711218, val_loss: 0.4958340048789978\n",
      "5990, train_loss: 0.5022791738693531, val_loss: 0.47924553155899047\n",
      "5991, train_loss: 0.5049101733244382, val_loss: 0.5086401045322418\n",
      "5992, train_loss: 0.5002088844776154, val_loss: 0.5039300143718719\n",
      "5993, train_loss: 0.5001290979293677, val_loss: 0.5039616405963898\n",
      "5994, train_loss: 0.5004518605195559, val_loss: 0.49858341813087464\n",
      "5995, train_loss: 0.5048441256468112, val_loss: 0.4786497473716736\n",
      "5996, train_loss: 0.5048538813224206, val_loss: 0.499122154712677\n",
      "5997, train_loss: 0.5020896975810711, val_loss: 0.48448447585105897\n",
      "5998, train_loss: 0.5047190418610206, val_loss: 0.4990581214427948\n",
      "5999, train_loss: 0.5007874507170457, val_loss: 0.48568198680877683\n",
      "6000, train_loss: 0.504687195787063, val_loss: 0.5037265300750733\n",
      "6001, train_loss: 0.4997524137680347, val_loss: 0.49837794303894045\n",
      "6002, train_loss: 0.5046480171955549, val_loss: 0.4858279824256897\n",
      "6003, train_loss: 0.5046055901509064, val_loss: 0.4910249590873718\n",
      "6004, train_loss: 0.5001307336183695, val_loss: 0.5028870463371277\n",
      "6005, train_loss: 0.5021805992493262, val_loss: 0.47097401022911073\n",
      "6006, train_loss: 0.5045063942670822, val_loss: 0.48183786273002627\n",
      "6007, train_loss: 0.5003413638243308, val_loss: 0.499147492647171\n",
      "6008, train_loss: 0.49961941975813645, val_loss: 0.4982185363769531\n",
      "6009, train_loss: 0.500111230290853, val_loss: 0.4838926553726196\n",
      "6010, train_loss: 0.5007147376353924, val_loss: 0.5079433023929596\n",
      "6011, train_loss: 0.5017131280440551, val_loss: 0.4957206606864929\n",
      "6012, train_loss: 0.5017754424076813, val_loss: 0.4861695647239685\n",
      "6013, train_loss: 0.5021743533702997, val_loss: 0.4866910636425018\n",
      "6014, train_loss: 0.500281001512821, val_loss: 0.49532232284545896\n",
      "6015, train_loss: 0.5024456473497244, val_loss: 0.4840261697769165\n",
      "6016, train_loss: 0.5026465413662103, val_loss: 0.48683562874794006\n",
      "6017, train_loss: 0.5015436433828794, val_loss: 0.4796716392040253\n",
      "6018, train_loss: 0.5016256983463581, val_loss: 0.4776570975780487\n",
      "6019, train_loss: 0.504124165727542, val_loss: 0.5033787727355957\n",
      "6020, train_loss: 0.5000783594755026, val_loss: 0.4885977029800415\n",
      "6021, train_loss: 0.5002127954593072, val_loss: 0.4792306959629059\n",
      "6022, train_loss: 0.5026428837042588, val_loss: 0.4952499806880951\n",
      "6023, train_loss: 0.5040511305515583, val_loss: 0.5032256841659546\n",
      "6024, train_loss: 0.5001699523283885, val_loss: 0.5004415214061737\n",
      "6025, train_loss: 0.5039844134679208, val_loss: 0.5018769383430481\n",
      "6026, train_loss: 0.5012478977441788, val_loss: 0.4986179113388062\n",
      "6027, train_loss: 0.49985148585759676, val_loss: 0.48389683961868285\n",
      "6028, train_loss: 0.5002103459376556, val_loss: 0.4949265420436859\n",
      "6029, train_loss: 0.5012217588149585, val_loss: 0.4917332768440247\n",
      "6030, train_loss: 0.4995075876896198, val_loss: 0.4982000946998596\n",
      "6031, train_loss: 0.5038822992489889, val_loss: 0.4801349401473999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6032, train_loss: 0.5011390619553052, val_loss: 0.4786474108695984\n",
      "6033, train_loss: 0.5037881731987, val_loss: 0.4975160777568817\n",
      "6034, train_loss: 0.5037926320846264, val_loss: 0.5154890775680542\n",
      "6035, train_loss: 0.5037377499617063, val_loss: 0.5154220044612885\n",
      "6036, train_loss: 0.5037492387569867, val_loss: 0.49829223155975344\n",
      "6037, train_loss: 0.501544272670379, val_loss: 0.479536110162735\n",
      "6038, train_loss: 0.49879319621966434, val_loss: 0.5153292000293732\n",
      "6039, train_loss: 0.5036601321055338, val_loss: 0.48448596000671384\n",
      "6040, train_loss: 0.500075020469152, val_loss: 0.4738504409790039\n",
      "6041, train_loss: 0.5036224780174402, val_loss: 0.4808612525463104\n",
      "6042, train_loss: 0.4992071344302251, val_loss: 0.4969426512718201\n",
      "6043, train_loss: 0.5036366547529514, val_loss: 0.47800239324569704\n",
      "6044, train_loss: 0.5035803845295539, val_loss: 0.48927255868911745\n",
      "6045, train_loss: 0.5035598530219152, val_loss: 0.5022859573364258\n",
      "6046, train_loss: 0.4985201908991887, val_loss: 0.4761582434177399\n",
      "6047, train_loss: 0.5035363653531442, val_loss: 0.482608437538147\n",
      "6048, train_loss: 0.5035263311404449, val_loss: 0.514870572090149\n",
      "6049, train_loss: 0.5034503054160339, val_loss: 0.48880091309547424\n",
      "6050, train_loss: 0.5020411530366311, val_loss: 0.5014976143836976\n",
      "6051, train_loss: 0.5033572625655395, val_loss: 0.479910147190094\n",
      "6052, train_loss: 0.5033621799487334, val_loss: 0.49681344628334045\n",
      "6053, train_loss: 0.49864698831851667, val_loss: 0.49763417840003965\n",
      "6054, train_loss: 0.5033137500286102, val_loss: 0.5101921916007995\n",
      "6055, train_loss: 0.5007364623821698, val_loss: 0.5149907350540162\n",
      "6056, train_loss: 0.50106536425077, val_loss: 0.5068255603313446\n",
      "6057, train_loss: 0.4993495482664842, val_loss: 0.5007700622081757\n",
      "6058, train_loss: 0.5031717889584028, val_loss: 0.48887261748313904\n",
      "6059, train_loss: 0.4996173966389436, val_loss: 0.49933320879936216\n",
      "6060, train_loss: 0.5009543620623075, val_loss: 0.5022788763046264\n",
      "6061, train_loss: 0.49900601231134856, val_loss: 0.488868910074234\n",
      "6062, train_loss: 0.5030378779539695, val_loss: 0.496173232793808\n",
      "6063, train_loss: 0.5008083490224985, val_loss: 0.4946687340736389\n",
      "6064, train_loss: 0.500629221017544, val_loss: 0.4789948046207428\n",
      "6065, train_loss: 0.5011426829374753, val_loss: 0.49767311811447146\n",
      "6066, train_loss: 0.5029017558464637, val_loss: 0.5014431238174438\n",
      "6067, train_loss: 0.502852547627229, val_loss: 0.5069153070449829\n",
      "6068, train_loss: 0.4981673417183069, val_loss: 0.48582765460014343\n",
      "6069, train_loss: 0.4976229931299503, val_loss: 0.5021318376064301\n",
      "6070, train_loss: 0.5006051258398936, val_loss: 0.49287636280059816\n",
      "6071, train_loss: 0.5027354073065978, val_loss: 0.49343016743659973\n",
      "6072, train_loss: 0.5011696849878018, val_loss: 0.4945231258869171\n",
      "6073, train_loss: 0.49830745733701265, val_loss: 0.5011860311031342\n",
      "6074, train_loss: 0.49793776067403644, val_loss: 0.4750492095947266\n",
      "6075, train_loss: 0.49914372769685894, val_loss: 0.48357169032096864\n",
      "6076, train_loss: 0.4981360389636113, val_loss: 0.4888860583305359\n",
      "6077, train_loss: 0.5026401155270063, val_loss: 0.4758364915847778\n",
      "6078, train_loss: 0.5026336243519416, val_loss: 0.4805935263633728\n",
      "6079, train_loss: 0.502571376470419, val_loss: 0.5098403751850128\n",
      "6080, train_loss: 0.4989779373774162, val_loss: 0.5097695350646972\n",
      "6081, train_loss: 0.49810694272701556, val_loss: 0.4962912619113922\n",
      "6082, train_loss: 0.5010466472460673, val_loss: 0.4843972146511078\n",
      "6083, train_loss: 0.4999322925622647, val_loss: 0.5017073035240174\n",
      "6084, train_loss: 0.5002353007976825, val_loss: 0.4837316989898682\n",
      "6085, train_loss: 0.49906849975769335, val_loss: 0.501687866449356\n",
      "6086, train_loss: 0.5005228244341337, val_loss: 0.4978940963745117\n",
      "6087, train_loss: 0.5003952429844782, val_loss: 0.4967977523803711\n",
      "6088, train_loss: 0.49840606634433454, val_loss: 0.5026220262050629\n",
      "6089, train_loss: 0.4996638114635761, val_loss: 0.5027387917041779\n",
      "6090, train_loss: 0.5022604110149237, val_loss: 0.5026127159595489\n",
      "6091, train_loss: 0.502220712029017, val_loss: 0.5147582173347474\n",
      "6092, train_loss: 0.49851969801462614, val_loss: 0.5010274708271026\n",
      "6093, train_loss: 0.4990325077221944, val_loss: 0.49366451501846315\n",
      "6094, train_loss: 0.4995612043600816, val_loss: 0.5003153324127197\n",
      "6095, train_loss: 0.5021172314882278, val_loss: 0.5146108031272888\n",
      "6096, train_loss: 0.5020787521050527, val_loss: 0.4965217649936676\n",
      "6097, train_loss: 0.4976523449787727, val_loss: 0.4755305230617523\n",
      "6098, train_loss: 0.5009742711599057, val_loss: 0.5015378296375275\n",
      "6099, train_loss: 0.5020184769080236, val_loss: 0.4967170715332031\n",
      "6100, train_loss: 0.499230132653163, val_loss: 0.4963774442672729\n",
      "6101, train_loss: 0.49752152539216554, val_loss: 0.47920987010002136\n",
      "6102, train_loss: 0.4979944767860266, val_loss: 0.4697887420654297\n",
      "6103, train_loss: 0.49976879816788894, val_loss: 0.49987573027610777\n",
      "6104, train_loss: 0.4972298535016867, val_loss: 0.49691529870033263\n",
      "6105, train_loss: 0.5018606988283304, val_loss: 0.4840706467628479\n",
      "6106, train_loss: 0.4991000478084271, val_loss: 0.49521101713180543\n",
      "6107, train_loss: 0.4977135429015526, val_loss: 0.4963145315647125\n",
      "6108, train_loss: 0.501761088004479, val_loss: 0.48165624141693114\n",
      "6109, train_loss: 0.4976580750483733, val_loss: 0.4886401355266571\n",
      "6110, train_loss: 0.5017242993299778, val_loss: 0.5005240917205811\n",
      "6111, train_loss: 0.49909984033841354, val_loss: 0.4850330948829651\n",
      "6112, train_loss: 0.4989115549967839, val_loss: 0.4824541211128235\n",
      "6113, train_loss: 0.5016307635949209, val_loss: 0.5094747960567474\n",
      "6114, train_loss: 0.5015833458075156, val_loss: 0.49688441157341\n",
      "6115, train_loss: 0.4987224122652641, val_loss: 0.4938589155673981\n",
      "6116, train_loss: 0.49634834894767177, val_loss: 0.48162779211997986\n",
      "6117, train_loss: 0.4979367313476709, val_loss: 0.47130261063575746\n",
      "6118, train_loss: 0.4984554614012058, val_loss: 0.47519962191581727\n",
      "6119, train_loss: 0.4983806277696903, val_loss: 0.4791417598724365\n",
      "6120, train_loss: 0.49845519203406113, val_loss: 0.4933370232582092\n",
      "6121, train_loss: 0.49759923953276414, val_loss: 0.4934397578239441\n",
      "6122, train_loss: 0.5014059864557706, val_loss: 0.4933568835258484\n",
      "6123, train_loss: 0.501391908297172, val_loss: 0.49547743797302246\n",
      "6124, train_loss: 0.5014205792775521, val_loss: 0.48937254548072817\n",
      "6125, train_loss: 0.5014109451037186, val_loss: 0.47625466585159304\n",
      "6126, train_loss: 0.5013497208173459, val_loss: 0.4750836193561554\n",
      "6127, train_loss: 0.501380667090416, val_loss: 0.49180774092674256\n",
      "6128, train_loss: 0.49825385442146886, val_loss: 0.49966983795166015\n",
      "6129, train_loss: 0.49871093607865846, val_loss: 0.48258848786354064\n",
      "6130, train_loss: 0.5012636264929404, val_loss: 0.47784915566444397\n",
      "6131, train_loss: 0.4964841604232788, val_loss: 0.47428505420684813\n",
      "6132, train_loss: 0.4998049701635654, val_loss: 0.49900734424591064\n",
      "6133, train_loss: 0.5011774049355433, val_loss: 0.5004802703857422\n",
      "6134, train_loss: 0.501108861886538, val_loss: 0.4876242637634277\n",
      "6135, train_loss: 0.4966634213924408, val_loss: 0.5051899313926697\n",
      "6136, train_loss: 0.4972559752372595, val_loss: 0.5087801277637481\n",
      "6137, train_loss: 0.49669844255997586, val_loss: 0.48221208453178405\n",
      "6138, train_loss: 0.49644896158805263, val_loss: 0.4874120891094208\n",
      "6139, train_loss: 0.5009770530920762, val_loss: 0.4808441877365112\n",
      "6140, train_loss: 0.4970438870099875, val_loss: 0.4808845579624176\n",
      "6141, train_loss: 0.4990444091650156, val_loss: 0.5133298516273499\n",
      "6142, train_loss: 0.5009247076052886, val_loss: 0.47985556721687317\n",
      "6143, train_loss: 0.49620269582821774, val_loss: 0.4737663149833679\n",
      "6144, train_loss: 0.5008794241226636, val_loss: 0.48643837571144105\n",
      "6145, train_loss: 0.5008401125669479, val_loss: 0.49489009380340576\n",
      "6146, train_loss: 0.5008029616796054, val_loss: 0.5002537190914154\n",
      "6147, train_loss: 0.5007905994470303, val_loss: 0.4813685715198517\n",
      "6148, train_loss: 0.49863220292788285, val_loss: 0.4920294463634491\n",
      "6149, train_loss: 0.500754693379769, val_loss: 0.5002588152885437\n",
      "6150, train_loss: 0.4967973782466008, val_loss: 0.47987295389175416\n",
      "6151, train_loss: 0.4967410277861815, val_loss: 0.4857546627521515\n",
      "6152, train_loss: 0.4980422120827895, val_loss: 0.49534178972244264\n",
      "6153, train_loss: 0.5006005133573825, val_loss: 0.4783164024353027\n",
      "6154, train_loss: 0.5005710193744073, val_loss: 0.49278897047042847\n",
      "6155, train_loss: 0.5005360199854925, val_loss: 0.5048471808433532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6156, train_loss: 0.500524287040417, val_loss: 0.4753233253955841\n",
      "6157, train_loss: 0.4967006559555347, val_loss: 0.473373943567276\n",
      "6158, train_loss: 0.5005280535954696, val_loss: 0.4907418727874756\n",
      "6159, train_loss: 0.5004887259923495, val_loss: 0.47878405451774597\n",
      "6160, train_loss: 0.4956878274679184, val_loss: 0.48697423934936523\n",
      "6161, train_loss: 0.5004330392067249, val_loss: 0.4910719871520996\n",
      "6162, train_loss: 0.49568324708021605, val_loss: 0.4880707383155823\n",
      "6163, train_loss: 0.500434045608227, val_loss: 0.4949779033660889\n",
      "6164, train_loss: 0.5004307662065213, val_loss: 0.47049381136894225\n",
      "6165, train_loss: 0.5003952223521012, val_loss: 0.5123202323913574\n",
      "6166, train_loss: 0.5003997179178091, val_loss: 0.47344602942466735\n",
      "6167, train_loss: 0.4964487529717959, val_loss: 0.48566409945487976\n",
      "6168, train_loss: 0.5003644159206977, val_loss: 0.5120951116085053\n",
      "6169, train_loss: 0.4980458216025279, val_loss: 0.500061857700348\n",
      "6170, train_loss: 0.5002779421898035, val_loss: 0.48202463388442995\n",
      "6171, train_loss: 0.5002472400665283, val_loss: 0.47319995164871215\n",
      "6172, train_loss: 0.5002270501393539, val_loss: 0.4984580159187317\n",
      "6173, train_loss: 0.4957774384663655, val_loss: 0.5000493049621582\n",
      "6174, train_loss: 0.4955854152257626, val_loss: 0.4854340672492981\n",
      "6175, train_loss: 0.49699486104341656, val_loss: 0.49113945960998534\n",
      "6176, train_loss: 0.4956834534039864, val_loss: 0.4855417013168335\n",
      "6177, train_loss: 0.4962567732884334, val_loss: 0.47643699645996096\n",
      "6178, train_loss: 0.5000248688917893, val_loss: 0.4916009485721588\n",
      "6179, train_loss: 0.49999695213941425, val_loss: 0.4938500583171844\n",
      "6180, train_loss: 0.49995557963848114, val_loss: 0.4783101141452789\n",
      "6181, train_loss: 0.49998334967173064, val_loss: 0.469613641500473\n",
      "6182, train_loss: 0.4972641101250282, val_loss: 0.4823855996131897\n",
      "6183, train_loss: 0.49992192823153275, val_loss: 0.4976707100868225\n",
      "6184, train_loss: 0.49988584449658024, val_loss: 0.49910750389099123\n",
      "6185, train_loss: 0.49458712568649876, val_loss: 0.5072431087493896\n",
      "6186, train_loss: 0.49573880777909207, val_loss: 0.4693803071975708\n",
      "6187, train_loss: 0.4951039759012369, val_loss: 0.48526981472969055\n",
      "6188, train_loss: 0.49718445654098803, val_loss: 0.49745580554008484\n",
      "6189, train_loss: 0.49973798715151274, val_loss: 0.49356684684753416\n",
      "6190, train_loss: 0.4950279559080417, val_loss: 0.4668710947036743\n",
      "6191, train_loss: 0.4977302642968985, val_loss: 0.5117215216159821\n",
      "6192, train_loss: 0.4996911814579597, val_loss: 0.49729514718055723\n",
      "6193, train_loss: 0.4957574147444505, val_loss: 0.4978706955909729\n",
      "6194, train_loss: 0.49464701689206636, val_loss: 0.472403484582901\n",
      "6195, train_loss: 0.4996476872609212, val_loss: 0.4977122485637665\n",
      "6196, train_loss: 0.4970231984670346, val_loss: 0.48752983212471007\n",
      "6197, train_loss: 0.49954692675517154, val_loss: 0.5035671114921569\n",
      "6198, train_loss: 0.494032621383667, val_loss: 0.47769835591316223\n",
      "6199, train_loss: 0.49951185056796443, val_loss: 0.49414504766464235\n",
      "6200, train_loss: 0.49950096813532024, val_loss: 0.4760307550430298\n",
      "6201, train_loss: 0.49724522691506606, val_loss: 0.4931916773319244\n",
      "6202, train_loss: 0.49606773486504185, val_loss: 0.47658228874206543\n",
      "6203, train_loss: 0.4975803620540179, val_loss: 0.48934239745140073\n",
      "6204, train_loss: 0.4962114439560817, val_loss: 0.49869970679283143\n",
      "6205, train_loss: 0.49930875920332396, val_loss: 0.47675061225891113\n",
      "6206, train_loss: 0.49456518315351927, val_loss: 0.4899976313114166\n",
      "6207, train_loss: 0.49729290489967054, val_loss: 0.4696012675762177\n",
      "6208, train_loss: 0.4992561615430392, val_loss: 0.4940168857574463\n",
      "6209, train_loss: 0.4966485798358917, val_loss: 0.5067517995834351\n",
      "6210, train_loss: 0.49551231815264773, val_loss: 0.49766733050346373\n",
      "6211, train_loss: 0.4991706678500542, val_loss: 0.49764997363090513\n",
      "6212, train_loss: 0.49535297659727245, val_loss: 0.4779439628124237\n",
      "6213, train_loss: 0.49669321454488313, val_loss: 0.4851569950580597\n",
      "6214, train_loss: 0.49717373572863066, val_loss: 0.4984488070011139\n",
      "6215, train_loss: 0.4990355567290233, val_loss: 0.47903725504875183\n",
      "6216, train_loss: 0.4990183527653034, val_loss: 0.47922423481941223\n",
      "6217, train_loss: 0.4989360880393248, val_loss: 0.4911236703395844\n",
      "6218, train_loss: 0.4989398752267544, val_loss: 0.4940043747425079\n",
      "6219, train_loss: 0.49506839078206283, val_loss: 0.48463268876075744\n",
      "6220, train_loss: 0.49889440261400664, val_loss: 0.4808803915977478\n",
      "6221, train_loss: 0.49580140526478106, val_loss: 0.48551869988441465\n",
      "6222, train_loss: 0.49412132226503813, val_loss: 0.47117137908935547\n",
      "6223, train_loss: 0.4951190799474716, val_loss: 0.4925839722156525\n",
      "6224, train_loss: 0.4960596549969453, val_loss: 0.46572964191436766\n",
      "6225, train_loss: 0.4988230329293471, val_loss: 0.48509045243263244\n",
      "6226, train_loss: 0.4987646455948169, val_loss: 0.49370392560958865\n",
      "6227, train_loss: 0.4963591717756711, val_loss: 0.48506870269775393\n",
      "6228, train_loss: 0.4949993605797107, val_loss: 0.48057634234428404\n",
      "6229, train_loss: 0.49675040061657244, val_loss: 0.47172329425811765\n",
      "6230, train_loss: 0.4971341857543358, val_loss: 0.4938609480857849\n",
      "6231, train_loss: 0.49630864652303547, val_loss: 0.4938520610332489\n",
      "6232, train_loss: 0.498606868661367, val_loss: 0.49667046666145326\n",
      "6233, train_loss: 0.4985652474256662, val_loss: 0.49002503156661986\n",
      "6234, train_loss: 0.49409140875706303, val_loss: 0.49264256954193114\n",
      "6235, train_loss: 0.49573288743312544, val_loss: 0.48269538283348085\n",
      "6236, train_loss: 0.4984613840396588, val_loss: 0.4897496998310089\n",
      "6237, train_loss: 0.49464645179418415, val_loss: 0.47636899948120115\n",
      "6238, train_loss: 0.49838939767617446, val_loss: 0.48953937292099\n",
      "6239, train_loss: 0.4950180626832522, val_loss: 0.49251754879951476\n",
      "6240, train_loss: 0.4983582622729815, val_loss: 0.47266841530799864\n",
      "6241, train_loss: 0.49523351284173817, val_loss: 0.48428643941879274\n",
      "6242, train_loss: 0.4938393384218216, val_loss: 0.5062359571456909\n",
      "6243, train_loss: 0.4983000789697354, val_loss: 0.49346197247505186\n",
      "6244, train_loss: 0.4944190497581775, val_loss: 0.4794132232666016\n",
      "6245, train_loss: 0.4982380179258493, val_loss: 0.511041796207428\n",
      "6246, train_loss: 0.49597440086878264, val_loss: 0.4841809868812561\n",
      "6247, train_loss: 0.4981551514222072, val_loss: 0.490060156583786\n",
      "6248, train_loss: 0.49704515360868895, val_loss: 0.4934414863586426\n",
      "6249, train_loss: 0.496259773006806, val_loss: 0.48510017395019533\n",
      "6250, train_loss: 0.49805154823339903, val_loss: 0.4972601354122162\n",
      "6251, train_loss: 0.49805541107287776, val_loss: 0.4848381280899048\n",
      "6252, train_loss: 0.4942667151872928, val_loss: 0.47608699798583987\n",
      "6253, train_loss: 0.49612776132730335, val_loss: 0.47839435338974\n",
      "6254, train_loss: 0.49795110867573666, val_loss: 0.4895202457904816\n",
      "6255, train_loss: 0.49512307804364425, val_loss: 0.4745366096496582\n",
      "6256, train_loss: 0.49401500018743366, val_loss: 0.49307842254638673\n",
      "6257, train_loss: 0.4963706823495718, val_loss: 0.46897372603416443\n",
      "6258, train_loss: 0.4978532206553679, val_loss: 0.4775230348110199\n",
      "6259, train_loss: 0.4934805196065169, val_loss: 0.48159810304641726\n",
      "6260, train_loss: 0.49309495091438293, val_loss: 0.48783957958221436\n",
      "6261, train_loss: 0.49598466662260204, val_loss: 0.49029396176338197\n",
      "6262, train_loss: 0.4934215121544324, val_loss: 0.4930885374546051\n",
      "6263, train_loss: 0.4954574085198916, val_loss: 0.4768198192119598\n",
      "6264, train_loss: 0.4977800387602586, val_loss: 0.4974659442901611\n",
      "6265, train_loss: 0.49769603518339306, val_loss: 0.4803196549415588\n",
      "6266, train_loss: 0.4947804476206119, val_loss: 0.4985233902931213\n",
      "6267, train_loss: 0.49762789790446943, val_loss: 0.4895662546157837\n",
      "6268, train_loss: 0.4932260708167003, val_loss: 0.5106947422027588\n",
      "6269, train_loss: 0.49766758657418764, val_loss: 0.49245978593826295\n",
      "6270, train_loss: 0.49440121994568753, val_loss: 0.4889098763465881\n",
      "6271, train_loss: 0.493090427838839, val_loss: 0.4776827335357666\n",
      "6272, train_loss: 0.497575316291589, val_loss: 0.4858376085758209\n",
      "6273, train_loss: 0.49757164831344897, val_loss: 0.48021867871284485\n",
      "6274, train_loss: 0.49477779750640577, val_loss: 0.49722546339035034\n",
      "6275, train_loss: 0.49385375128342557, val_loss: 0.4832037687301636\n",
      "6276, train_loss: 0.4974131549780185, val_loss: 0.4737602949142456\n",
      "6277, train_loss: 0.4974742222290773, val_loss: 0.4762060046195984\n",
      "6278, train_loss: 0.4973888122118436, val_loss: 0.4859199523925781\n",
      "6279, train_loss: 0.49189308514961827, val_loss: 0.48407121300697326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6280, train_loss: 0.4916318276753792, val_loss: 0.4924738943576813\n",
      "6281, train_loss: 0.49745544676597303, val_loss: 0.4677468538284302\n",
      "6282, train_loss: 0.4927530368933311, val_loss: 0.47797698974609376\n",
      "6283, train_loss: 0.4973633564435519, val_loss: 0.5050006747245789\n",
      "6284, train_loss: 0.4973672330379486, val_loss: 0.47556493282318113\n",
      "6285, train_loss: 0.4945249018760828, val_loss: 0.4885741949081421\n",
      "6286, train_loss: 0.4927847236394882, val_loss: 0.47505484223365785\n",
      "6287, train_loss: 0.4972680222529631, val_loss: 0.47603908777236936\n",
      "6288, train_loss: 0.49527440735927, val_loss: 0.4973957002162933\n",
      "6289, train_loss: 0.492785414824119, val_loss: 0.49089027047157285\n",
      "6290, train_loss: 0.49716523404304797, val_loss: 0.47792690992355347\n",
      "6291, train_loss: 0.49566163695775545, val_loss: 0.46792388558387754\n",
      "6292, train_loss: 0.4922107572738941, val_loss: 0.49093857407569885\n",
      "6293, train_loss: 0.49392935977532315, val_loss: 0.5049145340919494\n",
      "6294, train_loss: 0.4928403932314653, val_loss: 0.49639679193496705\n",
      "6295, train_loss: 0.4945838566009815, val_loss: 0.4744658529758453\n",
      "6296, train_loss: 0.49419214633794933, val_loss: 0.47904533743858335\n",
      "6297, train_loss: 0.49692562222480774, val_loss: 0.4885687530040741\n",
      "6298, train_loss: 0.49531909364920396, val_loss: 0.5097787618637085\n",
      "6299, train_loss: 0.49420565825242263, val_loss: 0.49741280674934385\n",
      "6300, train_loss: 0.492098032281949, val_loss: 0.4744893014431\n",
      "6301, train_loss: 0.49685916763085586, val_loss: 0.4922601044178009\n",
      "6302, train_loss: 0.4917113540264276, val_loss: 0.4696276605129242\n",
      "6303, train_loss: 0.49520740715356976, val_loss: 0.5046285212039947\n",
      "6304, train_loss: 0.4936685458971904, val_loss: 0.48895445466041565\n",
      "6305, train_loss: 0.49675984451403987, val_loss: 0.5094306707382202\n",
      "6306, train_loss: 0.4931363004904527, val_loss: 0.4833950877189636\n",
      "6307, train_loss: 0.4926069745650658, val_loss: 0.4961048424243927\n",
      "6308, train_loss: 0.49672435911802143, val_loss: 0.49696677923202515\n",
      "6309, train_loss: 0.493875285753837, val_loss: 0.48886876702308657\n",
      "6310, train_loss: 0.49665758930719817, val_loss: 0.4828524589538574\n",
      "6311, train_loss: 0.493829872745734, val_loss: 0.47946408987045286\n",
      "6312, train_loss: 0.4965571635044538, val_loss: 0.47639371156692506\n",
      "6313, train_loss: 0.49210385175851673, val_loss: 0.4945279598236084\n",
      "6314, train_loss: 0.49507156358315396, val_loss: 0.49601663947105407\n",
      "6315, train_loss: 0.49401899599112, val_loss: 0.47004168629646303\n",
      "6316, train_loss: 0.4964605581301909, val_loss: 0.4873848259449005\n",
      "6317, train_loss: 0.4919848877650041, val_loss: 0.5042799115180969\n",
      "6318, train_loss: 0.4964614063501358, val_loss: 0.48268517255783083\n",
      "6319, train_loss: 0.49642726205862486, val_loss: 0.5042283177375794\n",
      "6320, train_loss: 0.49641992954107433, val_loss: 0.48832463622093203\n",
      "6321, train_loss: 0.4924860206934122, val_loss: 0.48754081726074217\n",
      "6322, train_loss: 0.4917710079596593, val_loss: 0.48806952834129336\n",
      "6323, train_loss: 0.49639517298111546, val_loss: 0.49012464880943296\n",
      "6324, train_loss: 0.49440341614759886, val_loss: 0.47963046431541445\n",
      "6325, train_loss: 0.4962492264234103, val_loss: 0.5089696228504181\n",
      "6326, train_loss: 0.49624697864055634, val_loss: 0.4795689761638641\n",
      "6327, train_loss: 0.4924206091807439, val_loss: 0.47197293043136596\n",
      "6328, train_loss: 0.49141215819578904, val_loss: 0.47397109866142273\n",
      "6329, train_loss: 0.4939262591875516, val_loss: 0.494948673248291\n",
      "6330, train_loss: 0.49388120495356047, val_loss: 0.48828468322753904\n",
      "6331, train_loss: 0.4914646710340793, val_loss: 0.4949696481227875\n",
      "6332, train_loss: 0.49373875099879044, val_loss: 0.4733290195465088\n",
      "6333, train_loss: 0.49604201775330764, val_loss: 0.49154640436172486\n",
      "6334, train_loss: 0.495989943926151, val_loss: 0.4917367517948151\n",
      "6335, train_loss: 0.49328919098927426, val_loss: 0.4957805573940277\n",
      "6336, train_loss: 0.4919496648586713, val_loss: 0.5091439843177795\n",
      "6337, train_loss: 0.49593246900118315, val_loss: 0.47396191358566286\n",
      "6338, train_loss: 0.49590106079211604, val_loss: 0.4843291461467743\n",
      "6339, train_loss: 0.4958510662500675, val_loss: 0.4872900784015656\n",
      "6340, train_loss: 0.4958332031965256, val_loss: 0.4949060320854187\n",
      "6341, train_loss: 0.49207697006372303, val_loss: 0.4743362903594971\n",
      "6342, train_loss: 0.4957879586861684, val_loss: 0.503903615474701\n",
      "6343, train_loss: 0.49309146862763625, val_loss: 0.491047728061676\n",
      "6344, train_loss: 0.49195937926952654, val_loss: 0.49412608742713926\n",
      "6345, train_loss: 0.4914599840457623, val_loss: 0.48301392793655396\n",
      "6346, train_loss: 0.49287146444504076, val_loss: 0.49562252759933473\n",
      "6347, train_loss: 0.49206484166475445, val_loss: 0.48765559792518615\n",
      "6348, train_loss: 0.49101560505536884, val_loss: 0.4946064591407776\n",
      "6349, train_loss: 0.49410800635814667, val_loss: 0.4824725925922394\n",
      "6350, train_loss: 0.4955550856315173, val_loss: 0.4750283777713776\n",
      "6351, train_loss: 0.4918255095298474, val_loss: 0.4805865943431854\n",
      "6352, train_loss: 0.49160827925572026, val_loss: 0.476470535993576\n",
      "6353, train_loss: 0.49549200099248153, val_loss: 0.495315945148468\n",
      "6354, train_loss: 0.4954433005589705, val_loss: 0.4785355508327484\n",
      "6355, train_loss: 0.49092304706573486, val_loss: 0.5002397060394287\n",
      "6356, train_loss: 0.4954254042643767, val_loss: 0.4924195110797882\n",
      "6357, train_loss: 0.49127827699367815, val_loss: 0.5036284983158111\n",
      "6358, train_loss: 0.4925655390207584, val_loss: 0.4772962093353271\n",
      "6359, train_loss: 0.4915733474951524, val_loss: 0.48974440097808836\n",
      "6360, train_loss: 0.4908654277141278, val_loss: 0.4717928409576416\n",
      "6361, train_loss: 0.49530031360112703, val_loss: 0.5085725247859955\n",
      "6362, train_loss: 0.49026298179076266, val_loss: 0.4877607226371765\n",
      "6363, train_loss: 0.49528713753590214, val_loss: 0.4935867428779602\n",
      "6364, train_loss: 0.4913550913333893, val_loss: 0.4729159414768219\n",
      "6365, train_loss: 0.49325196788861203, val_loss: 0.4761712372303009\n",
      "6366, train_loss: 0.49094972702173084, val_loss: 0.4834830105304718\n",
      "6367, train_loss: 0.49239921225951266, val_loss: 0.4893661022186279\n",
      "6368, train_loss: 0.49518468288274914, val_loss: 0.4816197454929352\n",
      "6369, train_loss: 0.49510664550157696, val_loss: 0.4744147539138794\n",
      "6370, train_loss: 0.4928399616709122, val_loss: 0.48365670442581177\n",
      "6371, train_loss: 0.49132315585246455, val_loss: 0.47615193128585814\n",
      "6372, train_loss: 0.4950478065472383, val_loss: 0.495678174495697\n",
      "6373, train_loss: 0.4950635123711366, val_loss: 0.4660847902297974\n",
      "6374, train_loss: 0.49056605994701385, val_loss: 0.4767359495162964\n",
      "6375, train_loss: 0.4907621225485435, val_loss: 0.4995070159435272\n",
      "6376, train_loss: 0.4949603619483801, val_loss: 0.4813037931919098\n",
      "6377, train_loss: 0.4949207523694405, val_loss: 0.48738022446632384\n",
      "6378, train_loss: 0.49494780829319585, val_loss: 0.46725329756736755\n",
      "6379, train_loss: 0.4932811764570383, val_loss: 0.48137531280517576\n",
      "6380, train_loss: 0.4928685472561763, val_loss: 0.4862969398498535\n",
      "6381, train_loss: 0.4947981398839217, val_loss: 0.48509477972984316\n",
      "6382, train_loss: 0.4915175231603476, val_loss: 0.4955519914627075\n",
      "6383, train_loss: 0.4947704655619768, val_loss: 0.48743962645530703\n",
      "6384, train_loss: 0.4909334515149777, val_loss: 0.46507076621055604\n",
      "6385, train_loss: 0.49475438548968387, val_loss: 0.5077205717563629\n",
      "6386, train_loss: 0.49014742099321806, val_loss: 0.4780216574668884\n",
      "6387, train_loss: 0.4947472822207671, val_loss: 0.48935834169387815\n",
      "6388, train_loss: 0.49466995665660274, val_loss: 0.47607550024986267\n",
      "6389, train_loss: 0.4946729368888415, val_loss: 0.4896629095077515\n",
      "6390, train_loss: 0.49073564318510204, val_loss: 0.4815313875675201\n",
      "6391, train_loss: 0.4904940460736935, val_loss: 0.4911714673042297\n",
      "6392, train_loss: 0.49460244981142193, val_loss: 0.4816662669181824\n",
      "6393, train_loss: 0.4906602530525281, val_loss: 0.4842178881168365\n",
      "6394, train_loss: 0.4921765545239815, val_loss: 0.46958543062210084\n",
      "6395, train_loss: 0.49449211015151096, val_loss: 0.46895551681518555\n",
      "6396, train_loss: 0.48885139708335584, val_loss: 0.49327571988105773\n",
      "6397, train_loss: 0.49082624969574123, val_loss: 0.47457022666931153\n",
      "6398, train_loss: 0.49073647535764253, val_loss: 0.49098131656646726\n",
      "6399, train_loss: 0.4894452542066574, val_loss: 0.4883767247200012\n",
      "6400, train_loss: 0.4944007625946632, val_loss: 0.4863804459571838\n",
      "6401, train_loss: 0.4943596984331424, val_loss: 0.4926077425479889\n",
      "6402, train_loss: 0.4899060187431482, val_loss: 0.4948694407939911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6403, train_loss: 0.49202391734490025, val_loss: 0.4925534904003143\n",
      "6404, train_loss: 0.49010855761858135, val_loss: 0.4733258843421936\n",
      "6405, train_loss: 0.4906180248810695, val_loss: 0.484329354763031\n",
      "6406, train_loss: 0.4903083283167619, val_loss: 0.46444140672683715\n",
      "6407, train_loss: 0.49032434821128845, val_loss: 0.4929215729236603\n",
      "6408, train_loss: 0.4900867732671591, val_loss: 0.48881487250328065\n",
      "6409, train_loss: 0.49268624301140124, val_loss: 0.4822396457195282\n",
      "6410, train_loss: 0.48899455483143145, val_loss: 0.481879061460495\n",
      "6411, train_loss: 0.4942021473095967, val_loss: 0.48578407168388366\n",
      "6412, train_loss: 0.49414155116448033, val_loss: 0.48191174268722536\n",
      "6413, train_loss: 0.4895926152284329, val_loss: 0.47538298964500425\n",
      "6414, train_loss: 0.49413419228333694, val_loss: 0.46601776480674745\n",
      "6415, train_loss: 0.4941156334601916, val_loss: 0.48584685325622556\n",
      "6416, train_loss: 0.4901491483816734, val_loss: 0.46682912707328794\n",
      "6417, train_loss: 0.49096822853271777, val_loss: 0.49321812987327573\n",
      "6418, train_loss: 0.4894830103103931, val_loss: 0.5063907921314239\n",
      "6419, train_loss: 0.4908799872948573, val_loss: 0.5064428687095642\n",
      "6420, train_loss: 0.4939755659836989, val_loss: 0.47607043385505676\n",
      "6421, train_loss: 0.49397048354148865, val_loss: 0.5062988996505737\n",
      "6422, train_loss: 0.49390651285648346, val_loss: 0.47084023952484133\n",
      "6423, train_loss: 0.49387229864413923, val_loss: 0.5014462292194366\n",
      "6424, train_loss: 0.489940556196066, val_loss: 0.4874464452266693\n",
      "6425, train_loss: 0.4938281900607623, val_loss: 0.5062636971473694\n",
      "6426, train_loss: 0.4901622419173901, val_loss: 0.46371619701385497\n",
      "6427, train_loss: 0.490147753403737, val_loss: 0.47751909792423247\n",
      "6428, train_loss: 0.4892404813032884, val_loss: 0.4659155786037445\n",
      "6429, train_loss: 0.4892354905605316, val_loss: 0.48120530843734743\n",
      "6430, train_loss: 0.4919668080715033, val_loss: 0.4813942492008209\n",
      "6431, train_loss: 0.49092129331368667, val_loss: 0.49778335094451903\n",
      "6432, train_loss: 0.4936507653731566, val_loss: 0.47354605197906496\n",
      "6433, train_loss: 0.4897353568902382, val_loss: 0.4938418686389923\n",
      "6434, train_loss: 0.4935992279878029, val_loss: 0.4800044596195221\n",
      "6435, train_loss: 0.49356399935025436, val_loss: 0.4745649456977844\n",
      "6436, train_loss: 0.49351598437015826, val_loss: 0.4898469567298889\n",
      "6437, train_loss: 0.489090791115394, val_loss: 0.48019513487815857\n",
      "6438, train_loss: 0.4887240483210637, val_loss: 0.4976767063140869\n",
      "6439, train_loss: 0.48967051620666796, val_loss: 0.48815072178840635\n",
      "6440, train_loss: 0.4910091883861102, val_loss: 0.46646573543548586\n",
      "6441, train_loss: 0.49341366726618546, val_loss: 0.4705381512641907\n",
      "6442, train_loss: 0.49341822129029494, val_loss: 0.48726209402084353\n",
      "6443, train_loss: 0.4933700355199667, val_loss: 0.4748393654823303\n",
      "6444, train_loss: 0.48877072448913866, val_loss: 0.4796168148517609\n",
      "6445, train_loss: 0.48940476660545057, val_loss: 0.5060831427574157\n",
      "6446, train_loss: 0.4932275185218224, val_loss: 0.48470471501350404\n",
      "6447, train_loss: 0.49040119693829465, val_loss: 0.47055851817131045\n",
      "6448, train_loss: 0.49092719188103306, val_loss: 0.47605258226394653\n",
      "6449, train_loss: 0.4931593812428988, val_loss: 0.49190192222595214\n",
      "6450, train_loss: 0.4901997527250877, val_loss: 0.48982652425765993\n",
      "6451, train_loss: 0.490734535914201, val_loss: 0.4799532055854797\n",
      "6452, train_loss: 0.49083883143388307, val_loss: 0.4794833719730377\n",
      "6453, train_loss: 0.48763569043232846, val_loss: 0.5012597978115082\n",
      "6454, train_loss: 0.48854275850149304, val_loss: 0.4936025023460388\n",
      "6455, train_loss: 0.49015233608392567, val_loss: 0.4785757541656494\n",
      "6456, train_loss: 0.4896856706876021, val_loss: 0.47794741988182066\n",
      "6457, train_loss: 0.48828055079166705, val_loss: 0.4928861379623413\n",
      "6458, train_loss: 0.4929172694683075, val_loss: 0.478818815946579\n",
      "6459, train_loss: 0.4887780936864706, val_loss: 0.48558503985404966\n",
      "6460, train_loss: 0.49286490220289964, val_loss: 0.49124962091445923\n",
      "6461, train_loss: 0.48763613173594844, val_loss: 0.4880188167095184\n",
      "6462, train_loss: 0.48744703141542584, val_loss: 0.4841387867927551\n",
      "6463, train_loss: 0.49277035662761104, val_loss: 0.4896144211292267\n",
      "6464, train_loss: 0.4927082657814026, val_loss: 0.4880965828895569\n",
      "6465, train_loss: 0.49273215578152585, val_loss: 0.4896054208278656\n",
      "6466, train_loss: 0.4894147114111827, val_loss: 0.4847715735435486\n",
      "6467, train_loss: 0.4897113557045276, val_loss: 0.5060816824436187\n",
      "6468, train_loss: 0.4888880184063545, val_loss: 0.4830326557159424\n",
      "6469, train_loss: 0.4926105382350775, val_loss: 0.5060669660568238\n",
      "6470, train_loss: 0.4881453044139422, val_loss: 0.48028971552848815\n",
      "6471, train_loss: 0.48977645887778354, val_loss: 0.4811584770679474\n",
      "6472, train_loss: 0.49020574872310346, val_loss: 0.49727867245674134\n",
      "6473, train_loss: 0.4925364164205698, val_loss: 0.48243597745895384\n",
      "6474, train_loss: 0.4906703858421399, val_loss: 0.47927132844924925\n",
      "6475, train_loss: 0.49096733790177566, val_loss: 0.4677788019180298\n",
      "6476, train_loss: 0.48702336618533504, val_loss: 0.48778110146522524\n",
      "6477, train_loss: 0.49244030163838315, val_loss: 0.4837839126586914\n",
      "6478, train_loss: 0.4878867795834175, val_loss: 0.4767287731170654\n",
      "6479, train_loss: 0.48732966643113357, val_loss: 0.47120068073272703\n",
      "6480, train_loss: 0.48961776380355543, val_loss: 0.5009195566177368\n",
      "6481, train_loss: 0.4923012394171495, val_loss: 0.4876954734325409\n",
      "6482, train_loss: 0.4885505477969463, val_loss: 0.5056491553783417\n",
      "6483, train_loss: 0.48820031033112454, val_loss: 0.5055695474147797\n",
      "6484, train_loss: 0.49228669932255376, val_loss: 0.4627893328666687\n",
      "6485, train_loss: 0.492308198259427, val_loss: 0.5053580641746521\n",
      "6486, train_loss: 0.49010191513941836, val_loss: 0.5003971576690673\n",
      "6487, train_loss: 0.4899667455599858, val_loss: 0.487929505109787\n",
      "6488, train_loss: 0.4922137501148077, val_loss: 0.4814118206501007\n",
      "6489, train_loss: 0.4885223393256848, val_loss: 0.48784682154655457\n",
      "6490, train_loss: 0.4921313558633511, val_loss: 0.4838711380958557\n",
      "6491, train_loss: 0.48840248470123, val_loss: 0.4887051582336426\n",
      "6492, train_loss: 0.49213195821413624, val_loss: 0.49022836685180665\n",
      "6493, train_loss: 0.48849862813949585, val_loss: 0.4746010184288025\n",
      "6494, train_loss: 0.4875348588595024, val_loss: 0.49004209637641905\n",
      "6495, train_loss: 0.4920441015408589, val_loss: 0.48611497282981875\n",
      "6496, train_loss: 0.49200650705741, val_loss: 0.47491766810417174\n",
      "6497, train_loss: 0.4875254619580049, val_loss: 0.4591565191745758\n",
      "6498, train_loss: 0.4920102105690883, val_loss: 0.46771798133850095\n",
      "6499, train_loss: 0.49200313137127805, val_loss: 0.4691882371902466\n",
      "6500, train_loss: 0.49193263397766995, val_loss: 0.47102304697036745\n",
      "6501, train_loss: 0.4895810295756047, val_loss: 0.48192723393440245\n",
      "6502, train_loss: 0.489595495737516, val_loss: 0.4869468748569489\n",
      "6503, train_loss: 0.4872493090537878, val_loss: 0.48306227922439576\n",
      "6504, train_loss: 0.48950578845464265, val_loss: 0.4926678240299225\n",
      "6505, train_loss: 0.4876274684300789, val_loss: 0.4886485576629639\n",
      "6506, train_loss: 0.4879158219465843, val_loss: 0.5050700187683106\n",
      "6507, train_loss: 0.48931644971554095, val_loss: 0.4724967241287231\n",
      "6508, train_loss: 0.4873730643437459, val_loss: 0.49160303473472594\n",
      "6509, train_loss: 0.4896717839516126, val_loss: 0.49166666269302367\n",
      "6510, train_loss: 0.4879901260137558, val_loss: 0.47674874067306516\n",
      "6511, train_loss: 0.4870500002916043, val_loss: 0.4876602113246918\n",
      "6512, train_loss: 0.4876574381039693, val_loss: 0.486553829908371\n",
      "6513, train_loss: 0.4866932997336754, val_loss: 0.48150686621665956\n",
      "6514, train_loss: 0.48867125522631866, val_loss: 0.47899147868156433\n",
      "6515, train_loss: 0.4883053950392283, val_loss: 0.4704615414142609\n",
      "6516, train_loss: 0.4895335670847159, val_loss: 0.4927418351173401\n",
      "6517, train_loss: 0.48933840141846585, val_loss: 0.4831913948059082\n",
      "6518, train_loss: 0.4912912994623184, val_loss: 0.48490811586380006\n",
      "6519, train_loss: 0.48833716259552884, val_loss: 0.48887163400650024\n",
      "6520, train_loss: 0.48542594565795016, val_loss: 0.48527114391326903\n",
      "6521, train_loss: 0.49005954082195574, val_loss: 0.49193477630615234\n",
      "6522, train_loss: 0.49117142535172975, val_loss: 0.466492110490799\n",
      "6523, train_loss: 0.4863910354100741, val_loss: 0.47905499339103697\n",
      "6524, train_loss: 0.4911289925758655, val_loss: 0.48618103861808776\n",
      "6525, train_loss: 0.4873868376016617, val_loss: 0.4631733536720276\n",
      "6526, train_loss: 0.49113273047483885, val_loss: 0.4717692077159882\n",
      "6527, train_loss: 0.49115116321123564, val_loss: 0.4964393198490143\n",
      "6528, train_loss: 0.4864247945638803, val_loss: 0.4700047791004181\n",
      "6529, train_loss: 0.4910867970723372, val_loss: 0.4676676869392395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6530, train_loss: 0.487360995549422, val_loss: 0.49054224491119386\n",
      "6531, train_loss: 0.4891803344854942, val_loss: 0.4780526340007782\n",
      "6532, train_loss: 0.4909806354687764, val_loss: 0.49063902497291567\n",
      "6533, train_loss: 0.48778388362664443, val_loss: 0.47061802744865416\n",
      "6534, train_loss: 0.4864380806684494, val_loss: 0.49127628803253176\n",
      "6535, train_loss: 0.4864294437261728, val_loss: 0.48980902433395385\n",
      "6536, train_loss: 0.4870879122844109, val_loss: 0.5048271954059601\n",
      "6537, train_loss: 0.4862875124582878, val_loss: 0.46161659359931945\n",
      "6538, train_loss: 0.4909194398384828, val_loss: 0.4909709393978119\n",
      "6539, train_loss: 0.4849827667841545, val_loss: 0.471074765920639\n",
      "6540, train_loss: 0.4885977873435387, val_loss: 0.48312203884124755\n",
      "6541, train_loss: 0.4897190011464633, val_loss: 0.4739463686943054\n",
      "6542, train_loss: 0.4870593295647548, val_loss: 0.46594190001487734\n",
      "6543, train_loss: 0.4889722695717445, val_loss: 0.48601697087287904\n",
      "6544, train_loss: 0.4866847705382567, val_loss: 0.4627585172653198\n",
      "6545, train_loss: 0.48512933632502186, val_loss: 0.5039409101009369\n",
      "6546, train_loss: 0.4858767562187635, val_loss: 0.4770534038543701\n",
      "6547, train_loss: 0.48701712718376744, val_loss: 0.48224645256996157\n",
      "6548, train_loss: 0.4879008439870981, val_loss: 0.46361523270606997\n",
      "6549, train_loss: 0.48793314970456636, val_loss: 0.47386130690574646\n",
      "6550, train_loss: 0.4861489780820333, val_loss: 0.4854317784309387\n",
      "6551, train_loss: 0.48534482373641086, val_loss: 0.48157431483268737\n",
      "6552, train_loss: 0.49067954088632876, val_loss: 0.47379026412963865\n",
      "6553, train_loss: 0.48688900012236375, val_loss: 0.4564622938632965\n",
      "6554, train_loss: 0.48797340117968047, val_loss: 0.5034458994865417\n",
      "6555, train_loss: 0.48867790687542695, val_loss: 0.5033822417259216\n",
      "6556, train_loss: 0.48879817586678725, val_loss: 0.47185772061347964\n",
      "6557, train_loss: 0.49055089400364804, val_loss: 0.47745331525802615\n",
      "6558, train_loss: 0.4905137580174666, val_loss: 0.4681013286113739\n",
      "6559, train_loss: 0.49046209569160754, val_loss: 0.461286336183548\n",
      "6560, train_loss: 0.4888406911721596, val_loss: 0.4899790346622467\n",
      "6561, train_loss: 0.4872186499146315, val_loss: 0.48159236311912534\n",
      "6562, train_loss: 0.49038140361125654, val_loss: 0.48441707491874697\n",
      "6563, train_loss: 0.48557812433976394, val_loss: 0.48190056085586547\n",
      "6564, train_loss: 0.4884369201385058, val_loss: 0.47348201274871826\n",
      "6565, train_loss: 0.49031441372174484, val_loss: 0.5034101009368896\n",
      "6566, train_loss: 0.4876588433980942, val_loss: 0.48202902674674986\n",
      "6567, train_loss: 0.49032975962528813, val_loss: 0.4682594180107117\n",
      "6568, train_loss: 0.4881691061533414, val_loss: 0.4851810455322266\n",
      "6569, train_loss: 0.4845508738205983, val_loss: 0.48132814168930055\n",
      "6570, train_loss: 0.48784291171110594, val_loss: 0.4984247624874115\n",
      "6571, train_loss: 0.4863996081627332, val_loss: 0.4851747274398804\n",
      "6572, train_loss: 0.4856229630800394, val_loss: 0.4821790397167206\n",
      "6573, train_loss: 0.490172803401947, val_loss: 0.48949143290519714\n",
      "6574, train_loss: 0.4860161313643822, val_loss: 0.5029586136341095\n",
      "6575, train_loss: 0.4901301310612605, val_loss: 0.48136707544326784\n",
      "6576, train_loss: 0.4862484931945801, val_loss: 0.4806347548961639\n",
      "6577, train_loss: 0.49013032821508556, val_loss: 0.4843862593173981\n",
      "6578, train_loss: 0.4900925331390821, val_loss: 0.47519879341125487\n",
      "6579, train_loss: 0.4848312047811655, val_loss: 0.48143596649169923\n",
      "6580, train_loss: 0.487842695071147, val_loss: 0.48469282388687135\n",
      "6581, train_loss: 0.48402186655081236, val_loss: 0.494322681427002\n",
      "6582, train_loss: 0.48512675211979794, val_loss: 0.4878609836101532\n",
      "6583, train_loss: 0.48498019576072693, val_loss: 0.4800484776496887\n",
      "6584, train_loss: 0.48400761645573837, val_loss: 0.4710345447063446\n",
      "6585, train_loss: 0.485278668311926, val_loss: 0.4777048766613007\n",
      "6586, train_loss: 0.4869105460552069, val_loss: 0.48450958728790283\n",
      "6587, train_loss: 0.48622677819086957, val_loss: 0.497747015953064\n",
      "6588, train_loss: 0.4882061298076923, val_loss: 0.5026685535907746\n",
      "6589, train_loss: 0.4898075478581282, val_loss: 0.47570600509643557\n",
      "6590, train_loss: 0.4838470426889566, val_loss: 0.5026091396808624\n",
      "6591, train_loss: 0.4869290613211118, val_loss: 0.4891684532165527\n",
      "6592, train_loss: 0.48574728862597394, val_loss: 0.4892068922519684\n",
      "6593, train_loss: 0.4868326210058652, val_loss: 0.49422330856323243\n",
      "6594, train_loss: 0.48479175223754, val_loss: 0.4941900372505188\n",
      "6595, train_loss: 0.48962250237281507, val_loss: 0.4676301896572113\n",
      "6596, train_loss: 0.4872844322369649, val_loss: 0.48188657164573667\n",
      "6597, train_loss: 0.4895783467934682, val_loss: 0.4861145198345184\n",
      "6598, train_loss: 0.48573585599660873, val_loss: 0.4805812776088715\n",
      "6599, train_loss: 0.48703025396053606, val_loss: 0.4810889422893524\n",
      "6600, train_loss: 0.4856752587052492, val_loss: 0.4632913589477539\n",
      "6601, train_loss: 0.4894913973716589, val_loss: 0.4707209527492523\n",
      "6602, train_loss: 0.48664960952905506, val_loss: 0.48592979907989503\n",
      "6603, train_loss: 0.48537684747805965, val_loss: 0.48327234387397766\n",
      "6604, train_loss: 0.4848784219760161, val_loss: 0.4682346284389496\n",
      "6605, train_loss: 0.4894144947712238, val_loss: 0.4673268795013428\n",
      "6606, train_loss: 0.48546963471632737, val_loss: 0.5022659122943878\n",
      "6607, train_loss: 0.4855375691102101, val_loss: 0.4686865031719208\n",
      "6608, train_loss: 0.4893935059125607, val_loss: 0.4895321011543274\n",
      "6609, train_loss: 0.48514250264717984, val_loss: 0.4696858525276184\n",
      "6610, train_loss: 0.48783101026828474, val_loss: 0.4744748055934906\n",
      "6611, train_loss: 0.4853545450247251, val_loss: 0.4887742519378662\n",
      "6612, train_loss: 0.4847401426388667, val_loss: 0.45892874598503114\n",
      "6613, train_loss: 0.4847554209140631, val_loss: 0.46753972172737124\n",
      "6614, train_loss: 0.4842664817204842, val_loss: 0.4577488124370575\n",
      "6615, train_loss: 0.48640788518465483, val_loss: 0.4767169296741486\n",
      "6616, train_loss: 0.4892024982434053, val_loss: 0.47420841455459595\n",
      "6617, train_loss: 0.4851601215509268, val_loss: 0.4748736977577209\n",
      "6618, train_loss: 0.48912957081427944, val_loss: 0.46315104961395265\n",
      "6619, train_loss: 0.48536484975081223, val_loss: 0.4931259095668793\n",
      "6620, train_loss: 0.48537391080306125, val_loss: 0.4547877848148346\n",
      "6621, train_loss: 0.489124045922206, val_loss: 0.46977471709251406\n",
      "6622, train_loss: 0.48517432579627406, val_loss: 0.46491822600364685\n",
      "6623, train_loss: 0.4848761008335994, val_loss: 0.4706884980201721\n",
      "6624, train_loss: 0.48676237292014635, val_loss: 0.47166816592216493\n",
      "6625, train_loss: 0.4851428476663736, val_loss: 0.465684050321579\n",
      "6626, train_loss: 0.4889745448644345, val_loss: 0.4674826145172119\n",
      "6627, train_loss: 0.4889338452082414, val_loss: 0.4880577564239502\n",
      "6628, train_loss: 0.488938576900042, val_loss: 0.48741604685783385\n",
      "6629, train_loss: 0.4888351937899223, val_loss: 0.47155595421791074\n",
      "6630, train_loss: 0.4888166372592633, val_loss: 0.4583256602287292\n",
      "6631, train_loss: 0.48418288964491624, val_loss: 0.48803790807724\n",
      "6632, train_loss: 0.48592768953396726, val_loss: 0.4716733396053314\n",
      "6633, train_loss: 0.48874016679250276, val_loss: 0.4676498770713806\n",
      "6634, train_loss: 0.48478893591807437, val_loss: 0.48902751207351686\n",
      "6635, train_loss: 0.484894606929559, val_loss: 0.4806139647960663\n",
      "6636, train_loss: 0.48596934515696305, val_loss: 0.47638514041900637\n",
      "6637, train_loss: 0.48864726492991817, val_loss: 0.4622588336467743\n",
      "6638, train_loss: 0.4886748710503945, val_loss: 0.4626373291015625\n",
      "6639, train_loss: 0.48866186348291546, val_loss: 0.46550520062446593\n",
      "6640, train_loss: 0.48410276495493376, val_loss: 0.47446449995040896\n",
      "6641, train_loss: 0.48517667100979733, val_loss: 0.48468915224075315\n",
      "6642, train_loss: 0.4885647170818769, val_loss: 0.48866504430770874\n",
      "6643, train_loss: 0.4856930524110794, val_loss: 0.47530111074447634\n",
      "6644, train_loss: 0.48478996409819675, val_loss: 0.4838143765926361\n",
      "6645, train_loss: 0.4884366553563338, val_loss: 0.4877829372882843\n",
      "6646, train_loss: 0.48561261135798234, val_loss: 0.47060545086860656\n",
      "6647, train_loss: 0.48352955740231734, val_loss: 0.4712593138217926\n",
      "6648, train_loss: 0.48240404576063156, val_loss: 0.5013673961162567\n",
      "6649, train_loss: 0.48386111053136677, val_loss: 0.4716371178627014\n",
      "6650, train_loss: 0.4856168260941139, val_loss: 0.4886196255683899\n",
      "6651, train_loss: 0.48829967356645143, val_loss: 0.48760005235672\n",
      "6652, train_loss: 0.48536322437799895, val_loss: 0.4598937153816223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6653, train_loss: 0.4844970668737705, val_loss: 0.5011364221572876\n",
      "6654, train_loss: 0.48821582014744097, val_loss: 0.48760515451431274\n",
      "6655, train_loss: 0.4881995818935908, val_loss: 0.4875966489315033\n",
      "6656, train_loss: 0.48365372992478883, val_loss: 0.5011176645755768\n",
      "6657, train_loss: 0.488203417796355, val_loss: 0.4789368987083435\n",
      "6658, train_loss: 0.4881772238474626, val_loss: 0.48171715140342714\n",
      "6659, train_loss: 0.488133063683143, val_loss: 0.4646719813346863\n",
      "6660, train_loss: 0.48349705223853773, val_loss: 0.4816857039928436\n",
      "6661, train_loss: 0.4848669606905717, val_loss: 0.4961596608161926\n",
      "6662, train_loss: 0.4839560859478437, val_loss: 0.46081714034080506\n",
      "6663, train_loss: 0.4825598093179556, val_loss: 0.4756798207759857\n",
      "6664, train_loss: 0.48802168438067806, val_loss: 0.4797447681427002\n",
      "6665, train_loss: 0.48807832369437587, val_loss: 0.46417086720466616\n",
      "6666, train_loss: 0.48423709777685314, val_loss: 0.4872749030590057\n",
      "6667, train_loss: 0.4868095861031459, val_loss: 0.4656653642654419\n",
      "6668, train_loss: 0.4855007598033318, val_loss: 0.48724032640457154\n",
      "6669, train_loss: 0.48785863702113813, val_loss: 0.48281081914901736\n",
      "6670, train_loss: 0.4878480847065265, val_loss: 0.461517471075058\n",
      "6671, train_loss: 0.48442067205905914, val_loss: 0.4704746603965759\n",
      "6672, train_loss: 0.48462777527479023, val_loss: 0.46584829688072205\n",
      "6673, train_loss: 0.48261984151143295, val_loss: 0.4738074004650116\n",
      "6674, train_loss: 0.4824870159992805, val_loss: 0.4814473748207092\n",
      "6675, train_loss: 0.4877522759712659, val_loss: 0.4786075592041016\n",
      "6676, train_loss: 0.48768679797649384, val_loss: 0.4797039568424225\n",
      "6677, train_loss: 0.48376616033223957, val_loss: 0.482852703332901\n",
      "6678, train_loss: 0.48769158812669605, val_loss: 0.4868249297142029\n",
      "6679, train_loss: 0.48580595965568835, val_loss: 0.46123540997505186\n",
      "6680, train_loss: 0.48310530414948094, val_loss: 0.461581814289093\n",
      "6681, train_loss: 0.48302296147896695, val_loss: 0.45674002170562744\n",
      "6682, train_loss: 0.48276191376722777, val_loss: 0.46361241340637205\n",
      "6683, train_loss: 0.48763472529558033, val_loss: 0.4723047077655792\n",
      "6684, train_loss: 0.48302644376571363, val_loss: 0.46063620448112486\n",
      "6685, train_loss: 0.4833789857534262, val_loss: 0.4650647699832916\n",
      "6686, train_loss: 0.4830099860062966, val_loss: 0.48169900178909303\n",
      "6687, train_loss: 0.48754920867773205, val_loss: 0.46564399003982543\n",
      "6688, train_loss: 0.48752004022781664, val_loss: 0.4850186944007874\n",
      "6689, train_loss: 0.4874887386193642, val_loss: 0.4867207586765289\n",
      "6690, train_loss: 0.48330331307191116, val_loss: 0.46746782064437864\n",
      "6691, train_loss: 0.4837330671457144, val_loss: 0.4833526611328125\n",
      "6692, train_loss: 0.48279665410518646, val_loss: 0.47772127389907837\n",
      "6693, train_loss: 0.4827805826297173, val_loss: 0.47750616669654844\n",
      "6694, train_loss: 0.4873891415504309, val_loss: 0.4650926530361176\n",
      "6695, train_loss: 0.48520836119468397, val_loss: 0.46698646545410155\n",
      "6696, train_loss: 0.48733025560012233, val_loss: 0.4832065761089325\n",
      "6697, train_loss: 0.48265362129761624, val_loss: 0.4805305302143097\n",
      "6698, train_loss: 0.48724667269449967, val_loss: 0.4712784826755524\n",
      "6699, train_loss: 0.48258453149061936, val_loss: 0.47461780309677126\n",
      "6700, train_loss: 0.4872090151676765, val_loss: 0.4733534038066864\n",
      "6701, train_loss: 0.4819125131918834, val_loss: 0.4947922706604004\n",
      "6702, train_loss: 0.4832921429322316, val_loss: 0.4995961308479309\n",
      "6703, train_loss: 0.4848465621471405, val_loss: 0.476934552192688\n",
      "6704, train_loss: 0.4823647771890347, val_loss: 0.477981299161911\n",
      "6705, train_loss: 0.48711575911595273, val_loss: 0.4830412447452545\n",
      "6706, train_loss: 0.48313893377780914, val_loss: 0.46462156176567077\n",
      "6707, train_loss: 0.48243738825504595, val_loss: 0.47430548071861267\n",
      "6708, train_loss: 0.48702816092050993, val_loss: 0.4675688147544861\n",
      "6709, train_loss: 0.4823673378962737, val_loss: 0.4646111726760864\n",
      "6710, train_loss: 0.48230005456851077, val_loss: 0.478049111366272\n",
      "6711, train_loss: 0.48689382007488835, val_loss: 0.472532594203949\n",
      "6712, train_loss: 0.4820158527447627, val_loss: 0.4818913221359253\n",
      "6713, train_loss: 0.48183052241802216, val_loss: 0.485149621963501\n",
      "6714, train_loss: 0.4868620920639772, val_loss: 0.4693669080734253\n",
      "6715, train_loss: 0.4857196303514334, val_loss: 0.48450230360031127\n",
      "6716, train_loss: 0.48393779534559983, val_loss: 0.4947752237319946\n",
      "6717, train_loss: 0.4867276973449267, val_loss: 0.4676905333995819\n",
      "6718, train_loss: 0.48669576186400193, val_loss: 0.46613518595695497\n",
      "6719, train_loss: 0.48140645371033597, val_loss: 0.47281593084335327\n",
      "6720, train_loss: 0.48662850719231826, val_loss: 0.4815633654594421\n",
      "6721, train_loss: 0.4826932274378263, val_loss: 0.4667430341243744\n",
      "6722, train_loss: 0.4846197504263658, val_loss: 0.47325244545936584\n",
      "6723, train_loss: 0.4837013609134234, val_loss: 0.4997737228870392\n",
      "6724, train_loss: 0.4805217866714184, val_loss: 0.4910088062286377\n",
      "6725, train_loss: 0.4864922928122374, val_loss: 0.46180949807167054\n",
      "6726, train_loss: 0.48196105315135074, val_loss: 0.47867263555526735\n",
      "6727, train_loss: 0.4841511415747496, val_loss: 0.4744333863258362\n",
      "6728, train_loss: 0.48095690172452193, val_loss: 0.4994054794311523\n",
      "6729, train_loss: 0.48643247668559736, val_loss: 0.47408360838890073\n",
      "6730, train_loss: 0.4815882226595512, val_loss: 0.463206285238266\n",
      "6731, train_loss: 0.48247366226636446, val_loss: 0.4856772243976593\n",
      "6732, train_loss: 0.48129651179680455, val_loss: 0.47586997747421267\n",
      "6733, train_loss: 0.48253323710881746, val_loss: 0.46487154364585875\n",
      "6734, train_loss: 0.4863594936636778, val_loss: 0.4770744025707245\n",
      "6735, train_loss: 0.486384222140679, val_loss: 0.45666574239730834\n",
      "6736, train_loss: 0.4862881772793256, val_loss: 0.4609306037425995\n",
      "6737, train_loss: 0.4826079194362347, val_loss: 0.46707412600517273\n",
      "6738, train_loss: 0.48392382951883167, val_loss: 0.4856268286705017\n",
      "6739, train_loss: 0.4861614325871834, val_loss: 0.47501381039619445\n",
      "6740, train_loss: 0.48230198942697966, val_loss: 0.47992839813232424\n",
      "6741, train_loss: 0.48612496428764784, val_loss: 0.4589156985282898\n",
      "6742, train_loss: 0.48610604726351225, val_loss: 0.47214874625205994\n",
      "6743, train_loss: 0.48157417659576124, val_loss: 0.49415384531021117\n",
      "6744, train_loss: 0.4828049815618075, val_loss: 0.46195935010910033\n",
      "6745, train_loss: 0.48005364949886614, val_loss: 0.46724080443382265\n",
      "6746, train_loss: 0.4860069648577617, val_loss: 0.4815267324447632\n",
      "6747, train_loss: 0.4860342557613666, val_loss: 0.47383628487586976\n",
      "6748, train_loss: 0.4831251089389508, val_loss: 0.4797929346561432\n",
      "6749, train_loss: 0.48303423478053165, val_loss: 0.4992362678050995\n",
      "6750, train_loss: 0.48594281535882217, val_loss: 0.4782177209854126\n",
      "6751, train_loss: 0.48102574394299435, val_loss: 0.4651287019252777\n",
      "6752, train_loss: 0.4809890618691078, val_loss: 0.49884390234947207\n",
      "6753, train_loss: 0.4858853920147969, val_loss: 0.4861248850822449\n",
      "6754, train_loss: 0.48316717262451464, val_loss: 0.4638775587081909\n",
      "6755, train_loss: 0.4820515215396881, val_loss: 0.4643515408039093\n",
      "6756, train_loss: 0.48251828436668104, val_loss: 0.47687126994132994\n",
      "6757, train_loss: 0.4818010221307094, val_loss: 0.4550876200199127\n",
      "6758, train_loss: 0.48357369693425983, val_loss: 0.4806501269340515\n",
      "6759, train_loss: 0.485717984346243, val_loss: 0.4550467371940613\n",
      "6760, train_loss: 0.48568587750196457, val_loss: 0.4661635339260101\n",
      "6761, train_loss: 0.48106715656243837, val_loss: 0.4666857600212097\n",
      "6762, train_loss: 0.48279845256071824, val_loss: 0.49884448647499086\n",
      "6763, train_loss: 0.4856170083467777, val_loss: 0.4792261302471161\n",
      "6764, train_loss: 0.48069771092671615, val_loss: 0.4800996005535126\n",
      "6765, train_loss: 0.48191632674290585, val_loss: 0.4792382478713989\n",
      "6766, train_loss: 0.4855409092628039, val_loss: 0.4850111365318298\n",
      "6767, train_loss: 0.4797517044039873, val_loss: 0.4714070200920105\n",
      "6768, train_loss: 0.48077161610126495, val_loss: 0.4842978775501251\n",
      "6769, train_loss: 0.48378404057942903, val_loss: 0.4836353838443756\n",
      "6770, train_loss: 0.4805568685898414, val_loss: 0.46342471837997434\n",
      "6771, train_loss: 0.4816999825147482, val_loss: 0.479289174079895\n",
      "6772, train_loss: 0.4806959376885341, val_loss: 0.4850454568862915\n",
      "6773, train_loss: 0.4832579963482343, val_loss: 0.4988061785697937\n",
      "6774, train_loss: 0.48532830350674117, val_loss: 0.47184385657310485\n",
      "6775, train_loss: 0.4820512682199478, val_loss: 0.4770201504230499\n",
      "6776, train_loss: 0.4827771083666728, val_loss: 0.49901471734046937\n",
      "6777, train_loss: 0.48118151838962847, val_loss: 0.4779664933681488\n",
      "6778, train_loss: 0.4837141094299463, val_loss: 0.476692134141922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6779, train_loss: 0.4824401048513559, val_loss: 0.47782249450683595\n",
      "6780, train_loss: 0.48219707722847277, val_loss: 0.4772120833396912\n",
      "6781, train_loss: 0.4851687126434766, val_loss: 0.49861345291137693\n",
      "6782, train_loss: 0.4851024735432405, val_loss: 0.4710822761058807\n",
      "6783, train_loss: 0.48281368613243103, val_loss: 0.45503856539726256\n",
      "6784, train_loss: 0.48506251321389127, val_loss: 0.46401968598365784\n",
      "6785, train_loss: 0.48506433688677275, val_loss: 0.4986282527446747\n",
      "6786, train_loss: 0.4801051255602103, val_loss: 0.4732362747192383\n",
      "6787, train_loss: 0.47898910080011076, val_loss: 0.4513594627380371\n",
      "6788, train_loss: 0.48504696098657757, val_loss: 0.4755270957946777\n",
      "6789, train_loss: 0.48498507187916684, val_loss: 0.45734617710113523\n",
      "6790, train_loss: 0.4849785692416705, val_loss: 0.46270025968551637\n",
      "6791, train_loss: 0.4811664934341724, val_loss: 0.4548371613025665\n",
      "6792, train_loss: 0.4811613674347217, val_loss: 0.4755805850028992\n",
      "6793, train_loss: 0.47918798144047076, val_loss: 0.469703871011734\n",
      "6794, train_loss: 0.48495527643423814, val_loss: 0.46654847264289856\n",
      "6795, train_loss: 0.4803562817665247, val_loss: 0.4624698519706726\n",
      "6796, train_loss: 0.4848588315340189, val_loss: 0.48104100227355956\n",
      "6797, train_loss: 0.48481450974941254, val_loss: 0.4624554216861725\n",
      "6798, train_loss: 0.4848320885346486, val_loss: 0.4802391767501831\n",
      "6799, train_loss: 0.48478836394273317, val_loss: 0.4891966700553894\n",
      "6800, train_loss: 0.4789436918038588, val_loss: 0.4752440333366394\n",
      "6801, train_loss: 0.4847711290304477, val_loss: 0.45838856101036074\n",
      "6802, train_loss: 0.4835998977606113, val_loss: 0.49764119982719424\n",
      "6803, train_loss: 0.48014021149048436, val_loss: 0.4721705973148346\n",
      "6804, train_loss: 0.4789202969807845, val_loss: 0.45959259271621705\n",
      "6805, train_loss: 0.48471336639844453, val_loss: 0.47967910170555117\n",
      "6806, train_loss: 0.482007873746065, val_loss: 0.472034215927124\n",
      "6807, train_loss: 0.48236248986079144, val_loss: 0.4750105798244476\n",
      "6808, train_loss: 0.48180873004289776, val_loss: 0.4665136754512787\n",
      "6809, train_loss: 0.48207773726720077, val_loss: 0.4620472192764282\n",
      "6810, train_loss: 0.48274312225671917, val_loss: 0.4762292802333832\n",
      "6811, train_loss: 0.48058715577308947, val_loss: 0.47216511368751524\n",
      "6812, train_loss: 0.4816708346972099, val_loss: 0.4711388647556305\n",
      "6813, train_loss: 0.48077563826854414, val_loss: 0.4846681594848633\n",
      "6814, train_loss: 0.4801355623281919, val_loss: 0.46445355415344236\n",
      "6815, train_loss: 0.4844180253835825, val_loss: 0.46373674273490906\n",
      "6816, train_loss: 0.4843634997422879, val_loss: 0.4622306227684021\n",
      "6817, train_loss: 0.4832055763556407, val_loss: 0.4648555636405945\n",
      "6818, train_loss: 0.48042983275193435, val_loss: 0.4838538944721222\n",
      "6819, train_loss: 0.4842485602085407, val_loss: 0.49271275401115416\n",
      "6820, train_loss: 0.47963640494988513, val_loss: 0.4644783973693848\n",
      "6821, train_loss: 0.4808756044277778, val_loss: 0.4694138169288635\n",
      "6822, train_loss: 0.48304353883633244, val_loss: 0.4795298993587494\n",
      "6823, train_loss: 0.48410986134639156, val_loss: 0.4791055262088776\n",
      "6824, train_loss: 0.4802560152915808, val_loss: 0.4783319473266602\n",
      "6825, train_loss: 0.4785724649062523, val_loss: 0.483285391330719\n",
      "6826, train_loss: 0.4798164860560344, val_loss: 0.48408313989639284\n",
      "6827, train_loss: 0.4789306487028415, val_loss: 0.4662181675434113\n",
      "6828, train_loss: 0.4792611323870145, val_loss: 0.45089595913887026\n",
      "6829, train_loss: 0.4793864293740346, val_loss: 0.46156365275382993\n",
      "6830, train_loss: 0.47999104398947495, val_loss: 0.4974101483821869\n",
      "6831, train_loss: 0.4840384561281938, val_loss: 0.4718645513057709\n",
      "6832, train_loss: 0.48013266118673176, val_loss: 0.4788466811180115\n",
      "6833, train_loss: 0.48105451693901646, val_loss: 0.4626846730709076\n",
      "6834, train_loss: 0.48389991372823715, val_loss: 0.4667960822582245\n",
      "6835, train_loss: 0.48152417918810475, val_loss: 0.47934529185295105\n",
      "6836, train_loss: 0.48018133067167723, val_loss: 0.4582057178020477\n",
      "6837, train_loss: 0.4787825386111553, val_loss: 0.4719035267829895\n",
      "6838, train_loss: 0.4791808518079611, val_loss: 0.46995546817779543\n",
      "6839, train_loss: 0.4838479785965039, val_loss: 0.4521251738071442\n",
      "6840, train_loss: 0.47911787720826954, val_loss: 0.488273561000824\n",
      "6841, train_loss: 0.47998736454890323, val_loss: 0.46209853887557983\n",
      "6842, train_loss: 0.48377533142383283, val_loss: 0.45689404010772705\n",
      "6843, train_loss: 0.4804896070406987, val_loss: 0.47719491124153135\n",
      "6844, train_loss: 0.4795608205290941, val_loss: 0.4967573404312134\n",
      "6845, train_loss: 0.4788060807264768, val_loss: 0.4782601952552795\n",
      "6846, train_loss: 0.48083695711997837, val_loss: 0.48297053575515747\n",
      "6847, train_loss: 0.4836725409214313, val_loss: 0.48147633075714114\n",
      "6848, train_loss: 0.4836294249846385, val_loss: 0.4687268018722534\n",
      "6849, train_loss: 0.4821028457238124, val_loss: 0.46484353542327883\n",
      "6850, train_loss: 0.48118439947183317, val_loss: 0.46074549555778505\n",
      "6851, train_loss: 0.48346620396925855, val_loss: 0.478281968832016\n",
      "6852, train_loss: 0.4788311570882797, val_loss: 0.48834891319274903\n",
      "6853, train_loss: 0.4801435344494306, val_loss: 0.4970046043395996\n",
      "6854, train_loss: 0.4800470070197032, val_loss: 0.4739060878753662\n",
      "6855, train_loss: 0.4833339876853503, val_loss: 0.4762032270431519\n",
      "6856, train_loss: 0.4833244469303351, val_loss: 0.473023796081543\n",
      "6857, train_loss: 0.48114977089258343, val_loss: 0.4587076485157013\n",
      "6858, train_loss: 0.4772401383289924, val_loss: 0.4749907970428467\n",
      "6859, train_loss: 0.48331471991080505, val_loss: 0.4841869294643402\n",
      "6860, train_loss: 0.4795027466920706, val_loss: 0.49684998393058777\n",
      "6861, train_loss: 0.4785890378631078, val_loss: 0.47570339441299436\n",
      "6862, train_loss: 0.4786775398712892, val_loss: 0.45867704749107363\n",
      "6863, train_loss: 0.4832344066638213, val_loss: 0.46441646218299865\n",
      "6864, train_loss: 0.4813568133574266, val_loss: 0.4879246413707733\n",
      "6865, train_loss: 0.48075275810865253, val_loss: 0.4744811594486237\n",
      "6866, train_loss: 0.47941051308925337, val_loss: 0.4659103214740753\n",
      "6867, train_loss: 0.4785145016816946, val_loss: 0.47789143323898314\n",
      "6868, train_loss: 0.4819510756776883, val_loss: 0.4712933123111725\n",
      "6869, train_loss: 0.48306703567504883, val_loss: 0.4768770396709442\n",
      "6870, train_loss: 0.48103995391955745, val_loss: 0.4966196656227112\n",
      "6871, train_loss: 0.4791916992801886, val_loss: 0.482718300819397\n",
      "6872, train_loss: 0.4829534280758638, val_loss: 0.4653737485408783\n",
      "6873, train_loss: 0.4818809341925841, val_loss: 0.48206743597984314\n",
      "6874, train_loss: 0.47913078791820085, val_loss: 0.4778759956359863\n",
      "6875, train_loss: 0.4778180821583821, val_loss: 0.4965729653835297\n",
      "6876, train_loss: 0.47837239045363206, val_loss: 0.44941877126693724\n",
      "6877, train_loss: 0.48011942437061894, val_loss: 0.4524210214614868\n",
      "6878, train_loss: 0.479062000146279, val_loss: 0.47440149784088137\n",
      "6879, train_loss: 0.4789685927904569, val_loss: 0.44821391701698304\n",
      "6880, train_loss: 0.4778631696334252, val_loss: 0.45622608065605164\n",
      "6881, train_loss: 0.48295333637641025, val_loss: 0.460785847902298\n",
      "6882, train_loss: 0.4807503131719736, val_loss: 0.4733841121196747\n",
      "6883, train_loss: 0.47997024196844834, val_loss: 0.47614657282829287\n",
      "6884, train_loss: 0.4789338788160911, val_loss: 0.482079404592514\n",
      "6885, train_loss: 0.4801129079782046, val_loss: 0.46037461757659914\n",
      "6886, train_loss: 0.4786590521152203, val_loss: 0.4958059906959534\n",
      "6887, train_loss: 0.4827081962273671, val_loss: 0.4566225230693817\n",
      "6888, train_loss: 0.4789184618454713, val_loss: 0.48712311387062074\n",
      "6889, train_loss: 0.4827060200847112, val_loss: 0.47025011777877807\n",
      "6890, train_loss: 0.4826911733700679, val_loss: 0.48041436076164246\n",
      "6891, train_loss: 0.48265284987596363, val_loss: 0.457458621263504\n",
      "6892, train_loss: 0.48259754880116534, val_loss: 0.4601320266723633\n",
      "6893, train_loss: 0.482609273149417, val_loss: 0.47382580041885375\n",
      "6894, train_loss: 0.4814672607641954, val_loss: 0.456646591424942\n",
      "6895, train_loss: 0.47839929507328915, val_loss: 0.49046719670295713\n",
      "6896, train_loss: 0.4826458142353938, val_loss: 0.49058465361595155\n",
      "6897, train_loss: 0.48255061415525585, val_loss: 0.4826840817928314\n",
      "6898, train_loss: 0.48247454028863174, val_loss: 0.473162978887558\n",
      "6899, train_loss: 0.47733966891582197, val_loss: 0.4742864668369293\n",
      "6900, train_loss: 0.48248278406950146, val_loss: 0.4769567549228668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6901, train_loss: 0.47661511026895964, val_loss: 0.4824475109577179\n",
      "6902, train_loss: 0.48241162529358494, val_loss: 0.4480014741420746\n",
      "6903, train_loss: 0.47777204788648164, val_loss: 0.46530447006225584\n",
      "6904, train_loss: 0.48243480691542995, val_loss: 0.4806100964546204\n",
      "6905, train_loss: 0.4774239126306314, val_loss: 0.47974061965942383\n",
      "6906, train_loss: 0.47624609562066883, val_loss: 0.4900858819484711\n",
      "6907, train_loss: 0.48231403873516965, val_loss: 0.4541963517665863\n",
      "6908, train_loss: 0.4823006752591867, val_loss: 0.46460756063461306\n",
      "6909, train_loss: 0.4794575193753609, val_loss: 0.46115649938583375\n",
      "6910, train_loss: 0.48109374596522403, val_loss: 0.46047422885894773\n",
      "6911, train_loss: 0.4772441043303563, val_loss: 0.45444161891937257\n",
      "6912, train_loss: 0.48218930054169434, val_loss: 0.4766148865222931\n",
      "6913, train_loss: 0.4822145528518237, val_loss: 0.479928070306778\n",
      "6914, train_loss: 0.4774584833246011, val_loss: 0.47810630202293397\n",
      "6915, train_loss: 0.4775052534846159, val_loss: 0.4627551257610321\n",
      "6916, train_loss: 0.47882498800754547, val_loss: 0.46360833644866944\n",
      "6917, train_loss: 0.4820188834117009, val_loss: 0.4590248644351959\n",
      "6918, train_loss: 0.47692138758989483, val_loss: 0.4667316794395447\n",
      "6919, train_loss: 0.4819523485807272, val_loss: 0.47530064582824705\n",
      "6920, train_loss: 0.4783037075629601, val_loss: 0.4717440366744995\n",
      "6921, train_loss: 0.47864774098763097, val_loss: 0.48226717710494993\n",
      "6922, train_loss: 0.47823469741986346, val_loss: 0.4805751502513885\n",
      "6923, train_loss: 0.4818400987065755, val_loss: 0.45275384187698364\n",
      "6924, train_loss: 0.47929482276623064, val_loss: 0.4864763915538788\n",
      "6925, train_loss: 0.4771547237267861, val_loss: 0.48132582306861876\n",
      "6926, train_loss: 0.47709439121759856, val_loss: 0.4562169075012207\n",
      "6927, train_loss: 0.47889010780132735, val_loss: 0.4578215956687927\n",
      "6928, train_loss: 0.47784910752223086, val_loss: 0.4675223410129547\n",
      "6929, train_loss: 0.4792859468322534, val_loss: 0.45964505076408385\n",
      "6930, train_loss: 0.48164748457761913, val_loss: 0.45447670221328734\n",
      "6931, train_loss: 0.4787568346812175, val_loss: 0.4589772343635559\n",
      "6932, train_loss: 0.4816181487762011, val_loss: 0.4725514590740204\n",
      "6933, train_loss: 0.4792435627717238, val_loss: 0.4669769763946533\n",
      "6934, train_loss: 0.4769743296962518, val_loss: 0.4537448465824127\n",
      "6935, train_loss: 0.47863613069057465, val_loss: 0.46231712102890016\n",
      "6936, train_loss: 0.4796070995239111, val_loss: 0.4629661202430725\n",
      "6937, train_loss: 0.4767992404791025, val_loss: 0.46287686228752134\n",
      "6938, train_loss: 0.4813745113519522, val_loss: 0.48246392607688904\n",
      "6939, train_loss: 0.4779285696836618, val_loss: 0.4545807480812073\n",
      "6940, train_loss: 0.47825124515936923, val_loss: 0.4867306113243103\n",
      "6941, train_loss: 0.4812620282173157, val_loss: 0.4678903579711914\n",
      "6942, train_loss: 0.4778709772687692, val_loss: 0.4534001350402832\n",
      "6943, train_loss: 0.4812476600591953, val_loss: 0.4765899956226349\n",
      "6944, train_loss: 0.4811726040565051, val_loss: 0.46276888251304626\n",
      "6945, train_loss: 0.48116709234622806, val_loss: 0.46345316171646117\n",
      "6946, train_loss: 0.4811051579622122, val_loss: 0.45951136350631716\n",
      "6947, train_loss: 0.47600057721138, val_loss: 0.4904837131500244\n",
      "6948, train_loss: 0.47598874683563525, val_loss: 0.48661773204803466\n",
      "6949, train_loss: 0.481111011826075, val_loss: 0.47650848627090453\n",
      "6950, train_loss: 0.4810413798460594, val_loss: 0.45935981869697573\n",
      "6951, train_loss: 0.4773746809134117, val_loss: 0.4617878019809723\n",
      "6952, train_loss: 0.48098004437409914, val_loss: 0.48158047795295716\n",
      "6953, train_loss: 0.4809778481721878, val_loss: 0.46286860704421995\n",
      "6954, train_loss: 0.47709243114177996, val_loss: 0.46418213844299316\n",
      "6955, train_loss: 0.4768554510978552, val_loss: 0.49034457802772524\n",
      "6956, train_loss: 0.4809288921264502, val_loss: 0.4953952610492706\n",
      "6957, train_loss: 0.4788690988834088, val_loss: 0.4578429043292999\n",
      "6958, train_loss: 0.4808550075842784, val_loss: 0.45991994738578795\n",
      "6959, train_loss: 0.4808178051159932, val_loss: 0.4777213454246521\n",
      "6960, train_loss: 0.4808055999187323, val_loss: 0.49518250226974486\n",
      "6961, train_loss: 0.48078421560617596, val_loss: 0.47363627552986143\n",
      "6962, train_loss: 0.4769812478468968, val_loss: 0.4862231254577637\n",
      "6963, train_loss: 0.4757531193586496, val_loss: 0.4772290468215942\n",
      "6964, train_loss: 0.47705724147649914, val_loss: 0.4721020460128784\n",
      "6965, train_loss: 0.47789697234447187, val_loss: 0.45551679730415345\n",
      "6966, train_loss: 0.48073927485025847, val_loss: 0.45957860350608826\n",
      "6967, train_loss: 0.4755440056324005, val_loss: 0.45853603482246397\n",
      "6968, train_loss: 0.48074031334656936, val_loss: 0.47991440892219545\n",
      "6969, train_loss: 0.4768728556541296, val_loss: 0.47462289929389956\n",
      "6970, train_loss: 0.4769023868900079, val_loss: 0.47454812526702883\n",
      "6971, train_loss: 0.4806568164091844, val_loss: 0.47564694881439207\n",
      "6972, train_loss: 0.4806453333451198, val_loss: 0.45339876413345337\n",
      "6973, train_loss: 0.47857816288104427, val_loss: 0.4723162710666656\n",
      "6974, train_loss: 0.48056286573410034, val_loss: 0.45174058675765993\n",
      "6975, train_loss: 0.48057895325697386, val_loss: 0.46080623269081117\n",
      "6976, train_loss: 0.4805684834718704, val_loss: 0.4578745126724243\n",
      "6977, train_loss: 0.48055002895685345, val_loss: 0.45870351791381836\n",
      "6978, train_loss: 0.4805120378732681, val_loss: 0.45419284105300906\n",
      "6979, train_loss: 0.4789833907897656, val_loss: 0.47877169847488404\n",
      "6980, train_loss: 0.47628584389503187, val_loss: 0.46137102246284484\n",
      "6981, train_loss: 0.47573997653447664, val_loss: 0.464238578081131\n",
      "6982, train_loss: 0.47654886887623715, val_loss: 0.49427138566970824\n",
      "6983, train_loss: 0.47428061068058014, val_loss: 0.48126899003982543\n",
      "6984, train_loss: 0.4754133132787851, val_loss: 0.4742768585681915\n",
      "6985, train_loss: 0.4803245629255588, val_loss: 0.4553275167942047\n",
      "6986, train_loss: 0.47574593356022465, val_loss: 0.4770953953266144\n",
      "6987, train_loss: 0.4760639277788309, val_loss: 0.4764198184013367\n",
      "6988, train_loss: 0.48025574592443615, val_loss: 0.46119734048843386\n",
      "6989, train_loss: 0.47743466611091906, val_loss: 0.47713856101036073\n",
      "6990, train_loss: 0.48018134328035206, val_loss: 0.47523810863494875\n",
      "6991, train_loss: 0.48012070243175214, val_loss: 0.47957698702812196\n",
      "6992, train_loss: 0.4756005796102377, val_loss: 0.47249419093132017\n",
      "6993, train_loss: 0.47815113686598265, val_loss: 0.48024863600730894\n",
      "6994, train_loss: 0.4759541486318295, val_loss: 0.475684779882431\n",
      "6995, train_loss: 0.4748812048481061, val_loss: 0.46465085744857787\n",
      "6996, train_loss: 0.47609878847232234, val_loss: 0.45775261521339417\n",
      "6997, train_loss: 0.48004579887940335, val_loss: 0.45378040075302123\n",
      "6998, train_loss: 0.4760817742118469, val_loss: 0.48493534326553345\n",
      "6999, train_loss: 0.4785115054020515, val_loss: 0.49375681281089784\n",
      "7000, train_loss: 0.47847647219896317, val_loss: 0.4766982734203339\n",
      "7001, train_loss: 0.47779109386297375, val_loss: 0.47281327843666077\n",
      "7002, train_loss: 0.4759791034918565, val_loss: 0.4688999176025391\n",
      "7003, train_loss: 0.4757355652176417, val_loss: 0.46698171496391294\n",
      "7004, train_loss: 0.47984131941428554, val_loss: 0.44728697538375856\n",
      "7005, train_loss: 0.47985515800806194, val_loss: 0.46759167313575745\n",
      "7006, train_loss: 0.4761288825135965, val_loss: 0.4935754895210266\n",
      "7007, train_loss: 0.47983863262029797, val_loss: 0.46360477805137634\n",
      "7008, train_loss: 0.4769000720519286, val_loss: 0.4536391139030457\n",
      "7009, train_loss: 0.4797950776723715, val_loss: 0.47372556328773496\n",
      "7010, train_loss: 0.4797800206221067, val_loss: 0.4714945077896118\n",
      "7011, train_loss: 0.479706608905242, val_loss: 0.47582953572273257\n",
      "7012, train_loss: 0.4797256760872327, val_loss: 0.4564846992492676\n",
      "7013, train_loss: 0.47629387562091535, val_loss: 0.47266232371330263\n",
      "7014, train_loss: 0.4796583320085819, val_loss: 0.47958638072013854\n",
      "7015, train_loss: 0.4763302080906354, val_loss: 0.46259077787399294\n",
      "7016, train_loss: 0.479615718126297, val_loss: 0.4589232265949249\n",
      "7017, train_loss: 0.47571825981140137, val_loss: 0.47113505005836487\n",
      "7018, train_loss: 0.47957749435534847, val_loss: 0.47441444396972654\n",
      "7019, train_loss: 0.4795568149823409, val_loss: 0.47220656275749207\n",
      "7020, train_loss: 0.4762489509124022, val_loss: 0.4932717204093933\n",
      "7021, train_loss: 0.4757228677089398, val_loss: 0.44928189516067507\n",
      "7022, train_loss: 0.4776864441541525, val_loss: 0.47608076930046084\n",
      "7023, train_loss: 0.4748974396632268, val_loss: 0.47319467067718507\n",
      "7024, train_loss: 0.47734187428767866, val_loss: 0.4575827896595001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7025, train_loss: 0.47945485550623673, val_loss: 0.471498841047287\n",
      "7026, train_loss: 0.4753611580683635, val_loss: 0.46061243414878844\n",
      "7027, train_loss: 0.47734321424594295, val_loss: 0.4932882070541382\n",
      "7028, train_loss: 0.4793429500781573, val_loss: 0.4742317259311676\n",
      "7029, train_loss: 0.4750862912489818, val_loss: 0.4561259806156158\n",
      "7030, train_loss: 0.4756257522564668, val_loss: 0.4577543377876282\n",
      "7031, train_loss: 0.47367706780250257, val_loss: 0.4486826479434967\n",
      "7032, train_loss: 0.4770952508999751, val_loss: 0.48821407556533813\n",
      "7033, train_loss: 0.4762862210090344, val_loss: 0.4660800814628601\n",
      "7034, train_loss: 0.4771648714175591, val_loss: 0.47221885323524476\n",
      "7035, train_loss: 0.4751494928048207, val_loss: 0.4802488923072815\n",
      "7036, train_loss: 0.4791372578877669, val_loss: 0.46898298859596255\n",
      "7037, train_loss: 0.4756832340588936, val_loss: 0.4792559266090393\n",
      "7038, train_loss: 0.4751351481446853, val_loss: 0.45929927825927735\n",
      "7039, train_loss: 0.47902754293038297, val_loss: 0.4505823731422424\n",
      "7040, train_loss: 0.4790635487208, val_loss: 0.47403210401535034\n",
      "7041, train_loss: 0.47899692677534544, val_loss: 0.4568631827831268\n",
      "7042, train_loss: 0.47522696394186753, val_loss: 0.48803635239601134\n",
      "7043, train_loss: 0.4789316476537631, val_loss: 0.4573099732398987\n",
      "7044, train_loss: 0.47508085805636185, val_loss: 0.4490021049976349\n",
      "7045, train_loss: 0.47894708124490887, val_loss: 0.49270225763320924\n",
      "7046, train_loss: 0.47430015871158016, val_loss: 0.4537578523159027\n",
      "7047, train_loss: 0.47508875452555144, val_loss: 0.4726999521255493\n",
      "7048, train_loss: 0.47888652177957386, val_loss: 0.474110871553421\n",
      "7049, train_loss: 0.4789041383908345, val_loss: 0.4753866374492645\n",
      "7050, train_loss: 0.47545794111031753, val_loss: 0.4740892291069031\n",
      "7051, train_loss: 0.4765106038405345, val_loss: 0.47152674198150635\n",
      "7052, train_loss: 0.47883366506833297, val_loss: 0.4785573661327362\n",
      "7053, train_loss: 0.4753530741884158, val_loss: 0.49258986711502073\n",
      "7054, train_loss: 0.4744592308998108, val_loss: 0.4924220323562622\n",
      "7055, train_loss: 0.47650396537322265, val_loss: 0.44702763557434083\n",
      "7056, train_loss: 0.4766330380852406, val_loss: 0.4735628545284271\n",
      "7057, train_loss: 0.4786796203026405, val_loss: 0.45147534012794494\n",
      "7058, train_loss: 0.4724909949761171, val_loss: 0.47467507123947145\n",
      "7059, train_loss: 0.4753221571445465, val_loss: 0.4701083242893219\n",
      "7060, train_loss: 0.4735200668756778, val_loss: 0.4775726437568665\n",
      "7061, train_loss: 0.4758438261655661, val_loss: 0.4612783670425415\n",
      "7062, train_loss: 0.4756037100003316, val_loss: 0.4547345459461212\n",
      "7063, train_loss: 0.47384375161849535, val_loss: 0.478409081697464\n",
      "7064, train_loss: 0.4784957113174292, val_loss: 0.4769382655620575\n",
      "7065, train_loss: 0.47481566896805394, val_loss: 0.46541016101837157\n",
      "7066, train_loss: 0.47847650486689347, val_loss: 0.45153995752334597\n",
      "7067, train_loss: 0.47425653498906356, val_loss: 0.4551051676273346\n",
      "7068, train_loss: 0.4784068006735582, val_loss: 0.4708093047142029\n",
      "7069, train_loss: 0.47381262481212616, val_loss: 0.4583099067211151\n",
      "7070, train_loss: 0.4783870107852496, val_loss: 0.4579903304576874\n",
      "7071, train_loss: 0.4759003451237312, val_loss: 0.4571940839290619\n",
      "7072, train_loss: 0.478329598903656, val_loss: 0.455957818031311\n",
      "7073, train_loss: 0.4733433356651893, val_loss: 0.464411860704422\n",
      "7074, train_loss: 0.474283543916849, val_loss: 0.47933398485183715\n",
      "7075, train_loss: 0.4782090691419748, val_loss: 0.46798462271690366\n",
      "7076, train_loss: 0.4743479306881244, val_loss: 0.47001351714134215\n",
      "7077, train_loss: 0.4740195388977344, val_loss: 0.47422379851341245\n",
      "7078, train_loss: 0.47422100947453427, val_loss: 0.4611538827419281\n",
      "7079, train_loss: 0.4781362402897615, val_loss: 0.45575538873672483\n",
      "7080, train_loss: 0.4781089138526183, val_loss: 0.4780129373073578\n",
      "7081, train_loss: 0.47295475464600784, val_loss: 0.46996030807495115\n",
      "7082, train_loss: 0.47411130368709564, val_loss: 0.46152280569076537\n",
      "7083, train_loss: 0.4780744577829654, val_loss: 0.47419085502624514\n",
      "7084, train_loss: 0.4780573329100242, val_loss: 0.4763904929161072\n",
      "7085, train_loss: 0.47649093774648815, val_loss: 0.47281649708747864\n",
      "7086, train_loss: 0.4750196234538005, val_loss: 0.45125770568847656\n",
      "7087, train_loss: 0.4759185784138166, val_loss: 0.46654651761054994\n",
      "7088, train_loss: 0.47589687544565934, val_loss: 0.45468373894691466\n",
      "7089, train_loss: 0.4749120599948443, val_loss: 0.4921180784702301\n",
      "7090, train_loss: 0.4740003232772534, val_loss: 0.45213490128517153\n",
      "7091, train_loss: 0.4778236127816714, val_loss: 0.47789987325668337\n",
      "7092, train_loss: 0.47782617005018085, val_loss: 0.4579130232334137\n",
      "7093, train_loss: 0.47777173954706925, val_loss: 0.4778868019580841\n",
      "7094, train_loss: 0.4740348859475209, val_loss: 0.45791745781898496\n",
      "7095, train_loss: 0.4777790926969968, val_loss: 0.49183944463729856\n",
      "7096, train_loss: 0.47561120643065524, val_loss: 0.4707543790340424\n",
      "7097, train_loss: 0.47351527443298924, val_loss: 0.4916475176811218\n",
      "7098, train_loss: 0.4777188025988065, val_loss: 0.4488100051879883\n",
      "7099, train_loss: 0.4730714582479917, val_loss: 0.4723506569862366\n",
      "7100, train_loss: 0.47565455161608183, val_loss: 0.46654502153396604\n",
      "7101, train_loss: 0.4756103925980054, val_loss: 0.46313716173172\n",
      "7102, train_loss: 0.47760175053889936, val_loss: 0.4559935688972473\n",
      "7103, train_loss: 0.47754045518545, val_loss: 0.46065753102302553\n",
      "7104, train_loss: 0.47365477681159973, val_loss: 0.4776000678539276\n",
      "7105, train_loss: 0.47751186100336224, val_loss: 0.45752304792404175\n",
      "7106, train_loss: 0.47634963805858904, val_loss: 0.4628594398498535\n",
      "7107, train_loss: 0.47266079084231305, val_loss: 0.45607247948646545\n",
      "7108, train_loss: 0.4755023912741588, val_loss: 0.47086378931999207\n",
      "7109, train_loss: 0.47342364948529464, val_loss: 0.4917584717273712\n",
      "7110, train_loss: 0.474360554264142, val_loss: 0.472164922952652\n",
      "7111, train_loss: 0.4735239457625609, val_loss: 0.44845898151397706\n",
      "7112, train_loss: 0.47734715044498444, val_loss: 0.4693038284778595\n",
      "7113, train_loss: 0.47734444301861984, val_loss: 0.4768753707408905\n",
      "7114, train_loss: 0.4739375951198431, val_loss: 0.45189722776412966\n",
      "7115, train_loss: 0.47729017528203815, val_loss: 0.47732353806495664\n",
      "7116, train_loss: 0.4726664527104451, val_loss: 0.4758178651332855\n",
      "7117, train_loss: 0.47331942274020267, val_loss: 0.4773524284362793\n",
      "7118, train_loss: 0.4772182840567369, val_loss: 0.45727471709251405\n",
      "7119, train_loss: 0.4738652923932442, val_loss: 0.47433456778526306\n",
      "7120, train_loss: 0.4771369959299381, val_loss: 0.46444674730300906\n",
      "7121, train_loss: 0.47473585376372707, val_loss: 0.4917701244354248\n",
      "7122, train_loss: 0.4729659855365753, val_loss: 0.4575405478477478\n",
      "7123, train_loss: 0.47702423540445477, val_loss: 0.47310950756073\n",
      "7124, train_loss: 0.47236358374357224, val_loss: 0.4609368681907654\n",
      "7125, train_loss: 0.47337280213832855, val_loss: 0.4772750973701477\n",
      "7126, train_loss: 0.47703028126404834, val_loss: 0.4527548551559448\n",
      "7127, train_loss: 0.4769661621405528, val_loss: 0.4563336491584778\n",
      "7128, train_loss: 0.4769476331197299, val_loss: 0.4670648634433746\n",
      "7129, train_loss: 0.4769634959789423, val_loss: 0.4723436951637268\n",
      "7130, train_loss: 0.47307785886984605, val_loss: 0.4678696125745773\n",
      "7131, train_loss: 0.4722997878606503, val_loss: 0.45436962246894835\n",
      "7132, train_loss: 0.47193386463018566, val_loss: 0.45024548172950746\n",
      "7133, train_loss: 0.4757254312817867, val_loss: 0.49107274413108826\n",
      "7134, train_loss: 0.4726282747892233, val_loss: 0.47550261616706846\n",
      "7135, train_loss: 0.47482064366340637, val_loss: 0.4861504018306732\n",
      "7136, train_loss: 0.4747460518891995, val_loss: 0.4911853730678558\n",
      "7137, train_loss: 0.47217479520119154, val_loss: 0.4571502208709717\n",
      "7138, train_loss: 0.47673607617616653, val_loss: 0.4588349640369415\n",
      "7139, train_loss: 0.4766946349006433, val_loss: 0.4691912293434143\n",
      "7140, train_loss: 0.47447239091763127, val_loss: 0.4690343976020813\n",
      "7141, train_loss: 0.472822177868623, val_loss: 0.47180006504058836\n",
      "7142, train_loss: 0.47509855605088747, val_loss: 0.46304149031639097\n",
      "7143, train_loss: 0.47657692203154933, val_loss: 0.4569136738777161\n",
      "7144, train_loss: 0.4728033897968439, val_loss: 0.4656368434429169\n",
      "7145, train_loss: 0.4719634766762073, val_loss: 0.4753383040428162\n",
      "7146, train_loss: 0.4749959879196607, val_loss: 0.4717921316623688\n",
      "7147, train_loss: 0.47339264704630923, val_loss: 0.459533029794693\n",
      "7148, train_loss: 0.476475674372453, val_loss: 0.4821999728679657\n",
      "7149, train_loss: 0.4733469755603717, val_loss: 0.4613920867443085\n",
      "7150, train_loss: 0.4763835771725728, val_loss: 0.47706134915351867\n",
      "7151, train_loss: 0.4712250381708145, val_loss: 0.4622340738773346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7152, train_loss: 0.47242713604982084, val_loss: 0.4516313672065735\n",
      "7153, train_loss: 0.47253983181256515, val_loss: 0.46862993240356443\n",
      "7154, train_loss: 0.47634563079247105, val_loss: 0.44789664149284364\n",
      "7155, train_loss: 0.473312513759503, val_loss: 0.4761035740375519\n",
      "7156, train_loss: 0.4762991896042457, val_loss: 0.4476716220378876\n",
      "7157, train_loss: 0.47629282107720006, val_loss: 0.47765270471572874\n",
      "7158, train_loss: 0.47318830627661485, val_loss: 0.45869527459144593\n",
      "7159, train_loss: 0.4712759176125893, val_loss: 0.4705312728881836\n",
      "7160, train_loss: 0.4761823576230269, val_loss: 0.4769633412361145\n",
      "7161, train_loss: 0.47613858718138474, val_loss: 0.47072126865386965\n",
      "7162, train_loss: 0.4727091032725114, val_loss: 0.47612289190292356\n",
      "7163, train_loss: 0.47610172973229337, val_loss: 0.45853846073150634\n",
      "7164, train_loss: 0.47607482282014996, val_loss: 0.45736612677574157\n",
      "7165, train_loss: 0.4736415663590798, val_loss: 0.4522230863571167\n",
      "7166, train_loss: 0.4718469868485744, val_loss: 0.47522265315055845\n",
      "7167, train_loss: 0.47371764137194705, val_loss: 0.490939998626709\n",
      "7168, train_loss: 0.4742446725185101, val_loss: 0.4698850989341736\n",
      "7169, train_loss: 0.4709843099117279, val_loss: 0.45665380358695984\n",
      "7170, train_loss: 0.47103245785603154, val_loss: 0.4576561987400055\n",
      "7171, train_loss: 0.47434425124755275, val_loss: 0.45630383491516113\n",
      "7172, train_loss: 0.471880636536158, val_loss: 0.4682877480983734\n",
      "7173, train_loss: 0.47245290187688976, val_loss: 0.4637324094772339\n",
      "7174, train_loss: 0.47021178213449627, val_loss: 0.4691294848918915\n",
      "7175, train_loss: 0.4758032411336899, val_loss: 0.44777190685272217\n",
      "7176, train_loss: 0.47282996945656264, val_loss: 0.47505914568901064\n",
      "7177, train_loss: 0.47267531087765324, val_loss: 0.4511809527873993\n",
      "7178, train_loss: 0.4711689639549989, val_loss: 0.46052122116088867\n",
      "7179, train_loss: 0.4727507669192094, val_loss: 0.45095539689064024\n",
      "7180, train_loss: 0.47575581474946094, val_loss: 0.481591534614563\n",
      "7181, train_loss: 0.47266485484746784, val_loss: 0.4537265717983246\n",
      "7182, train_loss: 0.4756521169955914, val_loss: 0.45714842081069945\n",
      "7183, train_loss: 0.4756458757015375, val_loss: 0.4521905958652496\n",
      "7184, train_loss: 0.4714692555941068, val_loss: 0.4816406428813934\n",
      "7185, train_loss: 0.4727106529932756, val_loss: 0.45978904962539674\n",
      "7186, train_loss: 0.4727479677933913, val_loss: 0.44994873404502866\n",
      "7187, train_loss: 0.4731511095395455, val_loss: 0.48553876876831054\n",
      "7188, train_loss: 0.47236593870016247, val_loss: 0.45277345180511475\n",
      "7189, train_loss: 0.47547057614876675, val_loss: 0.45629009008407595\n",
      "7190, train_loss: 0.47113728867127347, val_loss: 0.464428174495697\n",
      "7191, train_loss: 0.4720367365158521, val_loss: 0.47481935620307925\n",
      "7192, train_loss: 0.47538918543320435, val_loss: 0.481539911031723\n",
      "7193, train_loss: 0.47080801255427873, val_loss: 0.47005953788757326\n",
      "7194, train_loss: 0.4728750368723503, val_loss: 0.4682827353477478\n",
      "7195, train_loss: 0.4753478536239037, val_loss: 0.45614486932754517\n",
      "7196, train_loss: 0.4699234847839062, val_loss: 0.44843162298202516\n",
      "7197, train_loss: 0.4718872578098224, val_loss: 0.469142085313797\n",
      "7198, train_loss: 0.47022884281782, val_loss: 0.4714536666870117\n",
      "7199, train_loss: 0.4752891625349338, val_loss: 0.4531840801239014\n",
      "7200, train_loss: 0.47527555662852067, val_loss: 0.47603386640548706\n",
      "7201, train_loss: 0.47524603513570934, val_loss: 0.4610561549663544\n",
      "7202, train_loss: 0.4706016927957535, val_loss: 0.46883134841918944\n",
      "7203, train_loss: 0.4709769934415817, val_loss: 0.4712048888206482\n",
      "7204, train_loss: 0.47091966982071215, val_loss: 0.4484011113643646\n",
      "7205, train_loss: 0.4731642260001256, val_loss: 0.4624014437198639\n",
      "7206, train_loss: 0.4752186628488394, val_loss: 0.46405301094055174\n",
      "7207, train_loss: 0.4751577984828215, val_loss: 0.4753602921962738\n",
      "7208, train_loss: 0.47513037748061693, val_loss: 0.46727152466773986\n",
      "7209, train_loss: 0.47211154378377473, val_loss: 0.48946815729141235\n",
      "7210, train_loss: 0.475065237054458, val_loss: 0.44665147066116334\n",
      "7211, train_loss: 0.4751154436514928, val_loss: 0.47617812156677247\n",
      "7212, train_loss: 0.4716656288275352, val_loss: 0.4635985791683197\n",
      "7213, train_loss: 0.47273500722188216, val_loss: 0.4601085066795349\n",
      "7214, train_loss: 0.47296995039169604, val_loss: 0.46816179156303406\n",
      "7215, train_loss: 0.4725748621500455, val_loss: 0.44529486894607545\n",
      "7216, train_loss: 0.4716130919181384, val_loss: 0.48902390599250795\n",
      "7217, train_loss: 0.47496107335274035, val_loss: 0.4646829545497894\n",
      "7218, train_loss: 0.4749460243261777, val_loss: 0.45494459867477416\n",
      "7219, train_loss: 0.47192503626529986, val_loss: 0.47439795136451723\n",
      "7220, train_loss: 0.47485559032513547, val_loss: 0.4717341661453247\n",
      "7221, train_loss: 0.4748582988977432, val_loss: 0.471430116891861\n",
      "7222, train_loss: 0.4748731473317513, val_loss: 0.46977037787437437\n",
      "7223, train_loss: 0.47024912100571853, val_loss: 0.47495642900466917\n",
      "7224, train_loss: 0.4701067329599307, val_loss: 0.46611430644989016\n",
      "7225, train_loss: 0.472487415258701, val_loss: 0.47500150799751284\n",
      "7226, train_loss: 0.470632713001508, val_loss: 0.4593797743320465\n",
      "7227, train_loss: 0.47172058946811235, val_loss: 0.4532367467880249\n",
      "7228, train_loss: 0.47164377111655015, val_loss: 0.4649194359779358\n",
      "7229, train_loss: 0.4710877893062738, val_loss: 0.4503061234951019\n",
      "7230, train_loss: 0.4696199366679558, val_loss: 0.4636951208114624\n",
      "7231, train_loss: 0.47455876721785617, val_loss: 0.4442572951316833\n",
      "7232, train_loss: 0.47455591651109547, val_loss: 0.4503734946250916\n",
      "7233, train_loss: 0.47038529354792374, val_loss: 0.45252091288566587\n",
      "7234, train_loss: 0.470406901377898, val_loss: 0.4540039002895355\n",
      "7235, train_loss: 0.4745584221986624, val_loss: 0.4676418244838715\n",
      "7236, train_loss: 0.47160626030885255, val_loss: 0.4670248508453369\n",
      "7237, train_loss: 0.47451570343512756, val_loss: 0.47391570806503297\n",
      "7238, train_loss: 0.4708858992044742, val_loss: 0.48856457471847536\n",
      "7239, train_loss: 0.4744591082517917, val_loss: 0.4505595564842224\n",
      "7240, train_loss: 0.46921620002159703, val_loss: 0.47105194330215455\n",
      "7241, train_loss: 0.4725588204768988, val_loss: 0.47440711259841917\n",
      "7242, train_loss: 0.47437569957513076, val_loss: 0.45560342669487\n",
      "7243, train_loss: 0.4743755029944273, val_loss: 0.4709352135658264\n",
      "7244, train_loss: 0.4701048708879031, val_loss: 0.4544685184955597\n",
      "7245, train_loss: 0.47433974421941316, val_loss: 0.4744057834148407\n",
      "7246, train_loss: 0.47218547532191646, val_loss: 0.46508296132087706\n",
      "7247, train_loss: 0.4742398170324472, val_loss: 0.457010418176651\n",
      "7248, train_loss: 0.47418361787612623, val_loss: 0.4798744797706604\n",
      "7249, train_loss: 0.4719269103728808, val_loss: 0.445541250705719\n",
      "7250, train_loss: 0.4695813117118982, val_loss: 0.4492237329483032\n",
      "7251, train_loss: 0.47209618297907024, val_loss: 0.45074751377105715\n",
      "7252, train_loss: 0.4679153091632403, val_loss: 0.4566440969705582\n",
      "7253, train_loss: 0.4702832819177554, val_loss: 0.48839417695999143\n",
      "7254, train_loss: 0.47191372513771057, val_loss: 0.47069126963615415\n",
      "7255, train_loss: 0.46916928543494296, val_loss: 0.4664787113666534\n",
      "7256, train_loss: 0.4691257740442569, val_loss: 0.45382705330848694\n",
      "7257, train_loss: 0.4740621264164264, val_loss: 0.4676989197731018\n",
      "7258, train_loss: 0.4700274398693672, val_loss: 0.4723545014858246\n",
      "7259, train_loss: 0.4688875125004695, val_loss: 0.473216187953949\n",
      "7260, train_loss: 0.47195210938270277, val_loss: 0.45460341572761537\n",
      "7261, train_loss: 0.4700784797851856, val_loss: 0.46570390462875366\n",
      "7262, train_loss: 0.47116081989728487, val_loss: 0.4420360207557678\n",
      "7263, train_loss: 0.46876902419787186, val_loss: 0.45283291339874265\n",
      "7264, train_loss: 0.4720567109493109, val_loss: 0.4657592594623566\n",
      "7265, train_loss: 0.4687865903744331, val_loss: 0.4686137557029724\n",
      "7266, train_loss: 0.473860427737236, val_loss: 0.44292908906936646\n",
      "7267, train_loss: 0.46819835614699584, val_loss: 0.465214216709137\n",
      "7268, train_loss: 0.47049675308741057, val_loss: 0.45911957025527955\n",
      "7269, train_loss: 0.47132673744971937, val_loss: 0.46022602915763855\n",
      "7270, train_loss: 0.47025169088290286, val_loss: 0.4478297889232635\n",
      "7271, train_loss: 0.47074193679369414, val_loss: 0.47406342029571535\n",
      "7272, train_loss: 0.4699329917247479, val_loss: 0.4576055645942688\n",
      "7273, train_loss: 0.470765766616051, val_loss: 0.4884094774723053\n",
      "7274, train_loss: 0.46844854950904846, val_loss: 0.46646422147750854\n",
      "7275, train_loss: 0.4695388743510613, val_loss: 0.4668766736984253\n",
      "7276, train_loss: 0.4706456775848682, val_loss: 0.47022799849510194\n",
      "7277, train_loss: 0.4692317327627769, val_loss: 0.45269243121147157\n",
      "7278, train_loss: 0.47356501794778383, val_loss: 0.46918514370918274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7279, train_loss: 0.47011272609233856, val_loss: 0.4606368064880371\n",
      "7280, train_loss: 0.47350822732998776, val_loss: 0.4536608338356018\n",
      "7281, train_loss: 0.4700707220114194, val_loss: 0.46843254566192627\n",
      "7282, train_loss: 0.46931372869473237, val_loss: 0.47890776991844175\n",
      "7283, train_loss: 0.4688476054714276, val_loss: 0.4416287183761597\n",
      "7284, train_loss: 0.4687885573277107, val_loss: 0.4696105122566223\n",
      "7285, train_loss: 0.46816848791562593, val_loss: 0.44245184063911436\n",
      "7286, train_loss: 0.46963909153754896, val_loss: 0.46323179006576537\n",
      "7287, train_loss: 0.4686921685934067, val_loss: 0.45862168073654175\n",
      "7288, train_loss: 0.46915360482839435, val_loss: 0.4563852310180664\n",
      "7289, train_loss: 0.47332656727387357, val_loss: 0.4507060408592224\n",
      "7290, train_loss: 0.4699080620820706, val_loss: 0.46582567095756533\n",
      "7291, train_loss: 0.4732693066963783, val_loss: 0.47271197438240053\n",
      "7292, train_loss: 0.4689980676540962, val_loss: 0.473384290933609\n",
      "7293, train_loss: 0.4732273541964017, val_loss: 0.4553542971611023\n",
      "7294, train_loss: 0.4708747703295488, val_loss: 0.4699441373348236\n",
      "7295, train_loss: 0.4701711581303523, val_loss: 0.4477968990802765\n",
      "7296, train_loss: 0.4689161479473114, val_loss: 0.4502786934375763\n",
      "7297, train_loss: 0.46913633667505705, val_loss: 0.4678803265094757\n",
      "7298, train_loss: 0.47308951501662916, val_loss: 0.450589257478714\n",
      "7299, train_loss: 0.46886514929624706, val_loss: 0.46578251719474795\n",
      "7300, train_loss: 0.47074086448320973, val_loss: 0.46834232807159426\n",
      "7301, train_loss: 0.46832114400771946, val_loss: 0.4662593185901642\n",
      "7302, train_loss: 0.46834887678806597, val_loss: 0.48713520765304563\n",
      "7303, train_loss: 0.4686501748286761, val_loss: 0.45063574612140656\n",
      "7304, train_loss: 0.4695263940554399, val_loss: 0.4677667260169983\n",
      "7305, train_loss: 0.4710978659299704, val_loss: 0.4480393886566162\n",
      "7306, train_loss: 0.4689782663033559, val_loss: 0.46093919277191164\n",
      "7307, train_loss: 0.4729072222342858, val_loss: 0.48716686964035033\n",
      "7308, train_loss: 0.4729141340805934, val_loss: 0.46543272137641906\n",
      "7309, train_loss: 0.4677165477321698, val_loss: 0.45268171429634096\n",
      "7310, train_loss: 0.4728388534142421, val_loss: 0.46435020565986634\n",
      "7311, train_loss: 0.4728255237524326, val_loss: 0.45509331226348876\n",
      "7312, train_loss: 0.4680214501344241, val_loss: 0.4650034368038177\n",
      "7313, train_loss: 0.46818856780345625, val_loss: 0.472536301612854\n",
      "7314, train_loss: 0.46915297783338106, val_loss: 0.4495692729949951\n",
      "7315, train_loss: 0.471288637473033, val_loss: 0.47256680130958556\n",
      "7316, train_loss: 0.4706146396123446, val_loss: 0.48669875264167783\n",
      "7317, train_loss: 0.4705683279495973, val_loss: 0.48186107277870177\n",
      "7318, train_loss: 0.4698116252055535, val_loss: 0.4780985414981842\n",
      "7319, train_loss: 0.46915514824482113, val_loss: 0.4727452516555786\n",
      "7320, train_loss: 0.47019751312640995, val_loss: 0.44837117195129395\n",
      "7321, train_loss: 0.4683528152795938, val_loss: 0.46399604678153994\n",
      "7322, train_loss: 0.46784607149087465, val_loss: 0.4541043281555176\n",
      "7323, train_loss: 0.46905059768603397, val_loss: 0.4552393913269043\n",
      "7324, train_loss: 0.467819597858649, val_loss: 0.48685395121574404\n",
      "7325, train_loss: 0.4694640269646278, val_loss: 0.44716817140579224\n",
      "7326, train_loss: 0.46906450161567104, val_loss: 0.4524121046066284\n",
      "7327, train_loss: 0.47092539415909695, val_loss: 0.4499198913574219\n",
      "7328, train_loss: 0.46767989374124086, val_loss: 0.4453822135925293\n",
      "7329, train_loss: 0.46921543776988983, val_loss: 0.4510423123836517\n",
      "7330, train_loss: 0.472313261949099, val_loss: 0.46940314769744873\n",
      "7331, train_loss: 0.466894921201926, val_loss: 0.4721287488937378\n",
      "7332, train_loss: 0.46687706961081576, val_loss: 0.4508382141590118\n",
      "7333, train_loss: 0.47230982264647114, val_loss: 0.4866603076457977\n",
      "7334, train_loss: 0.47114675549360424, val_loss: 0.4398385763168335\n",
      "7335, train_loss: 0.4676633362586682, val_loss: 0.44660083055496214\n",
      "7336, train_loss: 0.4680277040371528, val_loss: 0.4628157436847687\n",
      "7337, train_loss: 0.47225491129435027, val_loss: 0.4689319610595703\n",
      "7338, train_loss: 0.47220292687416077, val_loss: 0.46402603983879087\n",
      "7339, train_loss: 0.4722273177825488, val_loss: 0.4565520226955414\n",
      "7340, train_loss: 0.4667787402868271, val_loss: 0.46395441293716433\n",
      "7341, train_loss: 0.4669843350465481, val_loss: 0.45541941523551943\n",
      "7342, train_loss: 0.4721828911166925, val_loss: 0.48115246295928954\n",
      "7343, train_loss: 0.472114065518746, val_loss: 0.4418022811412811\n",
      "7344, train_loss: 0.46799503381435686, val_loss: 0.45870237946510317\n",
      "7345, train_loss: 0.46973105577322155, val_loss: 0.48593655228614807\n",
      "7346, train_loss: 0.4721395562474544, val_loss: 0.44638108611106875\n",
      "7347, train_loss: 0.4668835493234488, val_loss: 0.4857053279876709\n",
      "7348, train_loss: 0.47207606182648587, val_loss: 0.44882477521896363\n",
      "7349, train_loss: 0.47204701602458954, val_loss: 0.46311580538749697\n",
      "7350, train_loss: 0.4720916278087176, val_loss: 0.45695914030075074\n",
      "7351, train_loss: 0.470032729781591, val_loss: 0.44589943885803224\n",
      "7352, train_loss: 0.46802117790167147, val_loss: 0.4451340615749359\n",
      "7353, train_loss: 0.4696568777927986, val_loss: 0.44285924434661866\n",
      "7354, train_loss: 0.469329467186561, val_loss: 0.47264904379844663\n",
      "7355, train_loss: 0.46772197920542496, val_loss: 0.47259471416473386\n",
      "7356, train_loss: 0.4698502719402313, val_loss: 0.4599192261695862\n",
      "7357, train_loss: 0.4678627791313025, val_loss: 0.4708739161491394\n",
      "7358, train_loss: 0.46614359147273576, val_loss: 0.4668269753456116\n",
      "7359, train_loss: 0.4689025408946551, val_loss: 0.4466192305088043\n",
      "7360, train_loss: 0.47070701076434207, val_loss: 0.46994966864585874\n",
      "7361, train_loss: 0.4717611727806238, val_loss: 0.4854768097400665\n",
      "7362, train_loss: 0.4698799390059251, val_loss: 0.4661605417728424\n",
      "7363, train_loss: 0.47167306450697094, val_loss: 0.47003357410430907\n",
      "7364, train_loss: 0.47166156138365084, val_loss: 0.446823388338089\n",
      "7365, train_loss: 0.466411754488945, val_loss: 0.46603221297264097\n",
      "7366, train_loss: 0.4697478333344826, val_loss: 0.4639206051826477\n",
      "7367, train_loss: 0.47160040644498974, val_loss: 0.46671987771987916\n",
      "7368, train_loss: 0.46866509375663906, val_loss: 0.46357441544532774\n",
      "7369, train_loss: 0.46690284747343797, val_loss: 0.4539149284362793\n",
      "7370, train_loss: 0.4691351256691493, val_loss: 0.45855286717414856\n",
      "7371, train_loss: 0.4684270929831725, val_loss: 0.44310822486877444\n",
      "7372, train_loss: 0.47143064668545354, val_loss: 0.4716310083866119\n",
      "7373, train_loss: 0.47134897800592274, val_loss: 0.4470792770385742\n",
      "7374, train_loss: 0.46766091883182526, val_loss: 0.45925135612487794\n",
      "7375, train_loss: 0.4713687954040674, val_loss: 0.45740788578987124\n",
      "7376, train_loss: 0.4690724089741707, val_loss: 0.4681282460689545\n",
      "7377, train_loss: 0.4713282080797049, val_loss: 0.47153072357177733\n",
      "7378, train_loss: 0.4712562377636249, val_loss: 0.4857247292995453\n",
      "7379, train_loss: 0.4666139076535518, val_loss: 0.45505101084709165\n",
      "7380, train_loss: 0.4670723286958841, val_loss: 0.45323904156684874\n",
      "7381, train_loss: 0.4712326687115889, val_loss: 0.447344571352005\n",
      "7382, train_loss: 0.4665183493724236, val_loss: 0.4548864424228668\n",
      "7383, train_loss: 0.46493104329475987, val_loss: 0.44580066204071045\n",
      "7384, train_loss: 0.4697192322749358, val_loss: 0.4696260094642639\n",
      "7385, train_loss: 0.4711814895272255, val_loss: 0.44309120774269106\n",
      "7386, train_loss: 0.4676647507227384, val_loss: 0.44730939269065856\n",
      "7387, train_loss: 0.4687791076990274, val_loss: 0.47117539048194884\n",
      "7388, train_loss: 0.46689759767972505, val_loss: 0.45350232124328616\n",
      "7389, train_loss: 0.4655964970588684, val_loss: 0.46645318269729613\n",
      "7390, train_loss: 0.471106985440621, val_loss: 0.4850571632385254\n",
      "7391, train_loss: 0.47105545378648317, val_loss: 0.4616214096546173\n",
      "7392, train_loss: 0.4676325905781526, val_loss: 0.4429531216621399\n",
      "7393, train_loss: 0.4689315981589831, val_loss: 0.45261767506599426\n",
      "7394, train_loss: 0.4674825416161464, val_loss: 0.4510366082191467\n",
      "7395, train_loss: 0.4669629530264781, val_loss: 0.4526047229766846\n",
      "7396, train_loss: 0.46879304028474367, val_loss: 0.454423850774765\n",
      "7397, train_loss: 0.47081129596783566, val_loss: 0.46775447726249697\n",
      "7398, train_loss: 0.46564277891929334, val_loss: 0.46661523580551145\n",
      "7399, train_loss: 0.4707967203397017, val_loss: 0.4514473259449005\n",
      "7400, train_loss: 0.4707689812550178, val_loss: 0.4518225729465485\n",
      "7401, train_loss: 0.464443183862246, val_loss: 0.45083265006542206\n",
      "7402, train_loss: 0.4661267256507507, val_loss: 0.47082781195640566\n",
      "7403, train_loss: 0.47068991454748005, val_loss: 0.4527933359146118\n",
      "7404, train_loss: 0.466659094278629, val_loss: 0.471031129360199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7405, train_loss: 0.46434684556264144, val_loss: 0.4850288569927216\n",
      "7406, train_loss: 0.4664606543687674, val_loss: 0.48481133580207825\n",
      "7407, train_loss: 0.4671521737025334, val_loss: 0.43862355351448057\n",
      "7408, train_loss: 0.4706608263345865, val_loss: 0.4531802237033844\n",
      "7409, train_loss: 0.46587213988487536, val_loss: 0.4531794905662537\n",
      "7410, train_loss: 0.47055143461777615, val_loss: 0.45448832511901854\n",
      "7411, train_loss: 0.4668440601000419, val_loss: 0.4706894099712372\n",
      "7412, train_loss: 0.4680988857379326, val_loss: 0.46437908411026\n",
      "7413, train_loss: 0.4668070994890653, val_loss: 0.48487324118614195\n",
      "7414, train_loss: 0.46668920723291546, val_loss: 0.4511443555355072\n",
      "7415, train_loss: 0.4683561256298652, val_loss: 0.4692735016345978\n",
      "7416, train_loss: 0.4667218533846048, val_loss: 0.47180572152137756\n",
      "7417, train_loss: 0.47037739765185577, val_loss: 0.46269055008888244\n",
      "7418, train_loss: 0.46737655194906086, val_loss: 0.46593241691589354\n",
      "7419, train_loss: 0.4657466388665713, val_loss: 0.48491684794425965\n",
      "7420, train_loss: 0.4656356710654039, val_loss: 0.46279156804084776\n",
      "7421, train_loss: 0.46639998429096663, val_loss: 0.46909751296043395\n",
      "7422, train_loss: 0.47028603003575253, val_loss: 0.4715845763683319\n",
      "7423, train_loss: 0.4661748489508262, val_loss: 0.45285407900810243\n",
      "7424, train_loss: 0.4702506329004581, val_loss: 0.44434494376182554\n",
      "7425, train_loss: 0.467625509087856, val_loss: 0.46993316411972047\n",
      "7426, train_loss: 0.46771639241622043, val_loss: 0.4759277403354645\n",
      "7427, train_loss: 0.4666447960413419, val_loss: 0.47060068845748904\n",
      "7428, train_loss: 0.4661274254322052, val_loss: 0.4759636461734772\n",
      "7429, train_loss: 0.46590543595644146, val_loss: 0.4447474777698517\n",
      "7430, train_loss: 0.4700816869735718, val_loss: 0.45562166571617124\n",
      "7431, train_loss: 0.46621857010401213, val_loss: 0.4798164367675781\n",
      "7432, train_loss: 0.46531136563191045, val_loss: 0.4639639496803284\n",
      "7433, train_loss: 0.4660146947090442, val_loss: 0.46104295253753663\n",
      "7434, train_loss: 0.47000695077272564, val_loss: 0.4521183967590332\n",
      "7435, train_loss: 0.46691520855976987, val_loss: 0.46690126657485964\n",
      "7436, train_loss: 0.46993117263683903, val_loss: 0.4451903343200684\n",
      "7437, train_loss: 0.4649650047604854, val_loss: 0.4637263596057892\n",
      "7438, train_loss: 0.465955444253408, val_loss: 0.4653471946716309\n",
      "7439, train_loss: 0.46609599315203154, val_loss: 0.4663287103176117\n",
      "7440, train_loss: 0.464925616979599, val_loss: 0.46673575043678284\n",
      "7441, train_loss: 0.4669609940969027, val_loss: 0.4712360560894012\n",
      "7442, train_loss: 0.4652283168756045, val_loss: 0.45158138275146487\n",
      "7443, train_loss: 0.4655642601159903, val_loss: 0.4843663513660431\n",
      "7444, train_loss: 0.4673354390722055, val_loss: 0.44443597793579104\n",
      "7445, train_loss: 0.4697212978051259, val_loss: 0.4499755263328552\n",
      "7446, train_loss: 0.4696980451162045, val_loss: 0.4657166004180908\n",
      "7447, train_loss: 0.46402566822675556, val_loss: 0.46245739459991453\n",
      "7448, train_loss: 0.46627640838806445, val_loss: 0.4477896451950073\n",
      "7449, train_loss: 0.4696985723880621, val_loss: 0.44863653779029844\n",
      "7450, train_loss: 0.4672601010936957, val_loss: 0.4580855071544647\n",
      "7451, train_loss: 0.4648173308143249, val_loss: 0.475178474187851\n",
      "7452, train_loss: 0.4655120705182736, val_loss: 0.4556553602218628\n",
      "7453, train_loss: 0.4648887916253163, val_loss: 0.4791114807128906\n",
      "7454, train_loss: 0.4695880195269218, val_loss: 0.45287095904350283\n",
      "7455, train_loss: 0.4657801263607465, val_loss: 0.46817790865898135\n",
      "7456, train_loss: 0.4654209533563027, val_loss: 0.46957728266716003\n",
      "7457, train_loss: 0.4695291542089902, val_loss: 0.4356246471405029\n",
      "7458, train_loss: 0.46957094680804473, val_loss: 0.4525230824947357\n",
      "7459, train_loss: 0.4665744797541545, val_loss: 0.4630146622657776\n",
      "7460, train_loss: 0.46420379326893735, val_loss: 0.47041249871253965\n",
      "7461, train_loss: 0.46397336629720837, val_loss: 0.453016984462738\n",
      "7462, train_loss: 0.46698231995105743, val_loss: 0.4472753882408142\n",
      "7463, train_loss: 0.4646711882490378, val_loss: 0.4440563380718231\n",
      "7464, train_loss: 0.4639833712807068, val_loss: 0.44213869571685793\n",
      "7465, train_loss: 0.4658857583999634, val_loss: 0.46270876526832583\n",
      "7466, train_loss: 0.4675121410534932, val_loss: 0.4658420443534851\n",
      "7467, train_loss: 0.46580807119607925, val_loss: 0.46218450665473937\n",
      "7468, train_loss: 0.46927773493986863, val_loss: 0.4391689598560333\n",
      "7469, train_loss: 0.46709849857367003, val_loss: 0.44393436312675477\n",
      "7470, train_loss: 0.4654543651984288, val_loss: 0.45153366327285765\n",
      "7471, train_loss: 0.4635398731781886, val_loss: 0.46077234745025636\n",
      "7472, train_loss: 0.4662953523489145, val_loss: 0.45600939989089967\n",
      "7473, train_loss: 0.4691987862953773, val_loss: 0.44309585094451903\n",
      "7474, train_loss: 0.46681976547608006, val_loss: 0.45780988931655886\n",
      "7475, train_loss: 0.4691269581134503, val_loss: 0.46975250244140626\n",
      "7476, train_loss: 0.4652850410112968, val_loss: 0.46556624174118044\n",
      "7477, train_loss: 0.4648798956320836, val_loss: 0.4783558905124664\n",
      "7478, train_loss: 0.4691194754380446, val_loss: 0.45722696781158445\n",
      "7479, train_loss: 0.46441277059224934, val_loss: 0.45238093137741087\n",
      "7480, train_loss: 0.46386876186499226, val_loss: 0.46885080337524415\n",
      "7481, train_loss: 0.46434904921513337, val_loss: 0.43568441867828367\n",
      "7482, train_loss: 0.46428845249689543, val_loss: 0.46323508620262144\n",
      "7483, train_loss: 0.46903309111411756, val_loss: 0.4466272830963135\n",
      "7484, train_loss: 0.4642772342150028, val_loss: 0.4478111624717712\n",
      "7485, train_loss: 0.46422846558002323, val_loss: 0.4826721608638763\n",
      "7486, train_loss: 0.4689888713451532, val_loss: 0.47391321063041686\n",
      "7487, train_loss: 0.4689586976399788, val_loss: 0.4471094846725464\n",
      "7488, train_loss: 0.4649476053623053, val_loss: 0.46387707591056826\n",
      "7489, train_loss: 0.4659680598057233, val_loss: 0.4686018466949463\n",
      "7490, train_loss: 0.4642280787229538, val_loss: 0.4436600565910339\n",
      "7491, train_loss: 0.4688508418890146, val_loss: 0.46513479948043823\n",
      "7492, train_loss: 0.4677000269293785, val_loss: 0.46393603682518003\n",
      "7493, train_loss: 0.4663747761111993, val_loss: 0.44530012011528014\n",
      "7494, train_loss: 0.46402465265530807, val_loss: 0.4478966772556305\n",
      "7495, train_loss: 0.466701586659138, val_loss: 0.474011105298996\n",
      "7496, train_loss: 0.4686798075070748, val_loss: 0.4622049152851105\n",
      "7497, train_loss: 0.4686471155056587, val_loss: 0.4555040061473846\n",
      "7498, train_loss: 0.4661920924599354, val_loss: 0.4687520623207092\n",
      "7499, train_loss: 0.4685685932636261, val_loss: 0.47425328493118285\n",
      "7500, train_loss: 0.4655431623642261, val_loss: 0.43551817536354065\n",
      "7501, train_loss: 0.46855027973651886, val_loss: 0.44577403664588927\n",
      "7502, train_loss: 0.4685075649848351, val_loss: 0.4479576826095581\n",
      "7503, train_loss: 0.46677186626654404, val_loss: 0.48297608494758604\n",
      "7504, train_loss: 0.46846729860855985, val_loss: 0.45707952976226807\n",
      "7505, train_loss: 0.46489612528911006, val_loss: 0.4399318039417267\n",
      "7506, train_loss: 0.4634101516925372, val_loss: 0.4827196359634399\n",
      "7507, train_loss: 0.4635792294373879, val_loss: 0.4471928119659424\n",
      "7508, train_loss: 0.46834482367222124, val_loss: 0.4602822005748749\n",
      "7509, train_loss: 0.46440054361636823, val_loss: 0.45685853362083434\n",
      "7510, train_loss: 0.4646230615102328, val_loss: 0.4465204417705536\n",
      "7511, train_loss: 0.46832402508992416, val_loss: 0.4590976893901825\n",
      "7512, train_loss: 0.4632474396091241, val_loss: 0.44184592366218567\n",
      "7513, train_loss: 0.4682609524864417, val_loss: 0.48232781887054443\n",
      "7514, train_loss: 0.4667736475284283, val_loss: 0.44657717943191527\n",
      "7515, train_loss: 0.46453335651984584, val_loss: 0.45355530381202697\n",
      "7516, train_loss: 0.46620481977095973, val_loss: 0.4551159739494324\n",
      "7517, train_loss: 0.4666311935736583, val_loss: 0.4460686922073364\n",
      "7518, train_loss: 0.4642611604470473, val_loss: 0.4825018227100372\n",
      "7519, train_loss: 0.46347152957549465, val_loss: 0.4635751128196716\n",
      "7520, train_loss: 0.46810212158239806, val_loss: 0.4431659936904907\n",
      "7521, train_loss: 0.4642540365457535, val_loss: 0.4635070085525513\n",
      "7522, train_loss: 0.4656855704692694, val_loss: 0.4518269121646881\n",
      "7523, train_loss: 0.4680469414362541, val_loss: 0.44591731429100034\n",
      "7524, train_loss: 0.46801854784672076, val_loss: 0.4605650782585144\n",
      "7525, train_loss: 0.4629983901977539, val_loss: 0.4597808837890625\n",
      "7526, train_loss: 0.4680205388711049, val_loss: 0.438436222076416\n",
      "7527, train_loss: 0.4644158436701848, val_loss: 0.459477835893631\n",
      "7528, train_loss: 0.4640534703548138, val_loss: 0.4457288861274719\n",
      "7529, train_loss: 0.4632932933477255, val_loss: 0.4555134832859039\n",
      "7530, train_loss: 0.46413207398011136, val_loss: 0.48135365843772887\n",
      "7531, train_loss: 0.4645462529017375, val_loss: 0.45953552722930907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7532, train_loss: 0.4632628388129748, val_loss: 0.48122445344924925\n",
      "7533, train_loss: 0.4656176498303047, val_loss: 0.44774931073188784\n",
      "7534, train_loss: 0.46267307377778566, val_loss: 0.45881747007369994\n",
      "7535, train_loss: 0.46315551033386815, val_loss: 0.4596128582954407\n",
      "7536, train_loss: 0.4631468986089413, val_loss: 0.4493892788887024\n",
      "7537, train_loss: 0.4678757677857692, val_loss: 0.4623481512069702\n",
      "7538, train_loss: 0.46786591754509854, val_loss: 0.46714858412742616\n",
      "7539, train_loss: 0.4630722300364421, val_loss: 0.47650890946388247\n",
      "7540, train_loss: 0.4625094922689291, val_loss: 0.4495743095874786\n",
      "7541, train_loss: 0.4677730443385931, val_loss: 0.46817747354507444\n",
      "7542, train_loss: 0.46399733825371814, val_loss: 0.4465520799160004\n",
      "7543, train_loss: 0.4677290629882079, val_loss: 0.43736292719841\n",
      "7544, train_loss: 0.4677074540119905, val_loss: 0.4680336654186249\n",
      "7545, train_loss: 0.4646635450995885, val_loss: 0.45399101376533507\n",
      "7546, train_loss: 0.4646938701088612, val_loss: 0.4365447163581848\n",
      "7547, train_loss: 0.46418846112031203, val_loss: 0.45470441579818727\n",
      "7548, train_loss: 0.46757127516544783, val_loss: 0.44156801104545595\n",
      "7549, train_loss: 0.46759600593493533, val_loss: 0.44040772318840027\n",
      "7550, train_loss: 0.4675584974197241, val_loss: 0.46539226770401\n",
      "7551, train_loss: 0.4675410963021792, val_loss: 0.433122044801712\n",
      "7552, train_loss: 0.46383477518191707, val_loss: 0.4455648005008698\n",
      "7553, train_loss: 0.4655376523733139, val_loss: 0.45046878457069395\n",
      "7554, train_loss: 0.46267678302067977, val_loss: 0.47617160677909853\n",
      "7555, train_loss: 0.4627402711373109, val_loss: 0.45464484095573426\n",
      "7556, train_loss: 0.4645167915866925, val_loss: 0.4446086406707764\n",
      "7557, train_loss: 0.4631874687396563, val_loss: 0.46328346729278563\n",
      "7558, train_loss: 0.46323310985014987, val_loss: 0.43882474303245544\n",
      "7559, train_loss: 0.46740005681147945, val_loss: 0.4510878145694733\n",
      "7560, train_loss: 0.46353697089048534, val_loss: 0.45655423402786255\n",
      "7561, train_loss: 0.4643507989553305, val_loss: 0.44078155755996706\n",
      "7562, train_loss: 0.46729671038114107, val_loss: 0.4405601918697357\n",
      "7563, train_loss: 0.4672919397170727, val_loss: 0.4485504388809204\n",
      "7564, train_loss: 0.4635131691510861, val_loss: 0.4413531482219696\n",
      "7565, train_loss: 0.4624977742250149, val_loss: 0.46008933186531065\n",
      "7566, train_loss: 0.4642456082197336, val_loss: 0.45805549025535586\n",
      "7567, train_loss: 0.4630015824849789, val_loss: 0.46620803475379946\n",
      "7568, train_loss: 0.46712086693598676, val_loss: 0.4652545988559723\n",
      "7569, train_loss: 0.4610561911876385, val_loss: 0.4761491000652313\n",
      "7570, train_loss: 0.4654196340304155, val_loss: 0.4435829520225525\n",
      "7571, train_loss: 0.46700553137522477, val_loss: 0.46675817370414735\n",
      "7572, train_loss: 0.46699462143274456, val_loss: 0.4668146014213562\n",
      "7573, train_loss: 0.46698261682803816, val_loss: 0.45210657119750974\n",
      "7574, train_loss: 0.4622091232584073, val_loss: 0.46337397694587706\n",
      "7575, train_loss: 0.4668868493575316, val_loss: 0.4621249377727509\n",
      "7576, train_loss: 0.46690235000390273, val_loss: 0.44262107610702517\n",
      "7577, train_loss: 0.4637825076396649, val_loss: 0.43450583815574645\n",
      "7578, train_loss: 0.4621454282448842, val_loss: 0.4634894371032715\n",
      "7579, train_loss: 0.46315795412430394, val_loss: 0.4353742837905884\n",
      "7580, train_loss: 0.4647898880335001, val_loss: 0.43535966277122495\n",
      "7581, train_loss: 0.4645445335369844, val_loss: 0.44265326857566833\n",
      "7582, train_loss: 0.4620186182168814, val_loss: 0.4621525049209595\n",
      "7583, train_loss: 0.46330190335328764, val_loss: 0.4601856589317322\n",
      "7584, train_loss: 0.462841109587596, val_loss: 0.46019123792648314\n",
      "7585, train_loss: 0.4619276019243094, val_loss: 0.46108163595199586\n",
      "7586, train_loss: 0.4620697865119347, val_loss: 0.4484186708927155\n",
      "7587, train_loss: 0.4618021777042976, val_loss: 0.44515950679779054\n",
      "7588, train_loss: 0.46660509075109774, val_loss: 0.466446852684021\n",
      "7589, train_loss: 0.46658779508792436, val_loss: 0.46758577823638914\n",
      "7590, train_loss: 0.46263083815574646, val_loss: 0.4599457561969757\n",
      "7591, train_loss: 0.46474545964827907, val_loss: 0.4719964683055878\n",
      "7592, train_loss: 0.46270267034952456, val_loss: 0.4806576192378998\n",
      "7593, train_loss: 0.4665090407316501, val_loss: 0.4578226625919342\n",
      "7594, train_loss: 0.4664700294916446, val_loss: 0.46127424836158754\n",
      "7595, train_loss: 0.4634449069316571, val_loss: 0.44752960205078124\n",
      "7596, train_loss: 0.4640897363424301, val_loss: 0.46627159118652345\n",
      "7597, train_loss: 0.46232470640769374, val_loss: 0.44445475935935974\n",
      "7598, train_loss: 0.4663223303281344, val_loss: 0.45923728346824644\n",
      "7599, train_loss: 0.46339981659100604, val_loss: 0.44630773067474366\n",
      "7600, train_loss: 0.46630184810895187, val_loss: 0.4407496154308319\n",
      "7601, train_loss: 0.46379278485591596, val_loss: 0.44900299310684205\n",
      "7602, train_loss: 0.4646944822027133, val_loss: 0.4551476716995239\n",
      "7603, train_loss: 0.46617922530724454, val_loss: 0.4665315091609955\n",
      "7604, train_loss: 0.46618933173326343, val_loss: 0.4544719040393829\n",
      "7605, train_loss: 0.464603732411678, val_loss: 0.46037346720695493\n",
      "7606, train_loss: 0.4637104135293227, val_loss: 0.46671133041381835\n",
      "7607, train_loss: 0.46141876165683454, val_loss: 0.4666029095649719\n",
      "7608, train_loss: 0.4649116568840467, val_loss: 0.4593395531177521\n",
      "7609, train_loss: 0.46054829771702105, val_loss: 0.44221959114074705\n",
      "7610, train_loss: 0.4660230244581516, val_loss: 0.4649499714374542\n",
      "7611, train_loss: 0.46236029267311096, val_loss: 0.448708176612854\n",
      "7612, train_loss: 0.465995192527771, val_loss: 0.438634580373764\n",
      "7613, train_loss: 0.4602316847214332, val_loss: 0.4593860626220703\n",
      "7614, train_loss: 0.4641349006157655, val_loss: 0.44857155680656435\n",
      "7615, train_loss: 0.4659257771877142, val_loss: 0.4582330107688904\n",
      "7616, train_loss: 0.4658991190103384, val_loss: 0.46712054014205934\n",
      "7617, train_loss: 0.46429789754060596, val_loss: 0.43880597949028016\n",
      "7618, train_loss: 0.46581775408524734, val_loss: 0.453141850233078\n",
      "7619, train_loss: 0.46215291779774886, val_loss: 0.4421506106853485\n",
      "7620, train_loss: 0.4642933801962779, val_loss: 0.458442223072052\n",
      "7621, train_loss: 0.4636818938530408, val_loss: 0.4447168469429016\n",
      "7622, train_loss: 0.4618036345793651, val_loss: 0.47178520560264586\n",
      "7623, train_loss: 0.4599931904902825, val_loss: 0.43946839570999147\n",
      "7624, train_loss: 0.46051101558483565, val_loss: 0.44032456874847414\n",
      "7625, train_loss: 0.46152444183826447, val_loss: 0.45730842351913453\n",
      "7626, train_loss: 0.45963985472917557, val_loss: 0.44171189069747924\n",
      "7627, train_loss: 0.4613117151535474, val_loss: 0.4659331738948822\n",
      "7628, train_loss: 0.4656551331281662, val_loss: 0.44177284836769104\n",
      "7629, train_loss: 0.4615192883289777, val_loss: 0.4802586197853088\n",
      "7630, train_loss: 0.4656025744401492, val_loss: 0.4517547994852066\n",
      "7631, train_loss: 0.46557855491454786, val_loss: 0.4660056531429291\n",
      "7632, train_loss: 0.4655464772994702, val_loss: 0.4507530450820923\n",
      "7633, train_loss: 0.4655267791106151, val_loss: 0.4545319139957428\n",
      "7634, train_loss: 0.46143184716884905, val_loss: 0.4354942262172699\n",
      "7635, train_loss: 0.4625160682659883, val_loss: 0.4467078924179077\n",
      "7636, train_loss: 0.4609008993093784, val_loss: 0.45772082209587095\n",
      "7637, train_loss: 0.4625112024637369, val_loss: 0.4510459303855896\n",
      "7638, train_loss: 0.46540216643076676, val_loss: 0.4577332139015198\n",
      "7639, train_loss: 0.46545034188490647, val_loss: 0.4610312283039093\n",
      "7640, train_loss: 0.46427133220892686, val_loss: 0.4498785614967346\n",
      "7641, train_loss: 0.46296232594893527, val_loss: 0.4515449106693268\n",
      "7642, train_loss: 0.4652922291022081, val_loss: 0.4490972995758057\n",
      "7643, train_loss: 0.4604899510741234, val_loss: 0.4600867509841919\n",
      "7644, train_loss: 0.4652627626290688, val_loss: 0.4800413608551025\n",
      "7645, train_loss: 0.4652714247886951, val_loss: 0.45941345691680907\n",
      "7646, train_loss: 0.46240448837096876, val_loss: 0.45899157524108886\n",
      "7647, train_loss: 0.46521102350491744, val_loss: 0.457664555311203\n",
      "7648, train_loss: 0.46152641681524426, val_loss: 0.4513164162635803\n",
      "7649, train_loss: 0.46521893258278185, val_loss: 0.43773516416549685\n",
      "7650, train_loss: 0.4612782998726918, val_loss: 0.4433324635028839\n",
      "7651, train_loss: 0.46213144350510377, val_loss: 0.44320098757743837\n",
      "7652, train_loss: 0.465116132910435, val_loss: 0.4654622316360474\n",
      "7653, train_loss: 0.4650598191297971, val_loss: 0.43568095564842224\n",
      "7654, train_loss: 0.4650897544163924, val_loss: 0.449139004945755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7655, train_loss: 0.46505472981012785, val_loss: 0.45351417660713195\n",
      "7656, train_loss: 0.4650465805943196, val_loss: 0.4449463844299316\n",
      "7657, train_loss: 0.46506546896237594, val_loss: 0.4533211052417755\n",
      "7658, train_loss: 0.46112298506956834, val_loss: 0.4644702851772308\n",
      "7659, train_loss: 0.46197884587141186, val_loss: 0.4356842041015625\n",
      "7660, train_loss: 0.4599979187433536, val_loss: 0.4439707338809967\n",
      "7661, train_loss: 0.461210205577887, val_loss: 0.47041475772857666\n",
      "7662, train_loss: 0.45995644995799434, val_loss: 0.4790006518363953\n",
      "7663, train_loss: 0.46500276029109955, val_loss: 0.4612181305885315\n",
      "7664, train_loss: 0.46495692088053775, val_loss: 0.46470826864242554\n",
      "7665, train_loss: 0.4649215340614319, val_loss: 0.45996988415718076\n",
      "7666, train_loss: 0.46287010266230655, val_loss: 0.4414324343204498\n",
      "7667, train_loss: 0.4648358466533514, val_loss: 0.44897831678390504\n",
      "7668, train_loss: 0.4631414952186438, val_loss: 0.43228132724761964\n",
      "7669, train_loss: 0.4600909329377688, val_loss: 0.4571471154689789\n",
      "7670, train_loss: 0.45975058812361497, val_loss: 0.44711833000183104\n",
      "7671, train_loss: 0.46474429965019226, val_loss: 0.46423295736312864\n",
      "7672, train_loss: 0.4617510982430898, val_loss: 0.4613803029060364\n",
      "7673, train_loss: 0.46228311038934267, val_loss: 0.4593496203422546\n",
      "7674, train_loss: 0.4626097369652528, val_loss: 0.4450878441333771\n",
      "7675, train_loss: 0.45953016441601974, val_loss: 0.44505963325500486\n",
      "7676, train_loss: 0.46112184341137225, val_loss: 0.44626050591468813\n",
      "7677, train_loss: 0.4587836047777763, val_loss: 0.4616031885147095\n",
      "7678, train_loss: 0.46449418595203984, val_loss: 0.4528645217418671\n",
      "7679, train_loss: 0.46231725697334, val_loss: 0.44564217925071714\n",
      "7680, train_loss: 0.46087825814118755, val_loss: 0.4616744637489319\n",
      "7681, train_loss: 0.4644426279343091, val_loss: 0.44264732003211976\n",
      "7682, train_loss: 0.4604860567129575, val_loss: 0.4384169280529022\n",
      "7683, train_loss: 0.4596859491788424, val_loss: 0.45301989912986756\n",
      "7684, train_loss: 0.4644299172438108, val_loss: 0.4741332709789276\n",
      "7685, train_loss: 0.4605830151301164, val_loss: 0.4518821954727173\n",
      "7686, train_loss: 0.4609729074514829, val_loss: 0.4433289051055908\n",
      "7687, train_loss: 0.4643515577683082, val_loss: 0.44217981696128844\n",
      "7688, train_loss: 0.4643354186644921, val_loss: 0.47873584032058714\n",
      "7689, train_loss: 0.46432425998724425, val_loss: 0.4452634632587433\n",
      "7690, train_loss: 0.4606765199166078, val_loss: 0.44559099078178405\n",
      "7691, train_loss: 0.4581644833087921, val_loss: 0.4451808899641037\n",
      "7692, train_loss: 0.46162949617092425, val_loss: 0.44635279178619386\n",
      "7693, train_loss: 0.4642138618689317, val_loss: 0.47006959319114683\n",
      "7694, train_loss: 0.4605971569052109, val_loss: 0.4419198095798492\n",
      "7695, train_loss: 0.4641317238028233, val_loss: 0.457647317647934\n",
      "7696, train_loss: 0.45885952619405895, val_loss: 0.45764660835266113\n",
      "7697, train_loss: 0.4617145938368944, val_loss: 0.46100199818611143\n",
      "7698, train_loss: 0.46068276866124225, val_loss: 0.43935362696647645\n",
      "7699, train_loss: 0.4623858401408562, val_loss: 0.4406092643737793\n",
      "7700, train_loss: 0.46103246166155887, val_loss: 0.4466397225856781\n",
      "7701, train_loss: 0.4599505410744594, val_loss: 0.45225929021835326\n",
      "7702, train_loss: 0.46398481268149155, val_loss: 0.47881550192832945\n",
      "7703, train_loss: 0.46394197241618085, val_loss: 0.45281676650047303\n",
      "7704, train_loss: 0.46177030870547664, val_loss: 0.45672023892402647\n",
      "7705, train_loss: 0.45980213238642764, val_loss: 0.4699399948120117\n",
      "7706, train_loss: 0.4638870862814096, val_loss: 0.45006662607192993\n",
      "7707, train_loss: 0.46384372734106505, val_loss: 0.45292149782180785\n",
      "7708, train_loss: 0.4588231925780957, val_loss: 0.4349079132080078\n",
      "7709, train_loss: 0.4638330042362213, val_loss: 0.43523756265640257\n",
      "7710, train_loss: 0.4601351315012345, val_loss: 0.4347961723804474\n",
      "7711, train_loss: 0.46003415148991805, val_loss: 0.46057626605033875\n",
      "7712, train_loss: 0.4618136825469824, val_loss: 0.4782064914703369\n",
      "7713, train_loss: 0.4603704638206042, val_loss: 0.44256436824798584\n",
      "7714, train_loss: 0.4597318344391309, val_loss: 0.46052892208099366\n",
      "7715, train_loss: 0.4612951089556401, val_loss: 0.44157997965812684\n",
      "7716, train_loss: 0.46371836559130597, val_loss: 0.4421668767929077\n",
      "7717, train_loss: 0.4597987016806236, val_loss: 0.4303393721580505\n",
      "7718, train_loss: 0.46372107301767057, val_loss: 0.4550772666931152\n",
      "7719, train_loss: 0.4602303138146034, val_loss: 0.44953846335411074\n",
      "7720, train_loss: 0.4601489844230505, val_loss: 0.43651813864707945\n",
      "7721, train_loss: 0.4635383922320146, val_loss: 0.46382102370262146\n",
      "7722, train_loss: 0.4635998537907234, val_loss: 0.4381647348403931\n",
      "7723, train_loss: 0.46358579511825854, val_loss: 0.44900730848312376\n",
      "7724, train_loss: 0.4635318832901808, val_loss: 0.4471843898296356\n",
      "7725, train_loss: 0.4584904049451535, val_loss: 0.45898401737213135\n",
      "7726, train_loss: 0.45800624100061565, val_loss: 0.4600870430469513\n",
      "7727, train_loss: 0.4634857550263405, val_loss: 0.44079798460006714\n",
      "7728, train_loss: 0.45959085111434644, val_loss: 0.4298203349113464\n",
      "7729, train_loss: 0.4634881718800618, val_loss: 0.4729734122753143\n",
      "7730, train_loss: 0.4634789274289058, val_loss: 0.44237312078475954\n",
      "7731, train_loss: 0.4614120102845706, val_loss: 0.4566891312599182\n",
      "7732, train_loss: 0.4594661197983302, val_loss: 0.4689687013626099\n",
      "7733, train_loss: 0.4618362899009998, val_loss: 0.45999846458435056\n",
      "7734, train_loss: 0.4608797419529695, val_loss: 0.43471981287002565\n",
      "7735, train_loss: 0.460935693520766, val_loss: 0.4432427406311035\n",
      "7736, train_loss: 0.4598075839189383, val_loss: 0.43818061947822573\n",
      "7737, train_loss: 0.4602550526077931, val_loss: 0.4433921992778778\n",
      "7738, train_loss: 0.4632073480349321, val_loss: 0.4552434265613556\n",
      "7739, train_loss: 0.46020223945379257, val_loss: 0.4292150855064392\n",
      "7740, train_loss: 0.45850116129104906, val_loss: 0.461605441570282\n",
      "7741, train_loss: 0.45932567004974073, val_loss: 0.45849767327308655\n",
      "7742, train_loss: 0.4606085419654846, val_loss: 0.4374927878379822\n",
      "7743, train_loss: 0.46316175965162426, val_loss: 0.46422595381736753\n",
      "7744, train_loss: 0.459579640856156, val_loss: 0.4474768340587616\n",
      "7745, train_loss: 0.4599353831547957, val_loss: 0.4393190860748291\n",
      "7746, train_loss: 0.4606752177843681, val_loss: 0.4557891309261322\n",
      "7747, train_loss: 0.46305008003344905, val_loss: 0.45741512775421145\n",
      "7748, train_loss: 0.4607872057419557, val_loss: 0.44076249599456785\n",
      "7749, train_loss: 0.46301887470942277, val_loss: 0.4386750340461731\n",
      "7750, train_loss: 0.458253970512977, val_loss: 0.4583639144897461\n",
      "7751, train_loss: 0.4599806803923387, val_loss: 0.46257039308547976\n",
      "7752, train_loss: 0.4629291227230659, val_loss: 0.44541105031967165\n",
      "7753, train_loss: 0.45891017466783524, val_loss: 0.44886202216148374\n",
      "7754, train_loss: 0.45914084292375124, val_loss: 0.4420983254909515\n",
      "7755, train_loss: 0.4628098366352228, val_loss: 0.43526514172554015\n",
      "7756, train_loss: 0.45812048476475936, val_loss: 0.45631900429725647\n",
      "7757, train_loss: 0.45918137293595535, val_loss: 0.4641431212425232\n",
      "7758, train_loss: 0.45931619577682936, val_loss: 0.45563472509384156\n",
      "7759, train_loss: 0.4601261099943748, val_loss: 0.45629955530166627\n",
      "7760, train_loss: 0.4627157369485268, val_loss: 0.47737463712692263\n",
      "7761, train_loss: 0.4596381244751123, val_loss: 0.4594821572303772\n",
      "7762, train_loss: 0.4595949575304985, val_loss: 0.45973716378211976\n",
      "7763, train_loss: 0.46258289424272686, val_loss: 0.4464706301689148\n",
      "7764, train_loss: 0.46024779975414276, val_loss: 0.4539035618305206\n",
      "7765, train_loss: 0.46255996651374376, val_loss: 0.4642051696777344\n",
      "7766, train_loss: 0.46250646160199094, val_loss: 0.47744404673576357\n",
      "7767, train_loss: 0.45912671318420994, val_loss: 0.4562082588672638\n",
      "7768, train_loss: 0.4585859523369716, val_loss: 0.4560021638870239\n",
      "7769, train_loss: 0.4577830112897433, val_loss: 0.4581234335899353\n",
      "7770, train_loss: 0.4624999841818443, val_loss: 0.4509279429912567\n",
      "7771, train_loss: 0.4625305160880089, val_loss: 0.4326944470405579\n",
      "7772, train_loss: 0.458174304320262, val_loss: 0.4446935474872589\n",
      "7773, train_loss: 0.462500845010464, val_loss: 0.4609404861927032\n",
      "7774, train_loss: 0.4593890137397326, val_loss: 0.4448802888393402\n",
      "7775, train_loss: 0.45722633829483617, val_loss: 0.43975679874420165\n",
      "7776, train_loss: 0.45635439684757817, val_loss: 0.4608665704727173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7777, train_loss: 0.4598296783291377, val_loss: 0.4549179792404175\n",
      "7778, train_loss: 0.46240489987226635, val_loss: 0.4618777632713318\n",
      "7779, train_loss: 0.46234142092558056, val_loss: 0.4765515148639679\n",
      "7780, train_loss: 0.45764869107649875, val_loss: 0.44649458527565\n",
      "7781, train_loss: 0.45745538633603317, val_loss: 0.44685999751091005\n",
      "7782, train_loss: 0.457667805827581, val_loss: 0.43777626752853394\n",
      "7783, train_loss: 0.4575575005549651, val_loss: 0.45526644587516785\n",
      "7784, train_loss: 0.4584504881730446, val_loss: 0.45863896012306216\n",
      "7785, train_loss: 0.46228210570720524, val_loss: 0.45723543763160707\n",
      "7786, train_loss: 0.45919738480677974, val_loss: 0.46202470660209655\n",
      "7787, train_loss: 0.46221615775273395, val_loss: 0.445957225561142\n",
      "7788, train_loss: 0.45838670432567596, val_loss: 0.4404232919216156\n",
      "7789, train_loss: 0.4582811083931189, val_loss: 0.45864492654800415\n",
      "7790, train_loss: 0.4570830332545134, val_loss: 0.46149123311042783\n",
      "7791, train_loss: 0.4621166220078102, val_loss: 0.46057172417640685\n",
      "7792, train_loss: 0.46206462727143216, val_loss: 0.4717558443546295\n",
      "7793, train_loss: 0.4620291212430367, val_loss: 0.476294606924057\n",
      "7794, train_loss: 0.4583757141461739, val_loss: 0.4716862738132477\n",
      "7795, train_loss: 0.46196845403084386, val_loss: 0.45698636770248413\n",
      "7796, train_loss: 0.45780517963262707, val_loss: 0.4443727433681488\n",
      "7797, train_loss: 0.4619589757460814, val_loss: 0.4395164608955383\n",
      "7798, train_loss: 0.4619263932108879, val_loss: 0.44872220158576964\n",
      "7799, train_loss: 0.4619068893102499, val_loss: 0.46150932312011717\n",
      "7800, train_loss: 0.45792345702648163, val_loss: 0.44932379722595217\n",
      "7801, train_loss: 0.4566061943769455, val_loss: 0.4405540883541107\n",
      "7802, train_loss: 0.457482642852343, val_loss: 0.435051703453064\n",
      "7803, train_loss: 0.4618356835383635, val_loss: 0.4531602680683136\n",
      "7804, train_loss: 0.45786294684960294, val_loss: 0.4456980645656586\n",
      "7805, train_loss: 0.4618217028104342, val_loss: 0.47596909403800963\n",
      "7806, train_loss: 0.4617702834881269, val_loss: 0.4486314654350281\n",
      "7807, train_loss: 0.4617115889604275, val_loss: 0.4452799499034882\n",
      "7808, train_loss: 0.4593907617605649, val_loss: 0.4618206202983856\n",
      "7809, train_loss: 0.461679549744496, val_loss: 0.4583571910858154\n",
      "7810, train_loss: 0.4594204935889978, val_loss: 0.4604401350021362\n",
      "7811, train_loss: 0.4577709207167992, val_loss: 0.4584129512310028\n",
      "7812, train_loss: 0.4573196619749069, val_loss: 0.4762277364730835\n",
      "7813, train_loss: 0.4591772968952472, val_loss: 0.43394775986671447\n",
      "7814, train_loss: 0.4576826955263431, val_loss: 0.46287608742713926\n",
      "7815, train_loss: 0.4573205354122015, val_loss: 0.4428377687931061\n",
      "7816, train_loss: 0.45623638137028766, val_loss: 0.47595666646957396\n",
      "7817, train_loss: 0.46147835369293505, val_loss: 0.44252849817276\n",
      "7818, train_loss: 0.46145899708454424, val_loss: 0.46168450117111204\n",
      "7819, train_loss: 0.45842528343200684, val_loss: 0.46166958212852477\n",
      "7820, train_loss: 0.45665468734044296, val_loss: 0.44842137694358825\n",
      "7821, train_loss: 0.4574237121985509, val_loss: 0.43724122643470764\n",
      "7822, train_loss: 0.4613500695962172, val_loss: 0.44282294511795045\n",
      "7823, train_loss: 0.4613298922777176, val_loss: 0.44020105004310606\n",
      "7824, train_loss: 0.45948059169145733, val_loss: 0.43547154068946836\n",
      "7825, train_loss: 0.4564701553720694, val_loss: 0.46004060506820676\n",
      "7826, train_loss: 0.45734368150050825, val_loss: 0.4528166472911835\n",
      "7827, train_loss: 0.45708213459986907, val_loss: 0.43232190012931826\n",
      "7828, train_loss: 0.4565322548151016, val_loss: 0.4389948844909668\n",
      "7829, train_loss: 0.4612280875444412, val_loss: 0.44121080040931704\n",
      "7830, train_loss: 0.4612183433312636, val_loss: 0.45328652262687685\n",
      "7831, train_loss: 0.46123180710352385, val_loss: 0.43172918558120726\n",
      "7832, train_loss: 0.45740335148114425, val_loss: 0.43185927867889407\n",
      "7833, train_loss: 0.45725859701633453, val_loss: 0.46663397550582886\n",
      "7834, train_loss: 0.4611638532235072, val_loss: 0.43751088380813596\n",
      "7835, train_loss: 0.4570820721296164, val_loss: 0.4541516721248627\n",
      "7836, train_loss: 0.45713326793450576, val_loss: 0.43644123077392577\n",
      "7837, train_loss: 0.4610852805467752, val_loss: 0.470607602596283\n",
      "7838, train_loss: 0.4572869653885181, val_loss: 0.4594063818454742\n",
      "7839, train_loss: 0.46106641109173113, val_loss: 0.4489221930503845\n",
      "7840, train_loss: 0.46106421374357665, val_loss: 0.44618446230888364\n",
      "7841, train_loss: 0.46101109511577165, val_loss: 0.4548829019069672\n",
      "7842, train_loss: 0.4609402332168359, val_loss: 0.4404844999313354\n",
      "7843, train_loss: 0.4573652079472175, val_loss: 0.46098493337631224\n",
      "7844, train_loss: 0.45477503824692506, val_loss: 0.43963298201560974\n",
      "7845, train_loss: 0.45774308477456754, val_loss: 0.4750980734825134\n",
      "7846, train_loss: 0.46087002066465527, val_loss: 0.46081225872039794\n",
      "7847, train_loss: 0.4593296990944789, val_loss: 0.45235801339149473\n",
      "7848, train_loss: 0.4573309559088487, val_loss: 0.44476953744888303\n",
      "7849, train_loss: 0.46074368403508115, val_loss: 0.46110371351242063\n",
      "7850, train_loss: 0.4585512922360347, val_loss: 0.45648335218429564\n",
      "7851, train_loss: 0.45777665078639984, val_loss: 0.44529770612716674\n",
      "7852, train_loss: 0.45686614971894485, val_loss: 0.44287302494049074\n",
      "7853, train_loss: 0.460592773098212, val_loss: 0.44967504739761355\n",
      "7854, train_loss: 0.45536596843829524, val_loss: 0.4433897078037262\n",
      "7855, train_loss: 0.4606141849206044, val_loss: 0.45305745005607606\n",
      "7856, train_loss: 0.4606407777621196, val_loss: 0.4752288818359375\n",
      "7857, train_loss: 0.4590828206676703, val_loss: 0.4394084930419922\n",
      "7858, train_loss: 0.46058215831334776, val_loss: 0.45352437496185305\n",
      "7859, train_loss: 0.4585175646039156, val_loss: 0.4575110077857971\n",
      "7860, train_loss: 0.4554135100199626, val_loss: 0.4485724449157715\n",
      "7861, train_loss: 0.45639897940250546, val_loss: 0.43623063564300535\n",
      "7862, train_loss: 0.45806019695905537, val_loss: 0.45731682777404786\n",
      "7863, train_loss: 0.4569683579298166, val_loss: 0.44913159012794496\n",
      "7864, train_loss: 0.4584206400009302, val_loss: 0.44071961641311647\n",
      "7865, train_loss: 0.45665939954610973, val_loss: 0.45931975841522216\n",
      "7866, train_loss: 0.45526850108916944, val_loss: 0.44899600744247437\n",
      "7867, train_loss: 0.46034292762096113, val_loss: 0.47489883899688723\n",
      "7868, train_loss: 0.460343483548898, val_loss: 0.4605372667312622\n",
      "7869, train_loss: 0.4583518344622392, val_loss: 0.45324414372444155\n",
      "7870, train_loss: 0.4555998880129594, val_loss: 0.43934038281440735\n",
      "7871, train_loss: 0.4549836218357086, val_loss: 0.4275737702846527\n",
      "7872, train_loss: 0.45504148877584016, val_loss: 0.4555597543716431\n",
      "7873, train_loss: 0.4567995655995149, val_loss: 0.45346813797950747\n",
      "7874, train_loss: 0.45779866667894215, val_loss: 0.4342483222484589\n",
      "7875, train_loss: 0.45703582580272967, val_loss: 0.445607191324234\n",
      "7876, train_loss: 0.45404433516355663, val_loss: 0.4700378358364105\n",
      "7877, train_loss: 0.45543380769399494, val_loss: 0.46593406796455383\n",
      "7878, train_loss: 0.45813266130594105, val_loss: 0.43460466861724856\n",
      "7879, train_loss: 0.46013914621793306, val_loss: 0.4375855028629303\n",
      "7880, train_loss: 0.4590086168967761, val_loss: 0.4294589847326279\n",
      "7881, train_loss: 0.45636942294927746, val_loss: 0.4369416952133179\n",
      "7882, train_loss: 0.4600786818907811, val_loss: 0.46569274067878724\n",
      "7883, train_loss: 0.4564984177167599, val_loss: 0.42662966847419737\n",
      "7884, train_loss: 0.45529877222501314, val_loss: 0.4741060435771942\n",
      "7885, train_loss: 0.45602742525247425, val_loss: 0.4495585739612579\n",
      "7886, train_loss: 0.45619114946860534, val_loss: 0.4696172773838043\n",
      "7887, train_loss: 0.45587679973015416, val_loss: 0.44794484972953796\n",
      "7888, train_loss: 0.45705838386829084, val_loss: 0.4402435839176178\n",
      "7889, train_loss: 0.459949638407964, val_loss: 0.44085159301757815\n",
      "7890, train_loss: 0.4548917951492163, val_loss: 0.43273099660873415\n",
      "7891, train_loss: 0.45991766395477146, val_loss: 0.4522084355354309\n",
      "7892, train_loss: 0.4574669370284447, val_loss: 0.45182035565376283\n",
      "7893, train_loss: 0.4566789578932982, val_loss: 0.43919368982315066\n",
      "7894, train_loss: 0.45980456127570224, val_loss: 0.4655163288116455\n",
      "7895, train_loss: 0.45449548959732056, val_loss: 0.45820253491401675\n",
      "7896, train_loss: 0.4563498949775329, val_loss: 0.43218948841094973\n",
      "7897, train_loss: 0.45977500768808216, val_loss: 0.4478169918060303\n",
      "7898, train_loss: 0.45634073133652026, val_loss: 0.4547698378562927\n",
      "7899, train_loss: 0.4596919251176027, val_loss: 0.45144449472427367\n",
      "7900, train_loss: 0.4597123838388003, val_loss: 0.47367696166038514\n",
      "7901, train_loss: 0.4597411442261476, val_loss: 0.4537414193153381\n",
      "7902, train_loss: 0.4597046146026024, val_loss: 0.45911463499069216\n",
      "7903, train_loss: 0.4540305126171846, val_loss: 0.4382168471813202\n",
      "7904, train_loss: 0.4540177182509349, val_loss: 0.45488272309303285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7905, train_loss: 0.4548789606644557, val_loss: 0.4522134065628052\n",
      "7906, train_loss: 0.4548552173834581, val_loss: 0.45153285264968873\n",
      "7907, train_loss: 0.45486310812143177, val_loss: 0.44698238372802734\n",
      "7908, train_loss: 0.45624298315781814, val_loss: 0.44241165518760683\n",
      "7909, train_loss: 0.45576731058267445, val_loss: 0.4600475549697876\n",
      "7910, train_loss: 0.45659076823638034, val_loss: 0.4399224042892456\n",
      "7911, train_loss: 0.45551472902297974, val_loss: 0.43678706884384155\n",
      "7912, train_loss: 0.45752528539070714, val_loss: 0.45319961905479433\n",
      "7913, train_loss: 0.457127014031777, val_loss: 0.42969648241996766\n",
      "7914, train_loss: 0.4552575567593941, val_loss: 0.468691748380661\n",
      "7915, train_loss: 0.45435127787865126, val_loss: 0.4519978046417236\n",
      "7916, train_loss: 0.4593975773224464, val_loss: 0.4553689181804657\n",
      "7917, train_loss: 0.45942291216208386, val_loss: 0.47311737537384035\n",
      "7918, train_loss: 0.45936621496310603, val_loss: 0.43624078035354613\n",
      "7919, train_loss: 0.45737648468751174, val_loss: 0.4730165958404541\n",
      "7920, train_loss: 0.459349009853143, val_loss: 0.46451022028923034\n",
      "7921, train_loss: 0.45501731679989743, val_loss: 0.45530402660369873\n",
      "7922, train_loss: 0.4539080938467613, val_loss: 0.4472544252872467\n",
      "7923, train_loss: 0.45542355340260726, val_loss: 0.4728811025619507\n",
      "7924, train_loss: 0.4567745144550617, val_loss: 0.4456729769706726\n",
      "7925, train_loss: 0.4545775285133949, val_loss: 0.4729370534420013\n",
      "7926, train_loss: 0.4581451931825051, val_loss: 0.4398537874221802\n",
      "7927, train_loss: 0.45914142980025363, val_loss: 0.4599479794502258\n",
      "7928, train_loss: 0.45507001590270263, val_loss: 0.45140360593795775\n",
      "7929, train_loss: 0.4550940807049091, val_loss: 0.4514272093772888\n",
      "7930, train_loss: 0.45400310365053326, val_loss: 0.43832499384880064\n",
      "7931, train_loss: 0.459068442766483, val_loss: 0.43867064714431764\n",
      "7932, train_loss: 0.45699934088266814, val_loss: 0.44532005190849305\n",
      "7933, train_loss: 0.4549868622651467, val_loss: 0.4326741695404053\n",
      "7934, train_loss: 0.4557766283933933, val_loss: 0.45082296133041383\n",
      "7935, train_loss: 0.45892826181191665, val_loss: 0.4382971405982971\n",
      "7936, train_loss: 0.4588882361467068, val_loss: 0.451916766166687\n",
      "7937, train_loss: 0.4588630669392072, val_loss: 0.4518126606941223\n",
      "7938, train_loss: 0.4588755185787494, val_loss: 0.4685400664806366\n",
      "7939, train_loss: 0.45665113971783566, val_loss: 0.4396205127239227\n",
      "7940, train_loss: 0.4548050738297976, val_loss: 0.4330345273017883\n",
      "7941, train_loss: 0.4571718779894022, val_loss: 0.4374053061008453\n",
      "7942, train_loss: 0.4551400553721648, val_loss: 0.44048413038253786\n",
      "7943, train_loss: 0.4587501138448715, val_loss: 0.45283350348472595\n",
      "7944, train_loss: 0.4558266991606125, val_loss: 0.45868030190467834\n",
      "7945, train_loss: 0.45574058019197905, val_loss: 0.43362059593200686\n",
      "7946, train_loss: 0.45867385600621885, val_loss: 0.45161662101745603\n",
      "7947, train_loss: 0.4556077386324222, val_loss: 0.43495298027992246\n",
      "7948, train_loss: 0.4585851591366988, val_loss: 0.4582176744937897\n",
      "7949, train_loss: 0.4546791532864937, val_loss: 0.4505560338497162\n",
      "7950, train_loss: 0.4555422577720422, val_loss: 0.46846277117729185\n",
      "7951, train_loss: 0.4585478878938235, val_loss: 0.4685475707054138\n",
      "7952, train_loss: 0.4585228103857774, val_loss: 0.43394343852996825\n",
      "7953, train_loss: 0.45446839871314854, val_loss: 0.4517424166202545\n",
      "7954, train_loss: 0.45614561897057754, val_loss: 0.43405601978302\n",
      "7955, train_loss: 0.4543155466134732, val_loss: 0.45706349015235903\n",
      "7956, train_loss: 0.4560825148454079, val_loss: 0.45374804735183716\n",
      "7957, train_loss: 0.4583610055538324, val_loss: 0.4518122494220734\n",
      "7958, train_loss: 0.4583977277462299, val_loss: 0.42938371896743777\n",
      "7959, train_loss: 0.4583588850039702, val_loss: 0.440802663564682\n",
      "7960, train_loss: 0.4583312295950376, val_loss: 0.44187706112861636\n",
      "7961, train_loss: 0.45348011415738326, val_loss: 0.4503073453903198\n",
      "7962, train_loss: 0.45630214993770307, val_loss: 0.4301566183567047\n",
      "7963, train_loss: 0.45594632224394727, val_loss: 0.4312758147716522\n",
      "7964, train_loss: 0.45824959301031554, val_loss: 0.43387689590454104\n",
      "7965, train_loss: 0.45676742035609025, val_loss: 0.44027513861656187\n",
      "7966, train_loss: 0.4582078600159058, val_loss: 0.4403433859348297\n",
      "7967, train_loss: 0.45821188390254974, val_loss: 0.45341668725013734\n",
      "7968, train_loss: 0.45818197154081786, val_loss: 0.459386932849884\n",
      "7969, train_loss: 0.4559411177268395, val_loss: 0.45790040493011475\n",
      "7970, train_loss: 0.45416364761499256, val_loss: 0.4496981203556061\n",
      "7971, train_loss: 0.4533331176409355, val_loss: 0.43623884320259093\n",
      "7972, train_loss: 0.4543423452056371, val_loss: 0.45083209276199343\n",
      "7973, train_loss: 0.45332068548752713, val_loss: 0.44488654732704164\n",
      "7974, train_loss: 0.45276180654764175, val_loss: 0.44597355723381044\n",
      "7975, train_loss: 0.45385313549867046, val_loss: 0.4353849709033966\n",
      "7976, train_loss: 0.45512328526148427, val_loss: 0.46797706484794616\n",
      "7977, train_loss: 0.45212322473526, val_loss: 0.454736602306366\n",
      "7978, train_loss: 0.4579341961787297, val_loss: 0.4499831050634384\n",
      "7979, train_loss: 0.45796732891064423, val_loss: 0.4383030474185944\n",
      "7980, train_loss: 0.4548466228521787, val_loss: 0.44133822321891786\n",
      "7981, train_loss: 0.45424011235053724, val_loss: 0.44330514073371885\n",
      "7982, train_loss: 0.4542196966134585, val_loss: 0.4680072844028473\n",
      "7983, train_loss: 0.4562986114850411, val_loss: 0.428825306892395\n",
      "7984, train_loss: 0.4547810646203848, val_loss: 0.4546555519104004\n",
      "7985, train_loss: 0.45510189808332, val_loss: 0.4581978917121887\n",
      "7986, train_loss: 0.4529486573659457, val_loss: 0.47248235940933225\n",
      "7987, train_loss: 0.4534606612645663, val_loss: 0.4359401881694794\n",
      "7988, train_loss: 0.45551360570467436, val_loss: 0.43639145493507386\n",
      "7989, train_loss: 0.45569827808783603, val_loss: 0.4494427561759949\n",
      "7990, train_loss: 0.45146201436336225, val_loss: 0.43048174381256105\n",
      "7991, train_loss: 0.45347593610103315, val_loss: 0.4579313337802887\n",
      "7992, train_loss: 0.45759536440555865, val_loss: 0.45204274654388427\n",
      "7993, train_loss: 0.4545729664655832, val_loss: 0.43554826974868777\n",
      "7994, train_loss: 0.45284658211928147, val_loss: 0.4677115261554718\n",
      "7995, train_loss: 0.4541188467007417, val_loss: 0.44991905689239503\n",
      "7996, train_loss: 0.45347322065096635, val_loss: 0.4578021585941315\n",
      "7997, train_loss: 0.4574788086689435, val_loss: 0.4509563446044922\n",
      "7998, train_loss: 0.4536659981195743, val_loss: 0.4457764089107513\n",
      "7999, train_loss: 0.4557405039668083, val_loss: 0.4502310812473297\n",
      "8000, train_loss: 0.4528717713860365, val_loss: 0.4460910677909851\n",
      "8001, train_loss: 0.45743505312846255, val_loss: 0.43506431579589844\n",
      "8002, train_loss: 0.4574391773113838, val_loss: 0.4407871127128601\n",
      "8003, train_loss: 0.451620421730555, val_loss: 0.42860778570175173\n",
      "8004, train_loss: 0.455643372466931, val_loss: 0.43072693347930907\n",
      "8005, train_loss: 0.45740246314268845, val_loss: 0.42760607600212097\n",
      "8006, train_loss: 0.45737612362091357, val_loss: 0.4491625726222992\n",
      "8007, train_loss: 0.45338442004643953, val_loss: 0.44052388668060305\n",
      "8008, train_loss: 0.4573538326300107, val_loss: 0.43699190616607664\n",
      "8009, train_loss: 0.4533149376511574, val_loss: 0.43557456135749817\n",
      "8010, train_loss: 0.4534412891818927, val_loss: 0.44271464347839357\n",
      "8011, train_loss: 0.4548390450385901, val_loss: 0.4231285512447357\n",
      "8012, train_loss: 0.4542103593166058, val_loss: 0.4492068111896515\n",
      "8013, train_loss: 0.4572214220578854, val_loss: 0.43671677708625795\n",
      "8014, train_loss: 0.4524445596795816, val_loss: 0.45361738204956054\n",
      "8015, train_loss: 0.45241164244138277, val_loss: 0.42979841828346255\n",
      "8016, train_loss: 0.45551482416116273, val_loss: 0.44508819580078124\n",
      "8017, train_loss: 0.45411958774695027, val_loss: 0.45200309753417967\n",
      "8018, train_loss: 0.4571107362325375, val_loss: 0.4522196054458618\n",
      "8019, train_loss: 0.4570798163230603, val_loss: 0.47125629186630247\n",
      "8020, train_loss: 0.45311232255055356, val_loss: 0.4667866289615631\n",
      "8021, train_loss: 0.4531853565802941, val_loss: 0.44985492825508117\n",
      "8022, train_loss: 0.452970299583215, val_loss: 0.4341856002807617\n",
      "8023, train_loss: 0.4570055454969406, val_loss: 0.434664785861969\n",
      "8024, train_loss: 0.45465392905932206, val_loss: 0.4494999527931213\n",
      "8025, train_loss: 0.4533598400079287, val_loss: 0.4390637516975403\n",
      "8026, train_loss: 0.45217537994568163, val_loss: 0.4334444761276245\n",
      "8027, train_loss: 0.45683961648207444, val_loss: 0.4483794867992401\n",
      "8028, train_loss: 0.4544889491337996, val_loss: 0.45006307363510134\n",
      "8029, train_loss: 0.45123545538920623, val_loss: 0.45663405060768125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8030, train_loss: 0.45681113119308764, val_loss: 0.43318183422088624\n",
      "8031, train_loss: 0.45455976403676546, val_loss: 0.43354094624519346\n",
      "8032, train_loss: 0.4529030059392636, val_loss: 0.4309713542461395\n",
      "8033, train_loss: 0.45285450839079344, val_loss: 0.44764848351478576\n",
      "8034, train_loss: 0.4566769886475343, val_loss: 0.4370046854019165\n",
      "8035, train_loss: 0.4566599027468608, val_loss: 0.4519843578338623\n",
      "8036, train_loss: 0.45662785608034867, val_loss: 0.4488470196723938\n",
      "8037, train_loss: 0.454435795545578, val_loss: 0.44986876249313357\n",
      "8038, train_loss: 0.4518103267137821, val_loss: 0.43541865348815917\n",
      "8039, train_loss: 0.45356372457284194, val_loss: 0.4497208297252655\n",
      "8040, train_loss: 0.4566222383425786, val_loss: 0.4446878135204315\n",
      "8041, train_loss: 0.4565951881500391, val_loss: 0.44091227650642395\n",
      "8042, train_loss: 0.4527325045603972, val_loss: 0.4531368792057037\n",
      "8043, train_loss: 0.4524796542066794, val_loss: 0.43262007236480715\n",
      "8044, train_loss: 0.4565034262262858, val_loss: 0.45754432678222656\n",
      "8045, train_loss: 0.45364736822935253, val_loss: 0.4495060920715332\n",
      "8046, train_loss: 0.4528373812253659, val_loss: 0.4472624957561493\n",
      "8047, train_loss: 0.45260868680018645, val_loss: 0.44524086713790895\n",
      "8048, train_loss: 0.4541535612482291, val_loss: 0.4533152341842651\n",
      "8049, train_loss: 0.45108232589868397, val_loss: 0.4410854041576385\n",
      "8050, train_loss: 0.4527301788330078, val_loss: 0.4506133317947388\n",
      "8051, train_loss: 0.45156254447423494, val_loss: 0.4505149364471436\n",
      "8052, train_loss: 0.4529189272568776, val_loss: 0.4708427906036377\n",
      "8053, train_loss: 0.4532524083669369, val_loss: 0.4354488909244537\n",
      "8054, train_loss: 0.455179553765517, val_loss: 0.42734426259994507\n",
      "8055, train_loss: 0.4562030079273077, val_loss: 0.45613340735435487\n",
      "8056, train_loss: 0.4561862154648854, val_loss: 0.45059173703193667\n",
      "8057, train_loss: 0.4541568864996617, val_loss: 0.4463166773319244\n",
      "8058, train_loss: 0.4537110294287021, val_loss: 0.44060086011886596\n",
      "8059, train_loss: 0.4508403642819478, val_loss: 0.4577206611633301\n",
      "8060, train_loss: 0.45232032812558687, val_loss: 0.45656144618988037\n",
      "8061, train_loss: 0.45606665370556027, val_loss: 0.462323921918869\n",
      "8062, train_loss: 0.456022363442641, val_loss: 0.4708724319934845\n",
      "8063, train_loss: 0.45253502978728366, val_loss: 0.435490483045578\n",
      "8064, train_loss: 0.4559969500853465, val_loss: 0.4529653251171112\n",
      "8065, train_loss: 0.4523206307337834, val_loss: 0.4464426159858704\n",
      "8066, train_loss: 0.4520549659545605, val_loss: 0.4533374190330505\n",
      "8067, train_loss: 0.4544092198977104, val_loss: 0.45056391954422\n",
      "8068, train_loss: 0.455873232621413, val_loss: 0.44336843490600586\n",
      "8069, train_loss: 0.45079667980854327, val_loss: 0.43545898199081423\n",
      "8070, train_loss: 0.45285759980861956, val_loss: 0.4534071683883667\n",
      "8071, train_loss: 0.4505048589064525, val_loss: 0.44469088315963745\n",
      "8072, train_loss: 0.45583906082006603, val_loss: 0.4347688615322113\n",
      "8073, train_loss: 0.4523977362192594, val_loss: 0.45293822288513186\n",
      "8074, train_loss: 0.4510827087439023, val_loss: 0.4659600079059601\n",
      "8075, train_loss: 0.45576431315678817, val_loss: 0.4481150686740875\n",
      "8076, train_loss: 0.4537784056021617, val_loss: 0.47028809785842896\n",
      "8077, train_loss: 0.45186051439780456, val_loss: 0.4559186577796936\n",
      "8078, train_loss: 0.4504471020056651, val_loss: 0.4440526723861694\n",
      "8079, train_loss: 0.4522636601558098, val_loss: 0.43412542939186094\n",
      "8080, train_loss: 0.45329062927227753, val_loss: 0.4302195608615875\n",
      "8081, train_loss: 0.45057915036494917, val_loss: 0.4506422996520996\n",
      "8082, train_loss: 0.45279706441439116, val_loss: 0.44762340784072874\n",
      "8083, train_loss: 0.4527348354458809, val_loss: 0.42439979314804077\n",
      "8084, train_loss: 0.45211272973280686, val_loss: 0.465470552444458\n",
      "8085, train_loss: 0.45563576083916885, val_loss: 0.45521926283836367\n",
      "8086, train_loss: 0.4539396269963338, val_loss: 0.42240443229675295\n",
      "8087, train_loss: 0.45073952869727063, val_loss: 0.4551222860813141\n",
      "8088, train_loss: 0.4538041313107197, val_loss: 0.4481703519821167\n",
      "8089, train_loss: 0.45554118087658513, val_loss: 0.45544991493225095\n",
      "8090, train_loss: 0.45551669483001417, val_loss: 0.45078495144844055\n",
      "8091, train_loss: 0.45033881526726943, val_loss: 0.4344047009944916\n",
      "8092, train_loss: 0.45545781002594876, val_loss: 0.45186752676963804\n",
      "8093, train_loss: 0.45064398417106044, val_loss: 0.43749952912330625\n",
      "8094, train_loss: 0.4554324144354233, val_loss: 0.4520781636238098\n",
      "8095, train_loss: 0.45176361615841204, val_loss: 0.4697334587574005\n",
      "8096, train_loss: 0.4528958906347935, val_loss: 0.45218672752380373\n",
      "8097, train_loss: 0.451377713909516, val_loss: 0.4314789712429047\n",
      "8098, train_loss: 0.4528582290961192, val_loss: 0.45514688491821287\n",
      "8099, train_loss: 0.45222942187235904, val_loss: 0.4470556974411011\n",
      "8100, train_loss: 0.4515990007382173, val_loss: 0.4236577033996582\n",
      "8101, train_loss: 0.4499045576040561, val_loss: 0.4329631984233856\n",
      "8102, train_loss: 0.4551656326422325, val_loss: 0.4223692715167999\n",
      "8103, train_loss: 0.45107604563236237, val_loss: 0.4522171139717102\n",
      "8104, train_loss: 0.45001627734074223, val_loss: 0.4485433757305145\n",
      "8105, train_loss: 0.45517152891709256, val_loss: 0.4474026679992676\n",
      "8106, train_loss: 0.4551532749946301, val_loss: 0.44670981764793394\n",
      "8107, train_loss: 0.4551024127465028, val_loss: 0.429159140586853\n",
      "8108, train_loss: 0.4503273115708278, val_loss: 0.4339419901371002\n",
      "8109, train_loss: 0.45188104475920016, val_loss: 0.4339580059051514\n",
      "8110, train_loss: 0.455066061936892, val_loss: 0.4693168759346008\n",
      "8111, train_loss: 0.45195769518613815, val_loss: 0.4239166259765625\n",
      "8112, train_loss: 0.4508219097669308, val_loss: 0.4691323101520538\n",
      "8113, train_loss: 0.4550529901797955, val_loss: 0.42976261377334596\n",
      "8114, train_loss: 0.4550178601191594, val_loss: 0.44035354256629944\n",
      "8115, train_loss: 0.45107351358120257, val_loss: 0.4388654887676239\n",
      "8116, train_loss: 0.45496054509511363, val_loss: 0.4532959759235382\n",
      "8117, train_loss: 0.45194286967699343, val_loss: 0.4345840036869049\n",
      "8118, train_loss: 0.4548854174522253, val_loss: 0.4488565564155579\n",
      "8119, train_loss: 0.4548340691969945, val_loss: 0.43465560078620913\n",
      "8120, train_loss: 0.4500556278687257, val_loss: 0.4257756948471069\n",
      "8121, train_loss: 0.4537841110275342, val_loss: 0.45331133604049684\n",
      "8122, train_loss: 0.45481251982542187, val_loss: 0.4342177927494049\n",
      "8123, train_loss: 0.4517059956605618, val_loss: 0.446519261598587\n",
      "8124, train_loss: 0.4493530753713388, val_loss: 0.4291240215301514\n",
      "8125, train_loss: 0.4510701149702072, val_loss: 0.4330499291419983\n",
      "8126, train_loss: 0.44993312656879425, val_loss: 0.44802390336990355\n",
      "8127, train_loss: 0.4522275454722918, val_loss: 0.44771826863288877\n",
      "8128, train_loss: 0.4515279565866177, val_loss: 0.44033266305923463\n",
      "8129, train_loss: 0.45149275775139147, val_loss: 0.4434693455696106\n",
      "8130, train_loss: 0.45311265610731566, val_loss: 0.4324397325515747\n",
      "8131, train_loss: 0.4520575151993678, val_loss: 0.45016334652900697\n",
      "8132, train_loss: 0.45448906318499493, val_loss: 0.46929181218147276\n",
      "8133, train_loss: 0.4544822436112624, val_loss: 0.4334152638912201\n",
      "8134, train_loss: 0.4497405932499812, val_loss: 0.4605722546577454\n",
      "8135, train_loss: 0.4509513658972887, val_loss: 0.4606718599796295\n",
      "8136, train_loss: 0.45088814886716694, val_loss: 0.4433933079242706\n",
      "8137, train_loss: 0.45073504516711604, val_loss: 0.469155615568161\n",
      "8138, train_loss: 0.454367995262146, val_loss: 0.46476109623908995\n",
      "8139, train_loss: 0.4543483778834343, val_loss: 0.4412719190120697\n",
      "8140, train_loss: 0.4504883965620628, val_loss: 0.44791232943534853\n",
      "8141, train_loss: 0.4543447672174527, val_loss: 0.4467122733592987\n",
      "8142, train_loss: 0.4513897872888125, val_loss: 0.45026405453681945\n",
      "8143, train_loss: 0.4519643932580948, val_loss: 0.4297297179698944\n",
      "8144, train_loss: 0.4506091269162985, val_loss: 0.44311060905456545\n",
      "8145, train_loss: 0.44949038555988896, val_loss: 0.43527672290802\n",
      "8146, train_loss: 0.45177988364146304, val_loss: 0.4424244225025177\n",
      "8147, train_loss: 0.44881022091095263, val_loss: 0.42942640781402586\n",
      "8148, train_loss: 0.4541744589805603, val_loss: 0.4688909649848938\n",
      "8149, train_loss: 0.45415498316287994, val_loss: 0.46884538531303405\n",
      "8150, train_loss: 0.45068529821359193, val_loss: 0.4556551992893219\n",
      "8151, train_loss: 0.4487510587160404, val_loss: 0.4273665726184845\n",
      "8152, train_loss: 0.4511192630116756, val_loss: 0.4368033468723297\n",
      "8153, train_loss: 0.45406556129455566, val_loss: 0.4271787881851196\n",
      "8154, train_loss: 0.45005371135014755, val_loss: 0.4468861520290375\n",
      "8155, train_loss: 0.45084269917928255, val_loss: 0.42111570239067075\n",
      "8156, train_loss: 0.4540576785802841, val_loss: 0.4504048228263855\n",
      "8157, train_loss: 0.4540395559026645, val_loss: 0.43863933682441714\n",
      "8158, train_loss: 0.45040021263636076, val_loss: 0.4598443150520325\n",
      "8159, train_loss: 0.4498860824566621, val_loss: 0.4395406424999237\n",
      "8160, train_loss: 0.45191305589217406, val_loss: 0.4366950809955597\n",
      "8161, train_loss: 0.4521932670703301, val_loss: 0.4281895816326141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8162, train_loss: 0.45079050614283633, val_loss: 0.43139726519584654\n",
      "8163, train_loss: 0.45158327657442826, val_loss: 0.43407775163650514\n",
      "8164, train_loss: 0.4537580930269681, val_loss: 0.43646873235702516\n",
      "8165, train_loss: 0.4484364974957246, val_loss: 0.43195350766181945\n",
      "8166, train_loss: 0.45373938175348133, val_loss: 0.43185009956359866\n",
      "8167, train_loss: 0.4500689305938207, val_loss: 0.45437681674957275\n",
      "8168, train_loss: 0.4493967787577556, val_loss: 0.42711824774742124\n",
      "8169, train_loss: 0.4536504206749109, val_loss: 0.4481606721878052\n",
      "8170, train_loss: 0.45261335602173436, val_loss: 0.4279306590557098\n",
      "8171, train_loss: 0.4518420627483955, val_loss: 0.45287405848503115\n",
      "8172, train_loss: 0.4485037590448673, val_loss: 0.44090609550476073\n",
      "8173, train_loss: 0.45358388125896454, val_loss: 0.4685931444168091\n",
      "8174, train_loss: 0.4535767974761816, val_loss: 0.4351525127887726\n",
      "8175, train_loss: 0.4535316125704692, val_loss: 0.45418556332588195\n",
      "8176, train_loss: 0.44875759516771024, val_loss: 0.4423639506101608\n",
      "8177, train_loss: 0.44879029805843645, val_loss: 0.43311687707901003\n",
      "8178, train_loss: 0.4505164892627643, val_loss: 0.42925639152526857\n",
      "8179, train_loss: 0.450590390425462, val_loss: 0.4379184484481812\n",
      "8180, train_loss: 0.45019874091331774, val_loss: 0.454129296541214\n",
      "8181, train_loss: 0.45001487663159, val_loss: 0.42181276679039004\n",
      "8182, train_loss: 0.4511755510018422, val_loss: 0.454013979434967\n",
      "8183, train_loss: 0.44971500910245454, val_loss: 0.4524950206279755\n",
      "8184, train_loss: 0.45332400844647336, val_loss: 0.4422971308231354\n",
      "8185, train_loss: 0.453299218072341, val_loss: 0.4422508180141449\n",
      "8186, train_loss: 0.4497927679465367, val_loss: 0.4524516224861145\n",
      "8187, train_loss: 0.4481854507556328, val_loss: 0.4286831319332123\n",
      "8188, train_loss: 0.44917339373093385, val_loss: 0.44218246936798095\n",
      "8189, train_loss: 0.4482244723118268, val_loss: 0.4196907103061676\n",
      "8190, train_loss: 0.44942697710715807, val_loss: 0.42001196146011355\n",
      "8191, train_loss: 0.44819896267010617, val_loss: 0.4498641550540924\n",
      "8192, train_loss: 0.45093053923203397, val_loss: 0.4529522478580475\n",
      "8193, train_loss: 0.4492322779618777, val_loss: 0.45179698467254636\n",
      "8194, train_loss: 0.4484657977636044, val_loss: 0.44619948267936704\n",
      "8195, train_loss: 0.44923858229930586, val_loss: 0.4409532606601715\n",
      "8196, train_loss: 0.4475726943749648, val_loss: 0.4628230035305023\n",
      "8197, train_loss: 0.4532303076524001, val_loss: 0.4190730392932892\n",
      "8198, train_loss: 0.4532504758009544, val_loss: 0.4211656153202057\n",
      "8199, train_loss: 0.4475693152501033, val_loss: 0.43237909078598025\n",
      "8200, train_loss: 0.4490427363377351, val_loss: 0.43191057443618774\n",
      "8201, train_loss: 0.44809422756616885, val_loss: 0.41907843947410583\n",
      "8202, train_loss: 0.4531913497127019, val_loss: 0.462580144405365\n",
      "8203, train_loss: 0.4531629796211536, val_loss: 0.42769888043403625\n",
      "8204, train_loss: 0.44924829327143156, val_loss: 0.46228126883506776\n",
      "8205, train_loss: 0.4501344252091188, val_loss: 0.44881861805915835\n",
      "8206, train_loss: 0.45305722378767455, val_loss: 0.4369567513465881\n",
      "8207, train_loss: 0.45005223613518935, val_loss: 0.447252357006073\n",
      "8208, train_loss: 0.4530386116642218, val_loss: 0.4509428858757019\n",
      "8209, train_loss: 0.4500347960453767, val_loss: 0.42273597717285155\n",
      "8210, train_loss: 0.45102518567672145, val_loss: 0.43596009016036985\n",
      "8211, train_loss: 0.44783086387010723, val_loss: 0.4318454921245575\n",
      "8212, train_loss: 0.44998560501978946, val_loss: 0.41795110106468203\n",
      "8213, train_loss: 0.45296719899544347, val_loss: 0.4270985543727875\n",
      "8214, train_loss: 0.45291272608133465, val_loss: 0.46222237348556516\n",
      "8215, train_loss: 0.44773323375445145, val_loss: 0.4402517259120941\n",
      "8216, train_loss: 0.44890671509962815, val_loss: 0.4580457448959351\n",
      "8217, train_loss: 0.4491920413879248, val_loss: 0.4485940158367157\n",
      "8218, train_loss: 0.45282989969620335, val_loss: 0.4267694354057312\n",
      "8219, train_loss: 0.44908569294672745, val_loss: 0.42955951690673827\n",
      "8220, train_loss: 0.4508024603128433, val_loss: 0.42758881449699404\n",
      "8221, train_loss: 0.449134607727711, val_loss: 0.43057029843330386\n",
      "8222, train_loss: 0.4527018116070674, val_loss: 0.4481565535068512\n",
      "8223, train_loss: 0.4478661830608661, val_loss: 0.43406440019607545\n",
      "8224, train_loss: 0.4495830054466541, val_loss: 0.4401655673980713\n",
      "8225, train_loss: 0.4474596002927193, val_loss: 0.4331107079982758\n",
      "8226, train_loss: 0.45256021045721495, val_loss: 0.46652418971061704\n",
      "8227, train_loss: 0.44714375413381136, val_loss: 0.4533697485923767\n",
      "8228, train_loss: 0.4502205630907646, val_loss: 0.4470962405204773\n",
      "8229, train_loss: 0.45033905597833485, val_loss: 0.4471294701099396\n",
      "8230, train_loss: 0.452498448582796, val_loss: 0.4534276783466339\n",
      "8231, train_loss: 0.44764234584111434, val_loss: 0.4408978283405304\n",
      "8232, train_loss: 0.4488050966308667, val_loss: 0.43031632900238037\n",
      "8233, train_loss: 0.44954988761590076, val_loss: 0.44530039429664614\n",
      "8234, train_loss: 0.4506478045995419, val_loss: 0.4358030498027802\n",
      "8235, train_loss: 0.44749260120666945, val_loss: 0.4303989470005035\n",
      "8236, train_loss: 0.44872803871448225, val_loss: 0.4663927137851715\n",
      "8237, train_loss: 0.4506623469866239, val_loss: 0.4254316329956055\n",
      "8238, train_loss: 0.44815551661528075, val_loss: 0.4358173906803131\n",
      "8239, train_loss: 0.4493438062759546, val_loss: 0.43063735365867617\n",
      "8240, train_loss: 0.4483460503128859, val_loss: 0.4663389205932617\n",
      "8241, train_loss: 0.4484506066028888, val_loss: 0.4486425518989563\n",
      "8242, train_loss: 0.44923545305545515, val_loss: 0.4408838927745819\n",
      "8243, train_loss: 0.45057102693961215, val_loss: 0.4520276069641113\n",
      "8244, train_loss: 0.4467765259054991, val_loss: 0.43990843892097475\n",
      "8245, train_loss: 0.4521379264501425, val_loss: 0.4442489743232727\n",
      "8246, train_loss: 0.4521324863800636, val_loss: 0.42960060834884645\n",
      "8247, train_loss: 0.44868818613199085, val_loss: 0.45189998149871824\n",
      "8248, train_loss: 0.4491977978211183, val_loss: 0.42459639310836794\n",
      "8249, train_loss: 0.4477788175527866, val_loss: 0.45768943428993225\n",
      "8250, train_loss: 0.4520516429956143, val_loss: 0.4342514336109161\n",
      "8251, train_loss: 0.44831764239531297, val_loss: 0.42592037916183473\n",
      "8252, train_loss: 0.44533403103168195, val_loss: 0.44417884945869446\n",
      "8253, train_loss: 0.4519976211281923, val_loss: 0.4262844294309616\n",
      "8254, train_loss: 0.44898467453626484, val_loss: 0.42320317029953003\n",
      "8255, train_loss: 0.446835451401197, val_loss: 0.4444567322731018\n",
      "8256, train_loss: 0.4471955826649299, val_loss: 0.4391651153564453\n",
      "8257, train_loss: 0.45198189868376804, val_loss: 0.42386454343795776\n",
      "8258, train_loss: 0.4492924133172402, val_loss: 0.4515090823173523\n",
      "8259, train_loss: 0.4518497528938147, val_loss: 0.44804099202156067\n",
      "8260, train_loss: 0.44792736837497127, val_loss: 0.4513734996318817\n",
      "8261, train_loss: 0.4518062094083199, val_loss: 0.42500601410865785\n",
      "8262, train_loss: 0.4470698776153418, val_loss: 0.4336062133312225\n",
      "8263, train_loss: 0.44773610165485966, val_loss: 0.4469018459320068\n",
      "8264, train_loss: 0.4491663517860266, val_loss: 0.43518338203430174\n",
      "8265, train_loss: 0.45177399195157564, val_loss: 0.42184269428253174\n",
      "8266, train_loss: 0.4479589353387172, val_loss: 0.44400880932807923\n",
      "8267, train_loss: 0.4517453656746791, val_loss: 0.44979228377342223\n",
      "8268, train_loss: 0.4476296053482936, val_loss: 0.45719481706619264\n",
      "8269, train_loss: 0.4463227763772011, val_loss: 0.42950661182403566\n",
      "8270, train_loss: 0.44916283453886324, val_loss: 0.44119431972503664\n",
      "8271, train_loss: 0.44613733142614365, val_loss: 0.45115332007408143\n",
      "8272, train_loss: 0.4483238389858833, val_loss: 0.4463369965553284\n",
      "8273, train_loss: 0.44622981204436374, val_loss: 0.44617587327957153\n",
      "8274, train_loss: 0.44638605129260284, val_loss: 0.43185412883758545\n",
      "8275, train_loss: 0.4475682182953908, val_loss: 0.443217533826828\n",
      "8276, train_loss: 0.44743227786742723, val_loss: 0.43923973441123965\n",
      "8277, train_loss: 0.448058929007787, val_loss: 0.4458656132221222\n",
      "8278, train_loss: 0.4514306399684686, val_loss: 0.42475038170814516\n",
      "8279, train_loss: 0.4466544590317286, val_loss: 0.4456928431987762\n",
      "8280, train_loss: 0.44795945630623746, val_loss: 0.4447884917259216\n",
      "8281, train_loss: 0.4514070072999367, val_loss: 0.44360883831977843\n",
      "8282, train_loss: 0.447752378307856, val_loss: 0.4651347279548645\n",
      "8283, train_loss: 0.4484520038733116, val_loss: 0.44948596954345704\n",
      "8284, train_loss: 0.4465378671884537, val_loss: 0.4379128396511078\n",
      "8285, train_loss: 0.45126538093273455, val_loss: 0.4652420163154602\n",
      "8286, train_loss: 0.45124589938383836, val_loss: 0.4527751922607422\n",
      "8287, train_loss: 0.4512459933757782, val_loss: 0.4652734398841858\n",
      "8288, train_loss: 0.4485788219250165, val_loss: 0.4522531569004059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8289, train_loss: 0.4511457635806157, val_loss: 0.46533342599868777\n",
      "8290, train_loss: 0.4460643988389235, val_loss: 0.429938805103302\n",
      "8291, train_loss: 0.4511235791903276, val_loss: 0.465203857421875\n",
      "8292, train_loss: 0.45112841633649975, val_loss: 0.4388319730758667\n",
      "8293, train_loss: 0.44878972608309525, val_loss: 0.44565643072128297\n",
      "8294, train_loss: 0.44808144294298613, val_loss: 0.4297292113304138\n",
      "8295, train_loss: 0.45104613670936, val_loss: 0.4509094715118408\n",
      "8296, train_loss: 0.44721710223418015, val_loss: 0.4257745683193207\n",
      "8297, train_loss: 0.44475105232917345, val_loss: 0.44452768564224243\n",
      "8298, train_loss: 0.44666290053954494, val_loss: 0.4470991790294647\n",
      "8299, train_loss: 0.4481753460489787, val_loss: 0.43020681142807005\n",
      "8300, train_loss: 0.44686691806866574, val_loss: 0.4312891781330109\n",
      "8301, train_loss: 0.45088455080986023, val_loss: 0.4376980304718018\n",
      "8302, train_loss: 0.4478072002530098, val_loss: 0.42930041551589965\n",
      "8303, train_loss: 0.4484794965157142, val_loss: 0.43156273365020753\n",
      "8304, train_loss: 0.4464904132943887, val_loss: 0.4475508451461792\n",
      "8305, train_loss: 0.4460110211601624, val_loss: 0.4435282588005066\n",
      "8306, train_loss: 0.4440623705203717, val_loss: 0.4434198021888733\n",
      "8307, train_loss: 0.44832912431313443, val_loss: 0.4650975227355957\n",
      "8308, train_loss: 0.4487662739478625, val_loss: 0.4508569538593292\n",
      "8309, train_loss: 0.4507256562893207, val_loss: 0.4167042553424835\n",
      "8310, train_loss: 0.4471709126463303, val_loss: 0.43441557288169863\n",
      "8311, train_loss: 0.4458554765352836, val_loss: 0.43700757026672366\n",
      "8312, train_loss: 0.445930900482031, val_loss: 0.44910105466842654\n",
      "8313, train_loss: 0.4483399522992281, val_loss: 0.4503291845321655\n",
      "8314, train_loss: 0.4505960138944479, val_loss: 0.4360882997512817\n",
      "8315, train_loss: 0.45055497323091215, val_loss: 0.45074809789657594\n",
      "8316, train_loss: 0.4467784750920076, val_loss: 0.44660133123397827\n",
      "8317, train_loss: 0.44747838034079623, val_loss: 0.4434966087341309\n",
      "8318, train_loss: 0.45045851973386913, val_loss: 0.4440640270709991\n",
      "8319, train_loss: 0.44671762448090774, val_loss: 0.4565367937088013\n",
      "8320, train_loss: 0.4504161522938655, val_loss: 0.449180668592453\n",
      "8321, train_loss: 0.4445096328854561, val_loss: 0.4608799755573273\n",
      "8322, train_loss: 0.44727285091693586, val_loss: 0.4360601305961609\n",
      "8323, train_loss: 0.44623897396601164, val_loss: 0.43645812273025514\n",
      "8324, train_loss: 0.4446276689951236, val_loss: 0.4376331388950348\n",
      "8325, train_loss: 0.44549445922558123, val_loss: 0.4398480236530304\n",
      "8326, train_loss: 0.4460866256402089, val_loss: 0.42229518890380857\n",
      "8327, train_loss: 0.45023357982818896, val_loss: 0.46490238904953\n",
      "8328, train_loss: 0.45023588148447186, val_loss: 0.4427522301673889\n",
      "8329, train_loss: 0.45023854076862335, val_loss: 0.4467955768108368\n",
      "8330, train_loss: 0.4454187315243941, val_loss: 0.4521391332149506\n",
      "8331, train_loss: 0.4465859761604896, val_loss: 0.43480144143104554\n",
      "8332, train_loss: 0.44451886873978835, val_loss: 0.42504918575286865\n",
      "8333, train_loss: 0.44869296367351824, val_loss: 0.44317699074745176\n",
      "8334, train_loss: 0.44598234731417435, val_loss: 0.4648440420627594\n",
      "8335, train_loss: 0.4464558150905829, val_loss: 0.42529635429382323\n",
      "8336, train_loss: 0.4500767496915964, val_loss: 0.43503215312957766\n",
      "8337, train_loss: 0.4500844799555265, val_loss: 0.4292453646659851\n",
      "8338, train_loss: 0.4500746520665976, val_loss: 0.4502074122428894\n",
      "8339, train_loss: 0.4464345316474254, val_loss: 0.4428499698638916\n",
      "8340, train_loss: 0.45004103447382265, val_loss: 0.442917263507843\n",
      "8341, train_loss: 0.4478205396578862, val_loss: 0.42171390950679777\n",
      "8342, train_loss: 0.4448821281011288, val_loss: 0.41634091138839724\n",
      "8343, train_loss: 0.4480609349333323, val_loss: 0.42222813367843626\n",
      "8344, train_loss: 0.4463206988114577, val_loss: 0.46405301690101625\n",
      "8345, train_loss: 0.44702850855313814, val_loss: 0.42096905708312987\n",
      "8346, train_loss: 0.4499187973829416, val_loss: 0.44251522421836853\n",
      "8347, train_loss: 0.44476826603596026, val_loss: 0.4301650643348694\n",
      "8348, train_loss: 0.44792173688228315, val_loss: 0.4319371223449707\n",
      "8349, train_loss: 0.44986853977808583, val_loss: 0.41670461297035216\n",
      "8350, train_loss: 0.4498885159309094, val_loss: 0.4434386432170868\n",
      "8351, train_loss: 0.44982726184221417, val_loss: 0.44438928961753843\n",
      "8352, train_loss: 0.4497949698796639, val_loss: 0.42309839129447935\n",
      "8353, train_loss: 0.4461891267162103, val_loss: 0.4637742698192596\n",
      "8354, train_loss: 0.4449858321593358, val_loss: 0.4424765944480896\n",
      "8355, train_loss: 0.44982938583080584, val_loss: 0.42409037351608275\n",
      "8356, train_loss: 0.4459851590486673, val_loss: 0.4215183138847351\n",
      "8357, train_loss: 0.44677924995238966, val_loss: 0.4286662101745605\n",
      "8358, train_loss: 0.4497056534657112, val_loss: 0.4552661538124084\n",
      "8359, train_loss: 0.447714619911634, val_loss: 0.4282472014427185\n",
      "8360, train_loss: 0.4448483414374865, val_loss: 0.44945492744445803\n",
      "8361, train_loss: 0.44744520691724926, val_loss: 0.4295107305049896\n",
      "8362, train_loss: 0.4441781548353342, val_loss: 0.44502078294754027\n",
      "8363, train_loss: 0.44954626376812273, val_loss: 0.4457390129566193\n",
      "8364, train_loss: 0.44422050508169025, val_loss: 0.45960481762886046\n",
      "8365, train_loss: 0.4442212489935068, val_loss: 0.440997451543808\n",
      "8366, train_loss: 0.4443148374557495, val_loss: 0.4420060276985168\n",
      "8367, train_loss: 0.4454684183001518, val_loss: 0.4241266965866089\n",
      "8368, train_loss: 0.4454246163368225, val_loss: 0.45944939851760863\n",
      "8369, train_loss: 0.44470884135136235, val_loss: 0.442924702167511\n",
      "8370, train_loss: 0.4494498670101166, val_loss: 0.4150040864944458\n",
      "8371, train_loss: 0.44411550806118893, val_loss: 0.43480339646339417\n",
      "8372, train_loss: 0.44638653844594955, val_loss: 0.44173476099967957\n",
      "8373, train_loss: 0.4464700359564561, val_loss: 0.43543168902397156\n",
      "8374, train_loss: 0.44720742679559267, val_loss: 0.4491662263870239\n",
      "8375, train_loss: 0.4478699421653381, val_loss: 0.4492566823959351\n",
      "8376, train_loss: 0.44927456000676524, val_loss: 0.44370652437210084\n",
      "8377, train_loss: 0.4458509603371987, val_loss: 0.42750295996665955\n",
      "8378, train_loss: 0.44918350187631756, val_loss: 0.42270892262458803\n",
      "8379, train_loss: 0.4491876707627223, val_loss: 0.4452283442020416\n",
      "8380, train_loss: 0.44525011686178356, val_loss: 0.43126495480537413\n",
      "8381, train_loss: 0.44518038917046326, val_loss: 0.4361621856689453\n",
      "8382, train_loss: 0.449083859530779, val_loss: 0.4282276093959808\n",
      "8383, train_loss: 0.4447065798135904, val_loss: 0.44185258746147155\n",
      "8384, train_loss: 0.4490732860106688, val_loss: 0.4634475946426392\n",
      "8385, train_loss: 0.4452322245790408, val_loss: 0.4197019040584564\n",
      "8386, train_loss: 0.44904993359859174, val_loss: 0.4420794785022736\n",
      "8387, train_loss: 0.44902664766861844, val_loss: 0.42977486848831176\n",
      "8388, train_loss: 0.44905181802236116, val_loss: 0.4414974093437195\n",
      "8389, train_loss: 0.44704408714404476, val_loss: 0.44853082299232483\n",
      "8390, train_loss: 0.4489797158883168, val_loss: 0.42947072982788087\n",
      "8391, train_loss: 0.4452081322669983, val_loss: 0.4324128687381744\n",
      "8392, train_loss: 0.44515693531586575, val_loss: 0.4453786849975586\n",
      "8393, train_loss: 0.44890176676786864, val_loss: 0.441426146030426\n",
      "8394, train_loss: 0.44500121818139005, val_loss: 0.4264747202396393\n",
      "8395, train_loss: 0.44418152650961507, val_loss: 0.4626660287380219\n",
      "8396, train_loss: 0.44888752698898315, val_loss: 0.4147624671459198\n",
      "8397, train_loss: 0.4489033417059825, val_loss: 0.4625470221042633\n",
      "8398, train_loss: 0.4488637481744473, val_loss: 0.4206311762332916\n",
      "8399, train_loss: 0.4460049592531644, val_loss: 0.42337295413017273\n",
      "8400, train_loss: 0.4488583545272167, val_loss: 0.4278414845466614\n",
      "8401, train_loss: 0.44485212289370024, val_loss: 0.4224263310432434\n",
      "8402, train_loss: 0.44644402311398435, val_loss: 0.44028799533843993\n",
      "8403, train_loss: 0.4487819723211802, val_loss: 0.426638787984848\n",
      "8404, train_loss: 0.44642362342430997, val_loss: 0.4220210611820221\n",
      "8405, train_loss: 0.44654870606385744, val_loss: 0.42789140343666077\n",
      "8406, train_loss: 0.44451807324702924, val_loss: 0.4494780123233795\n",
      "8407, train_loss: 0.44861837992301357, val_loss: 0.4625775933265686\n",
      "8408, train_loss: 0.44561068885601485, val_loss: 0.43537309765815735\n",
      "8409, train_loss: 0.44288703684623426, val_loss: 0.42384849190711976\n",
      "8410, train_loss: 0.44642201639138734, val_loss: 0.44844338297843933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8411, train_loss: 0.4443855606592618, val_loss: 0.4541590571403503\n",
      "8412, train_loss: 0.44376572278829723, val_loss: 0.46241372227668764\n",
      "8413, train_loss: 0.4461634640510266, val_loss: 0.43614016771316527\n",
      "8414, train_loss: 0.44612274720118594, val_loss: 0.4229694664478302\n",
      "8415, train_loss: 0.4470271101364723, val_loss: 0.4379761040210724\n",
      "8416, train_loss: 0.44539689673827243, val_loss: 0.43266490697860716\n",
      "8417, train_loss: 0.4461605101823807, val_loss: 0.4160196542739868\n",
      "8418, train_loss: 0.4483152066285794, val_loss: 0.4469596385955811\n",
      "8419, train_loss: 0.44826863820736224, val_loss: 0.41483274698257444\n",
      "8420, train_loss: 0.44452603275959307, val_loss: 0.4364549696445465\n",
      "8421, train_loss: 0.44655450032307553, val_loss: 0.46259811520576477\n",
      "8422, train_loss: 0.4436540064903406, val_loss: 0.4324571490287781\n",
      "8423, train_loss: 0.44454128123246706, val_loss: 0.44825843572616575\n",
      "8424, train_loss: 0.44430941572556126, val_loss: 0.4479288339614868\n",
      "8425, train_loss: 0.4481577712755937, val_loss: 0.4263270080089569\n",
      "8426, train_loss: 0.44341219847018903, val_loss: 0.42346989214420316\n",
      "8427, train_loss: 0.44306077177707964, val_loss: 0.43228458166122435\n",
      "8428, train_loss: 0.4481167168571399, val_loss: 0.4323510468006134\n",
      "8429, train_loss: 0.44805887456123644, val_loss: 0.4322152018547058\n",
      "8430, train_loss: 0.4449968928327927, val_loss: 0.4624632000923157\n",
      "8431, train_loss: 0.4444027846822372, val_loss: 0.44129733443260194\n",
      "8432, train_loss: 0.44801764820630735, val_loss: 0.4622542202472687\n",
      "8433, train_loss: 0.44799749897076535, val_loss: 0.4479647994041443\n",
      "8434, train_loss: 0.4480024312551205, val_loss: 0.42409890294075014\n",
      "8435, train_loss: 0.4442919997068552, val_loss: 0.41391993761062623\n",
      "8436, train_loss: 0.4459742703116857, val_loss: 0.44061051607131957\n",
      "8437, train_loss: 0.4437073108095389, val_loss: 0.45797775983810424\n",
      "8438, train_loss: 0.4437617900279852, val_loss: 0.4423281192779541\n",
      "8439, train_loss: 0.447923766878935, val_loss: 0.4422603249549866\n",
      "8440, train_loss: 0.4463271636229295, val_loss: 0.4355969548225403\n",
      "8441, train_loss: 0.4430650438253696, val_loss: 0.457800155878067\n",
      "8442, train_loss: 0.4431179635799848, val_loss: 0.41987177133560183\n",
      "8443, train_loss: 0.4427640357842812, val_loss: 0.447358638048172\n",
      "8444, train_loss: 0.44556353642390323, val_loss: 0.4399786710739136\n",
      "8445, train_loss: 0.4478090720681044, val_loss: 0.42319431304931643\n",
      "8446, train_loss: 0.44259852514817166, val_loss: 0.44716617465019226\n",
      "8447, train_loss: 0.4477720512793614, val_loss: 0.41572983264923097\n",
      "8448, train_loss: 0.4477652391562095, val_loss: 0.44726903438568116\n",
      "8449, train_loss: 0.4441515224484297, val_loss: 0.44393439292907716\n",
      "8450, train_loss: 0.4434377344755026, val_loss: 0.42128774523735046\n",
      "8451, train_loss: 0.44358738454488605, val_loss: 0.44082680344581604\n",
      "8452, train_loss: 0.4463106525632051, val_loss: 0.4458092272281647\n",
      "8453, train_loss: 0.44607731241446275, val_loss: 0.4276345670223236\n",
      "8454, train_loss: 0.4475944729951712, val_loss: 0.42949584126472473\n",
      "8455, train_loss: 0.44218400980417544, val_loss: 0.4472823143005371\n",
      "8456, train_loss: 0.44275782200006336, val_loss: 0.4205941140651703\n",
      "8457, train_loss: 0.44619387273605055, val_loss: 0.4483543634414673\n",
      "8458, train_loss: 0.4458462206216959, val_loss: 0.4350806295871735\n",
      "8459, train_loss: 0.4457981724005479, val_loss: 0.4574629008769989\n",
      "8460, train_loss: 0.44403636340911573, val_loss: 0.41957632899284364\n",
      "8461, train_loss: 0.44744483266885465, val_loss: 0.44348533153533937\n",
      "8462, train_loss: 0.4426220575204262, val_loss: 0.45307636857032774\n",
      "8463, train_loss: 0.4457018650495089, val_loss: 0.4484138011932373\n",
      "8464, train_loss: 0.44197572882358843, val_loss: 0.45313228368759156\n",
      "8465, train_loss: 0.44326609487716967, val_loss: 0.44852846264839175\n",
      "8466, train_loss: 0.4433898341197234, val_loss: 0.4393416285514832\n",
      "8467, train_loss: 0.4448783202813222, val_loss: 0.43514862060546877\n",
      "8468, train_loss: 0.4425145364724673, val_loss: 0.42184523940086366\n",
      "8469, train_loss: 0.4448335050390317, val_loss: 0.4349430501461029\n",
      "8470, train_loss: 0.4444390724484737, val_loss: 0.4184597373008728\n",
      "8471, train_loss: 0.44482101041537064, val_loss: 0.4390852451324463\n",
      "8472, train_loss: 0.4471975358632895, val_loss: 0.4454872250556946\n",
      "8473, train_loss: 0.44525654442035234, val_loss: 0.4265523135662079\n",
      "8474, train_loss: 0.44404715528854954, val_loss: 0.42075772285461427\n",
      "8475, train_loss: 0.4457133091413058, val_loss: 0.4288914442062378\n",
      "8476, train_loss: 0.44405050919606137, val_loss: 0.4198492705821991\n",
      "8477, train_loss: 0.44247329922822803, val_loss: 0.4468276083469391\n",
      "8478, train_loss: 0.44377820308391863, val_loss: 0.4417912125587463\n",
      "8479, train_loss: 0.4424334346101834, val_loss: 0.42165000438690187\n",
      "8480, train_loss: 0.4427261467163379, val_loss: 0.44663227796554567\n",
      "8481, train_loss: 0.4432544937500587, val_loss: 0.44317529201507566\n",
      "8482, train_loss: 0.4443459121080545, val_loss: 0.44667679667472837\n",
      "8483, train_loss: 0.4432438096174827, val_loss: 0.4611333966255188\n",
      "8484, train_loss: 0.44210807807170427, val_loss: 0.43710707426071166\n",
      "8485, train_loss: 0.4438640268949362, val_loss: 0.4206895172595978\n",
      "8486, train_loss: 0.44159308534402114, val_loss: 0.4609688580036163\n",
      "8487, train_loss: 0.44684474284832293, val_loss: 0.44133883714675903\n",
      "8488, train_loss: 0.4428077214039289, val_loss: 0.44117100834846495\n",
      "8489, train_loss: 0.4468368784739421, val_loss: 0.4351987063884735\n",
      "8490, train_loss: 0.4437368002075415, val_loss: 0.4479194521903992\n",
      "8491, train_loss: 0.44312650423783523, val_loss: 0.4395090937614441\n",
      "8492, train_loss: 0.4467802523420407, val_loss: 0.44112356305122374\n",
      "8493, train_loss: 0.4467657242829983, val_loss: 0.4395645439624786\n",
      "8494, train_loss: 0.4426015770206085, val_loss: 0.4248393774032593\n",
      "8495, train_loss: 0.44666638855750745, val_loss: 0.45695316791534424\n",
      "8496, train_loss: 0.4466282988970096, val_loss: 0.43991997838020325\n",
      "8497, train_loss: 0.4452074399361244, val_loss: 0.41499537229537964\n",
      "8498, train_loss: 0.4466494596921481, val_loss: 0.4244691550731659\n",
      "8499, train_loss: 0.44268207939771503, val_loss: 0.44314643144607546\n",
      "8500, train_loss: 0.44660136906000286, val_loss: 0.4427028298377991\n",
      "8501, train_loss: 0.44426396317206895, val_loss: 0.4607789099216461\n",
      "8502, train_loss: 0.44135681654398257, val_loss: 0.4464603662490845\n",
      "8503, train_loss: 0.4442057884656466, val_loss: 0.43102902770042417\n",
      "8504, train_loss: 0.444079543535526, val_loss: 0.4203482151031494\n",
      "8505, train_loss: 0.4450077030521173, val_loss: 0.4358141481876373\n",
      "8506, train_loss: 0.4427870981968366, val_loss: 0.43831557035446167\n",
      "8507, train_loss: 0.4463557509275583, val_loss: 0.42455374598503115\n",
      "8508, train_loss: 0.4434937479404303, val_loss: 0.4452546894550323\n",
      "8509, train_loss: 0.4433646912758167, val_loss: 0.4413532167673111\n",
      "8510, train_loss: 0.44360542182738966, val_loss: 0.44541404843330384\n",
      "8511, train_loss: 0.4461778780588737, val_loss: 0.44053156971931456\n",
      "8512, train_loss: 0.44211149559571195, val_loss: 0.4270245611667633\n",
      "8513, train_loss: 0.4433167530940129, val_loss: 0.4359709322452545\n",
      "8514, train_loss: 0.4461817374596229, val_loss: 0.44282886385917664\n",
      "8515, train_loss: 0.44607314811303067, val_loss: 0.4415623426437378\n",
      "8516, train_loss: 0.4460992996509259, val_loss: 0.43617470264434816\n",
      "8517, train_loss: 0.4460716751905588, val_loss: 0.4427737474441528\n",
      "8518, train_loss: 0.44089221782409227, val_loss: 0.4245516538619995\n",
      "8519, train_loss: 0.4459828562461413, val_loss: 0.44529651999473574\n",
      "8520, train_loss: 0.44209702943380064, val_loss: 0.42391655445098875\n",
      "8521, train_loss: 0.44196358208472913, val_loss: 0.44641934633255004\n",
      "8522, train_loss: 0.4392206290593514, val_loss: 0.43889483213424685\n",
      "8523, train_loss: 0.44354560054265535, val_loss: 0.4290137469768524\n",
      "8524, train_loss: 0.44179824395821643, val_loss: 0.43152972459793093\n",
      "8525, train_loss: 0.44592603410665804, val_loss: 0.43548200726509095\n",
      "8526, train_loss: 0.44071937237794584, val_loss: 0.424367356300354\n",
      "8527, train_loss: 0.4458561631349417, val_loss: 0.4408382773399353\n",
      "8528, train_loss: 0.4410531589618096, val_loss: 0.43857392072677615\n",
      "8529, train_loss: 0.44135232269763947, val_loss: 0.4350544512271881\n",
      "8530, train_loss: 0.44419237742057216, val_loss: 0.42436947822570803\n",
      "8531, train_loss: 0.4435380617013344, val_loss: 0.42486436367034913\n",
      "8532, train_loss: 0.4409932660368773, val_loss: 0.44078409075737\n",
      "8533, train_loss: 0.4426818329554338, val_loss: 0.4473743736743927\n",
      "8534, train_loss: 0.4457338876449145, val_loss: 0.4328828096389771\n",
      "8535, train_loss: 0.4421318821035899, val_loss: 0.43867872953414916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8536, train_loss: 0.4456472316613564, val_loss: 0.4185673475265503\n",
      "8537, train_loss: 0.4456561901248418, val_loss: 0.4205044388771057\n",
      "8538, train_loss: 0.4456678657577588, val_loss: 0.4299058437347412\n",
      "8539, train_loss: 0.4456106401406802, val_loss: 0.41807950735092164\n",
      "8540, train_loss: 0.44559294099991137, val_loss: 0.4191713213920593\n",
      "8541, train_loss: 0.44083597568365246, val_loss: 0.4215292751789093\n",
      "8542, train_loss: 0.4427084212119763, val_loss: 0.4560367584228516\n",
      "8543, train_loss: 0.4431653733436878, val_loss: 0.42108324766159055\n",
      "8544, train_loss: 0.4425336581010085, val_loss: 0.42429545521736145\n",
      "8545, train_loss: 0.4421699557166833, val_loss: 0.4298420250415802\n",
      "8546, train_loss: 0.44077945901797366, val_loss: 0.44435107707977295\n",
      "8547, train_loss: 0.44408180793890584, val_loss: 0.44041610062122344\n",
      "8548, train_loss: 0.44186417987713444, val_loss: 0.4458493173122406\n",
      "8549, train_loss: 0.4454451094453151, val_loss: 0.4427004396915436\n",
      "8550, train_loss: 0.4424395733154737, val_loss: 0.445868319272995\n",
      "8551, train_loss: 0.44148017580692583, val_loss: 0.44698086977005\n",
      "8552, train_loss: 0.43940564073049104, val_loss: 0.4288152813911438\n",
      "8553, train_loss: 0.44052946682159716, val_loss: 0.4385974705219269\n",
      "8554, train_loss: 0.439947495666834, val_loss: 0.45149901509284973\n",
      "8555, train_loss: 0.44288042416939366, val_loss: 0.4313684344291687\n",
      "8556, train_loss: 0.4411480615918453, val_loss: 0.45594118237495423\n",
      "8557, train_loss: 0.4452498509333684, val_loss: 0.42231338620185854\n",
      "8558, train_loss: 0.4430512184133896, val_loss: 0.4455155789852142\n",
      "8559, train_loss: 0.44270289173493016, val_loss: 0.4443465113639832\n",
      "8560, train_loss: 0.43835796874303085, val_loss: 0.4338220298290253\n",
      "8561, train_loss: 0.4451636580320505, val_loss: 0.4391335189342499\n",
      "8562, train_loss: 0.44268996440447295, val_loss: 0.422805118560791\n",
      "8563, train_loss: 0.4400121816075765, val_loss: 0.4181327760219574\n",
      "8564, train_loss: 0.44141872169879764, val_loss: 0.4596921861171722\n",
      "8565, train_loss: 0.4409945687422386, val_loss: 0.4594405949115753\n",
      "8566, train_loss: 0.4451022377380958, val_loss: 0.41565114855766294\n",
      "8567, train_loss: 0.44277100494274724, val_loss: 0.4593715250492096\n",
      "8568, train_loss: 0.4412324462945645, val_loss: 0.4215232253074646\n",
      "8569, train_loss: 0.4412904725624965, val_loss: 0.423747307062149\n",
      "8570, train_loss: 0.44275281062492955, val_loss: 0.42329479455947877\n",
      "8571, train_loss: 0.44499010764635527, val_loss: 0.4334199368953705\n",
      "8572, train_loss: 0.4411391088595757, val_loss: 0.44482452273368833\n",
      "8573, train_loss: 0.4435739637567447, val_loss: 0.42712788581848143\n",
      "8574, train_loss: 0.4407450533830203, val_loss: 0.43793119192123414\n",
      "8575, train_loss: 0.44077779008791995, val_loss: 0.4275223135948181\n",
      "8576, train_loss: 0.44165666516010577, val_loss: 0.43305969834327696\n",
      "8577, train_loss: 0.44008199813274235, val_loss: 0.42171740531921387\n",
      "8578, train_loss: 0.4401025858062964, val_loss: 0.4239238679409027\n",
      "8579, train_loss: 0.4409712186226478, val_loss: 0.42664859294891355\n",
      "8580, train_loss: 0.44476722753964937, val_loss: 0.4180857717990875\n",
      "8581, train_loss: 0.4426487317452064, val_loss: 0.43942221999168396\n",
      "8582, train_loss: 0.44184970225279147, val_loss: 0.4164532482624054\n",
      "8583, train_loss: 0.43999407726984757, val_loss: 0.42241902351379396\n",
      "8584, train_loss: 0.4447247162461281, val_loss: 0.41614310145378114\n",
      "8585, train_loss: 0.4446812845193423, val_loss: 0.44598208665847777\n",
      "8586, train_loss: 0.44465295511942643, val_loss: 0.422874391078949\n",
      "8587, train_loss: 0.4403902166164838, val_loss: 0.441293740272522\n",
      "8588, train_loss: 0.4404853284358978, val_loss: 0.4446109890937805\n",
      "8589, train_loss: 0.4427371770143509, val_loss: 0.4189950168132782\n",
      "8590, train_loss: 0.44231725885317874, val_loss: 0.4267169415950775\n",
      "8591, train_loss: 0.44146538181946826, val_loss: 0.43820658326148987\n",
      "8592, train_loss: 0.4444766944417587, val_loss: 0.43829582929611205\n",
      "8593, train_loss: 0.4409000403605975, val_loss: 0.41741828322410585\n",
      "8594, train_loss: 0.4444648050344907, val_loss: 0.4446889102458954\n",
      "8595, train_loss: 0.44022986407463366, val_loss: 0.43918808698654177\n",
      "8596, train_loss: 0.4404007700773386, val_loss: 0.4390160977840424\n",
      "8597, train_loss: 0.44443334753696734, val_loss: 0.4247475445270538\n",
      "8598, train_loss: 0.4405504361941264, val_loss: 0.41754613518714906\n",
      "8599, train_loss: 0.4404270431170097, val_loss: 0.4444552719593048\n",
      "8600, train_loss: 0.4395729022530409, val_loss: 0.45026772022247313\n",
      "8601, train_loss: 0.44132086290762973, val_loss: 0.4455337941646576\n",
      "8602, train_loss: 0.4415081487252162, val_loss: 0.43666601181030273\n",
      "8603, train_loss: 0.44431888598662156, val_loss: 0.4442927896976471\n",
      "8604, train_loss: 0.44041042717603535, val_loss: 0.4442405581474304\n",
      "8605, train_loss: 0.4442613296783887, val_loss: 0.44047226309776305\n",
      "8606, train_loss: 0.441810484115894, val_loss: 0.4376045107841492\n",
      "8607, train_loss: 0.43941765335889965, val_loss: 0.4427562475204468\n",
      "8608, train_loss: 0.44006603956222534, val_loss: 0.4175736606121063\n",
      "8609, train_loss: 0.4442255302117421, val_loss: 0.42053807973861695\n",
      "8610, train_loss: 0.44284295577269334, val_loss: 0.42356148958206175\n",
      "8611, train_loss: 0.44413972932558793, val_loss: 0.44281965494155884\n",
      "8612, train_loss: 0.4441038782779987, val_loss: 0.4440286159515381\n",
      "8613, train_loss: 0.44030960763876253, val_loss: 0.4145862877368927\n",
      "8614, train_loss: 0.4405054014462691, val_loss: 0.4261305809020996\n",
      "8615, train_loss: 0.4392196742387918, val_loss: 0.4426762580871582\n",
      "8616, train_loss: 0.438724635885312, val_loss: 0.44419838190078736\n",
      "8617, train_loss: 0.4439993225611173, val_loss: 0.41759236454963683\n",
      "8618, train_loss: 0.4399182005570485, val_loss: 0.42111421227455137\n",
      "8619, train_loss: 0.4392053129581305, val_loss: 0.4278428554534912\n",
      "8620, train_loss: 0.43925469999129957, val_loss: 0.4279624164104462\n",
      "8621, train_loss: 0.4396236470112434, val_loss: 0.44385968446731566\n",
      "8622, train_loss: 0.44391586918097276, val_loss: 0.4151476800441742\n",
      "8623, train_loss: 0.4387295933870169, val_loss: 0.4371675789356232\n",
      "8624, train_loss: 0.43792862043930936, val_loss: 0.45399712920188906\n",
      "8625, train_loss: 0.44385972848305333, val_loss: 0.43642608523368837\n",
      "8626, train_loss: 0.4438946568048917, val_loss: 0.4180569231510162\n",
      "8627, train_loss: 0.44382897134010607, val_loss: 0.4434599816799164\n",
      "8628, train_loss: 0.43844403670384335, val_loss: 0.44212419390678404\n",
      "8629, train_loss: 0.4386539000731248, val_loss: 0.44334118962287905\n",
      "8630, train_loss: 0.4411467250723105, val_loss: 0.43149731755256654\n",
      "8631, train_loss: 0.43893372324796825, val_loss: 0.43658700585365295\n",
      "8632, train_loss: 0.4389253585384442, val_loss: 0.43640042543411256\n",
      "8633, train_loss: 0.44377336020653063, val_loss: 0.41468959450721743\n",
      "8634, train_loss: 0.44021455427775014, val_loss: 0.4223943054676056\n",
      "8635, train_loss: 0.43798052347623384, val_loss: 0.43244490027427673\n",
      "8636, train_loss: 0.443702121766714, val_loss: 0.4361188232898712\n",
      "8637, train_loss: 0.4389256462454796, val_loss: 0.4186274766921997\n",
      "8638, train_loss: 0.4414443253324582, val_loss: 0.44915984869003295\n",
      "8639, train_loss: 0.44171283967219865, val_loss: 0.4257493317127228\n",
      "8640, train_loss: 0.4436089579875653, val_loss: 0.43529272079467773\n",
      "8641, train_loss: 0.44359974333873164, val_loss: 0.4223415911197662\n",
      "8642, train_loss: 0.44353774247261196, val_loss: 0.449224466085434\n",
      "8643, train_loss: 0.44350174355965394, val_loss: 0.43631587028503416\n",
      "8644, train_loss: 0.44345821898717147, val_loss: 0.4537239074707031\n",
      "8645, train_loss: 0.43998665993030256, val_loss: 0.4286938488483429\n",
      "8646, train_loss: 0.4388186146433537, val_loss: 0.4289737343788147\n",
      "8647, train_loss: 0.4409265231627684, val_loss: 0.4183387577533722\n",
      "8648, train_loss: 0.44332269349923503, val_loss: 0.43148558735847475\n",
      "8649, train_loss: 0.44330217574651426, val_loss: 0.4377601981163025\n",
      "8650, train_loss: 0.43954722124796647, val_loss: 0.43375996351242063\n",
      "8651, train_loss: 0.4432405393857222, val_loss: 0.44939492344856263\n",
      "8652, train_loss: 0.43808723298402935, val_loss: 0.43031063079833987\n",
      "8653, train_loss: 0.4384191804207288, val_loss: 0.4575368106365204\n",
      "8654, train_loss: 0.4390797970386652, val_loss: 0.45736253559589385\n",
      "8655, train_loss: 0.43777879900657213, val_loss: 0.44296486377716066\n",
      "8656, train_loss: 0.4431629255414009, val_loss: 0.4534961521625519\n",
      "8657, train_loss: 0.44314904281726253, val_loss: 0.4168035566806793\n",
      "8658, train_loss: 0.43900228349062115, val_loss: 0.42515663504600526\n",
      "8659, train_loss: 0.4430995434522629, val_loss: 0.4572927117347717\n",
      "8660, train_loss: 0.4414410109703357, val_loss: 0.435525244474411\n",
      "8661, train_loss: 0.4383306640845079, val_loss: 0.4153448760509491\n",
      "8662, train_loss: 0.4430343382633649, val_loss: 0.43623378276824953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8663, train_loss: 0.44304004082312953, val_loss: 0.4428459882736206\n",
      "8664, train_loss: 0.44299796854074186, val_loss: 0.40946866273880006\n",
      "8665, train_loss: 0.4430079563305928, val_loss: 0.4208437740802765\n",
      "8666, train_loss: 0.4382301637759575, val_loss: 0.43112084865570066\n",
      "8667, train_loss: 0.43945661187171936, val_loss: 0.45308482050895693\n",
      "8668, train_loss: 0.4406451491209177, val_loss: 0.4426473259925842\n",
      "8669, train_loss: 0.4428960451712975, val_loss: 0.4363184213638306\n",
      "8670, train_loss: 0.4390946185359588, val_loss: 0.4426839768886566\n",
      "8671, train_loss: 0.4380598051043657, val_loss: 0.4531409740447998\n",
      "8672, train_loss: 0.4428818884950418, val_loss: 0.42984049320220946\n",
      "8673, train_loss: 0.43988267848124873, val_loss: 0.43455310463905333\n",
      "8674, train_loss: 0.44115802015249544, val_loss: 0.43922812938690187\n",
      "8675, train_loss: 0.4389569747906465, val_loss: 0.4138876795768738\n",
      "8676, train_loss: 0.43989145641143507, val_loss: 0.4427740275859833\n",
      "8677, train_loss: 0.439688218327669, val_loss: 0.41954152584075927\n",
      "8678, train_loss: 0.4389858005138544, val_loss: 0.42198375463485716\n",
      "8679, train_loss: 0.44257061183452606, val_loss: 0.4145576894283295\n",
      "8680, train_loss: 0.43853257023371184, val_loss: 0.4160449028015137\n",
      "8681, train_loss: 0.44258342110193694, val_loss: 0.4570053815841675\n",
      "8682, train_loss: 0.43662980600045276, val_loss: 0.45681257247924806\n",
      "8683, train_loss: 0.43868339405610013, val_loss: 0.42725160121917727\n",
      "8684, train_loss: 0.43680381774902344, val_loss: 0.4565865099430084\n",
      "8685, train_loss: 0.43715944771583265, val_loss: 0.43581660389900206\n",
      "8686, train_loss: 0.44254399606814754, val_loss: 0.43866205811500547\n",
      "8687, train_loss: 0.44038665982393116, val_loss: 0.4134591817855835\n",
      "8688, train_loss: 0.4411029867254771, val_loss: 0.44862971901893617\n",
      "8689, train_loss: 0.44012980449658173, val_loss: 0.4304911375045776\n",
      "8690, train_loss: 0.4408489683499703, val_loss: 0.4349174201488495\n",
      "8691, train_loss: 0.44008360917751604, val_loss: 0.42456769943237305\n",
      "8692, train_loss: 0.43597055971622467, val_loss: 0.4392875760793686\n",
      "8693, train_loss: 0.43823285973989046, val_loss: 0.4425155997276306\n",
      "8694, train_loss: 0.44230094380103624, val_loss: 0.4134701728820801\n",
      "8695, train_loss: 0.43712013157514423, val_loss: 0.43464691638946534\n",
      "8696, train_loss: 0.44225408423405427, val_loss: 0.42428131103515626\n",
      "8697, train_loss: 0.4387013568327977, val_loss: 0.4348159730434418\n",
      "8698, train_loss: 0.4381082814473372, val_loss: 0.41907931566238404\n",
      "8699, train_loss: 0.4383182307848564, val_loss: 0.4228538751602173\n",
      "8700, train_loss: 0.44021769899588364, val_loss: 0.4201248973608017\n",
      "8701, train_loss: 0.44212885200977325, val_loss: 0.42814613580703736\n",
      "8702, train_loss: 0.4379867556003424, val_loss: 0.4392634093761444\n",
      "8703, train_loss: 0.4420992514261833, val_loss: 0.44845365881919863\n",
      "8704, train_loss: 0.44205282399287593, val_loss: 0.43414853811264037\n",
      "8705, train_loss: 0.4372562009554643, val_loss: 0.4267150342464447\n",
      "8706, train_loss: 0.43722111674455494, val_loss: 0.41064728498458863\n",
      "8707, train_loss: 0.4360670309800368, val_loss: 0.4156969964504242\n",
      "8708, train_loss: 0.44014809223321766, val_loss: 0.4420750677585602\n",
      "8709, train_loss: 0.43773643787090594, val_loss: 0.4563290536403656\n",
      "8710, train_loss: 0.4372451878510989, val_loss: 0.41742313504219053\n",
      "8711, train_loss: 0.4372033797777616, val_loss: 0.41209747195243834\n",
      "8712, train_loss: 0.44105816231324124, val_loss: 0.4199803411960602\n",
      "8713, train_loss: 0.44194458482357174, val_loss: 0.447943115234375\n",
      "8714, train_loss: 0.43856389820575714, val_loss: 0.4239355683326721\n",
      "8715, train_loss: 0.4394695506646083, val_loss: 0.4162638485431671\n",
      "8716, train_loss: 0.4375037757249979, val_loss: 0.4197336733341217\n",
      "8717, train_loss: 0.4391842965896313, val_loss: 0.43959325551986694\n",
      "8718, train_loss: 0.43943430196780425, val_loss: 0.41359885334968566\n",
      "8719, train_loss: 0.4364186364870805, val_loss: 0.4225469708442688\n",
      "8720, train_loss: 0.4369563643748944, val_loss: 0.44210840463638307\n",
      "8721, train_loss: 0.4375830894479385, val_loss: 0.43541184067726135\n",
      "8722, train_loss: 0.4397704681524864, val_loss: 0.42913631200790403\n",
      "8723, train_loss: 0.43739041743370205, val_loss: 0.41316527128219604\n",
      "8724, train_loss: 0.4386847678285379, val_loss: 0.40900461077690126\n",
      "8725, train_loss: 0.43789637318024266, val_loss: 0.424457722902298\n",
      "8726, train_loss: 0.43848624252356017, val_loss: 0.435399067401886\n",
      "8727, train_loss: 0.43925946263166576, val_loss: 0.4169938683509827\n",
      "8728, train_loss: 0.441490392272289, val_loss: 0.43884457349777223\n",
      "8729, train_loss: 0.44150202205547917, val_loss: 0.4167600512504578\n",
      "8730, train_loss: 0.4384640111373021, val_loss: 0.43498349785804746\n",
      "8731, train_loss: 0.43757392122195315, val_loss: 0.41825343370437623\n",
      "8732, train_loss: 0.44140172921694243, val_loss: 0.441901034116745\n",
      "8733, train_loss: 0.437268275481004, val_loss: 0.4323425889015198\n",
      "8734, train_loss: 0.440006645826193, val_loss: 0.4222280025482178\n",
      "8735, train_loss: 0.44131280653751814, val_loss: 0.43079286217689516\n",
      "8736, train_loss: 0.4412993805912825, val_loss: 0.43896418809890747\n",
      "8737, train_loss: 0.4379491009391271, val_loss: 0.4143094301223755\n",
      "8738, train_loss: 0.4390721728022282, val_loss: 0.4405516028404236\n",
      "8739, train_loss: 0.4377328294974107, val_loss: 0.43372819423675535\n",
      "8740, train_loss: 0.4375132299386538, val_loss: 0.4290863573551178\n",
      "8741, train_loss: 0.4411164006361595, val_loss: 0.427670019865036\n",
      "8742, train_loss: 0.4380910706061583, val_loss: 0.44840375781059266\n",
      "8743, train_loss: 0.4410489694430278, val_loss: 0.43441908359527587\n",
      "8744, train_loss: 0.43769584366908443, val_loss: 0.4155769944190979\n",
      "8745, train_loss: 0.43628575251652646, val_loss: 0.43023611307144166\n",
      "8746, train_loss: 0.4369276933945142, val_loss: 0.4303383529186249\n",
      "8747, train_loss: 0.4410131722688675, val_loss: 0.4301854848861694\n",
      "8748, train_loss: 0.4369775836284344, val_loss: 0.4275047242641449\n",
      "8749, train_loss: 0.43740201454896194, val_loss: 0.43793282508850095\n",
      "8750, train_loss: 0.4371275764245253, val_loss: 0.43869598507881163\n",
      "8751, train_loss: 0.4409944713115692, val_loss: 0.4558933436870575\n",
      "8752, train_loss: 0.4410010392849262, val_loss: 0.4428406059741974\n",
      "8753, train_loss: 0.4376157121016429, val_loss: 0.4520860552787781\n",
      "8754, train_loss: 0.43710609124257016, val_loss: 0.42552400231361387\n",
      "8755, train_loss: 0.43767220412309354, val_loss: 0.43095330595970155\n",
      "8756, train_loss: 0.4361661672592163, val_loss: 0.45578349232673643\n",
      "8757, train_loss: 0.4372621041077834, val_loss: 0.4520002841949463\n",
      "8758, train_loss: 0.43668077427607316, val_loss: 0.4293882131576538\n",
      "8759, train_loss: 0.43891422565166766, val_loss: 0.42266919612884524\n",
      "8760, train_loss: 0.44082339795736164, val_loss: 0.4281944453716278\n",
      "8761, train_loss: 0.4407972085934419, val_loss: 0.43008099794387816\n",
      "8762, train_loss: 0.4377991964037602, val_loss: 0.42947080731391907\n",
      "8763, train_loss: 0.43439553391474944, val_loss: 0.42022639513015747\n",
      "8764, train_loss: 0.43550735310866284, val_loss: 0.43079418540000913\n",
      "8765, train_loss: 0.4407540284670316, val_loss: 0.4160615861415863\n",
      "8766, train_loss: 0.43774320070560163, val_loss: 0.4409806549549103\n",
      "8767, train_loss: 0.4366419395575157, val_loss: 0.41911972761154176\n",
      "8768, train_loss: 0.43664324627472806, val_loss: 0.41452057361602784\n",
      "8769, train_loss: 0.437097121316653, val_loss: 0.42061029076576234\n",
      "8770, train_loss: 0.437668210038772, val_loss: 0.4513350069522858\n",
      "8771, train_loss: 0.4406442487469086, val_loss: 0.44205220341682433\n",
      "8772, train_loss: 0.44061990770009846, val_loss: 0.42122164368629456\n",
      "8773, train_loss: 0.4405760570214345, val_loss: 0.4369597375392914\n",
      "8774, train_loss: 0.4383371862081381, val_loss: 0.42126811146736143\n",
      "8775, train_loss: 0.43911556899547577, val_loss: 0.4203068256378174\n",
      "8776, train_loss: 0.44044508383824277, val_loss: 0.42115441262722014\n",
      "8777, train_loss: 0.4404333715255444, val_loss: 0.4198871314525604\n",
      "8778, train_loss: 0.4370700504917365, val_loss: 0.42543612122535707\n",
      "8779, train_loss: 0.43843366320316607, val_loss: 0.43794147968292235\n",
      "8780, train_loss: 0.4362414072339351, val_loss: 0.4552424490451813\n",
      "8781, train_loss: 0.4356631671006863, val_loss: 0.43426852822303774\n",
      "8782, train_loss: 0.4386572683086762, val_loss: 0.4290286064147949\n",
      "8783, train_loss: 0.4380566133902623, val_loss: 0.43701353669166565\n",
      "8784, train_loss: 0.4366926997900009, val_loss: 0.4468925058841705\n",
      "8785, train_loss: 0.440268623141142, val_loss: 0.4199528157711029\n",
      "8786, train_loss: 0.4351634245652419, val_loss: 0.45491795539855956\n",
      "8787, train_loss: 0.4402626626766645, val_loss: 0.42320666313171384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788, train_loss: 0.43829473623862636, val_loss: 0.41444469094276426\n",
      "8789, train_loss: 0.4361590880614061, val_loss: 0.41556594967842103\n",
      "8790, train_loss: 0.4348149379858604, val_loss: 0.418353858590126\n",
      "8791, train_loss: 0.4353939455289107, val_loss: 0.433363801240921\n",
      "8792, train_loss: 0.4364895041172321, val_loss: 0.4150460034608841\n",
      "8793, train_loss: 0.4387890301071681, val_loss: 0.42880076766014097\n",
      "8794, train_loss: 0.4356287385408695, val_loss: 0.4074845790863037\n",
      "8795, train_loss: 0.43714533975491154, val_loss: 0.43644648790359497\n",
      "8796, train_loss: 0.4343541063941442, val_loss: 0.43453928232192995\n",
      "8797, train_loss: 0.44009909606896913, val_loss: 0.45437883734703066\n",
      "8798, train_loss: 0.44006358144374996, val_loss: 0.4462962806224823\n",
      "8799, train_loss: 0.4363391605707315, val_loss: 0.44620158076286315\n",
      "8800, train_loss: 0.4400138132847272, val_loss: 0.4400369644165039\n",
      "8801, train_loss: 0.4367920830845833, val_loss: 0.4334465801715851\n",
      "8802, train_loss: 0.43665953095142657, val_loss: 0.424406635761261\n",
      "8803, train_loss: 0.43856810377194333, val_loss: 0.44018752574920655\n",
      "8804, train_loss: 0.4357874250182739, val_loss: 0.4506630003452301\n",
      "8805, train_loss: 0.43992569927985853, val_loss: 0.4334329903125763\n",
      "8806, train_loss: 0.4350920606117982, val_loss: 0.42814346551895144\n",
      "8807, train_loss: 0.4361343120153134, val_loss: 0.4227082669734955\n",
      "8808, train_loss: 0.43977006811362046, val_loss: 0.44026411771774293\n",
      "8809, train_loss: 0.4357869258293739, val_loss: 0.4178549826145172\n",
      "8810, train_loss: 0.43977783849606145, val_loss: 0.4400717318058014\n",
      "8811, train_loss: 0.43670368653077346, val_loss: 0.4219660580158234\n",
      "8812, train_loss: 0.43461310863494873, val_loss: 0.4344118595123291\n",
      "8813, train_loss: 0.43972231562321, val_loss: 0.4201557695865631\n",
      "8814, train_loss: 0.4396816629629869, val_loss: 0.42854778170585633\n",
      "8815, train_loss: 0.4373222268544711, val_loss: 0.42404258251190186\n",
      "8816, train_loss: 0.43479421390936923, val_loss: 0.4386929988861084\n",
      "8817, train_loss: 0.4358866684711896, val_loss: 0.4188580811023712\n",
      "8818, train_loss: 0.4395614117383957, val_loss: 0.4386924743652344\n",
      "8819, train_loss: 0.43957336762776744, val_loss: 0.4168672949075699\n",
      "8820, train_loss: 0.4395255251572682, val_loss: 0.4280569672584534\n",
      "8821, train_loss: 0.4348025585596378, val_loss: 0.41661435961723325\n",
      "8822, train_loss: 0.4395316942380025, val_loss: 0.4409955859184265\n",
      "8823, train_loss: 0.43583305523945737, val_loss: 0.41658041477203367\n",
      "8824, train_loss: 0.43472691224171567, val_loss: 0.4276434540748596\n",
      "8825, train_loss: 0.43478634093816465, val_loss: 0.4394262582063675\n",
      "8826, train_loss: 0.4373362981356107, val_loss: 0.4329567015171051\n",
      "8827, train_loss: 0.43939485458227306, val_loss: 0.4338203489780426\n",
      "8828, train_loss: 0.43577544391155243, val_loss: 0.41859297156333924\n",
      "8829, train_loss: 0.43934770157703984, val_loss: 0.4289792895317078\n",
      "8830, train_loss: 0.43526744097471237, val_loss: 0.43163012266159057\n",
      "8831, train_loss: 0.4350369882125121, val_loss: 0.42532771825790405\n",
      "8832, train_loss: 0.4393082003180797, val_loss: 0.4100402593612671\n",
      "8833, train_loss: 0.4393241090270189, val_loss: 0.45352277159690857\n",
      "8834, train_loss: 0.43237712520819443, val_loss: 0.42638946771621705\n",
      "8835, train_loss: 0.43553463426920086, val_loss: 0.4319225549697876\n",
      "8836, train_loss: 0.4392336939389889, val_loss: 0.4065101325511932\n",
      "8837, train_loss: 0.4355801676328366, val_loss: 0.4360449850559235\n",
      "8838, train_loss: 0.43517219447172606, val_loss: 0.4325135827064514\n",
      "8839, train_loss: 0.4391627139770068, val_loss: 0.42792296409606934\n",
      "8840, train_loss: 0.4391928246388069, val_loss: 0.43595488667488097\n",
      "8841, train_loss: 0.43376687742196596, val_loss: 0.4248885989189148\n",
      "8842, train_loss: 0.4361383536687264, val_loss: 0.4341365694999695\n",
      "8843, train_loss: 0.4375107391522481, val_loss: 0.4454378604888916\n",
      "8844, train_loss: 0.43213795526669574, val_loss: 0.4497683584690094\n",
      "8845, train_loss: 0.4390486358450009, val_loss: 0.41415260434150697\n",
      "8846, train_loss: 0.4349205620013751, val_loss: 0.41698651313781737\n",
      "8847, train_loss: 0.439023399582276, val_loss: 0.41773008108139037\n",
      "8848, train_loss: 0.4353289053990291, val_loss: 0.4297282636165619\n",
      "8849, train_loss: 0.4342391479473848, val_loss: 0.41775848269462584\n",
      "8850, train_loss: 0.4370295967047031, val_loss: 0.431140661239624\n",
      "8851, train_loss: 0.4388931187299582, val_loss: 0.4149643123149872\n",
      "8852, train_loss: 0.4352578664055237, val_loss: 0.4164799928665161\n",
      "8853, train_loss: 0.43889743089675903, val_loss: 0.4142129302024841\n",
      "8854, train_loss: 0.4388650225905272, val_loss: 0.42763538360595704\n",
      "8855, train_loss: 0.43502796727877396, val_loss: 0.45297437310218813\n",
      "8856, train_loss: 0.4388183406912364, val_loss: 0.4307329416275024\n",
      "8857, train_loss: 0.434695303440094, val_loss: 0.41796061396598816\n",
      "8858, train_loss: 0.4357639579818799, val_loss: 0.43900383710861207\n",
      "8859, train_loss: 0.43872902599664837, val_loss: 0.4450302839279175\n",
      "8860, train_loss: 0.4387084406155806, val_loss: 0.45306567549705506\n",
      "8861, train_loss: 0.4344777579490955, val_loss: 0.4214365303516388\n",
      "8862, train_loss: 0.4386746224302512, val_loss: 0.43376670479774476\n",
      "8863, train_loss: 0.4386196354260811, val_loss: 0.4193152725696564\n",
      "8864, train_loss: 0.4386191608814093, val_loss: 0.45313050150871276\n",
      "8865, train_loss: 0.43477894136538875, val_loss: 0.41208918690681456\n",
      "8866, train_loss: 0.4355622541445952, val_loss: 0.4373562097549438\n",
      "8867, train_loss: 0.43853483291772694, val_loss: 0.4328970551490784\n",
      "8868, train_loss: 0.43854565345324004, val_loss: 0.4274380624294281\n",
      "8869, train_loss: 0.4362790836737706, val_loss: 0.4137285232543945\n",
      "8870, train_loss: 0.4347254393192438, val_loss: 0.4317272901535034\n",
      "8871, train_loss: 0.4384826650986305, val_loss: 0.4235859215259552\n",
      "8872, train_loss: 0.4361547925151311, val_loss: 0.4164893925189972\n",
      "8873, train_loss: 0.43474683509423184, val_loss: 0.41080422401428224\n",
      "8874, train_loss: 0.43457705126358914, val_loss: 0.42287845015525816\n",
      "8875, train_loss: 0.43836711232478803, val_loss: 0.4526825129985809\n",
      "8876, train_loss: 0.43465535801190597, val_loss: 0.4370963335037231\n",
      "8877, train_loss: 0.43440986367372364, val_loss: 0.4188815951347351\n",
      "8878, train_loss: 0.43832807586743283, val_loss: 0.41071311831474305\n",
      "8879, train_loss: 0.43830913878404176, val_loss: 0.42543784379959104\n",
      "8880, train_loss: 0.4382609896934949, val_loss: 0.4307849645614624\n",
      "8881, train_loss: 0.43830699760180253, val_loss: 0.4343773305416107\n",
      "8882, train_loss: 0.43357504216524273, val_loss: 0.43067635893821715\n",
      "8883, train_loss: 0.43824772307505977, val_loss: 0.43678134083747866\n",
      "8884, train_loss: 0.43439490405412823, val_loss: 0.41933191418647764\n",
      "8885, train_loss: 0.4382147817657544, val_loss: 0.4241847038269043\n",
      "8886, train_loss: 0.43818136476553404, val_loss: 0.4302334785461426\n",
      "8887, train_loss: 0.4340280695603444, val_loss: 0.42782378792762754\n",
      "8888, train_loss: 0.4316922930570749, val_loss: 0.41709590554237364\n",
      "8889, train_loss: 0.43624411064844865, val_loss: 0.4171101629734039\n",
      "8890, train_loss: 0.43446732599001664, val_loss: 0.4300489008426666\n",
      "8891, train_loss: 0.43673647252412945, val_loss: 0.41718441247940063\n",
      "8892, train_loss: 0.43433834726993853, val_loss: 0.4170254528522491\n",
      "8893, train_loss: 0.43610701996546525, val_loss: 0.4244031965732574\n",
      "8894, train_loss: 0.4344012336089061, val_loss: 0.4333203136920929\n",
      "8895, train_loss: 0.43790134214437926, val_loss: 0.42633991241455077\n",
      "8896, train_loss: 0.4378983894219765, val_loss: 0.4315613567829132\n",
      "8897, train_loss: 0.4379025772213936, val_loss: 0.4251618325710297\n",
      "8898, train_loss: 0.43401837463562304, val_loss: 0.41343334317207336\n",
      "8899, train_loss: 0.4331593095110013, val_loss: 0.4521937191486359\n",
      "8900, train_loss: 0.4378589844474426, val_loss: 0.4083179533481598\n",
      "8901, train_loss: 0.4338372355470291, val_loss: 0.45199698209762573\n",
      "8902, train_loss: 0.43570026698020786, val_loss: 0.42315576076507566\n",
      "8903, train_loss: 0.4377898613993938, val_loss: 0.44059703350067136\n",
      "8904, train_loss: 0.4377258993112124, val_loss: 0.4311109364032745\n",
      "8905, train_loss: 0.43775803538469166, val_loss: 0.41201679706573485\n",
      "8906, train_loss: 0.43769861127321535, val_loss: 0.4224702179431915\n",
      "8907, train_loss: 0.43765809444280773, val_loss: 0.43800921440124513\n",
      "8908, train_loss: 0.435367305118304, val_loss: 0.4314080595970154\n",
      "8909, train_loss: 0.43765003291460186, val_loss: 0.4139286935329437\n",
      "8910, train_loss: 0.4359975468653899, val_loss: 0.4085649847984314\n",
      "8911, train_loss: 0.4327707267724551, val_loss: 0.41796913743019104\n",
      "8912, train_loss: 0.43529380284822905, val_loss: 0.4339232087135315\n",
      "8913, train_loss: 0.4334592188780124, val_loss: 0.4310669243335724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8914, train_loss: 0.43372698586720687, val_loss: 0.43617154359817506\n",
      "8915, train_loss: 0.4346804389586815, val_loss: 0.4310114860534668\n",
      "8916, train_loss: 0.43751987929527575, val_loss: 0.4307913362979889\n",
      "8917, train_loss: 0.43539546544735247, val_loss: 0.4220894753932953\n",
      "8918, train_loss: 0.43336631243045515, val_loss: 0.4337338626384735\n",
      "8919, train_loss: 0.437418044759677, val_loss: 0.430027163028717\n",
      "8920, train_loss: 0.4374472281107536, val_loss: 0.41653830409049986\n",
      "8921, train_loss: 0.4322735552604382, val_loss: 0.4306993544101715\n",
      "8922, train_loss: 0.43370103664123094, val_loss: 0.43421393632888794\n",
      "8923, train_loss: 0.43226658266324264, val_loss: 0.4514369904994965\n",
      "8924, train_loss: 0.4339212333926788, val_loss: 0.43726696372032164\n",
      "8925, train_loss: 0.4335197920982654, val_loss: 0.4358889937400818\n",
      "8926, train_loss: 0.43730684427114636, val_loss: 0.4374347567558289\n",
      "8927, train_loss: 0.43729584492169893, val_loss: 0.4174453318119049\n",
      "8928, train_loss: 0.43323536389149153, val_loss: 0.4333605349063873\n",
      "8929, train_loss: 0.43355335982946247, val_loss: 0.4198827505111694\n",
      "8930, train_loss: 0.43725795356126934, val_loss: 0.4277990281581879\n",
      "8931, train_loss: 0.43720108614518094, val_loss: 0.42429848909378054\n",
      "8932, train_loss: 0.4371617069611183, val_loss: 0.4225014567375183\n",
      "8933, train_loss: 0.43419351829932284, val_loss: 0.41668060421943665\n",
      "8934, train_loss: 0.43279015444792235, val_loss: 0.4252128839492798\n",
      "8935, train_loss: 0.4327996957760591, val_loss: 0.4094466269016266\n",
      "8936, train_loss: 0.43189318076922345, val_loss: 0.4302519142627716\n",
      "8937, train_loss: 0.4337622563426311, val_loss: 0.41583854556083677\n",
      "8938, train_loss: 0.4370791419194295, val_loss: 0.4382234215736389\n",
      "8939, train_loss: 0.4322846016058555, val_loss: 0.41217076778411865\n",
      "8940, train_loss: 0.436108767413176, val_loss: 0.4337048053741455\n",
      "8941, train_loss: 0.4370065302802966, val_loss: 0.4134425699710846\n",
      "8942, train_loss: 0.43341196271089405, val_loss: 0.4150533854961395\n",
      "8943, train_loss: 0.4321395239004722, val_loss: 0.42450693249702454\n",
      "8944, train_loss: 0.43338840970626247, val_loss: 0.4157545745372772\n",
      "8945, train_loss: 0.43698685329694015, val_loss: 0.4352272987365723\n",
      "8946, train_loss: 0.43295254099827546, val_loss: 0.43326839804649353\n",
      "8947, train_loss: 0.43467089533805847, val_loss: 0.4209365963935852\n",
      "8948, train_loss: 0.43690196539346987, val_loss: 0.4285440564155579\n",
      "8949, train_loss: 0.4368725258570451, val_loss: 0.42977213859558105\n",
      "8950, train_loss: 0.43393660394045025, val_loss: 0.4107945740222931\n",
      "8951, train_loss: 0.43299115850375247, val_loss: 0.4364370763301849\n",
      "8952, train_loss: 0.433832137630536, val_loss: 0.4326347351074219\n",
      "8953, train_loss: 0.4367683208905734, val_loss: 0.42868590354919434\n",
      "8954, train_loss: 0.4322440314751405, val_loss: 0.4392355024814606\n",
      "8955, train_loss: 0.4348195722469917, val_loss: 0.4064732015132904\n",
      "8956, train_loss: 0.43124880011265093, val_loss: 0.4393086075782776\n",
      "8957, train_loss: 0.43357072197473967, val_loss: 0.4145242989063263\n",
      "8958, train_loss: 0.4366037530394701, val_loss: 0.4146686434745789\n",
      "8959, train_loss: 0.43657087362729585, val_loss: 0.42122223377227785\n",
      "8960, train_loss: 0.4324439632204863, val_loss: 0.4247123599052429\n",
      "8961, train_loss: 0.43135046328489596, val_loss: 0.4224635899066925\n",
      "8962, train_loss: 0.43261895271447987, val_loss: 0.44734025597572324\n",
      "8963, train_loss: 0.4364921095279547, val_loss: 0.42375520765781405\n",
      "8964, train_loss: 0.436454638838768, val_loss: 0.42484130859375\n",
      "8965, train_loss: 0.43067093250843197, val_loss: 0.4117056667804718\n",
      "8966, train_loss: 0.43226883445794767, val_loss: 0.40780444741249083\n",
      "8967, train_loss: 0.43480886404330915, val_loss: 0.4307073712348938\n",
      "8968, train_loss: 0.43209273654680985, val_loss: 0.42221242785453794\n",
      "8969, train_loss: 0.4334095928531427, val_loss: 0.4507966279983521\n",
      "8970, train_loss: 0.434041006060747, val_loss: 0.4292114615440369\n",
      "8971, train_loss: 0.43632839620113373, val_loss: 0.42851510643959045\n",
      "8972, train_loss: 0.4362499209550711, val_loss: 0.4197972297668457\n",
      "8973, train_loss: 0.43107852511681044, val_loss: 0.43049893975257875\n",
      "8974, train_loss: 0.4343262945230191, val_loss: 0.41918125152587893\n",
      "8975, train_loss: 0.4297409493189592, val_loss: 0.43650190234184266\n",
      "8976, train_loss: 0.4361948302158943, val_loss: 0.4234959900379181\n",
      "8977, train_loss: 0.4320897368284372, val_loss: 0.4505644738674164\n",
      "8978, train_loss: 0.4361233390294589, val_loss: 0.42182726263999937\n",
      "8979, train_loss: 0.4332878698523228, val_loss: 0.42844378352165224\n",
      "8980, train_loss: 0.4331160703530678, val_loss: 0.4325894773006439\n",
      "8981, train_loss: 0.4360452959170708, val_loss: 0.4089571237564087\n",
      "8982, train_loss: 0.43602176010608673, val_loss: 0.4079997479915619\n",
      "8983, train_loss: 0.4360169034737807, val_loss: 0.4125519335269928\n",
      "8984, train_loss: 0.4360022372924365, val_loss: 0.43144224882125853\n",
      "8985, train_loss: 0.43389711013207066, val_loss: 0.4349962830543518\n",
      "8986, train_loss: 0.43246059348950017, val_loss: 0.4255104064941406\n",
      "8987, train_loss: 0.4318525126347175, val_loss: 0.4215423107147217\n",
      "8988, train_loss: 0.4311201400481738, val_loss: 0.43033915758132935\n",
      "8989, train_loss: 0.43586597878199357, val_loss: 0.4349508941173553\n",
      "8990, train_loss: 0.43585020303726196, val_loss: 0.43286277651786803\n",
      "8991, train_loss: 0.4293675869703293, val_loss: 0.414590060710907\n",
      "8992, train_loss: 0.4310441819521097, val_loss: 0.43397789597511294\n",
      "8993, train_loss: 0.4342401795662366, val_loss: 0.4293994665145874\n",
      "8994, train_loss: 0.4357616202189372, val_loss: 0.4099497675895691\n",
      "8995, train_loss: 0.431655961733598, val_loss: 0.4280972838401794\n",
      "8996, train_loss: 0.4299886862819011, val_loss: 0.4300412595272064\n",
      "8997, train_loss: 0.4312472968147351, val_loss: 0.43379234671592715\n",
      "8998, train_loss: 0.4356836218100328, val_loss: 0.43602906465530394\n",
      "8999, train_loss: 0.43266852371967757, val_loss: 0.4467730462551117\n",
      "9000, train_loss: 0.42922135843680453, val_loss: 0.42938830256462096\n",
      "9001, train_loss: 0.4332548070412416, val_loss: 0.4218312978744507\n",
      "9002, train_loss: 0.435590718801205, val_loss: 0.42918201088905333\n",
      "9003, train_loss: 0.43558090466719407, val_loss: 0.4422085702419281\n",
      "9004, train_loss: 0.4325178609444545, val_loss: 0.4373741686344147\n",
      "9005, train_loss: 0.43394319999676484, val_loss: 0.40800451636314394\n",
      "9006, train_loss: 0.4316420520727451, val_loss: 0.43240848183631897\n",
      "9007, train_loss: 0.43190266077335066, val_loss: 0.4358736455440521\n",
      "9008, train_loss: 0.435463041640245, val_loss: 0.4074060618877411\n",
      "9009, train_loss: 0.4354468159950696, val_loss: 0.43192154765129087\n",
      "9010, train_loss: 0.43312360919438875, val_loss: 0.4466118812561035\n",
      "9011, train_loss: 0.4353677573112341, val_loss: 0.4386227786540985\n",
      "9012, train_loss: 0.43533439475756425, val_loss: 0.4345459699630737\n",
      "9013, train_loss: 0.43530863294234645, val_loss: 0.4074583828449249\n",
      "9014, train_loss: 0.43119239463255954, val_loss: 0.42936294674873354\n",
      "9015, train_loss: 0.43144863786605686, val_loss: 0.4293146252632141\n",
      "9016, train_loss: 0.4311608305344215, val_loss: 0.4238686740398407\n",
      "9017, train_loss: 0.435244429569978, val_loss: 0.43713671565055845\n",
      "9018, train_loss: 0.43260340851086837, val_loss: 0.40672117471694946\n",
      "9019, train_loss: 0.43519848585128784, val_loss: 0.40652490854263307\n",
      "9020, train_loss: 0.4351906638879042, val_loss: 0.43565328121185304\n",
      "9021, train_loss: 0.428713447199418, val_loss: 0.42366325855255127\n",
      "9022, train_loss: 0.4303458585188939, val_loss: 0.4108937501907349\n",
      "9023, train_loss: 0.4299919886084703, val_loss: 0.4367374211549759\n",
      "9024, train_loss: 0.43222166196658063, val_loss: 0.4076366722583771\n",
      "9025, train_loss: 0.43324890159643614, val_loss: 0.4116102933883667\n",
      "9026, train_loss: 0.42905231507924885, val_loss: 0.4277724802494049\n",
      "9027, train_loss: 0.4351122866456325, val_loss: 0.4319532632827759\n",
      "9028, train_loss: 0.4304294746655684, val_loss: 0.4021459937095642\n",
      "9029, train_loss: 0.4325648821317233, val_loss: 0.4273194432258606\n",
      "9030, train_loss: 0.4296039698215631, val_loss: 0.41044092178344727\n",
      "9031, train_loss: 0.43509860795277816, val_loss: 0.41489802598953246\n",
      "9032, train_loss: 0.43377890380529255, val_loss: 0.40702141523361207\n",
      "9033, train_loss: 0.4350316444268593, val_loss: 0.44874468445777893\n",
      "9034, train_loss: 0.43208178075460285, val_loss: 0.4270836412906647\n",
      "9035, train_loss: 0.43499106627244216, val_loss: 0.44080259203910827\n",
      "9036, train_loss: 0.43024147703097415, val_loss: 0.40600551962852477\n",
      "9037, train_loss: 0.4301974991193184, val_loss: 0.4133083999156952\n",
      "9038, train_loss: 0.4295062869787216, val_loss: 0.41340131163597105\n",
      "9039, train_loss: 0.43204321884191954, val_loss: 0.4344509899616241\n",
      "9040, train_loss: 0.43313239686764204, val_loss: 0.4218558192253113\n",
      "9041, train_loss: 0.43186044291808057, val_loss: 0.4143577039241791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9042, train_loss: 0.43105925619602203, val_loss: 0.4141059637069702\n",
      "9043, train_loss: 0.43203574877518874, val_loss: 0.4265026330947876\n",
      "9044, train_loss: 0.4348173863612689, val_loss: 0.4021372437477112\n",
      "9045, train_loss: 0.43479790825110215, val_loss: 0.41887704730033876\n",
      "9046, train_loss: 0.4309586836741521, val_loss: 0.4311780989170074\n",
      "9047, train_loss: 0.4317302405834198, val_loss: 0.4274473488330841\n",
      "9048, train_loss: 0.42869936101711714, val_loss: 0.42480258345603944\n",
      "9049, train_loss: 0.4347349623074898, val_loss: 0.4450190246105194\n",
      "9050, train_loss: 0.4307887852191925, val_loss: 0.44833210706710813\n",
      "9051, train_loss: 0.4317359053171598, val_loss: 0.41202689707279205\n",
      "9052, train_loss: 0.4294512787690529, val_loss: 0.4295801639556885\n",
      "9053, train_loss: 0.43070829946261185, val_loss: 0.4343841433525085\n",
      "9054, train_loss: 0.4298347784922673, val_loss: 0.4309972047805786\n",
      "9055, train_loss: 0.4303437534433145, val_loss: 0.4448800265789032\n",
      "9056, train_loss: 0.430466302885459, val_loss: 0.42713010907173155\n",
      "9057, train_loss: 0.42979344381735873, val_loss: 0.4277420282363892\n",
      "9058, train_loss: 0.4345670881179663, val_loss: 0.4271520137786865\n",
      "9059, train_loss: 0.4297848171912707, val_loss: 0.43042207360267637\n",
      "9060, train_loss: 0.42904223100497174, val_loss: 0.4138724684715271\n",
      "9061, train_loss: 0.4327547584588711, val_loss: 0.4477060616016388\n",
      "9062, train_loss: 0.43268569444234556, val_loss: 0.42570762038230897\n",
      "9063, train_loss: 0.43444178425348723, val_loss: 0.43241344690322875\n",
      "9064, train_loss: 0.4344163021216026, val_loss: 0.4134243607521057\n",
      "9065, train_loss: 0.43187993879501635, val_loss: 0.4478477716445923\n",
      "9066, train_loss: 0.42908128809470397, val_loss: 0.4116126954555511\n",
      "9067, train_loss: 0.43070922104211956, val_loss: 0.4338416337966919\n",
      "9068, train_loss: 0.43432846436133754, val_loss: 0.43241976499557494\n",
      "9069, train_loss: 0.4291498890289894, val_loss: 0.4189605534076691\n",
      "9070, train_loss: 0.4319411126466898, val_loss: 0.4338240385055542\n",
      "9071, train_loss: 0.429483987390995, val_loss: 0.4003236413002014\n",
      "9072, train_loss: 0.4342697560787201, val_loss: 0.42966277003288267\n",
      "9073, train_loss: 0.42904582161169785, val_loss: 0.42962974309921265\n",
      "9074, train_loss: 0.42970602959394455, val_loss: 0.4046134740114212\n",
      "9075, train_loss: 0.431349251132745, val_loss: 0.41058825254440307\n",
      "9076, train_loss: 0.4341586713607495, val_loss: 0.4337397038936615\n",
      "9077, train_loss: 0.4311914019859754, val_loss: 0.4399655401706696\n",
      "9078, train_loss: 0.4299766031595377, val_loss: 0.4267854571342468\n",
      "9079, train_loss: 0.434063121676445, val_loss: 0.4214905023574829\n",
      "9080, train_loss: 0.4311073634486932, val_loss: 0.4181147515773773\n",
      "9081, train_loss: 0.4299627955143268, val_loss: 0.4226653158664703\n",
      "9082, train_loss: 0.43401003457032716, val_loss: 0.4214483588933945\n",
      "9083, train_loss: 0.43398888638386357, val_loss: 0.4443428933620453\n",
      "9084, train_loss: 0.4339967696712567, val_loss: 0.41192587018013\n",
      "9085, train_loss: 0.4303593131212088, val_loss: 0.4336458444595337\n",
      "9086, train_loss: 0.43387892154546887, val_loss: 0.4273983120918274\n",
      "9087, train_loss: 0.4309451591510039, val_loss: 0.43219956159591677\n",
      "9088, train_loss: 0.4330177547839972, val_loss: 0.43992753624916076\n",
      "9089, train_loss: 0.4324801621528772, val_loss: 0.43996185064315796\n",
      "9090, train_loss: 0.4337845960488686, val_loss: 0.44448178112506864\n",
      "9091, train_loss: 0.4292939007282257, val_loss: 0.4399122416973114\n",
      "9092, train_loss: 0.43149794982029843, val_loss: 0.43506470918655393\n",
      "9093, train_loss: 0.43285321215024364, val_loss: 0.41312906742095945\n",
      "9094, train_loss: 0.43366443652373093, val_loss: 0.44789168834686277\n",
      "9095, train_loss: 0.42882428948695844, val_loss: 0.4177254199981689\n",
      "9096, train_loss: 0.43363438088160294, val_loss: 0.42682350277900694\n",
      "9097, train_loss: 0.4299367270790614, val_loss: 0.4234012484550476\n",
      "9098, train_loss: 0.4335968872675529, val_loss: 0.40911470651626586\n",
      "9099, train_loss: 0.4335550035421665, val_loss: 0.4196710765361786\n",
      "9100, train_loss: 0.42996890957538897, val_loss: 0.4262332022190094\n",
      "9101, train_loss: 0.43352227256848264, val_loss: 0.4274441719055176\n",
      "9102, train_loss: 0.4305673528176088, val_loss: 0.40749030709266665\n",
      "9103, train_loss: 0.4286854943403831, val_loss: 0.42139444351196287\n",
      "9104, train_loss: 0.43346216357671297, val_loss: 0.43203807473182676\n",
      "9105, train_loss: 0.4281573226818672, val_loss: 0.41111122965812685\n",
      "9106, train_loss: 0.42833289790612, val_loss: 0.4293802320957184\n",
      "9107, train_loss: 0.42986053228378296, val_loss: 0.430088946223259\n",
      "9108, train_loss: 0.42870864272117615, val_loss: 0.42503511905670166\n",
      "9109, train_loss: 0.4296632598225887, val_loss: 0.4261728644371033\n",
      "9110, train_loss: 0.4333937563575231, val_loss: 0.40842394828796386\n",
      "9111, train_loss: 0.4304461439068501, val_loss: 0.4317465007305145\n",
      "9112, train_loss: 0.42931695740956527, val_loss: 0.4344093441963196\n",
      "9113, train_loss: 0.43327714789372224, val_loss: 0.447120463848114\n",
      "9114, train_loss: 0.42962562923248, val_loss: 0.41096067428588867\n",
      "9115, train_loss: 0.4288099700441727, val_loss: 0.4221068203449249\n",
      "9116, train_loss: 0.4297233991898023, val_loss: 0.4436390459537506\n",
      "9117, train_loss: 0.42843624834830946, val_loss: 0.42886412143707275\n",
      "9118, train_loss: 0.42926138639450073, val_loss: 0.4281885027885437\n",
      "9119, train_loss: 0.4284193945618776, val_loss: 0.4118793189525604\n",
      "9120, train_loss: 0.43320409323160464, val_loss: 0.41125214099884033\n",
      "9121, train_loss: 0.433168235879678, val_loss: 0.42873614430427553\n",
      "9122, train_loss: 0.43021159217907834, val_loss: 0.4131150484085083\n",
      "9123, train_loss: 0.4294419437646866, val_loss: 0.42878655195236204\n",
      "9124, train_loss: 0.4278005063533783, val_loss: 0.42036849856376646\n",
      "9125, train_loss: 0.4270435772263087, val_loss: 0.4285780668258667\n",
      "9126, train_loss: 0.4309232687720886, val_loss: 0.4248990148305893\n",
      "9127, train_loss: 0.4330602058997521, val_loss: 0.39939275979995725\n",
      "9128, train_loss: 0.42947689673075307, val_loss: 0.411260324716568\n",
      "9129, train_loss: 0.4290430626043907, val_loss: 0.4247094035148621\n",
      "9130, train_loss: 0.4282160412806731, val_loss: 0.4066534638404846\n",
      "9131, train_loss: 0.4307469106637515, val_loss: 0.4175264298915863\n",
      "9132, train_loss: 0.4329642756627156, val_loss: 0.4323498845100403\n",
      "9133, train_loss: 0.43297138007787556, val_loss: 0.43860265612602234\n",
      "9134, train_loss: 0.4329249830200122, val_loss: 0.42893980741500853\n",
      "9135, train_loss: 0.42994111432478976, val_loss: 0.39784414172172544\n",
      "9136, train_loss: 0.4288428437251311, val_loss: 0.43859736919403075\n",
      "9137, train_loss: 0.429880848297706, val_loss: 0.4233099937438965\n",
      "9138, train_loss: 0.42803130413477236, val_loss: 0.40356839299201963\n",
      "9139, train_loss: 0.4327955056841557, val_loss: 0.43244969844818115\n",
      "9140, train_loss: 0.4327243979160602, val_loss: 0.4254240095615387\n",
      "9141, train_loss: 0.4309468406897325, val_loss: 0.4176976323127747\n",
      "9142, train_loss: 0.432679750598394, val_loss: 0.42470602989196776\n",
      "9143, train_loss: 0.4327071188734128, val_loss: 0.41753765642642976\n",
      "9144, train_loss: 0.4293940777962024, val_loss: 0.42467124462127687\n",
      "9145, train_loss: 0.42874175997880787, val_loss: 0.4113111913204193\n",
      "9146, train_loss: 0.432659408220878, val_loss: 0.42468254566192626\n",
      "9147, train_loss: 0.430361352287806, val_loss: 0.4092698752880096\n",
      "9148, train_loss: 0.43256499159794587, val_loss: 0.43083308935165404\n",
      "9149, train_loss: 0.4325663367143044, val_loss: 0.423152095079422\n",
      "9150, train_loss: 0.427838717515652, val_loss: 0.42899656295776367\n",
      "9151, train_loss: 0.4295662985398219, val_loss: 0.42001086473464966\n",
      "9152, train_loss: 0.4324820568928352, val_loss: 0.4256420373916626\n",
      "9153, train_loss: 0.42766047899539655, val_loss: 0.42815362215042113\n",
      "9154, train_loss: 0.42766817257954526, val_loss: 0.41172250509262087\n",
      "9155, train_loss: 0.4302785247564316, val_loss: 0.43344187140464785\n",
      "9156, train_loss: 0.43056557728694034, val_loss: 0.4167681038379669\n",
      "9157, train_loss: 0.4289424172960795, val_loss: 0.43347716331481934\n",
      "9158, train_loss: 0.4323386584336941, val_loss: 0.430810284614563\n",
      "9159, train_loss: 0.4297451480076863, val_loss: 0.416870242357254\n",
      "9160, train_loss: 0.42876409681943745, val_loss: 0.4196421802043915\n",
      "9161, train_loss: 0.4281940104869696, val_loss: 0.4143495798110962\n",
      "9162, train_loss: 0.42858909643613374, val_loss: 0.4463856160640717\n",
      "9163, train_loss: 0.42797630910690015, val_loss: 0.41945417523384093\n",
      "9164, train_loss: 0.4270117718439836, val_loss: 0.4462912082672119\n",
      "9165, train_loss: 0.43134972338493055, val_loss: 0.4020805597305298\n",
      "9166, train_loss: 0.43213321555119294, val_loss: 0.43348857164382937\n",
      "9167, train_loss: 0.43123083217785907, val_loss: 0.4167813420295715\n",
      "9168, train_loss: 0.4275665959486595, val_loss: 0.40614166259765627\n",
      "9169, train_loss: 0.4320607351569029, val_loss: 0.4200881540775299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9170, train_loss: 0.429114336004624, val_loss: 0.43340924978256223\n",
      "9171, train_loss: 0.4287396680850249, val_loss: 0.4074170351028442\n",
      "9172, train_loss: 0.42901377036021304, val_loss: 0.43214887380599976\n",
      "9173, train_loss: 0.42974131955550265, val_loss: 0.41009093821048737\n",
      "9174, train_loss: 0.4318486131154574, val_loss: 0.4250409662723541\n",
      "9175, train_loss: 0.42582355783535886, val_loss: 0.43079338073730467\n",
      "9176, train_loss: 0.4318572116585878, val_loss: 0.4254267454147339\n",
      "9177, train_loss: 0.43186428340581745, val_loss: 0.4461001932621002\n",
      "9178, train_loss: 0.4286294843141849, val_loss: 0.4258141279220581\n",
      "9179, train_loss: 0.428830990424523, val_loss: 0.42890238761901855\n",
      "9180, train_loss: 0.42777411811626875, val_loss: 0.4197735726833344\n",
      "9181, train_loss: 0.42698457493231845, val_loss: 0.404257196187973\n",
      "9182, train_loss: 0.43180595281032413, val_loss: 0.43160560131073\n",
      "9183, train_loss: 0.4317810948078449, val_loss: 0.4284380316734314\n",
      "9184, train_loss: 0.431724787904666, val_loss: 0.4145482122898102\n",
      "9185, train_loss: 0.4316933567707355, val_loss: 0.4425238370895386\n",
      "9186, train_loss: 0.4316976861311839, val_loss: 0.43178831934928896\n",
      "9187, train_loss: 0.42862340807914734, val_loss: 0.425156831741333\n",
      "9188, train_loss: 0.4295392202643248, val_loss: 0.4031821370124817\n",
      "9189, train_loss: 0.4287954649099937, val_loss: 0.41648121178150177\n",
      "9190, train_loss: 0.42625438708525437, val_loss: 0.4458208799362183\n",
      "9191, train_loss: 0.42771742664850676, val_loss: 0.41956169009208677\n",
      "9192, train_loss: 0.4285984503535124, val_loss: 0.4061695635318756\n",
      "9193, train_loss: 0.4277324819794068, val_loss: 0.42966697216033933\n",
      "9194, train_loss: 0.4315056101633952, val_loss: 0.416447651386261\n",
      "9195, train_loss: 0.43149333275281465, val_loss: 0.4040395736694336\n",
      "9196, train_loss: 0.4279019500200565, val_loss: 0.4079297840595245\n",
      "9197, train_loss: 0.42853946066819704, val_loss: 0.41716169118881224\n",
      "9198, train_loss: 0.4285876120512302, val_loss: 0.403979218006134\n",
      "9199, train_loss: 0.4313951197725076, val_loss: 0.4166485369205475\n",
      "9200, train_loss: 0.42654011857051116, val_loss: 0.40656461417675016\n",
      "9201, train_loss: 0.4283122649559608, val_loss: 0.4251302361488342\n",
      "9202, train_loss: 0.4266497469865359, val_loss: 0.41534415185451506\n",
      "9203, train_loss: 0.4297672762320592, val_loss: 0.3978313744068146\n",
      "9204, train_loss: 0.4298287263283363, val_loss: 0.43145636320114134\n",
      "9205, train_loss: 0.4259906926980385, val_loss: 0.4074455380439758\n",
      "9206, train_loss: 0.43129316660074085, val_loss: 0.41394985318183897\n",
      "9207, train_loss: 0.4252034528897359, val_loss: 0.4172828674316406\n",
      "9208, train_loss: 0.43121979901423824, val_loss: 0.42426965832710267\n",
      "9209, train_loss: 0.4273274237146744, val_loss: 0.4270572543144226\n",
      "9210, train_loss: 0.42937080791363347, val_loss: 0.40411814153194425\n",
      "9211, train_loss: 0.4273714216855856, val_loss: 0.4186603367328644\n",
      "9212, train_loss: 0.4311994480398985, val_loss: 0.4226210594177246\n",
      "9213, train_loss: 0.4311252614626518, val_loss: 0.4448411583900452\n",
      "9214, train_loss: 0.4311643007856149, val_loss: 0.41608318090438845\n",
      "9215, train_loss: 0.4311268570331427, val_loss: 0.4119373381137848\n",
      "9216, train_loss: 0.4292430986578648, val_loss: 0.44501652121543883\n",
      "9217, train_loss: 0.42700783564494205, val_loss: 0.4123581230640411\n",
      "9218, train_loss: 0.42734849338348097, val_loss: 0.43715330958366394\n",
      "9219, train_loss: 0.4310153057942024, val_loss: 0.42329577803611756\n",
      "9220, train_loss: 0.4295149783675487, val_loss: 0.4294710993766785\n",
      "9221, train_loss: 0.43098611613878834, val_loss: 0.4071965754032135\n",
      "9222, train_loss: 0.4291401751912557, val_loss: 0.39752955436706544\n",
      "9223, train_loss: 0.43091882879917437, val_loss: 0.44478737711906435\n",
      "9224, train_loss: 0.4308978645847394, val_loss: 0.39761377573013307\n",
      "9225, train_loss: 0.4270276106320895, val_loss: 0.4012599289417267\n",
      "9226, train_loss: 0.4272103298168916, val_loss: 0.40944418907165525\n",
      "9227, train_loss: 0.42956113987244093, val_loss: 0.40282832980155947\n",
      "9228, train_loss: 0.4307965556016335, val_loss: 0.4243761718273163\n",
      "9229, train_loss: 0.42824188562539905, val_loss: 0.4416542828083038\n",
      "9230, train_loss: 0.42852075627216923, val_loss: 0.4340446352958679\n",
      "9231, train_loss: 0.4306851304494418, val_loss: 0.42265222668647767\n",
      "9232, train_loss: 0.4268500999762462, val_loss: 0.40986862778663635\n",
      "9233, train_loss: 0.42544232652737546, val_loss: 0.43098592162132265\n",
      "9234, train_loss: 0.4268284703676517, val_loss: 0.4062942326068878\n",
      "9235, train_loss: 0.42697985355670637, val_loss: 0.424388986825943\n",
      "9236, train_loss: 0.43056237468352687, val_loss: 0.4321015179157257\n",
      "9237, train_loss: 0.42751155220545256, val_loss: 0.4128251612186432\n",
      "9238, train_loss: 0.42574335577396244, val_loss: 0.42340938448905946\n",
      "9239, train_loss: 0.43051474827986497, val_loss: 0.4093365788459778\n",
      "9240, train_loss: 0.4263596127812679, val_loss: 0.42246878147125244\n",
      "9241, train_loss: 0.4256626677054625, val_loss: 0.4293074131011963\n",
      "9242, train_loss: 0.43045508976166064, val_loss: 0.4307580828666687\n",
      "9243, train_loss: 0.4304302799013945, val_loss: 0.44155365228652954\n",
      "9244, train_loss: 0.42665800280295885, val_loss: 0.4230941653251648\n",
      "9245, train_loss: 0.4252596107813028, val_loss: 0.42617191672325133\n",
      "9246, train_loss: 0.4303108442288179, val_loss: 0.4099654495716095\n",
      "9247, train_loss: 0.4303270372060629, val_loss: 0.4448185861110687\n",
      "9248, train_loss: 0.4303191378712654, val_loss: 0.4242647647857666\n",
      "9249, train_loss: 0.43028000512948406, val_loss: 0.4293224573135376\n",
      "9250, train_loss: 0.42485946302230543, val_loss: 0.4304529011249542\n",
      "9251, train_loss: 0.4302412821696355, val_loss: 0.4094990313053131\n",
      "9252, train_loss: 0.4261689495581847, val_loss: 0.40830354690551757\n",
      "9253, train_loss: 0.43013863609387326, val_loss: 0.4095519304275513\n",
      "9254, train_loss: 0.4271833495451854, val_loss: 0.4101541876792908\n",
      "9255, train_loss: 0.43010258502685106, val_loss: 0.41520105600357055\n",
      "9256, train_loss: 0.43004968819709927, val_loss: 0.40522284507751466\n",
      "9257, train_loss: 0.4266114372473497, val_loss: 0.4266639113426208\n",
      "9258, train_loss: 0.43004452322538084, val_loss: 0.4233939707279205\n",
      "9259, train_loss: 0.4270325692800375, val_loss: 0.43071516752243044\n",
      "9260, train_loss: 0.4269217774271965, val_loss: 0.43381149768829347\n",
      "9261, train_loss: 0.42996026289004546, val_loss: 0.42411062121391296\n",
      "9262, train_loss: 0.42708130123523563, val_loss: 0.43074741363525393\n",
      "9263, train_loss: 0.4246449281389897, val_loss: 0.40280723571777344\n",
      "9264, train_loss: 0.4299665167927742, val_loss: 0.42321630120277404\n",
      "9265, train_loss: 0.42992336131059206, val_loss: 0.42734140157699585\n",
      "9266, train_loss: 0.42987808470542616, val_loss: 0.43059285879135134\n",
      "9267, train_loss: 0.4298174948646472, val_loss: 0.4240710437297821\n",
      "9268, train_loss: 0.4298664199618193, val_loss: 0.41502050757408143\n",
      "9269, train_loss: 0.4285362741121879, val_loss: 0.4232702195644379\n",
      "9270, train_loss: 0.4275098614967786, val_loss: 0.4238379955291748\n",
      "9271, train_loss: 0.4279278711630748, val_loss: 0.42077529430389404\n",
      "9272, train_loss: 0.4257486221882013, val_loss: 0.4239270925521851\n",
      "9273, train_loss: 0.42975017657646764, val_loss: 0.42387365698814394\n",
      "9274, train_loss: 0.4297068010155971, val_loss: 0.40132269263267517\n",
      "9275, train_loss: 0.4259349646476599, val_loss: 0.42340315580368043\n",
      "9276, train_loss: 0.42553239544996846, val_loss: 0.4081752061843872\n",
      "9277, train_loss: 0.42785751819610596, val_loss: 0.43011873960494995\n",
      "9278, train_loss: 0.4296706123993947, val_loss: 0.4312984347343445\n",
      "9279, train_loss: 0.4267835565484487, val_loss: 0.4180086612701416\n",
      "9280, train_loss: 0.42960183780926925, val_loss: 0.43004549145698545\n",
      "9281, train_loss: 0.4296065236513431, val_loss: 0.4226587533950806\n",
      "9282, train_loss: 0.426116950236834, val_loss: 0.4224480390548706\n",
      "9283, train_loss: 0.42552402787483656, val_loss: 0.4157315969467163\n",
      "9284, train_loss: 0.4295486377981993, val_loss: 0.4093056499958038\n",
      "9285, train_loss: 0.4294958383991168, val_loss: 0.42966129183769225\n",
      "9286, train_loss: 0.42593936966015744, val_loss: 0.42647446393966676\n",
      "9287, train_loss: 0.4279658009226506, val_loss: 0.4176293045282364\n",
      "9288, train_loss: 0.4258624710715734, val_loss: 0.39622819423675537\n",
      "9289, train_loss: 0.4255226008020915, val_loss: 0.41726155281066896\n",
      "9290, train_loss: 0.4233832210302353, val_loss: 0.41696555614471437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9291, train_loss: 0.42651938990904736, val_loss: 0.4252758026123047\n",
      "9292, train_loss: 0.42941788412057436, val_loss: 0.43555598258972167\n",
      "9293, train_loss: 0.42939892640480626, val_loss: 0.42599897980690005\n",
      "9294, train_loss: 0.42576833642446077, val_loss: 0.40885138511657715\n",
      "9295, train_loss: 0.4294018309849959, val_loss: 0.4293254852294922\n",
      "9296, train_loss: 0.42932864794364345, val_loss: 0.4431223809719086\n",
      "9297, train_loss: 0.4232777047615785, val_loss: 0.43042572140693663\n",
      "9298, train_loss: 0.42929734920079893, val_loss: 0.4225622177124023\n",
      "9299, train_loss: 0.4257450138147061, val_loss: 0.4027047395706177\n",
      "9300, train_loss: 0.42926237961420644, val_loss: 0.4292146623134613\n",
      "9301, train_loss: 0.42372310620087844, val_loss: 0.4046910166740417\n",
      "9302, train_loss: 0.42704814901718724, val_loss: 0.40987042188644407\n",
      "9303, train_loss: 0.42514369464837587, val_loss: 0.4215593457221985\n",
      "9304, train_loss: 0.4226109396952849, val_loss: 0.41760522723197935\n",
      "9305, train_loss: 0.4247149613041144, val_loss: 0.40851940512657164\n",
      "9306, train_loss: 0.4239459203986021, val_loss: 0.4084134638309479\n",
      "9307, train_loss: 0.4291480722335669, val_loss: 0.4045908093452454\n",
      "9308, train_loss: 0.42617110449534196, val_loss: 0.42913142442703245\n",
      "9309, train_loss: 0.4261181939106721, val_loss: 0.42459391951560976\n",
      "9310, train_loss: 0.42577118140000564, val_loss: 0.4039441645145416\n",
      "9311, train_loss: 0.42289642359201723, val_loss: 0.42775518298149107\n",
      "9312, train_loss: 0.42743379450761354, val_loss: 0.40994643568992617\n",
      "9313, train_loss: 0.42893019433204943, val_loss: 0.40445950627326965\n",
      "9314, train_loss: 0.4258607201851331, val_loss: 0.4139606475830078\n",
      "9315, train_loss: 0.4267725096299098, val_loss: 0.4008145987987518\n",
      "9316, train_loss: 0.425933155302818, val_loss: 0.3968379020690918\n",
      "9317, train_loss: 0.4252356497141031, val_loss: 0.43051677942276\n",
      "9318, train_loss: 0.4287687987089157, val_loss: 0.4207108557224274\n",
      "9319, train_loss: 0.42416456456367785, val_loss: 0.4030333936214447\n",
      "9320, train_loss: 0.4274897747314893, val_loss: 0.4249768316745758\n",
      "9321, train_loss: 0.4246772424532817, val_loss: 0.4292153000831604\n",
      "9322, train_loss: 0.4239330612696134, val_loss: 0.4037718951702118\n",
      "9323, train_loss: 0.4286643685056613, val_loss: 0.4276670694351196\n",
      "9324, train_loss: 0.4246316168170709, val_loss: 0.4258438408374786\n",
      "9325, train_loss: 0.42680368228600574, val_loss: 0.44297494292259215\n",
      "9326, train_loss: 0.4248156879956906, val_loss: 0.42897852659225466\n",
      "9327, train_loss: 0.42861391546634525, val_loss: 0.43978509306907654\n",
      "9328, train_loss: 0.42442092299461365, val_loss: 0.41303335428237914\n",
      "9329, train_loss: 0.4263862990416013, val_loss: 0.415119880437851\n",
      "9330, train_loss: 0.4247778436312309, val_loss: 0.41676084995269774\n",
      "9331, train_loss: 0.42499142770583814, val_loss: 0.3960365891456604\n",
      "9332, train_loss: 0.42853272878206694, val_loss: 0.44256778359413146\n",
      "9333, train_loss: 0.4276965529872821, val_loss: 0.4222849547863007\n",
      "9334, train_loss: 0.4238085551903798, val_loss: 0.4070309102535248\n",
      "9335, train_loss: 0.42505000417049116, val_loss: 0.4074432492256165\n",
      "9336, train_loss: 0.42380003745739275, val_loss: 0.43946373462677\n",
      "9337, train_loss: 0.4246326547402602, val_loss: 0.44238638281822207\n",
      "9338, train_loss: 0.4237679982414612, val_loss: 0.42969646453857424\n",
      "9339, train_loss: 0.4283976566333037, val_loss: 0.4012476086616516\n",
      "9340, train_loss: 0.42839923329078233, val_loss: 0.4391487419605255\n",
      "9341, train_loss: 0.42306638337098634, val_loss: 0.42137524485588074\n",
      "9342, train_loss: 0.42695270077540326, val_loss: 0.4213062167167664\n",
      "9343, train_loss: 0.4245578360099059, val_loss: 0.41384162902832033\n",
      "9344, train_loss: 0.42539016157388687, val_loss: 0.4059336304664612\n",
      "9345, train_loss: 0.4227722997848804, val_loss: 0.4204335391521454\n",
      "9346, train_loss: 0.42650221861325777, val_loss: 0.4212495148181915\n",
      "9347, train_loss: 0.42461164181049055, val_loss: 0.420911580324173\n",
      "9348, train_loss: 0.42628877094158757, val_loss: 0.4278244376182556\n",
      "9349, train_loss: 0.4282569329325969, val_loss: 0.41631982922554017\n",
      "9350, train_loss: 0.42820290991893184, val_loss: 0.42044315338134763\n",
      "9351, train_loss: 0.42447047050182635, val_loss: 0.4417832314968109\n",
      "9352, train_loss: 0.4281663132401613, val_loss: 0.42648433446884154\n",
      "9353, train_loss: 0.42516343066325557, val_loss: 0.41808091998100283\n",
      "9354, train_loss: 0.4232655528646249, val_loss: 0.43871269226074217\n",
      "9355, train_loss: 0.4232726910939583, val_loss: 0.4058434545993805\n",
      "9356, train_loss: 0.42806995717378765, val_loss: 0.40670751929283144\n",
      "9357, train_loss: 0.42458654596255374, val_loss: 0.42071170210838316\n",
      "9358, train_loss: 0.42414525093940586, val_loss: 0.41305350661277773\n",
      "9359, train_loss: 0.4247638491483835, val_loss: 0.4217358887195587\n",
      "9360, train_loss: 0.4279329799688779, val_loss: 0.4081541061401367\n",
      "9361, train_loss: 0.42589906660410076, val_loss: 0.4080633521080017\n",
      "9362, train_loss: 0.4238891458282104, val_loss: 0.4212211072444916\n",
      "9363, train_loss: 0.42366879949202907, val_loss: 0.4291833102703094\n",
      "9364, train_loss: 0.4278652685192915, val_loss: 0.4014075338840485\n",
      "9365, train_loss: 0.4277897672011302, val_loss: 0.44186717867851255\n",
      "9366, train_loss: 0.42376851118527925, val_loss: 0.3986892461776733\n",
      "9367, train_loss: 0.42554000593148744, val_loss: 0.39992459416389464\n",
      "9368, train_loss: 0.4277535281502284, val_loss: 0.4387695550918579\n",
      "9369, train_loss: 0.4239805547090677, val_loss: 0.42159971594810486\n",
      "9370, train_loss: 0.4229315215578446, val_loss: 0.41000953912734983\n",
      "9371, train_loss: 0.4276508459678063, val_loss: 0.4213192105293274\n",
      "9372, train_loss: 0.4276321604847908, val_loss: 0.416159650683403\n",
      "9373, train_loss: 0.4228699035369433, val_loss: 0.43880657851696014\n",
      "9374, train_loss: 0.4275889453979639, val_loss: 0.4206196069717407\n",
      "9375, train_loss: 0.42754394618364483, val_loss: 0.4032547652721405\n",
      "9376, train_loss: 0.4275292060696162, val_loss: 0.4249578297138214\n",
      "9377, train_loss: 0.4274647659980334, val_loss: 0.4343301296234131\n",
      "9378, train_loss: 0.42449715504279506, val_loss: 0.40762256979942324\n",
      "9379, train_loss: 0.4274399269085664, val_loss: 0.4041920602321625\n",
      "9380, train_loss: 0.4274377782757466, val_loss: 0.43426176309585574\n",
      "9381, train_loss: 0.42219390204319585, val_loss: 0.4203904688358307\n",
      "9382, train_loss: 0.4274286708006492, val_loss: 0.39487353563308714\n",
      "9383, train_loss: 0.4232574953482701, val_loss: 0.43836910724639894\n",
      "9384, train_loss: 0.4256154608268004, val_loss: 0.41734468936920166\n",
      "9385, train_loss: 0.427372823540981, val_loss: 0.42477150559425353\n",
      "9386, train_loss: 0.4240698115183757, val_loss: 0.4082896947860718\n",
      "9387, train_loss: 0.4235272224132831, val_loss: 0.43394973278045657\n",
      "9388, train_loss: 0.4273030436955966, val_loss: 0.4245697557926178\n",
      "9389, train_loss: 0.4244752824306488, val_loss: 0.42625261545181276\n",
      "9390, train_loss: 0.4232846326552905, val_loss: 0.3947819948196411\n",
      "9391, train_loss: 0.4272354766726494, val_loss: 0.4074891865253448\n",
      "9392, train_loss: 0.42110953766566056, val_loss: 0.4200921177864075\n",
      "9393, train_loss: 0.42539193882392, val_loss: 0.42340384125709535\n",
      "9394, train_loss: 0.42405202182439655, val_loss: 0.4056231141090393\n",
      "9395, train_loss: 0.42383775917383343, val_loss: 0.4276839017868042\n",
      "9396, train_loss: 0.42352068768097806, val_loss: 0.4414590120315552\n",
      "9397, train_loss: 0.42322154285816044, val_loss: 0.42075194120407106\n",
      "9398, train_loss: 0.4222473525083982, val_loss: 0.4274056673049927\n",
      "9399, train_loss: 0.42341276372854525, val_loss: 0.40689300298690795\n",
      "9400, train_loss: 0.42308758485775727, val_loss: 0.4410728693008423\n",
      "9401, train_loss: 0.4270250040751237, val_loss: 0.4257470190525055\n",
      "9402, train_loss: 0.4222193933450259, val_loss: 0.4167285621166229\n",
      "9403, train_loss: 0.4235025650033584, val_loss: 0.4269930899143219\n",
      "9404, train_loss: 0.426983498609983, val_loss: 0.4199711263179779\n",
      "9405, train_loss: 0.4215887716183296, val_loss: 0.40162622928619385\n",
      "9406, train_loss: 0.4269242034508632, val_loss: 0.4409002184867859\n",
      "9407, train_loss: 0.4268989637494087, val_loss: 0.4203673839569092\n",
      "9408, train_loss: 0.4268954430635159, val_loss: 0.4031332492828369\n",
      "9409, train_loss: 0.42211771125976855, val_loss: 0.4179163992404938\n",
      "9410, train_loss: 0.4239094125536772, val_loss: 0.42377732396125795\n",
      "9411, train_loss: 0.4223948591030561, val_loss: 0.42551981210708617\n",
      "9412, train_loss: 0.4249951243400574, val_loss: 0.43329299092292783\n",
      "9413, train_loss: 0.42460590027845824, val_loss: 0.42376800775527956\n",
      "9414, train_loss: 0.42677660974172443, val_loss: 0.4408216953277588\n",
      "9415, train_loss: 0.42495496628376156, val_loss: 0.4270127832889557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9416, train_loss: 0.42670338314313155, val_loss: 0.4238878309726715\n",
      "9417, train_loss: 0.42192023534041184, val_loss: 0.4022571682929993\n",
      "9418, train_loss: 0.42664637244664705, val_loss: 0.4238292634487152\n",
      "9419, train_loss: 0.4266389264510228, val_loss: 0.41259989738464353\n",
      "9420, train_loss: 0.4266210381801312, val_loss: 0.42547120451927184\n",
      "9421, train_loss: 0.4227487238553854, val_loss: 0.40080217719078065\n",
      "9422, train_loss: 0.42657982271451217, val_loss: 0.40294389128685\n",
      "9423, train_loss: 0.42655473890212864, val_loss: 0.4199027240276337\n",
      "9424, train_loss: 0.4224614432224861, val_loss: 0.41698487997055056\n",
      "9425, train_loss: 0.423278764463388, val_loss: 0.4197618365287781\n",
      "9426, train_loss: 0.4236111319982089, val_loss: 0.419939911365509\n",
      "9427, train_loss: 0.4265114344083346, val_loss: 0.4059534966945648\n",
      "9428, train_loss: 0.4222931368992879, val_loss: 0.4230912268161774\n",
      "9429, train_loss: 0.42646819811600906, val_loss: 0.40491386950016023\n",
      "9430, train_loss: 0.42281207041098523, val_loss: 0.4057517170906067\n",
      "9431, train_loss: 0.42468132823705673, val_loss: 0.4042843282222748\n",
      "9432, train_loss: 0.42364300271639455, val_loss: 0.42644923329353335\n",
      "9433, train_loss: 0.4263731315732002, val_loss: 0.426250284910202\n",
      "9434, train_loss: 0.42026771146517533, val_loss: 0.4112159192562103\n",
      "9435, train_loss: 0.41914072862038243, val_loss: 0.4057925343513489\n",
      "9436, train_loss: 0.4262968278848208, val_loss: 0.41951875686645507\n",
      "9437, train_loss: 0.42227011919021606, val_loss: 0.4113375425338745\n",
      "9438, train_loss: 0.4211529206771117, val_loss: 0.4063120365142822\n",
      "9439, train_loss: 0.4262404481952007, val_loss: 0.40386775732040403\n",
      "9440, train_loss: 0.41904191214304704, val_loss: 0.41107610464096067\n",
      "9441, train_loss: 0.4213759738665361, val_loss: 0.43994711637496947\n",
      "9442, train_loss: 0.42114907044630784, val_loss: 0.39825124144554136\n",
      "9443, train_loss: 0.42261098153316057, val_loss: 0.3984381675720215\n",
      "9444, train_loss: 0.42406826466321945, val_loss: 0.4163710832595825\n",
      "9445, train_loss: 0.4221394509077072, val_loss: 0.4060930609703064\n",
      "9446, train_loss: 0.42319711641623425, val_loss: 0.408031040430069\n",
      "9447, train_loss: 0.4218129584422478, val_loss: 0.41589565873146056\n",
      "9448, train_loss: 0.42603559906666094, val_loss: 0.4188764810562134\n",
      "9449, train_loss: 0.42200946922485644, val_loss: 0.40505422949790953\n",
      "9450, train_loss: 0.42361017717764926, val_loss: 0.4109593451023102\n",
      "9451, train_loss: 0.4259277301339003, val_loss: 0.43720491528511046\n",
      "9452, train_loss: 0.4230115975324924, val_loss: 0.437178361415863\n",
      "9453, train_loss: 0.4186918471868222, val_loss: 0.40046919584274293\n",
      "9454, train_loss: 0.42588243862757313, val_loss: 0.4260828077793121\n",
      "9455, train_loss: 0.42458969125380885, val_loss: 0.3991408050060272\n",
      "9456, train_loss: 0.4210693979492554, val_loss: 0.41571648716926574\n",
      "9457, train_loss: 0.42114351804439837, val_loss: 0.4184487760066986\n",
      "9458, train_loss: 0.42238198908475727, val_loss: 0.4231750875711441\n",
      "9459, train_loss: 0.4217439368367195, val_loss: 0.397013908624649\n",
      "9460, train_loss: 0.4205447997038181, val_loss: 0.4041735172271729\n",
      "9461, train_loss: 0.4221267791894766, val_loss: 0.4060069859027863\n",
      "9462, train_loss: 0.42189090985518235, val_loss: 0.3977508366107941\n",
      "9463, train_loss: 0.42207808506030303, val_loss: 0.40788434743881224\n",
      "9464, train_loss: 0.42219788695757204, val_loss: 0.425918310880661\n",
      "9465, train_loss: 0.4256680321234923, val_loss: 0.40888205766677854\n",
      "9466, train_loss: 0.42270347246756923, val_loss: 0.42575699687004087\n",
      "9467, train_loss: 0.4204717685396855, val_loss: 0.4132989108562469\n",
      "9468, train_loss: 0.42197279460155046, val_loss: 0.41225467920303344\n",
      "9469, train_loss: 0.4217926814005925, val_loss: 0.4245296001434326\n",
      "9470, train_loss: 0.42268018424510956, val_loss: 0.4186553776264191\n",
      "9471, train_loss: 0.4254793112094586, val_loss: 0.4194690227508545\n",
      "9472, train_loss: 0.42171707863991076, val_loss: 0.4034941077232361\n",
      "9473, train_loss: 0.4226358670454759, val_loss: 0.439829683303833\n",
      "9474, train_loss: 0.42072928754182964, val_loss: 0.41905184686183927\n",
      "9475, train_loss: 0.42541902913497043, val_loss: 0.4087708443403244\n",
      "9476, train_loss: 0.42161624706708467, val_loss: 0.39310079216957095\n",
      "9477, train_loss: 0.4205886320425914, val_loss: 0.391925585269928\n",
      "9478, train_loss: 0.4225036691014583, val_loss: 0.41513343453407286\n",
      "9479, train_loss: 0.4224638921710161, val_loss: 0.4185472786426544\n",
      "9480, train_loss: 0.4253447176172183, val_loss: 0.42394900918006895\n",
      "9481, train_loss: 0.42318248748779297, val_loss: 0.43926310539245605\n",
      "9482, train_loss: 0.42531801760196686, val_loss: 0.4041596710681915\n",
      "9483, train_loss: 0.42153277420080626, val_loss: 0.40687149465084077\n",
      "9484, train_loss: 0.42114561337691087, val_loss: 0.41295143961906433\n",
      "9485, train_loss: 0.42522133313692534, val_loss: 0.40417141914367677\n",
      "9486, train_loss: 0.4233937681867526, val_loss: 0.4267784237861633\n",
      "9487, train_loss: 0.42390383550753963, val_loss: 0.4034338057041168\n",
      "9488, train_loss: 0.4203513723153334, val_loss: 0.4180540680885315\n",
      "9489, train_loss: 0.42150580137968063, val_loss: 0.4005612850189209\n",
      "9490, train_loss: 0.4209107458591461, val_loss: 0.41875186562538147\n",
      "9491, train_loss: 0.42381480966623014, val_loss: 0.4180576503276825\n",
      "9492, train_loss: 0.42326920938033324, val_loss: 0.4004368305206299\n",
      "9493, train_loss: 0.42162131059628266, val_loss: 0.4266792595386505\n",
      "9494, train_loss: 0.42206936386915356, val_loss: 0.39928570985794065\n",
      "9495, train_loss: 0.42199914902448654, val_loss: 0.4189817011356354\n",
      "9496, train_loss: 0.4249608608392569, val_loss: 0.4221349358558655\n",
      "9497, train_loss: 0.4234785735607147, val_loss: 0.4004173815250397\n",
      "9498, train_loss: 0.42488309569083726, val_loss: 0.4047572255134583\n",
      "9499, train_loss: 0.42111600591586185, val_loss: 0.4109297156333923\n",
      "9500, train_loss: 0.42104531824588776, val_loss: 0.4082019805908203\n",
      "9501, train_loss: 0.4235953659965442, val_loss: 0.4179153382778168\n",
      "9502, train_loss: 0.422310002721273, val_loss: 0.4052575290203094\n",
      "9503, train_loss: 0.4193798051430629, val_loss: 0.40517454147338866\n",
      "9504, train_loss: 0.4200103569489259, val_loss: 0.3973951518535614\n",
      "9505, train_loss: 0.41940700377409273, val_loss: 0.42347040176391604\n",
      "9506, train_loss: 0.4211343779013707, val_loss: 0.41114869713783264\n",
      "9507, train_loss: 0.4247020013057269, val_loss: 0.4251928150653839\n",
      "9508, train_loss: 0.4195665797361961, val_loss: 0.4089109838008881\n",
      "9509, train_loss: 0.42099699721886563, val_loss: 0.39907343983650206\n",
      "9510, train_loss: 0.4246080873104242, val_loss: 0.43610742688179016\n",
      "9511, train_loss: 0.41876238641830593, val_loss: 0.3952003538608551\n",
      "9512, train_loss: 0.41740593829980266, val_loss: 0.42491289377212527\n",
      "9513, train_loss: 0.42457775427744937, val_loss: 0.4078047901391983\n",
      "9514, train_loss: 0.42458394972177654, val_loss: 0.42505158185958863\n",
      "9515, train_loss: 0.4227147618165383, val_loss: 0.4387970268726349\n",
      "9516, train_loss: 0.4245134236720892, val_loss: 0.40476712584495544\n",
      "9517, train_loss: 0.4207507452139488, val_loss: 0.41415255069732665\n",
      "9518, train_loss: 0.42011331996092427, val_loss: 0.3961026191711426\n",
      "9519, train_loss: 0.41972416983200955, val_loss: 0.39479570984840395\n",
      "9520, train_loss: 0.4244839566258284, val_loss: 0.40359162390232084\n",
      "9521, train_loss: 0.4244553343607829, val_loss: 0.4309511721134186\n",
      "9522, train_loss: 0.42369280526271236, val_loss: 0.43837600350379946\n",
      "9523, train_loss: 0.4210236439338097, val_loss: 0.4171174943447113\n",
      "9524, train_loss: 0.42437222599983215, val_loss: 0.43551899790763854\n",
      "9525, train_loss: 0.4243697982568007, val_loss: 0.42313542366027834\n",
      "9526, train_loss: 0.4201593055174901, val_loss: 0.4383058488368988\n",
      "9527, train_loss: 0.4191999446887236, val_loss: 0.38962578773498535\n",
      "9528, train_loss: 0.42125625106004566, val_loss: 0.41688149571418764\n",
      "9529, train_loss: 0.42103365980661833, val_loss: 0.43839857578277586\n",
      "9530, train_loss: 0.42423663861476457, val_loss: 0.4355347216129303\n",
      "9531, train_loss: 0.42421924895965135, val_loss: 0.41007678508758544\n",
      "9532, train_loss: 0.424164103773924, val_loss: 0.42032915353775024\n",
      "9533, train_loss: 0.4241538019134448, val_loss: 0.4175619840621948\n",
      "9534, train_loss: 0.4211299866437912, val_loss: 0.4000008463859558\n",
      "9535, train_loss: 0.4240989341185643, val_loss: 0.4095341295003891\n",
      "9536, train_loss: 0.42199230595276904, val_loss: 0.4213587522506714\n",
      "9537, train_loss: 0.4219458309503702, val_loss: 0.41590420007705686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9538, train_loss: 0.42401607506550276, val_loss: 0.4047849714756012\n",
      "9539, train_loss: 0.4240019539227852, val_loss: 0.4098590135574341\n",
      "9540, train_loss: 0.4239666439019717, val_loss: 0.412098354101181\n",
      "9541, train_loss: 0.4210257518749971, val_loss: 0.4124466896057129\n",
      "9542, train_loss: 0.4209580375598027, val_loss: 0.39871516823768616\n",
      "9543, train_loss: 0.41998661080232036, val_loss: 0.43541294932365415\n",
      "9544, train_loss: 0.4191583807651813, val_loss: 0.4229017078876495\n",
      "9545, train_loss: 0.42015179934409946, val_loss: 0.43064951300621035\n",
      "9546, train_loss: 0.42094850884034085, val_loss: 0.42015387415885924\n",
      "9547, train_loss: 0.42381483774918777, val_loss: 0.4062208294868469\n",
      "9548, train_loss: 0.4190468409886727, val_loss: 0.40356179475784304\n",
      "9549, train_loss: 0.4237873267668944, val_loss: 0.42560170888900756\n",
      "9550, train_loss: 0.4237909706739279, val_loss: 0.40207119584083556\n",
      "9551, train_loss: 0.4196013475839908, val_loss: 0.4306182265281677\n",
      "9552, train_loss: 0.4211857198522641, val_loss: 0.39683628976345064\n",
      "9553, train_loss: 0.4237290999064079, val_loss: 0.40384451150894163\n",
      "9554, train_loss: 0.4198896541045262, val_loss: 0.4255592405796051\n",
      "9555, train_loss: 0.423601902448214, val_loss: 0.42430267333984373\n",
      "9556, train_loss: 0.42025157923881823, val_loss: 0.403727263212204\n",
      "9557, train_loss: 0.4184438173587506, val_loss: 0.4062368035316467\n",
      "9558, train_loss: 0.421346678183629, val_loss: 0.39899235367774966\n",
      "9559, train_loss: 0.42060914922219056, val_loss: 0.43807253837585447\n",
      "9560, train_loss: 0.41872067749500275, val_loss: 0.4006728231906891\n",
      "9561, train_loss: 0.4187397274833459, val_loss: 0.3970028877258301\n",
      "9562, train_loss: 0.4191656903578685, val_loss: 0.42039782702922823\n",
      "9563, train_loss: 0.4207820651622919, val_loss: 0.3957260578870773\n",
      "9564, train_loss: 0.42064699415977186, val_loss: 0.4176999509334564\n",
      "9565, train_loss: 0.4199001290477239, val_loss: 0.42036905884742737\n",
      "9566, train_loss: 0.4234873939018983, val_loss: 0.4148212194442749\n",
      "9567, train_loss: 0.41758666703334224, val_loss: 0.4067570447921753\n",
      "9568, train_loss: 0.42131580584324324, val_loss: 0.41497036814689636\n",
      "9569, train_loss: 0.4233588988964374, val_loss: 0.43464871048927306\n",
      "9570, train_loss: 0.419203146145894, val_loss: 0.4046261250972748\n",
      "9571, train_loss: 0.4185214237524913, val_loss: 0.39867945909500124\n",
      "9572, train_loss: 0.4233631675059979, val_loss: 0.4192326307296753\n",
      "9573, train_loss: 0.42104056706795323, val_loss: 0.43731107115745543\n",
      "9574, train_loss: 0.4203632175922394, val_loss: 0.41090521216392517\n",
      "9575, train_loss: 0.4232094883918762, val_loss: 0.4193438708782196\n",
      "9576, train_loss: 0.42179074883461, val_loss: 0.434684681892395\n",
      "9577, train_loss: 0.4202653685441384, val_loss: 0.4080094635486603\n",
      "9578, train_loss: 0.4184077880703486, val_loss: 0.41610499620437624\n",
      "9579, train_loss: 0.41916611045598984, val_loss: 0.4083957076072693\n",
      "9580, train_loss: 0.41841376974032474, val_loss: 0.43732803463935854\n",
      "9581, train_loss: 0.4202341219553581, val_loss: 0.43740729689598085\n",
      "9582, train_loss: 0.42088881593484145, val_loss: 0.4041337013244629\n",
      "9583, train_loss: 0.4230408032353108, val_loss: 0.4207035660743713\n",
      "9584, train_loss: 0.4192536765566239, val_loss: 0.4237734735012054\n",
      "9585, train_loss: 0.4229892801779967, val_loss: 0.42359194755554197\n",
      "9586, train_loss: 0.41758992637579256, val_loss: 0.40675497353076934\n",
      "9587, train_loss: 0.42290994181082797, val_loss: 0.42366568446159364\n",
      "9588, train_loss: 0.41891816086494005, val_loss: 0.41698511838912966\n",
      "9589, train_loss: 0.4192530323679631, val_loss: 0.43718949556350706\n",
      "9590, train_loss: 0.4163056170711151, val_loss: 0.42969557642936707\n",
      "9591, train_loss: 0.4200003892183304, val_loss: 0.39564230144023893\n",
      "9592, train_loss: 0.4228747160388873, val_loss: 0.42955238819122316\n",
      "9593, train_loss: 0.4228664619418291, val_loss: 0.42958990335464475\n",
      "9594, train_loss: 0.42286543662731463, val_loss: 0.4137716293334961\n",
      "9595, train_loss: 0.4228348411046542, val_loss: 0.3897120416164398\n",
      "9596, train_loss: 0.42285484763292164, val_loss: 0.41872183084487913\n",
      "9597, train_loss: 0.41761753880060637, val_loss: 0.40041608810424806\n",
      "9598, train_loss: 0.41908357177789396, val_loss: 0.3971559703350067\n",
      "9599, train_loss: 0.4187811217628993, val_loss: 0.43661715984344485\n",
      "9600, train_loss: 0.4215233320227036, val_loss: 0.40024333596229555\n",
      "9601, train_loss: 0.4181232418005283, val_loss: 0.3992072522640228\n",
      "9602, train_loss: 0.41715477808163715, val_loss: 0.4019756615161896\n",
      "9603, train_loss: 0.41898842041309065, val_loss: 0.41118874549865725\n",
      "9604, train_loss: 0.4192563352676538, val_loss: 0.4015715539455414\n",
      "9605, train_loss: 0.4197413159104494, val_loss: 0.41543936133384707\n",
      "9606, train_loss: 0.42259472379317653, val_loss: 0.393869012594223\n",
      "9607, train_loss: 0.42252629651473117, val_loss: 0.4158337116241455\n",
      "9608, train_loss: 0.41528873489453244, val_loss: 0.41609553098678587\n",
      "9609, train_loss: 0.42181015702394337, val_loss: 0.39726880192756653\n",
      "9610, train_loss: 0.4194798584167774, val_loss: 0.4105581820011139\n",
      "9611, train_loss: 0.4210658749708763, val_loss: 0.3953488826751709\n",
      "9612, train_loss: 0.4203510828889333, val_loss: 0.4156411111354828\n",
      "9613, train_loss: 0.4187260006482785, val_loss: 0.41397190690040586\n",
      "9614, train_loss: 0.4186048312829091, val_loss: 0.4186853110790253\n",
      "9615, train_loss: 0.416271050962118, val_loss: 0.4017779529094696\n",
      "9616, train_loss: 0.4223530819782844, val_loss: 0.39712568521499636\n",
      "9617, train_loss: 0.4188656910107686, val_loss: 0.4026357471942902\n",
      "9618, train_loss: 0.42232599969093615, val_loss: 0.39348111748695375\n",
      "9619, train_loss: 0.415050955919119, val_loss: 0.4058638334274292\n",
      "9620, train_loss: 0.4174623191356659, val_loss: 0.39780521392822266\n",
      "9621, train_loss: 0.41754819796635556, val_loss: 0.4047700047492981\n",
      "9622, train_loss: 0.41899884893343997, val_loss: 0.41544349789619445\n",
      "9623, train_loss: 0.41666822593945724, val_loss: 0.41515021920204165\n",
      "9624, train_loss: 0.41822885091488177, val_loss: 0.4196619153022766\n",
      "9625, train_loss: 0.42221131978126675, val_loss: 0.4287282705307007\n",
      "9626, train_loss: 0.4187272981955455, val_loss: 0.43607298135757444\n",
      "9627, train_loss: 0.4221600592136383, val_loss: 0.3873607099056244\n",
      "9628, train_loss: 0.4197747799066397, val_loss: 0.4191096603870392\n",
      "9629, train_loss: 0.42215650987166625, val_loss: 0.4194549024105072\n",
      "9630, train_loss: 0.4170017196581914, val_loss: 0.4054358541965485\n",
      "9631, train_loss: 0.4220830098940776, val_loss: 0.39989803433418275\n",
      "9632, train_loss: 0.417316476886089, val_loss: 0.40105816125869753\n",
      "9633, train_loss: 0.4182029549892132, val_loss: 0.4154827415943146\n",
      "9634, train_loss: 0.4186882651769198, val_loss: 0.40858736336231233\n",
      "9635, train_loss: 0.4179485675234061, val_loss: 0.3946210205554962\n",
      "9636, train_loss: 0.4182146374995892, val_loss: 0.4227229058742523\n",
      "9637, train_loss: 0.4177845355409842, val_loss: 0.41603285670280454\n",
      "9638, train_loss: 0.42183797462628436, val_loss: 0.41527330279350283\n",
      "9639, train_loss: 0.41877087549521375, val_loss: 0.38986106514930724\n",
      "9640, train_loss: 0.4218267901585652, val_loss: 0.4208016604185104\n",
      "9641, train_loss: 0.418426629442435, val_loss: 0.4361268997192383\n",
      "9642, train_loss: 0.4172023099202376, val_loss: 0.39767459630966184\n",
      "9643, train_loss: 0.41761461129555333, val_loss: 0.41550828218460084\n",
      "9644, train_loss: 0.4172191803271954, val_loss: 0.3961553514003754\n",
      "9645, train_loss: 0.4180978066646136, val_loss: 0.3996858596801758\n",
      "9646, train_loss: 0.41880952280301315, val_loss: 0.41482287645339966\n",
      "9647, train_loss: 0.4216918475352801, val_loss: 0.3982722222805023\n",
      "9648, train_loss: 0.41777383192227435, val_loss: 0.4037171840667725\n",
      "9649, train_loss: 0.4169705412708796, val_loss: 0.43542397022247314\n",
      "9650, train_loss: 0.41770265194085926, val_loss: 0.42157973945140836\n",
      "9651, train_loss: 0.4187561944127083, val_loss: 0.40137423276901246\n",
      "9652, train_loss: 0.4194693101140169, val_loss: 0.41457001566886903\n",
      "9653, train_loss: 0.41801133579932725, val_loss: 0.3991109848022461\n",
      "9654, train_loss: 0.4177270778096639, val_loss: 0.42031370997428896\n",
      "9655, train_loss: 0.4201207894545335, val_loss: 0.40950278639793397\n",
      "9656, train_loss: 0.42155904265550465, val_loss: 0.4354083716869354\n",
      "9657, train_loss: 0.42156942131427616, val_loss: 0.4216671407222748\n",
      "9658, train_loss: 0.42027672552145445, val_loss: 0.4150894820690155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9659, train_loss: 0.41805923214325535, val_loss: 0.41276814937591555\n",
      "9660, train_loss: 0.41749381445921385, val_loss: 0.3961048603057861\n",
      "9661, train_loss: 0.4173214945655603, val_loss: 0.41530507802963257\n",
      "9662, train_loss: 0.416671661230234, val_loss: 0.4183735430240631\n",
      "9663, train_loss: 0.419223207120712, val_loss: 0.42020665407180785\n",
      "9664, train_loss: 0.41844628006219864, val_loss: 0.4151999056339264\n",
      "9665, train_loss: 0.42132206433094466, val_loss: 0.4189599335193634\n",
      "9666, train_loss: 0.41850519294922167, val_loss: 0.4144638180732727\n",
      "9667, train_loss: 0.41787666655503786, val_loss: 0.4101219713687897\n",
      "9668, train_loss: 0.4175957968601814, val_loss: 0.4216961026191711\n",
      "9669, train_loss: 0.41765973888910735, val_loss: 0.3941351920366287\n",
      "9670, train_loss: 0.41777320550038266, val_loss: 0.414204353094101\n",
      "9671, train_loss: 0.41598803435380644, val_loss: 0.42119215726852416\n",
      "9672, train_loss: 0.42117461676780993, val_loss: 0.40895277857780454\n",
      "9673, train_loss: 0.4212177023291588, val_loss: 0.41361030340194704\n",
      "9674, train_loss: 0.41727834710708034, val_loss: 0.4060067296028137\n",
      "9675, train_loss: 0.41645335176816356, val_loss: 0.41448071599006653\n",
      "9676, train_loss: 0.41559205662745696, val_loss: 0.4346702635288239\n",
      "9677, train_loss: 0.41910766580930126, val_loss: 0.40075014233589173\n",
      "9678, train_loss: 0.41636956425813526, val_loss: 0.4273666262626648\n",
      "9679, train_loss: 0.41905632328528625, val_loss: 0.41675970554351804\n",
      "9680, train_loss: 0.41623076166097933, val_loss: 0.39851226806640627\n",
      "9681, train_loss: 0.42104277931726897, val_loss: 0.41437867283821106\n",
      "9682, train_loss: 0.4210191397712781, val_loss: 0.3962467133998871\n",
      "9683, train_loss: 0.42096261565501875, val_loss: 0.4136355698108673\n",
      "9684, train_loss: 0.41709914001134724, val_loss: 0.43445658683776855\n",
      "9685, train_loss: 0.4172630545038443, val_loss: 0.3909775257110596\n",
      "9686, train_loss: 0.42093668706141985, val_loss: 0.4221289575099945\n",
      "9687, train_loss: 0.42089122304549587, val_loss: 0.41192554235458373\n",
      "9688, train_loss: 0.4181339150437942, val_loss: 0.4273987293243408\n",
      "9689, train_loss: 0.41738964789188826, val_loss: 0.40629584789276124\n",
      "9690, train_loss: 0.4184560294334705, val_loss: 0.41854541301727294\n",
      "9691, train_loss: 0.4164236869949561, val_loss: 0.4136336326599121\n",
      "9692, train_loss: 0.4178509901349361, val_loss: 0.40030786395072937\n",
      "9693, train_loss: 0.42075879585284454, val_loss: 0.4151275873184204\n",
      "9694, train_loss: 0.4169914349913597, val_loss: 0.4185153663158417\n",
      "9695, train_loss: 0.41689641716388554, val_loss: 0.4071753263473511\n",
      "9696, train_loss: 0.42067211064008564, val_loss: 0.4074308633804321\n",
      "9697, train_loss: 0.42060811244524443, val_loss: 0.4196342885494232\n",
      "9698, train_loss: 0.420582115650177, val_loss: 0.4209043025970459\n",
      "9699, train_loss: 0.41854100273205685, val_loss: 0.39845033288002013\n",
      "9700, train_loss: 0.42051848941124403, val_loss: 0.4348893165588379\n",
      "9701, train_loss: 0.4204806822996873, val_loss: 0.4086950421333313\n",
      "9702, train_loss: 0.4204529833335143, val_loss: 0.39851534366607666\n",
      "9703, train_loss: 0.41867375603088963, val_loss: 0.4034684360027313\n",
      "9704, train_loss: 0.4162818886912786, val_loss: 0.39968621134758\n",
      "9705, train_loss: 0.4175504319942914, val_loss: 0.4140663921833038\n",
      "9706, train_loss: 0.41823533406624425, val_loss: 0.4225414276123047\n",
      "9707, train_loss: 0.41654260800434995, val_loss: 0.4185719132423401\n",
      "9708, train_loss: 0.42027858931284684, val_loss: 0.42768189311027527\n",
      "9709, train_loss: 0.41724713146686554, val_loss: 0.3997128337621689\n",
      "9710, train_loss: 0.42019470838400036, val_loss: 0.39984036087989805\n",
      "9711, train_loss: 0.4201664076401637, val_loss: 0.41718813180923464\n",
      "9712, train_loss: 0.4201226257360898, val_loss: 0.4059943795204163\n",
      "9713, train_loss: 0.420092903650724, val_loss: 0.39443868696689605\n",
      "9714, train_loss: 0.41802046390680164, val_loss: 0.4211741089820862\n",
      "9715, train_loss: 0.41528941175112355, val_loss: 0.4124137580394745\n",
      "9716, train_loss: 0.4161215596474134, val_loss: 0.398750838637352\n",
      "9717, train_loss: 0.420062508720618, val_loss: 0.3985266208648682\n",
      "9718, train_loss: 0.4187784796723953, val_loss: 0.4351845979690552\n",
      "9719, train_loss: 0.4199682565835806, val_loss: 0.3864763557910919\n",
      "9720, train_loss: 0.4165542595661603, val_loss: 0.3883191764354706\n",
      "9721, train_loss: 0.4199404613329814, val_loss: 0.39987783432006835\n",
      "9722, train_loss: 0.41609786221614253, val_loss: 0.39262295961380006\n",
      "9723, train_loss: 0.41994335559698254, val_loss: 0.42232064008712766\n",
      "9724, train_loss: 0.41620783049326676, val_loss: 0.3919990062713623\n",
      "9725, train_loss: 0.4198784203483508, val_loss: 0.4320497214794159\n",
      "9726, train_loss: 0.4152091546700551, val_loss: 0.40039144158363343\n",
      "9727, train_loss: 0.41989425455148405, val_loss: 0.41188215613365176\n",
      "9728, train_loss: 0.41530315577983856, val_loss: 0.3966295480728149\n",
      "9729, train_loss: 0.4144970212991421, val_loss: 0.41631410717964173\n",
      "9730, train_loss: 0.4169292782361691, val_loss: 0.4207131862640381\n",
      "9731, train_loss: 0.4161929006759937, val_loss: 0.39780081510543824\n",
      "9732, train_loss: 0.4161271361204294, val_loss: 0.41108996868133546\n",
      "9733, train_loss: 0.41567572148946613, val_loss: 0.4180186569690704\n",
      "9734, train_loss: 0.41584856922809893, val_loss: 0.4270287036895752\n",
      "9735, train_loss: 0.4197314645235355, val_loss: 0.3927509695291519\n",
      "9736, train_loss: 0.4155784547328949, val_loss: 0.42093265652656553\n",
      "9737, train_loss: 0.4196242970915941, val_loss: 0.39158005118370054\n",
      "9738, train_loss: 0.4159380484085817, val_loss: 0.43422582745552063\n",
      "9739, train_loss: 0.41961066826031757, val_loss: 0.4141055643558502\n",
      "9740, train_loss: 0.4162135960964056, val_loss: 0.4202884674072266\n",
      "9741, train_loss: 0.41487474739551544, val_loss: 0.40815425515174864\n",
      "9742, train_loss: 0.4196278957220224, val_loss: 0.4063841879367828\n",
      "9743, train_loss: 0.41615650860162884, val_loss: 0.41718140840530393\n",
      "9744, train_loss: 0.4195502933401328, val_loss: 0.4340608179569244\n",
      "9745, train_loss: 0.4181621458667975, val_loss: 0.40647820830345155\n",
      "9746, train_loss: 0.41539937487015355, val_loss: 0.40869841575622556\n",
      "9747, train_loss: 0.4180357370239038, val_loss: 0.42025388181209566\n",
      "9748, train_loss: 0.41425607066888076, val_loss: 0.39452236890792847\n",
      "9749, train_loss: 0.41528600798203397, val_loss: 0.41135978102684023\n",
      "9750, train_loss: 0.4146319329738617, val_loss: 0.41599984765052794\n",
      "9751, train_loss: 0.41813497417248213, val_loss: 0.4267687678337097\n",
      "9752, train_loss: 0.41579292485347163, val_loss: 0.3929606735706329\n",
      "9753, train_loss: 0.41584520844312817, val_loss: 0.39550468921661375\n",
      "9754, train_loss: 0.41523080605726975, val_loss: 0.4156959056854248\n",
      "9755, train_loss: 0.4160642474889755, val_loss: 0.4338063716888428\n",
      "9756, train_loss: 0.41371757422502226, val_loss: 0.40023728609085085\n",
      "9757, train_loss: 0.41632576516041386, val_loss: 0.3946771383285522\n",
      "9758, train_loss: 0.4162054629280017, val_loss: 0.4110711872577667\n",
      "9759, train_loss: 0.41506355141217893, val_loss: 0.4161245286464691\n",
      "9760, train_loss: 0.4191158769222406, val_loss: 0.3958557665348053\n",
      "9761, train_loss: 0.41617406331575835, val_loss: 0.39742150604724885\n",
      "9762, train_loss: 0.4156160303033315, val_loss: 0.3980454981327057\n",
      "9763, train_loss: 0.41557319233050716, val_loss: 0.4000146448612213\n",
      "9764, train_loss: 0.4190818306345206, val_loss: 0.39790230989456177\n",
      "9765, train_loss: 0.41832927671762615, val_loss: 0.4005951702594757\n",
      "9766, train_loss: 0.4162187645068535, val_loss: 0.4158185601234436\n",
      "9767, train_loss: 0.4167084527703432, val_loss: 0.39569090604782103\n",
      "9768, train_loss: 0.41772080384767973, val_loss: 0.3947219967842102\n",
      "9769, train_loss: 0.4189152087156589, val_loss: 0.3879977285861969\n",
      "9770, train_loss: 0.41892385253539455, val_loss: 0.41090852916240694\n",
      "9771, train_loss: 0.41696533216879916, val_loss: 0.4142856955528259\n",
      "9772, train_loss: 0.4141982146180593, val_loss: 0.41286333799362185\n",
      "9773, train_loss: 0.4161139875650406, val_loss: 0.41674113273620605\n",
      "9774, train_loss: 0.41563042539816636, val_loss: 0.42626382112503053\n",
      "9775, train_loss: 0.41881326815256703, val_loss: 0.39589195847511294\n",
      "9776, train_loss: 0.41656953211014086, val_loss: 0.4334469199180603\n",
      "9777, train_loss: 0.41512994124339175, val_loss: 0.3967171490192413\n",
      "9778, train_loss: 0.4150268859588183, val_loss: 0.39982463121414186\n",
      "9779, train_loss: 0.41403702130684483, val_loss: 0.42082053422927856\n",
      "9780, train_loss: 0.4187561124563217, val_loss: 0.41815018057823183\n",
      "9781, train_loss: 0.4187303282893621, val_loss: 0.41989112496376035\n",
      "9782, train_loss: 0.41583117498801303, val_loss: 0.4105654895305634\n",
      "9783, train_loss: 0.41662273842554826, val_loss: 0.39191881418228147\n",
      "9784, train_loss: 0.4153923403758269, val_loss: 0.41232694387435914\n",
      "9785, train_loss: 0.4146841632632109, val_loss: 0.40600271224975587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9786, train_loss: 0.4162090844832934, val_loss: 0.39720349907875063\n",
      "9787, train_loss: 0.41851449471253616, val_loss: 0.40327935218811034\n",
      "9788, train_loss: 0.41508765117480206, val_loss: 0.4135324597358704\n",
      "9789, train_loss: 0.4145811286110144, val_loss: 0.41648560762405396\n",
      "9790, train_loss: 0.4185020396342644, val_loss: 0.41251835227012634\n",
      "9791, train_loss: 0.4146927171028577, val_loss: 0.4072795808315277\n",
      "9792, train_loss: 0.41419890981454116, val_loss: 0.4129007697105408\n",
      "9793, train_loss: 0.4184993660220733, val_loss: 0.41173062920570375\n",
      "9794, train_loss: 0.414939335332467, val_loss: 0.4104363977909088\n",
      "9795, train_loss: 0.41495328969680345, val_loss: 0.4189138948917389\n",
      "9796, train_loss: 0.41843662468286663, val_loss: 0.411615127325058\n",
      "9797, train_loss: 0.4137138712864656, val_loss: 0.39884900450706484\n",
      "9798, train_loss: 0.412837137396519, val_loss: 0.41744624376296996\n",
      "9799, train_loss: 0.41547751082823825, val_loss: 0.4162036538124084\n",
      "9800, train_loss: 0.4183600281293576, val_loss: 0.40467546582221986\n",
      "9801, train_loss: 0.41545556829525876, val_loss: 0.4085810363292694\n",
      "9802, train_loss: 0.4127587739091653, val_loss: 0.3995135068893433\n",
      "9803, train_loss: 0.41626390700156873, val_loss: 0.3994997262954712\n",
      "9804, train_loss: 0.41823095312485326, val_loss: 0.4175464570522308\n",
      "9805, train_loss: 0.4152187452866481, val_loss: 0.4037521153688431\n",
      "9806, train_loss: 0.4182431881244366, val_loss: 0.41197779178619387\n",
      "9807, train_loss: 0.415272057056427, val_loss: 0.39808682203292844\n",
      "9808, train_loss: 0.4181230263068126, val_loss: 0.4111146926879883\n",
      "9809, train_loss: 0.4157333431335596, val_loss: 0.40394845604896545\n",
      "9810, train_loss: 0.4173612646185435, val_loss: 0.4328043043613434\n",
      "9811, train_loss: 0.4151846422598912, val_loss: 0.4204147636890411\n",
      "9812, train_loss: 0.4114237152613126, val_loss: 0.39809650182724\n",
      "9813, train_loss: 0.4180226337451201, val_loss: 0.41192014813423156\n",
      "9814, train_loss: 0.4180065072499789, val_loss: 0.4186179757118225\n",
      "9815, train_loss: 0.4179797900410799, val_loss: 0.3886286973953247\n",
      "9816, train_loss: 0.4138809505563516, val_loss: 0.4185415804386139\n",
      "9817, train_loss: 0.4120952790746322, val_loss: 0.39314604103565215\n",
      "9818, train_loss: 0.41794190956996036, val_loss: 0.3977559208869934\n",
      "9819, train_loss: 0.4179292624959579, val_loss: 0.4296795606613159\n",
      "9820, train_loss: 0.41618159069464755, val_loss: 0.4047956943511963\n",
      "9821, train_loss: 0.41785756613199526, val_loss: 0.4112252354621887\n",
      "9822, train_loss: 0.4178461856566943, val_loss: 0.39280444383621216\n",
      "9823, train_loss: 0.41374149517371106, val_loss: 0.4113551139831543\n",
      "9824, train_loss: 0.41781761669195616, val_loss: 0.39126735329627993\n",
      "9825, train_loss: 0.41301074566749424, val_loss: 0.4113669157028198\n",
      "9826, train_loss: 0.41408242743748885, val_loss: 0.4296466827392578\n",
      "9827, train_loss: 0.4122192148978894, val_loss: 0.39751957058906556\n",
      "9828, train_loss: 0.41391897201538086, val_loss: 0.4294536173343658\n",
      "9829, train_loss: 0.41772041068627286, val_loss: 0.4067491412162781\n",
      "9830, train_loss: 0.4176998906410657, val_loss: 0.4109880208969116\n",
      "9831, train_loss: 0.41286090933359587, val_loss: 0.4320278584957123\n",
      "9832, train_loss: 0.41526767955376553, val_loss: 0.41050235331058504\n",
      "9833, train_loss: 0.41759423739635027, val_loss: 0.41695731282234194\n",
      "9834, train_loss: 0.4128819274214598, val_loss: 0.39046614766120913\n",
      "9835, train_loss: 0.41349838215571183, val_loss: 0.39417827129364014\n",
      "9836, train_loss: 0.4163639293267177, val_loss: 0.39709588289260866\n",
      "9837, train_loss: 0.4145025616654983, val_loss: 0.4032427668571472\n",
      "9838, train_loss: 0.41746870944133174, val_loss: 0.3929914772510529\n",
      "9839, train_loss: 0.41746154714089173, val_loss: 0.43208265900611875\n",
      "9840, train_loss: 0.4138816079268089, val_loss: 0.3860855340957642\n",
      "9841, train_loss: 0.4174577502103952, val_loss: 0.4110461413860321\n",
      "9842, train_loss: 0.41265376485311067, val_loss: 0.4155112862586975\n",
      "9843, train_loss: 0.4174217742223006, val_loss: 0.38565788269042967\n",
      "9844, train_loss: 0.4146866219548079, val_loss: 0.40886904001235963\n",
      "9845, train_loss: 0.4126033823077495, val_loss: 0.3847058773040771\n",
      "9846, train_loss: 0.41271713834542495, val_loss: 0.3978083848953247\n",
      "9847, train_loss: 0.4156826585531235, val_loss: 0.3955602526664734\n",
      "9848, train_loss: 0.4173715297992413, val_loss: 0.4311740756034851\n",
      "9849, train_loss: 0.41376802726433826, val_loss: 0.39723212718963624\n",
      "9850, train_loss: 0.4125337302684784, val_loss: 0.4186930239200592\n",
      "9851, train_loss: 0.41378911298054916, val_loss: 0.410141384601593\n",
      "9852, train_loss: 0.41731466123690975, val_loss: 0.4129753947257996\n",
      "9853, train_loss: 0.4148404919184171, val_loss: 0.4059609591960907\n",
      "9854, train_loss: 0.4121436052597486, val_loss: 0.4284814417362213\n",
      "9855, train_loss: 0.41723171506936735, val_loss: 0.3912353336811066\n",
      "9856, train_loss: 0.4129323850457485, val_loss: 0.4003201127052307\n",
      "9857, train_loss: 0.4172414197371556, val_loss: 0.4115667283535004\n",
      "9858, train_loss: 0.4171965248309649, val_loss: 0.41062926054000853\n",
      "9859, train_loss: 0.4128548525846921, val_loss: 0.4306642830371857\n",
      "9860, train_loss: 0.4171877119403619, val_loss: 0.41839814782142637\n",
      "9861, train_loss: 0.4171346706839708, val_loss: 0.41045363545417785\n",
      "9862, train_loss: 0.4119331745000986, val_loss: 0.3876388430595398\n",
      "9863, train_loss: 0.41713417493380034, val_loss: 0.40954039692878724\n",
      "9864, train_loss: 0.412414292876537, val_loss: 0.43015819787979126\n",
      "9865, train_loss: 0.4142449486714143, val_loss: 0.41473905444145204\n",
      "9866, train_loss: 0.41707319479722244, val_loss: 0.41547096967697145\n",
      "9867, train_loss: 0.41358119822465456, val_loss: 0.40247890949249265\n",
      "9868, train_loss: 0.4170366284938959, val_loss: 0.41683938503265383\n",
      "9869, train_loss: 0.41382076419316804, val_loss: 0.4181916415691376\n",
      "9870, train_loss: 0.4140760783965771, val_loss: 0.40544735789299013\n",
      "9871, train_loss: 0.412592283808268, val_loss: 0.3948490858078003\n",
      "9872, train_loss: 0.4140446472626466, val_loss: 0.4183180212974548\n",
      "9873, train_loss: 0.41323824857289976, val_loss: 0.3890006959438324\n",
      "9874, train_loss: 0.41171976121572346, val_loss: 0.4171741962432861\n",
      "9875, train_loss: 0.41683705380329716, val_loss: 0.41547887325286864\n",
      "9876, train_loss: 0.4151321890262457, val_loss: 0.4136081039905548\n",
      "9877, train_loss: 0.41544143855571747, val_loss: 0.39251876473426817\n",
      "9878, train_loss: 0.41402838837641937, val_loss: 0.41563465595245364\n",
      "9879, train_loss: 0.4126277451331799, val_loss: 0.4305640697479248\n",
      "9880, train_loss: 0.41290653439668507, val_loss: 0.40224520564079286\n",
      "9881, train_loss: 0.4166728968803699, val_loss: 0.409311318397522\n",
      "9882, train_loss: 0.41490695109734166, val_loss: 0.4078173041343689\n",
      "9883, train_loss: 0.4125048288932213, val_loss: 0.3909539312124252\n",
      "9884, train_loss: 0.414106747851922, val_loss: 0.43059670329093935\n",
      "9885, train_loss: 0.41310113496505296, val_loss: 0.4155908226966858\n",
      "9886, train_loss: 0.4091898575425148, val_loss: 0.40968325138092043\n",
      "9887, train_loss: 0.41129789100243497, val_loss: 0.4134090006351471\n",
      "9888, train_loss: 0.4138127714395523, val_loss: 0.4021757125854492\n",
      "9889, train_loss: 0.4103807176534946, val_loss: 0.4180233597755432\n",
      "9890, train_loss: 0.4147775396704674, val_loss: 0.39416831731796265\n",
      "9891, train_loss: 0.4164586061468491, val_loss: 0.38757861852645875\n",
      "9892, train_loss: 0.41398006734939724, val_loss: 0.38643845319747927\n",
      "9893, train_loss: 0.41439354763581204, val_loss: 0.3946014761924744\n",
      "9894, train_loss: 0.41524071991443634, val_loss: 0.38839149475097656\n",
      "9895, train_loss: 0.4127584798977925, val_loss: 0.42318189740180967\n",
      "9896, train_loss: 0.4124259432921043, val_loss: 0.3919721841812134\n",
      "9897, train_loss: 0.41279192670033527, val_loss: 0.4133310914039612\n",
      "9898, train_loss: 0.4162792769762186, val_loss: 0.3925230443477631\n",
      "9899, train_loss: 0.41415496972891, val_loss: 0.4087325930595398\n",
      "9900, train_loss: 0.41626552377755827, val_loss: 0.410809063911438\n",
      "9901, train_loss: 0.412165876191396, val_loss: 0.4161645948886871\n",
      "9902, train_loss: 0.41061371450240797, val_loss: 0.38835241198539733\n",
      "9903, train_loss: 0.4127778880871259, val_loss: 0.4163027763366699\n",
      "9904, train_loss: 0.41450532239217025, val_loss: 0.406099796295166\n",
      "9905, train_loss: 0.4139339551329613, val_loss: 0.4099127173423767\n",
      "9906, train_loss: 0.41093495373542493, val_loss: 0.41486313939094543\n",
      "9907, train_loss: 0.4161420338428937, val_loss: 0.3950773417949677\n",
      "9908, train_loss: 0.4147281073606931, val_loss: 0.4084327518939972\n",
      "9909, train_loss: 0.41435732405919296, val_loss: 0.3964040160179138\n",
      "9910, train_loss: 0.4160260128287169, val_loss: 0.40986207127571106\n",
      "9911, train_loss: 0.41603345653185475, val_loss: 0.3975765585899353\n",
      "9912, train_loss: 0.4160182378613032, val_loss: 0.4106404006481171\n",
      "9913, train_loss: 0.41598793176504284, val_loss: 0.40697680711746215\n",
      "9914, train_loss: 0.41594826028897214, val_loss: 0.3955954432487488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9915, train_loss: 0.4107331931591034, val_loss: 0.3928119122982025\n",
      "9916, train_loss: 0.4123136974298037, val_loss: 0.3904542922973633\n",
      "9917, train_loss: 0.4158860141268143, val_loss: 0.3982112020254135\n",
      "9918, train_loss: 0.4121719610232573, val_loss: 0.4011370360851288\n",
      "9919, train_loss: 0.4136640509733787, val_loss: 0.4025693893432617\n",
      "9920, train_loss: 0.4118945552752568, val_loss: 0.40975362062454224\n",
      "9921, train_loss: 0.4157940229544273, val_loss: 0.3946944892406464\n",
      "9922, train_loss: 0.41577546527752507, val_loss: 0.40264729261398313\n",
      "9923, train_loss: 0.41575488505455166, val_loss: 0.41174728870391847\n",
      "9924, train_loss: 0.4120400072290347, val_loss: 0.396809446811676\n",
      "9925, train_loss: 0.41572383504647475, val_loss: 0.40975645184516907\n",
      "9926, train_loss: 0.4126346609913386, val_loss: 0.40975395441055296\n",
      "9927, train_loss: 0.41567088892826665, val_loss: 0.41636934876441956\n",
      "9928, train_loss: 0.4111183898953291, val_loss: 0.41270496547222135\n",
      "9929, train_loss: 0.4156688285561708, val_loss: 0.4223788321018219\n",
      "9930, train_loss: 0.4109291835473134, val_loss: 0.3929552912712097\n",
      "9931, train_loss: 0.4155704046671207, val_loss: 0.41463316679000856\n",
      "9932, train_loss: 0.415531592300305, val_loss: 0.41458669900894163\n",
      "9933, train_loss: 0.4155440255999565, val_loss: 0.402265790104866\n",
      "9934, train_loss: 0.41547569517905897, val_loss: 0.4036697089672089\n",
      "9935, train_loss: 0.41075757145881653, val_loss: 0.3959267854690552\n",
      "9936, train_loss: 0.41381116899160236, val_loss: 0.38860827684402466\n",
      "9937, train_loss: 0.41162640945269513, val_loss: 0.42235016226768496\n",
      "9938, train_loss: 0.41539597855164456, val_loss: 0.3946144163608551\n",
      "9939, train_loss: 0.4153652454798038, val_loss: 0.42943443059921266\n",
      "9940, train_loss: 0.4153399925965529, val_loss: 0.4071558117866516\n",
      "9941, train_loss: 0.4114497900009155, val_loss: 0.4170700252056122\n",
      "9942, train_loss: 0.41144095017359805, val_loss: 0.3885574758052826\n",
      "9943, train_loss: 0.4120132831426767, val_loss: 0.3896169364452362\n",
      "9944, train_loss: 0.4099496746292481, val_loss: 0.40898343324661257\n",
      "9945, train_loss: 0.4104762249268018, val_loss: 0.4087858617305756\n",
      "9946, train_loss: 0.41526959377985734, val_loss: 0.3957884877920151\n",
      "9947, train_loss: 0.4105743565238439, val_loss: 0.4139587700366974\n",
      "9948, train_loss: 0.4135681608548531, val_loss: 0.39905468821525575\n",
      "9949, train_loss: 0.41011449236136216, val_loss: 0.4218152523040771\n",
      "9950, train_loss: 0.4085158705711365, val_loss: 0.4073653519153595\n",
      "9951, train_loss: 0.4135281844780995, val_loss: 0.40740959644317626\n",
      "9952, train_loss: 0.4115198352015935, val_loss: 0.4217467248439789\n",
      "9953, train_loss: 0.4104995343547601, val_loss: 0.42866974472999575\n",
      "9954, train_loss: 0.41514826852541703, val_loss: 0.41517152786254885\n",
      "9955, train_loss: 0.415114184984794, val_loss: 0.3866205632686615\n",
      "9956, train_loss: 0.41223062918736386, val_loss: 0.41372803449630735\n",
      "9957, train_loss: 0.41507243651610154, val_loss: 0.41520737409591674\n",
      "9958, train_loss: 0.4133586860620059, val_loss: 0.4138869345188141\n",
      "9959, train_loss: 0.41498399010071385, val_loss: 0.3868320226669312\n",
      "9960, train_loss: 0.4113432994255653, val_loss: 0.38793296217918394\n",
      "9961, train_loss: 0.41311974594226253, val_loss: 0.41505072116851804\n",
      "9962, train_loss: 0.4113451614975929, val_loss: 0.42148385047912595\n",
      "9963, train_loss: 0.4113791355719933, val_loss: 0.3902416110038757\n",
      "9964, train_loss: 0.40824858672343767, val_loss: 0.4006413102149963\n",
      "9965, train_loss: 0.414932386806378, val_loss: 0.40351076126098634\n",
      "9966, train_loss: 0.40900041736089265, val_loss: 0.4161076545715332\n",
      "9967, train_loss: 0.41242654335040313, val_loss: 0.4115210771560669\n",
      "9968, train_loss: 0.41117840776076686, val_loss: 0.4160241842269897\n",
      "9969, train_loss: 0.41354797035455704, val_loss: 0.38780525922775266\n",
      "9970, train_loss: 0.41130749995891863, val_loss: 0.3947718977928162\n",
      "9971, train_loss: 0.41274043172597885, val_loss: 0.4106435477733612\n",
      "9972, train_loss: 0.41258378670765805, val_loss: 0.39118468165397646\n",
      "9973, train_loss: 0.41180727229668546, val_loss: 0.4151055634021759\n",
      "9974, train_loss: 0.4111546535904591, val_loss: 0.41478240489959717\n",
      "9975, train_loss: 0.4124310612678528, val_loss: 0.40796753466129304\n",
      "9976, train_loss: 0.41395124105306774, val_loss: 0.3918523609638214\n",
      "9977, train_loss: 0.41459812281223446, val_loss: 0.42604159116744994\n",
      "9978, train_loss: 0.41457160447652525, val_loss: 0.3974389612674713\n",
      "9979, train_loss: 0.41450299322605133, val_loss: 0.39394218325614927\n",
      "9980, train_loss: 0.4122684976229301, val_loss: 0.4034299075603485\n",
      "9981, train_loss: 0.4092865139245987, val_loss: 0.3907168507575989\n",
      "9982, train_loss: 0.41145208248725307, val_loss: 0.402628231048584\n",
      "9983, train_loss: 0.41443365009931415, val_loss: 0.4147114157676697\n",
      "9984, train_loss: 0.4115446244294827, val_loss: 0.40130491852760314\n",
      "9985, train_loss: 0.41064572162353075, val_loss: 0.4079301357269287\n",
      "9986, train_loss: 0.41117165753474605, val_loss: 0.403545555472374\n",
      "9987, train_loss: 0.41366848005698276, val_loss: 0.40718536376953124\n",
      "9988, train_loss: 0.4142876874942046, val_loss: 0.3952318668365479\n",
      "9989, train_loss: 0.410876697072616, val_loss: 0.3905539572238922\n",
      "9990, train_loss: 0.4129005383986693, val_loss: 0.3982777178287506\n",
      "9991, train_loss: 0.4142262047299972, val_loss: 0.4113553524017334\n",
      "9992, train_loss: 0.4113141011733275, val_loss: 0.3958641588687897\n",
      "9993, train_loss: 0.40829846950677723, val_loss: 0.39688408374786377\n",
      "9994, train_loss: 0.411268406189405, val_loss: 0.39866565465927123\n",
      "9995, train_loss: 0.41410670945277583, val_loss: 0.42862078845500945\n",
      "9996, train_loss: 0.41409495358283704, val_loss: 0.38584038615226746\n",
      "9997, train_loss: 0.4140753705914204, val_loss: 0.3919405698776245\n",
      "9998, train_loss: 0.41185953181523544, val_loss: 0.3931552469730377\n",
      "9999, train_loss: 0.4116260277537199, val_loss: 0.41182509660720823\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    for x, y in validation_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        val_loss += loss.item()\n",
    "    \n",
    "    print(f'{epoch}, train_loss: {train_loss/len(train_dataloader)}, val_loss: {val_loss/len(validation_dataloader)}')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "47fde8eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ../models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\n\u001b[0;32m      2\u001b[0m     model,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:618\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    615\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    619\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[0;32m    620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:492\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    491\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:463\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory ../models does not exist."
     ]
    }
   ],
   "source": [
    "torch.save(\n",
    "    model,\n",
    "    \"../models/model.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7880aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    \"../models/model_state_dict.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd5029",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = torch.load(\"../models/model.pt\", map_location=device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b20ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    체크 포인트는 저장은 학습 중 오류 발생등으로 학습이 종료되었을 때, 학습을 처음부터 다시 시작하는 것이 아닌\n",
    "    저장된 체크 포인트도 학습을 시작하기 위해서 저장함\n",
    "\"\"\"\n",
    "#torch.save(\n",
    "#             {\n",
    "#                 \"model\": \"CustomModel\",\n",
    "#                 \"epoch\": epoch,\n",
    "#                 \"model_state_dict\": model.state_dict(),\n",
    "#                 \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "#                 \"cost\": cost,\n",
    "#                 \"description\": f\"CustomModel 체크포인트-{checkpoint}\",\n",
    "#             },\n",
    "#             f\"../models/checkpoint-{checkpoint}.pt\",\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db936eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# checkpoint = torch.load(\"../models/checkpoint-6.pt\")\n",
    "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "# optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "# checkpoint_epoch = checkpoint[\"epoch\"]\n",
    "# checkpoint_description = checkpoint[\"description\"]\n",
    "# print(checkpoint_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f5261ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(100.)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "정확도 측정\n",
    "\"\"\"\n",
    "label_list = []\n",
    "predictions_list = []\n",
    "total = 0\n",
    "correct = 0\n",
    "for x, y in test_dataloader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    output = model(x)\n",
    "    predictions = torch.max(output, 1)[1]\n",
    "    predictions_list.append(predictions)\n",
    "    correct += (predictions==y).sum()\n",
    "    total +=len(y)\n",
    "print(correct * 100 / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183614d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78038f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
